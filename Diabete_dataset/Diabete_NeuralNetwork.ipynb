{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1757fa7e",
   "metadata": {},
   "source": [
    "# Imports and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f836f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "diabete = load_diabetes(return_X_y=False,as_frame=True,scaled=True).frame\n",
    "X , y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f448278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    1.000000\n",
       "bmi       0.586450\n",
       "s5        0.565883\n",
       "bp        0.441482\n",
       "s4        0.430453\n",
       "s6        0.382483\n",
       "s1        0.212022\n",
       "age       0.187889\n",
       "s2        0.174054\n",
       "sex       0.043062\n",
       "s3       -0.394789\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = diabete.corr()\n",
    "corr_matrix['target'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e98d25df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4361e427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'age'}>, <Axes: title={'center': 'sex'}>,\n",
       "        <Axes: title={'center': 'bmi'}>],\n",
       "       [<Axes: title={'center': 'bp'}>, <Axes: title={'center': 's1'}>,\n",
       "        <Axes: title={'center': 's2'}>],\n",
       "       [<Axes: title={'center': 's3'}>, <Axes: title={'center': 's4'}>,\n",
       "        <Axes: title={'center': 's5'}>],\n",
       "       [<Axes: title={'center': 's6'}>,\n",
       "        <Axes: title={'center': 'target'}>, <Axes: >]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabete.hist(bins=50, figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67212a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([353]), torch.Size([353, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "y_test_tensor = torch.Tensor(y_test)\n",
    "\n",
    "y_train_tensor = y_train_tensor.view(-1, 1)\n",
    "y_test_tensor = y_test_tensor.view(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_tensor[:,0].size(),y_train_tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4206a97d",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9598e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(10,1,\n",
    "                                                requires_grad=True,\n",
    "                                                dtype=torch.float32))\n",
    "        self.bias = nn.Parameter(torch.randn(1,\n",
    "                                             requires_grad=True,\n",
    "                                             dtype=torch.float32))\n",
    "        \n",
    "    def forward(self,x:torch.Tensor) -> torch.Tensor:\n",
    "        return torch.matmul(x,self.weights)+ self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6913ff30",
   "metadata": {},
   "source": [
    "## Raw model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e43b01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights',\n",
       "              tensor([[ 0.3367],\n",
       "                      [ 0.1288],\n",
       "                      [ 0.2345],\n",
       "                      [ 0.2303],\n",
       "                      [-1.1229],\n",
       "                      [-0.1863],\n",
       "                      [ 2.2082],\n",
       "                      [-0.6380],\n",
       "                      [ 0.4617],\n",
       "                      [ 0.2674]])),\n",
       "             ('bias', tensor([0.5349]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "linear_model = LinearRegressionModel()\n",
    "\n",
    "linear_model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ac14e",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6969faaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([353, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# optimizer \n",
    "optimizer = torch.optim.SGD(params=linear_model.parameters(), lr=0.5)\n",
    "\n",
    "y_pred = linear_model(X_train_tensor)\n",
    "y_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c05c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | MAE Train Loss: 153.20103454589844 | MAE Test Loss: 144.7427978515625 \n",
      "Epoch: 10 | MAE Train Loss: 148.2009735107422 | MAE Test Loss: 139.74307250976562 \n",
      "Epoch: 20 | MAE Train Loss: 143.20089721679688 | MAE Test Loss: 134.74334716796875 \n",
      "Epoch: 30 | MAE Train Loss: 138.20083618164062 | MAE Test Loss: 129.7436065673828 \n",
      "Epoch: 40 | MAE Train Loss: 133.20077514648438 | MAE Test Loss: 124.7438735961914 \n",
      "Epoch: 50 | MAE Train Loss: 128.20689392089844 | MAE Test Loss: 119.74982452392578 \n",
      "Epoch: 60 | MAE Train Loss: 123.26332092285156 | MAE Test Loss: 114.77842712402344 \n",
      "Epoch: 70 | MAE Train Loss: 118.37033081054688 | MAE Test Loss: 109.83538818359375 \n",
      "Epoch: 80 | MAE Train Loss: 113.52085876464844 | MAE Test Loss: 105.00871276855469 \n",
      "Epoch: 90 | MAE Train Loss: 108.90849304199219 | MAE Test Loss: 100.40494537353516 \n",
      "Epoch: 100 | MAE Train Loss: 104.56873321533203 | MAE Test Loss: 96.07785034179688 \n",
      "Epoch: 110 | MAE Train Loss: 100.6949462890625 | MAE Test Loss: 92.21588897705078 \n",
      "Epoch: 120 | MAE Train Loss: 97.27164459228516 | MAE Test Loss: 88.64726257324219 \n",
      "Epoch: 130 | MAE Train Loss: 94.18223571777344 | MAE Test Loss: 85.36318969726562 \n",
      "Epoch: 140 | MAE Train Loss: 91.35795593261719 | MAE Test Loss: 82.50891876220703 \n",
      "Epoch: 150 | MAE Train Loss: 88.86003112792969 | MAE Test Loss: 79.98527526855469 \n",
      "Epoch: 160 | MAE Train Loss: 86.6537857055664 | MAE Test Loss: 77.88491821289062 \n",
      "Epoch: 170 | MAE Train Loss: 84.72103881835938 | MAE Test Loss: 76.0377197265625 \n",
      "Epoch: 180 | MAE Train Loss: 82.96050262451172 | MAE Test Loss: 74.3285140991211 \n",
      "Epoch: 190 | MAE Train Loss: 81.36912536621094 | MAE Test Loss: 72.71609497070312 \n",
      "Epoch: 200 | MAE Train Loss: 79.89582824707031 | MAE Test Loss: 71.2020492553711 \n",
      "Epoch: 210 | MAE Train Loss: 78.62264251708984 | MAE Test Loss: 69.88691711425781 \n",
      "Epoch: 220 | MAE Train Loss: 77.47975158691406 | MAE Test Loss: 68.69668579101562 \n",
      "Epoch: 230 | MAE Train Loss: 76.46521759033203 | MAE Test Loss: 67.75843048095703 \n",
      "Epoch: 240 | MAE Train Loss: 75.5747299194336 | MAE Test Loss: 66.93073272705078 \n",
      "Epoch: 250 | MAE Train Loss: 74.75359344482422 | MAE Test Loss: 66.238525390625 \n",
      "Epoch: 260 | MAE Train Loss: 74.00785827636719 | MAE Test Loss: 65.68843078613281 \n",
      "Epoch: 270 | MAE Train Loss: 73.3378677368164 | MAE Test Loss: 65.21434783935547 \n",
      "Epoch: 280 | MAE Train Loss: 72.69825744628906 | MAE Test Loss: 64.79850006103516 \n",
      "Epoch: 290 | MAE Train Loss: 72.12447357177734 | MAE Test Loss: 64.4603500366211 \n",
      "Epoch: 300 | MAE Train Loss: 71.61788177490234 | MAE Test Loss: 64.15200805664062 \n",
      "Epoch: 310 | MAE Train Loss: 71.1647720336914 | MAE Test Loss: 63.858123779296875 \n",
      "Epoch: 320 | MAE Train Loss: 70.71861267089844 | MAE Test Loss: 63.58268356323242 \n",
      "Epoch: 330 | MAE Train Loss: 70.28742980957031 | MAE Test Loss: 63.356231689453125 \n",
      "Epoch: 340 | MAE Train Loss: 69.91847229003906 | MAE Test Loss: 63.16484069824219 \n",
      "Epoch: 350 | MAE Train Loss: 69.5743637084961 | MAE Test Loss: 63.013572692871094 \n",
      "Epoch: 360 | MAE Train Loss: 69.24600219726562 | MAE Test Loss: 62.8763542175293 \n",
      "Epoch: 370 | MAE Train Loss: 68.94053649902344 | MAE Test Loss: 62.76040267944336 \n",
      "Epoch: 380 | MAE Train Loss: 68.6515121459961 | MAE Test Loss: 62.657535552978516 \n",
      "Epoch: 390 | MAE Train Loss: 68.39312744140625 | MAE Test Loss: 62.55990982055664 \n",
      "Epoch: 400 | MAE Train Loss: 68.15170288085938 | MAE Test Loss: 62.465091705322266 \n",
      "Epoch: 410 | MAE Train Loss: 67.92086791992188 | MAE Test Loss: 62.389671325683594 \n",
      "Epoch: 420 | MAE Train Loss: 67.707275390625 | MAE Test Loss: 62.322715759277344 \n",
      "Epoch: 430 | MAE Train Loss: 67.50629425048828 | MAE Test Loss: 62.25764846801758 \n",
      "Epoch: 440 | MAE Train Loss: 67.31854248046875 | MAE Test Loss: 62.194610595703125 \n",
      "Epoch: 450 | MAE Train Loss: 67.14629364013672 | MAE Test Loss: 62.153934478759766 \n",
      "Epoch: 460 | MAE Train Loss: 66.98558044433594 | MAE Test Loss: 62.11506271362305 \n",
      "Epoch: 470 | MAE Train Loss: 66.83035278320312 | MAE Test Loss: 62.07680892944336 \n",
      "Epoch: 480 | MAE Train Loss: 66.68838500976562 | MAE Test Loss: 62.039939880371094 \n",
      "Epoch: 490 | MAE Train Loss: 66.5473403930664 | MAE Test Loss: 62.00307846069336 \n",
      "Epoch: 500 | MAE Train Loss: 66.41737365722656 | MAE Test Loss: 61.96751022338867 \n",
      "Epoch: 510 | MAE Train Loss: 66.2979965209961 | MAE Test Loss: 61.93305969238281 \n",
      "Epoch: 520 | MAE Train Loss: 66.19522094726562 | MAE Test Loss: 61.90073013305664 \n",
      "Epoch: 530 | MAE Train Loss: 66.10541534423828 | MAE Test Loss: 61.8700065612793 \n",
      "Epoch: 540 | MAE Train Loss: 66.02485656738281 | MAE Test Loss: 61.84518051147461 \n",
      "Epoch: 550 | MAE Train Loss: 65.94670867919922 | MAE Test Loss: 61.83812713623047 \n",
      "Epoch: 560 | MAE Train Loss: 65.87749481201172 | MAE Test Loss: 61.833709716796875 \n",
      "Epoch: 570 | MAE Train Loss: 65.81773376464844 | MAE Test Loss: 61.8289794921875 \n",
      "Epoch: 580 | MAE Train Loss: 65.76496887207031 | MAE Test Loss: 61.82395553588867 \n",
      "Epoch: 590 | MAE Train Loss: 65.71630096435547 | MAE Test Loss: 61.81880187988281 \n",
      "Epoch: 600 | MAE Train Loss: 65.67200469970703 | MAE Test Loss: 61.81322479248047 \n",
      "Epoch: 610 | MAE Train Loss: 65.63111877441406 | MAE Test Loss: 61.807395935058594 \n",
      "Epoch: 620 | MAE Train Loss: 65.59154510498047 | MAE Test Loss: 61.80149459838867 \n",
      "Epoch: 630 | MAE Train Loss: 65.55196380615234 | MAE Test Loss: 61.795589447021484 \n",
      "Epoch: 640 | MAE Train Loss: 65.51238250732422 | MAE Test Loss: 61.789703369140625 \n",
      "Epoch: 650 | MAE Train Loss: 65.47280883789062 | MAE Test Loss: 61.7838020324707 \n",
      "Epoch: 660 | MAE Train Loss: 65.43701171875 | MAE Test Loss: 61.777530670166016 \n",
      "Epoch: 670 | MAE Train Loss: 65.40156555175781 | MAE Test Loss: 61.771270751953125 \n",
      "Epoch: 680 | MAE Train Loss: 65.36611938476562 | MAE Test Loss: 61.765010833740234 \n",
      "Epoch: 690 | MAE Train Loss: 65.3306655883789 | MAE Test Loss: 61.75874328613281 \n",
      "Epoch: 700 | MAE Train Loss: 65.2978744506836 | MAE Test Loss: 61.75541687011719 \n",
      "Epoch: 710 | MAE Train Loss: 65.26686096191406 | MAE Test Loss: 61.755470275878906 \n",
      "Epoch: 720 | MAE Train Loss: 65.24054718017578 | MAE Test Loss: 61.75416564941406 \n",
      "Epoch: 730 | MAE Train Loss: 65.21542358398438 | MAE Test Loss: 61.75261688232422 \n",
      "Epoch: 740 | MAE Train Loss: 65.1906967163086 | MAE Test Loss: 61.750911712646484 \n",
      "Epoch: 750 | MAE Train Loss: 65.1687240600586 | MAE Test Loss: 61.752925872802734 \n",
      "Epoch: 760 | MAE Train Loss: 65.14675903320312 | MAE Test Loss: 61.75559616088867 \n",
      "Epoch: 770 | MAE Train Loss: 65.12716674804688 | MAE Test Loss: 61.75702667236328 \n",
      "Epoch: 780 | MAE Train Loss: 65.10807800292969 | MAE Test Loss: 61.7583122253418 \n",
      "Epoch: 790 | MAE Train Loss: 65.0889892578125 | MAE Test Loss: 61.75959014892578 \n",
      "Epoch: 800 | MAE Train Loss: 65.06990051269531 | MAE Test Loss: 61.76087951660156 \n",
      "Epoch: 810 | MAE Train Loss: 65.0508041381836 | MAE Test Loss: 61.76216125488281 \n",
      "Epoch: 820 | MAE Train Loss: 65.0320053100586 | MAE Test Loss: 61.76313781738281 \n",
      "Epoch: 830 | MAE Train Loss: 65.01521301269531 | MAE Test Loss: 61.76290512084961 \n",
      "Epoch: 840 | MAE Train Loss: 64.99842071533203 | MAE Test Loss: 61.76266098022461 \n",
      "Epoch: 850 | MAE Train Loss: 64.98162841796875 | MAE Test Loss: 61.762420654296875 \n",
      "Epoch: 860 | MAE Train Loss: 64.96489715576172 | MAE Test Loss: 61.76199722290039 \n",
      "Epoch: 870 | MAE Train Loss: 64.94966888427734 | MAE Test Loss: 61.761138916015625 \n",
      "Epoch: 880 | MAE Train Loss: 64.93444061279297 | MAE Test Loss: 61.76276779174805 \n",
      "Epoch: 890 | MAE Train Loss: 64.91981506347656 | MAE Test Loss: 61.76322937011719 \n",
      "Epoch: 900 | MAE Train Loss: 64.90592956542969 | MAE Test Loss: 61.762508392333984 \n",
      "Epoch: 910 | MAE Train Loss: 64.89204406738281 | MAE Test Loss: 61.76179504394531 \n",
      "Epoch: 920 | MAE Train Loss: 64.8781509399414 | MAE Test Loss: 61.761070251464844 \n",
      "Epoch: 930 | MAE Train Loss: 64.8642578125 | MAE Test Loss: 61.760353088378906 \n",
      "Epoch: 940 | MAE Train Loss: 64.8503646850586 | MAE Test Loss: 61.7596321105957 \n",
      "Epoch: 950 | MAE Train Loss: 64.83677673339844 | MAE Test Loss: 61.75827407836914 \n",
      "Epoch: 960 | MAE Train Loss: 64.82488250732422 | MAE Test Loss: 61.753814697265625 \n",
      "Epoch: 970 | MAE Train Loss: 64.8133544921875 | MAE Test Loss: 61.74870681762695 \n",
      "Epoch: 980 | MAE Train Loss: 64.80181884765625 | MAE Test Loss: 61.743587493896484 \n",
      "Epoch: 990 | MAE Train Loss: 64.790283203125 | MAE Test Loss: 61.738468170166016 \n",
      "Epoch: 1000 | MAE Train Loss: 64.77875518798828 | MAE Test Loss: 61.73334884643555 \n",
      "Epoch: 1010 | MAE Train Loss: 64.76721954345703 | MAE Test Loss: 61.72823715209961 \n",
      "Epoch: 1020 | MAE Train Loss: 64.7562484741211 | MAE Test Loss: 61.72142791748047 \n",
      "Epoch: 1030 | MAE Train Loss: 64.74568176269531 | MAE Test Loss: 61.71311569213867 \n",
      "Epoch: 1040 | MAE Train Loss: 64.73536682128906 | MAE Test Loss: 61.7037353515625 \n",
      "Epoch: 1050 | MAE Train Loss: 64.72504425048828 | MAE Test Loss: 61.694339752197266 \n",
      "Epoch: 1060 | MAE Train Loss: 64.71472930908203 | MAE Test Loss: 61.68495559692383 \n",
      "Epoch: 1070 | MAE Train Loss: 64.70441436767578 | MAE Test Loss: 61.675559997558594 \n",
      "Epoch: 1080 | MAE Train Loss: 64.694091796875 | MAE Test Loss: 61.66617965698242 \n",
      "Epoch: 1090 | MAE Train Loss: 64.68377685546875 | MAE Test Loss: 61.65679168701172 \n",
      "Epoch: 1100 | MAE Train Loss: 64.67345428466797 | MAE Test Loss: 61.64739990234375 \n",
      "Epoch: 1110 | MAE Train Loss: 64.66313934326172 | MAE Test Loss: 61.63801956176758 \n",
      "Epoch: 1120 | MAE Train Loss: 64.65281677246094 | MAE Test Loss: 61.62862777709961 \n",
      "Epoch: 1130 | MAE Train Loss: 64.64250946044922 | MAE Test Loss: 61.619239807128906 \n",
      "Epoch: 1140 | MAE Train Loss: 64.6321792602539 | MAE Test Loss: 61.6098518371582 \n",
      "Epoch: 1150 | MAE Train Loss: 64.62186431884766 | MAE Test Loss: 61.6004638671875 \n",
      "Epoch: 1160 | MAE Train Loss: 64.6115493774414 | MAE Test Loss: 61.59107971191406 \n",
      "Epoch: 1170 | MAE Train Loss: 64.60122680664062 | MAE Test Loss: 61.58168411254883 \n",
      "Epoch: 1180 | MAE Train Loss: 64.59090423583984 | MAE Test Loss: 61.57229995727539 \n",
      "Epoch: 1190 | MAE Train Loss: 64.5805892944336 | MAE Test Loss: 61.56291198730469 \n",
      "Epoch: 1200 | MAE Train Loss: 64.57027435302734 | MAE Test Loss: 61.55353546142578 \n",
      "Epoch: 1210 | MAE Train Loss: 64.55995178222656 | MAE Test Loss: 61.54413604736328 \n",
      "Epoch: 1220 | MAE Train Loss: 64.54964447021484 | MAE Test Loss: 61.534751892089844 \n",
      "Epoch: 1230 | MAE Train Loss: 64.53932189941406 | MAE Test Loss: 61.52535629272461 \n",
      "Epoch: 1240 | MAE Train Loss: 64.52900695800781 | MAE Test Loss: 61.51597213745117 \n",
      "Epoch: 1250 | MAE Train Loss: 64.51868438720703 | MAE Test Loss: 61.50658416748047 \n",
      "Epoch: 1260 | MAE Train Loss: 64.50836944580078 | MAE Test Loss: 61.497196197509766 \n",
      "Epoch: 1270 | MAE Train Loss: 64.498046875 | MAE Test Loss: 61.487815856933594 \n",
      "Epoch: 1280 | MAE Train Loss: 64.48772430419922 | MAE Test Loss: 61.478416442871094 \n",
      "Epoch: 1290 | MAE Train Loss: 64.47743225097656 | MAE Test Loss: 61.468353271484375 \n",
      "Epoch: 1300 | MAE Train Loss: 64.46713256835938 | MAE Test Loss: 61.458274841308594 \n",
      "Epoch: 1310 | MAE Train Loss: 64.45683288574219 | MAE Test Loss: 61.44797897338867 \n",
      "Epoch: 1320 | MAE Train Loss: 64.446533203125 | MAE Test Loss: 61.437904357910156 \n",
      "Epoch: 1330 | MAE Train Loss: 64.43624114990234 | MAE Test Loss: 61.427608489990234 \n",
      "Epoch: 1340 | MAE Train Loss: 64.42593383789062 | MAE Test Loss: 61.41730880737305 \n",
      "Epoch: 1350 | MAE Train Loss: 64.41564178466797 | MAE Test Loss: 61.4072380065918 \n",
      "Epoch: 1360 | MAE Train Loss: 64.40534210205078 | MAE Test Loss: 61.39694595336914 \n",
      "Epoch: 1370 | MAE Train Loss: 64.39505004882812 | MAE Test Loss: 61.38686752319336 \n",
      "Epoch: 1380 | MAE Train Loss: 64.38475036621094 | MAE Test Loss: 61.37656784057617 \n",
      "Epoch: 1390 | MAE Train Loss: 64.37446594238281 | MAE Test Loss: 61.36638259887695 \n",
      "Epoch: 1400 | MAE Train Loss: 64.3641586303711 | MAE Test Loss: 61.3563117980957 \n",
      "Epoch: 1410 | MAE Train Loss: 64.3538589477539 | MAE Test Loss: 61.346012115478516 \n",
      "Epoch: 1420 | MAE Train Loss: 64.34355926513672 | MAE Test Loss: 61.33571243286133 \n",
      "Epoch: 1430 | MAE Train Loss: 64.33326721191406 | MAE Test Loss: 61.32563781738281 \n",
      "Epoch: 1440 | MAE Train Loss: 64.32296752929688 | MAE Test Loss: 61.31534194946289 \n",
      "Epoch: 1450 | MAE Train Loss: 64.31271362304688 | MAE Test Loss: 61.304866790771484 \n",
      "Epoch: 1460 | MAE Train Loss: 64.30261993408203 | MAE Test Loss: 61.29338455200195 \n",
      "Epoch: 1470 | MAE Train Loss: 64.2925033569336 | MAE Test Loss: 61.28190231323242 \n",
      "Epoch: 1480 | MAE Train Loss: 64.28240203857422 | MAE Test Loss: 61.27042007446289 \n",
      "Epoch: 1490 | MAE Train Loss: 64.27229309082031 | MAE Test Loss: 61.258941650390625 \n",
      "Epoch: 1500 | MAE Train Loss: 64.26219177246094 | MAE Test Loss: 61.24745559692383 \n",
      "Epoch: 1510 | MAE Train Loss: 64.25228881835938 | MAE Test Loss: 61.2376823425293 \n",
      "Epoch: 1520 | MAE Train Loss: 64.24253845214844 | MAE Test Loss: 61.228641510009766 \n",
      "Epoch: 1530 | MAE Train Loss: 64.23278045654297 | MAE Test Loss: 61.21961212158203 \n",
      "Epoch: 1540 | MAE Train Loss: 64.22303009033203 | MAE Test Loss: 61.210575103759766 \n",
      "Epoch: 1550 | MAE Train Loss: 64.21334075927734 | MAE Test Loss: 61.200218200683594 \n",
      "Epoch: 1560 | MAE Train Loss: 64.20368957519531 | MAE Test Loss: 61.189430236816406 \n",
      "Epoch: 1570 | MAE Train Loss: 64.19404602050781 | MAE Test Loss: 61.17863845825195 \n",
      "Epoch: 1580 | MAE Train Loss: 64.18440246582031 | MAE Test Loss: 61.16773986816406 \n",
      "Epoch: 1590 | MAE Train Loss: 64.17474365234375 | MAE Test Loss: 61.15694808959961 \n",
      "Epoch: 1600 | MAE Train Loss: 64.16510009765625 | MAE Test Loss: 61.146156311035156 \n",
      "Epoch: 1610 | MAE Train Loss: 64.15555572509766 | MAE Test Loss: 61.13609313964844 \n",
      "Epoch: 1620 | MAE Train Loss: 64.1461410522461 | MAE Test Loss: 61.12720489501953 \n",
      "Epoch: 1630 | MAE Train Loss: 64.13674926757812 | MAE Test Loss: 61.11832809448242 \n",
      "Epoch: 1640 | MAE Train Loss: 64.12734985351562 | MAE Test Loss: 61.10945129394531 \n",
      "Epoch: 1650 | MAE Train Loss: 64.1179428100586 | MAE Test Loss: 61.100563049316406 \n",
      "Epoch: 1660 | MAE Train Loss: 64.1085433959961 | MAE Test Loss: 61.09169387817383 \n",
      "Epoch: 1670 | MAE Train Loss: 64.09915161132812 | MAE Test Loss: 61.08280944824219 \n",
      "Epoch: 1680 | MAE Train Loss: 64.08972930908203 | MAE Test Loss: 61.07392883300781 \n",
      "Epoch: 1690 | MAE Train Loss: 64.08033752441406 | MAE Test Loss: 61.0650520324707 \n",
      "Epoch: 1700 | MAE Train Loss: 64.07093048095703 | MAE Test Loss: 61.056175231933594 \n",
      "Epoch: 1710 | MAE Train Loss: 64.06153869628906 | MAE Test Loss: 61.04729080200195 \n",
      "Epoch: 1720 | MAE Train Loss: 64.05213928222656 | MAE Test Loss: 61.038421630859375 \n",
      "Epoch: 1730 | MAE Train Loss: 64.04273986816406 | MAE Test Loss: 61.029537200927734 \n",
      "Epoch: 1740 | MAE Train Loss: 64.03333282470703 | MAE Test Loss: 61.02064895629883 \n",
      "Epoch: 1750 | MAE Train Loss: 64.02394104003906 | MAE Test Loss: 61.01155471801758 \n",
      "Epoch: 1760 | MAE Train Loss: 64.01456451416016 | MAE Test Loss: 61.00175476074219 \n",
      "Epoch: 1770 | MAE Train Loss: 64.00518035888672 | MAE Test Loss: 60.9921989440918 \n",
      "Epoch: 1780 | MAE Train Loss: 63.99580764770508 | MAE Test Loss: 60.982398986816406 \n",
      "Epoch: 1790 | MAE Train Loss: 63.98641586303711 | MAE Test Loss: 60.972843170166016 \n",
      "Epoch: 1800 | MAE Train Loss: 63.9770393371582 | MAE Test Loss: 60.96305465698242 \n",
      "Epoch: 1810 | MAE Train Loss: 63.96765899658203 | MAE Test Loss: 60.95349884033203 \n",
      "Epoch: 1820 | MAE Train Loss: 63.958274841308594 | MAE Test Loss: 60.94369888305664 \n",
      "Epoch: 1830 | MAE Train Loss: 63.94888687133789 | MAE Test Loss: 60.93413543701172 \n",
      "Epoch: 1840 | MAE Train Loss: 63.93950271606445 | MAE Test Loss: 60.92435073852539 \n",
      "Epoch: 1850 | MAE Train Loss: 63.93012619018555 | MAE Test Loss: 60.914791107177734 \n",
      "Epoch: 1860 | MAE Train Loss: 63.920745849609375 | MAE Test Loss: 60.90499496459961 \n",
      "Epoch: 1870 | MAE Train Loss: 63.91136932373047 | MAE Test Loss: 60.89543533325195 \n",
      "Epoch: 1880 | MAE Train Loss: 63.90198516845703 | MAE Test Loss: 60.885643005371094 \n",
      "Epoch: 1890 | MAE Train Loss: 63.89260482788086 | MAE Test Loss: 60.876075744628906 \n",
      "Epoch: 1900 | MAE Train Loss: 63.88323211669922 | MAE Test Loss: 60.86628723144531 \n",
      "Epoch: 1910 | MAE Train Loss: 63.873836517333984 | MAE Test Loss: 60.85660934448242 \n",
      "Epoch: 1920 | MAE Train Loss: 63.864463806152344 | MAE Test Loss: 60.84693145751953 \n",
      "Epoch: 1930 | MAE Train Loss: 63.855079650878906 | MAE Test Loss: 60.83725357055664 \n",
      "Epoch: 1940 | MAE Train Loss: 63.845703125 | MAE Test Loss: 60.82769775390625 \n",
      "Epoch: 1950 | MAE Train Loss: 63.836326599121094 | MAE Test Loss: 60.81791687011719 \n",
      "Epoch: 1960 | MAE Train Loss: 63.826934814453125 | MAE Test Loss: 60.80834197998047 \n",
      "Epoch: 1970 | MAE Train Loss: 63.81755828857422 | MAE Test Loss: 60.798553466796875 \n",
      "Epoch: 1980 | MAE Train Loss: 63.80817794799805 | MAE Test Loss: 60.78899002075195 \n",
      "Epoch: 1990 | MAE Train Loss: 63.79879379272461 | MAE Test Loss: 60.779197692871094 \n",
      "Epoch: 2000 | MAE Train Loss: 63.78942108154297 | MAE Test Loss: 60.769630432128906 \n",
      "Epoch: 2010 | MAE Train Loss: 63.780033111572266 | MAE Test Loss: 60.75983810424805 \n",
      "Epoch: 2020 | MAE Train Loss: 63.77064895629883 | MAE Test Loss: 60.75028991699219 \n",
      "Epoch: 2030 | MAE Train Loss: 63.76126480102539 | MAE Test Loss: 60.74049377441406 \n",
      "Epoch: 2040 | MAE Train Loss: 63.751895904541016 | MAE Test Loss: 60.73093032836914 \n",
      "Epoch: 2050 | MAE Train Loss: 63.742515563964844 | MAE Test Loss: 60.72114181518555 \n",
      "Epoch: 2060 | MAE Train Loss: 63.73313522338867 | MAE Test Loss: 60.71157455444336 \n",
      "Epoch: 2070 | MAE Train Loss: 63.723751068115234 | MAE Test Loss: 60.701786041259766 \n",
      "Epoch: 2080 | MAE Train Loss: 63.7143669128418 | MAE Test Loss: 60.692222595214844 \n",
      "Epoch: 2090 | MAE Train Loss: 63.70498275756836 | MAE Test Loss: 60.682437896728516 \n",
      "Epoch: 2100 | MAE Train Loss: 63.69560623168945 | MAE Test Loss: 60.672874450683594 \n",
      "Epoch: 2110 | MAE Train Loss: 63.68622589111328 | MAE Test Loss: 60.663082122802734 \n",
      "Epoch: 2120 | MAE Train Loss: 63.676841735839844 | MAE Test Loss: 60.65351867675781 \n",
      "Epoch: 2130 | MAE Train Loss: 63.66746520996094 | MAE Test Loss: 60.64372634887695 \n",
      "Epoch: 2140 | MAE Train Loss: 63.658077239990234 | MAE Test Loss: 60.6341667175293 \n",
      "Epoch: 2150 | MAE Train Loss: 63.648704528808594 | MAE Test Loss: 60.62437438964844 \n",
      "Epoch: 2160 | MAE Train Loss: 63.639320373535156 | MAE Test Loss: 60.614810943603516 \n",
      "Epoch: 2170 | MAE Train Loss: 63.62993621826172 | MAE Test Loss: 60.605018615722656 \n",
      "Epoch: 2180 | MAE Train Loss: 63.62055587768555 | MAE Test Loss: 60.5953483581543 \n",
      "Epoch: 2190 | MAE Train Loss: 63.611183166503906 | MAE Test Loss: 60.58567428588867 \n",
      "Epoch: 2200 | MAE Train Loss: 63.6017951965332 | MAE Test Loss: 60.57599639892578 \n",
      "Epoch: 2210 | MAE Train Loss: 63.59241485595703 | MAE Test Loss: 60.566429138183594 \n",
      "Epoch: 2220 | MAE Train Loss: 63.58302688598633 | MAE Test Loss: 60.556640625 \n",
      "Epoch: 2230 | MAE Train Loss: 63.57365036010742 | MAE Test Loss: 60.54707336425781 \n",
      "Epoch: 2240 | MAE Train Loss: 63.56427764892578 | MAE Test Loss: 60.53728485107422 \n",
      "Epoch: 2250 | MAE Train Loss: 63.55489730834961 | MAE Test Loss: 60.5277214050293 \n",
      "Epoch: 2260 | MAE Train Loss: 63.54551315307617 | MAE Test Loss: 60.51792907714844 \n",
      "Epoch: 2270 | MAE Train Loss: 63.536128997802734 | MAE Test Loss: 60.50837326049805 \n",
      "Epoch: 2280 | MAE Train Loss: 63.5267448425293 | MAE Test Loss: 60.49858474731445 \n",
      "Epoch: 2290 | MAE Train Loss: 63.51736831665039 | MAE Test Loss: 60.48902130126953 \n",
      "Epoch: 2300 | MAE Train Loss: 63.50798416137695 | MAE Test Loss: 60.47922897338867 \n",
      "Epoch: 2310 | MAE Train Loss: 63.49860382080078 | MAE Test Loss: 60.469661712646484 \n",
      "Epoch: 2320 | MAE Train Loss: 63.48922348022461 | MAE Test Loss: 60.45987319946289 \n",
      "Epoch: 2330 | MAE Train Loss: 63.47984313964844 | MAE Test Loss: 60.45030975341797 \n",
      "Epoch: 2340 | MAE Train Loss: 63.470458984375 | MAE Test Loss: 60.44051742553711 \n",
      "Epoch: 2350 | MAE Train Loss: 63.461082458496094 | MAE Test Loss: 60.43095397949219 \n",
      "Epoch: 2360 | MAE Train Loss: 63.45170211791992 | MAE Test Loss: 60.421165466308594 \n",
      "Epoch: 2370 | MAE Train Loss: 63.44231414794922 | MAE Test Loss: 60.41160583496094 \n",
      "Epoch: 2380 | MAE Train Loss: 63.43294143676758 | MAE Test Loss: 60.401817321777344 \n",
      "Epoch: 2390 | MAE Train Loss: 63.42354965209961 | MAE Test Loss: 60.392250061035156 \n",
      "Epoch: 2400 | MAE Train Loss: 63.4141731262207 | MAE Test Loss: 60.38246154785156 \n",
      "Epoch: 2410 | MAE Train Loss: 63.4047966003418 | MAE Test Loss: 60.372894287109375 \n",
      "Epoch: 2420 | MAE Train Loss: 63.39541244506836 | MAE Test Loss: 60.36310577392578 \n",
      "Epoch: 2430 | MAE Train Loss: 63.38603973388672 | MAE Test Loss: 60.35354995727539 \n",
      "Epoch: 2440 | MAE Train Loss: 63.37664794921875 | MAE Test Loss: 60.3437614440918 \n",
      "Epoch: 2450 | MAE Train Loss: 63.36726379394531 | MAE Test Loss: 60.33418655395508 \n",
      "Epoch: 2460 | MAE Train Loss: 63.357887268066406 | MAE Test Loss: 60.32450866699219 \n",
      "Epoch: 2470 | MAE Train Loss: 63.348506927490234 | MAE Test Loss: 60.31483840942383 \n",
      "Epoch: 2480 | MAE Train Loss: 63.33913040161133 | MAE Test Loss: 60.305049896240234 \n",
      "Epoch: 2490 | MAE Train Loss: 63.329750061035156 | MAE Test Loss: 60.29548263549805 \n",
      "Epoch: 2500 | MAE Train Loss: 63.320369720458984 | MAE Test Loss: 60.28569030761719 \n",
      "Epoch: 2510 | MAE Train Loss: 63.310977935791016 | MAE Test Loss: 60.27613830566406 \n",
      "Epoch: 2520 | MAE Train Loss: 63.30159378051758 | MAE Test Loss: 60.26633834838867 \n",
      "Epoch: 2530 | MAE Train Loss: 63.29222106933594 | MAE Test Loss: 60.25678253173828 \n",
      "Epoch: 2540 | MAE Train Loss: 63.2828369140625 | MAE Test Loss: 60.246986389160156 \n",
      "Epoch: 2550 | MAE Train Loss: 63.27346420288086 | MAE Test Loss: 60.2374267578125 \n",
      "Epoch: 2560 | MAE Train Loss: 63.264076232910156 | MAE Test Loss: 60.227630615234375 \n",
      "Epoch: 2570 | MAE Train Loss: 63.25478744506836 | MAE Test Loss: 60.21857452392578 \n",
      "Epoch: 2580 | MAE Train Loss: 63.245689392089844 | MAE Test Loss: 60.2098503112793 \n",
      "Epoch: 2590 | MAE Train Loss: 63.23666000366211 | MAE Test Loss: 60.1998405456543 \n",
      "Epoch: 2600 | MAE Train Loss: 63.22768020629883 | MAE Test Loss: 60.189640045166016 \n",
      "Epoch: 2610 | MAE Train Loss: 63.21875 | MAE Test Loss: 60.180355072021484 \n",
      "Epoch: 2620 | MAE Train Loss: 63.20981979370117 | MAE Test Loss: 60.17085266113281 \n",
      "Epoch: 2630 | MAE Train Loss: 63.20087814331055 | MAE Test Loss: 60.16157531738281 \n",
      "Epoch: 2640 | MAE Train Loss: 63.19193649291992 | MAE Test Loss: 60.152076721191406 \n",
      "Epoch: 2650 | MAE Train Loss: 63.18300247192383 | MAE Test Loss: 60.1425666809082 \n",
      "Epoch: 2660 | MAE Train Loss: 63.174072265625 | MAE Test Loss: 60.1332893371582 \n",
      "Epoch: 2670 | MAE Train Loss: 63.16514205932617 | MAE Test Loss: 60.12378692626953 \n",
      "Epoch: 2680 | MAE Train Loss: 63.15620040893555 | MAE Test Loss: 60.114280700683594 \n",
      "Epoch: 2690 | MAE Train Loss: 63.14726638793945 | MAE Test Loss: 60.10500717163086 \n",
      "Epoch: 2700 | MAE Train Loss: 63.138328552246094 | MAE Test Loss: 60.09549331665039 \n",
      "Epoch: 2710 | MAE Train Loss: 63.12939453125 | MAE Test Loss: 60.08622360229492 \n",
      "Epoch: 2720 | MAE Train Loss: 63.12046432495117 | MAE Test Loss: 60.07660675048828 \n",
      "Epoch: 2730 | MAE Train Loss: 63.111534118652344 | MAE Test Loss: 60.06732177734375 \n",
      "Epoch: 2740 | MAE Train Loss: 63.10259246826172 | MAE Test Loss: 60.05781936645508 \n",
      "Epoch: 2750 | MAE Train Loss: 63.09365463256836 | MAE Test Loss: 60.04854202270508 \n",
      "Epoch: 2760 | MAE Train Loss: 63.08472442626953 | MAE Test Loss: 60.03903579711914 \n",
      "Epoch: 2770 | MAE Train Loss: 63.07579040527344 | MAE Test Loss: 60.02964782714844 \n",
      "Epoch: 2780 | MAE Train Loss: 63.06684875488281 | MAE Test Loss: 60.0201416015625 \n",
      "Epoch: 2790 | MAE Train Loss: 63.05791473388672 | MAE Test Loss: 60.010868072509766 \n",
      "Epoch: 2800 | MAE Train Loss: 63.04898452758789 | MAE Test Loss: 60.00136184692383 \n",
      "Epoch: 2810 | MAE Train Loss: 63.040042877197266 | MAE Test Loss: 59.991851806640625 \n",
      "Epoch: 2820 | MAE Train Loss: 63.0311164855957 | MAE Test Loss: 59.98246765136719 \n",
      "Epoch: 2830 | MAE Train Loss: 63.02217483520508 | MAE Test Loss: 59.97319412231445 \n",
      "Epoch: 2840 | MAE Train Loss: 63.013240814208984 | MAE Test Loss: 59.96369171142578 \n",
      "Epoch: 2850 | MAE Train Loss: 63.004302978515625 | MAE Test Loss: 59.95417785644531 \n",
      "Epoch: 2860 | MAE Train Loss: 62.9953727722168 | MAE Test Loss: 59.94489669799805 \n",
      "Epoch: 2870 | MAE Train Loss: 62.986427307128906 | MAE Test Loss: 59.93551254272461 \n",
      "Epoch: 2880 | MAE Train Loss: 62.97749710083008 | MAE Test Loss: 59.92600631713867 \n",
      "Epoch: 2890 | MAE Train Loss: 62.968563079833984 | MAE Test Loss: 59.91650390625 \n",
      "Epoch: 2900 | MAE Train Loss: 62.95962142944336 | MAE Test Loss: 59.9072265625 \n",
      "Epoch: 2910 | MAE Train Loss: 62.95069122314453 | MAE Test Loss: 59.89772033691406 \n",
      "Epoch: 2920 | MAE Train Loss: 62.94175338745117 | MAE Test Loss: 59.88821792602539 \n",
      "Epoch: 2930 | MAE Train Loss: 62.932823181152344 | MAE Test Loss: 59.878944396972656 \n",
      "Epoch: 2940 | MAE Train Loss: 62.92388916015625 | MAE Test Loss: 59.86943054199219 \n",
      "Epoch: 2950 | MAE Train Loss: 62.914947509765625 | MAE Test Loss: 59.86015319824219 \n",
      "Epoch: 2960 | MAE Train Loss: 62.90601348876953 | MAE Test Loss: 59.850650787353516 \n",
      "Epoch: 2970 | MAE Train Loss: 62.89708709716797 | MAE Test Loss: 59.84113693237305 \n",
      "Epoch: 2980 | MAE Train Loss: 62.888145446777344 | MAE Test Loss: 59.831871032714844 \n",
      "Epoch: 2990 | MAE Train Loss: 62.879215240478516 | MAE Test Loss: 59.822364807128906 \n",
      "Epoch: 3000 | MAE Train Loss: 62.87028121948242 | MAE Test Loss: 59.812862396240234 \n",
      "Epoch: 3010 | MAE Train Loss: 62.86134338378906 | MAE Test Loss: 59.803585052490234 \n",
      "Epoch: 3020 | MAE Train Loss: 62.85240936279297 | MAE Test Loss: 59.7940788269043 \n",
      "Epoch: 3030 | MAE Train Loss: 62.84347152709961 | MAE Test Loss: 59.784793853759766 \n",
      "Epoch: 3040 | MAE Train Loss: 62.83454132080078 | MAE Test Loss: 59.775299072265625 \n",
      "Epoch: 3050 | MAE Train Loss: 62.82560729980469 | MAE Test Loss: 59.76578903198242 \n",
      "Epoch: 3060 | MAE Train Loss: 62.816673278808594 | MAE Test Loss: 59.75651931762695 \n",
      "Epoch: 3070 | MAE Train Loss: 62.80772399902344 | MAE Test Loss: 59.747005462646484 \n",
      "Epoch: 3080 | MAE Train Loss: 62.79880142211914 | MAE Test Loss: 59.73750305175781 \n",
      "Epoch: 3090 | MAE Train Loss: 62.78986358642578 | MAE Test Loss: 59.72822570800781 \n",
      "Epoch: 3100 | MAE Train Loss: 62.78092956542969 | MAE Test Loss: 59.71872329711914 \n",
      "Epoch: 3110 | MAE Train Loss: 62.77198791503906 | MAE Test Loss: 59.70933151245117 \n",
      "Epoch: 3120 | MAE Train Loss: 62.763057708740234 | MAE Test Loss: 59.6998291015625 \n",
      "Epoch: 3130 | MAE Train Loss: 62.75412368774414 | MAE Test Loss: 59.6905517578125 \n",
      "Epoch: 3140 | MAE Train Loss: 62.74518585205078 | MAE Test Loss: 59.6810417175293 \n",
      "Epoch: 3150 | MAE Train Loss: 62.73625183105469 | MAE Test Loss: 59.671539306640625 \n",
      "Epoch: 3160 | MAE Train Loss: 62.72732162475586 | MAE Test Loss: 59.662261962890625 \n",
      "Epoch: 3170 | MAE Train Loss: 62.7183837890625 | MAE Test Loss: 59.652870178222656 \n",
      "Epoch: 3180 | MAE Train Loss: 62.709449768066406 | MAE Test Loss: 59.643367767333984 \n",
      "Epoch: 3190 | MAE Train Loss: 62.70050811767578 | MAE Test Loss: 59.63386535644531 \n",
      "Epoch: 3200 | MAE Train Loss: 62.69157409667969 | MAE Test Loss: 59.62458419799805 \n",
      "Epoch: 3210 | MAE Train Loss: 62.682647705078125 | MAE Test Loss: 59.615081787109375 \n",
      "Epoch: 3220 | MAE Train Loss: 62.67371368408203 | MAE Test Loss: 59.605690002441406 \n",
      "Epoch: 3230 | MAE Train Loss: 62.664772033691406 | MAE Test Loss: 59.5961799621582 \n",
      "Epoch: 3240 | MAE Train Loss: 62.65584182739258 | MAE Test Loss: 59.586910247802734 \n",
      "Epoch: 3250 | MAE Train Loss: 62.64690399169922 | MAE Test Loss: 59.57740783691406 \n",
      "Epoch: 3260 | MAE Train Loss: 62.637969970703125 | MAE Test Loss: 59.56813049316406 \n",
      "Epoch: 3270 | MAE Train Loss: 62.629032135009766 | MAE Test Loss: 59.55850601196289 \n",
      "Epoch: 3280 | MAE Train Loss: 62.62009811401367 | MAE Test Loss: 59.549232482910156 \n",
      "Epoch: 3290 | MAE Train Loss: 62.61116027832031 | MAE Test Loss: 59.53972244262695 \n",
      "Epoch: 3300 | MAE Train Loss: 62.60222244262695 | MAE Test Loss: 59.53044509887695 \n",
      "Epoch: 3310 | MAE Train Loss: 62.593284606933594 | MAE Test Loss: 59.52094268798828 \n",
      "Epoch: 3320 | MAE Train Loss: 62.584354400634766 | MAE Test Loss: 59.51144027709961 \n",
      "Epoch: 3330 | MAE Train Loss: 62.57542037963867 | MAE Test Loss: 59.50216293334961 \n",
      "Epoch: 3340 | MAE Train Loss: 62.566490173339844 | MAE Test Loss: 59.49266052246094 \n",
      "Epoch: 3350 | MAE Train Loss: 62.55754852294922 | MAE Test Loss: 59.483150482177734 \n",
      "Epoch: 3360 | MAE Train Loss: 62.54861068725586 | MAE Test Loss: 59.473873138427734 \n",
      "Epoch: 3370 | MAE Train Loss: 62.53968048095703 | MAE Test Loss: 59.46437072753906 \n",
      "Epoch: 3380 | MAE Train Loss: 62.53074645996094 | MAE Test Loss: 59.4550895690918 \n",
      "Epoch: 3390 | MAE Train Loss: 62.521812438964844 | MAE Test Loss: 59.445587158203125 \n",
      "Epoch: 3400 | MAE Train Loss: 62.51287078857422 | MAE Test Loss: 59.43608474731445 \n",
      "Epoch: 3410 | MAE Train Loss: 62.50393295288086 | MAE Test Loss: 59.42680740356445 \n",
      "Epoch: 3420 | MAE Train Loss: 62.49501037597656 | MAE Test Loss: 59.417301177978516 \n",
      "Epoch: 3430 | MAE Train Loss: 62.4860725402832 | MAE Test Loss: 59.40779113769531 \n",
      "Epoch: 3440 | MAE Train Loss: 62.47713851928711 | MAE Test Loss: 59.398521423339844 \n",
      "Epoch: 3450 | MAE Train Loss: 62.468196868896484 | MAE Test Loss: 59.38901138305664 \n",
      "Epoch: 3460 | MAE Train Loss: 62.459266662597656 | MAE Test Loss: 59.37974166870117 \n",
      "Epoch: 3470 | MAE Train Loss: 62.45033645629883 | MAE Test Loss: 59.37023162841797 \n",
      "Epoch: 3480 | MAE Train Loss: 62.441402435302734 | MAE Test Loss: 59.3607292175293 \n",
      "Epoch: 3490 | MAE Train Loss: 62.43246078491211 | MAE Test Loss: 59.3514518737793 \n",
      "Epoch: 3500 | MAE Train Loss: 62.42352294921875 | MAE Test Loss: 59.34194564819336 \n",
      "Epoch: 3510 | MAE Train Loss: 62.41459274291992 | MAE Test Loss: 59.33255386352539 \n",
      "Epoch: 3520 | MAE Train Loss: 62.4056510925293 | MAE Test Loss: 59.323055267333984 \n",
      "Epoch: 3530 | MAE Train Loss: 62.396751403808594 | MAE Test Loss: 59.31312561035156 \n",
      "Epoch: 3540 | MAE Train Loss: 62.3879508972168 | MAE Test Loss: 59.302608489990234 \n",
      "Epoch: 3550 | MAE Train Loss: 62.37923812866211 | MAE Test Loss: 59.29190444946289 \n",
      "Epoch: 3560 | MAE Train Loss: 62.37051773071289 | MAE Test Loss: 59.28120422363281 \n",
      "Epoch: 3570 | MAE Train Loss: 62.36179733276367 | MAE Test Loss: 59.2704963684082 \n",
      "Epoch: 3580 | MAE Train Loss: 62.35307693481445 | MAE Test Loss: 59.259788513183594 \n",
      "Epoch: 3590 | MAE Train Loss: 62.3443603515625 | MAE Test Loss: 59.249088287353516 \n",
      "Epoch: 3600 | MAE Train Loss: 62.33563995361328 | MAE Test Loss: 59.238372802734375 \n",
      "Epoch: 3610 | MAE Train Loss: 62.32692337036133 | MAE Test Loss: 59.22767639160156 \n",
      "Epoch: 3620 | MAE Train Loss: 62.31820297241211 | MAE Test Loss: 59.21697235107422 \n",
      "Epoch: 3630 | MAE Train Loss: 62.30949020385742 | MAE Test Loss: 59.20626449584961 \n",
      "Epoch: 3640 | MAE Train Loss: 62.3007698059082 | MAE Test Loss: 59.19556427001953 \n",
      "Epoch: 3650 | MAE Train Loss: 62.292049407958984 | MAE Test Loss: 59.18485641479492 \n",
      "Epoch: 3660 | MAE Train Loss: 62.2833366394043 | MAE Test Loss: 59.17415237426758 \n",
      "Epoch: 3670 | MAE Train Loss: 62.27460861206055 | MAE Test Loss: 59.163448333740234 \n",
      "Epoch: 3680 | MAE Train Loss: 62.26590347290039 | MAE Test Loss: 59.15274429321289 \n",
      "Epoch: 3690 | MAE Train Loss: 62.25718307495117 | MAE Test Loss: 59.14203643798828 \n",
      "Epoch: 3700 | MAE Train Loss: 62.24846267700195 | MAE Test Loss: 59.13133239746094 \n",
      "Epoch: 3710 | MAE Train Loss: 62.23974609375 | MAE Test Loss: 59.120628356933594 \n",
      "Epoch: 3720 | MAE Train Loss: 62.23102569580078 | MAE Test Loss: 59.10992431640625 \n",
      "Epoch: 3730 | MAE Train Loss: 62.22230911254883 | MAE Test Loss: 59.099212646484375 \n",
      "Epoch: 3740 | MAE Train Loss: 62.213592529296875 | MAE Test Loss: 59.08851623535156 \n",
      "Epoch: 3750 | MAE Train Loss: 62.204872131347656 | MAE Test Loss: 59.07780838012695 \n",
      "Epoch: 3760 | MAE Train Loss: 62.19615173339844 | MAE Test Loss: 59.06709671020508 \n",
      "Epoch: 3770 | MAE Train Loss: 62.187435150146484 | MAE Test Loss: 59.056400299072266 \n",
      "Epoch: 3780 | MAE Train Loss: 62.17871856689453 | MAE Test Loss: 59.04569625854492 \n",
      "Epoch: 3790 | MAE Train Loss: 62.16999816894531 | MAE Test Loss: 59.03499221801758 \n",
      "Epoch: 3800 | MAE Train Loss: 62.161277770996094 | MAE Test Loss: 59.0242805480957 \n",
      "Epoch: 3810 | MAE Train Loss: 62.152565002441406 | MAE Test Loss: 59.013580322265625 \n",
      "Epoch: 3820 | MAE Train Loss: 62.14385223388672 | MAE Test Loss: 59.00287628173828 \n",
      "Epoch: 3830 | MAE Train Loss: 62.13512420654297 | MAE Test Loss: 58.99217224121094 \n",
      "Epoch: 3840 | MAE Train Loss: 62.12640380859375 | MAE Test Loss: 58.98146057128906 \n",
      "Epoch: 3850 | MAE Train Loss: 62.1176872253418 | MAE Test Loss: 58.97075653076172 \n",
      "Epoch: 3860 | MAE Train Loss: 62.108970642089844 | MAE Test Loss: 58.960052490234375 \n",
      "Epoch: 3870 | MAE Train Loss: 62.100250244140625 | MAE Test Loss: 58.949344635009766 \n",
      "Epoch: 3880 | MAE Train Loss: 62.09153747558594 | MAE Test Loss: 58.93864059448242 \n",
      "Epoch: 3890 | MAE Train Loss: 62.08281707763672 | MAE Test Loss: 58.92794418334961 \n",
      "Epoch: 3900 | MAE Train Loss: 62.0740966796875 | MAE Test Loss: 58.917240142822266 \n",
      "Epoch: 3910 | MAE Train Loss: 62.06537628173828 | MAE Test Loss: 58.90653610229492 \n",
      "Epoch: 3920 | MAE Train Loss: 62.05666732788086 | MAE Test Loss: 58.8956184387207 \n",
      "Epoch: 3930 | MAE Train Loss: 62.04798126220703 | MAE Test Loss: 58.88410186767578 \n",
      "Epoch: 3940 | MAE Train Loss: 62.03928756713867 | MAE Test Loss: 58.872581481933594 \n",
      "Epoch: 3950 | MAE Train Loss: 62.03059005737305 | MAE Test Loss: 58.861053466796875 \n",
      "Epoch: 3960 | MAE Train Loss: 62.02190399169922 | MAE Test Loss: 58.84953308105469 \n",
      "Epoch: 3970 | MAE Train Loss: 62.013214111328125 | MAE Test Loss: 58.8380126953125 \n",
      "Epoch: 3980 | MAE Train Loss: 62.004520416259766 | MAE Test Loss: 58.82648468017578 \n",
      "Epoch: 3990 | MAE Train Loss: 61.995826721191406 | MAE Test Loss: 58.81495666503906 \n",
      "Epoch: 4000 | MAE Train Loss: 61.98714065551758 | MAE Test Loss: 58.803443908691406 \n",
      "Epoch: 4010 | MAE Train Loss: 61.97845458984375 | MAE Test Loss: 58.79227828979492 \n",
      "Epoch: 4020 | MAE Train Loss: 61.969757080078125 | MAE Test Loss: 58.7816162109375 \n",
      "Epoch: 4030 | MAE Train Loss: 61.9610710144043 | MAE Test Loss: 58.77082061767578 \n",
      "Epoch: 4040 | MAE Train Loss: 61.95237731933594 | MAE Test Loss: 58.760162353515625 \n",
      "Epoch: 4050 | MAE Train Loss: 61.943687438964844 | MAE Test Loss: 58.749515533447266 \n",
      "Epoch: 4060 | MAE Train Loss: 61.934993743896484 | MAE Test Loss: 58.738853454589844 \n",
      "Epoch: 4070 | MAE Train Loss: 61.926307678222656 | MAE Test Loss: 58.72819900512695 \n",
      "Epoch: 4080 | MAE Train Loss: 61.91762161254883 | MAE Test Loss: 58.71754455566406 \n",
      "Epoch: 4090 | MAE Train Loss: 61.9089241027832 | MAE Test Loss: 58.70688247680664 \n",
      "Epoch: 4100 | MAE Train Loss: 61.90023422241211 | MAE Test Loss: 58.69623565673828 \n",
      "Epoch: 4110 | MAE Train Loss: 61.89154815673828 | MAE Test Loss: 58.68557357788086 \n",
      "Epoch: 4120 | MAE Train Loss: 61.882850646972656 | MAE Test Loss: 58.67491912841797 \n",
      "Epoch: 4130 | MAE Train Loss: 61.87416458129883 | MAE Test Loss: 58.66426086425781 \n",
      "Epoch: 4140 | MAE Train Loss: 61.86547088623047 | MAE Test Loss: 58.65360641479492 \n",
      "Epoch: 4150 | MAE Train Loss: 61.85678482055664 | MAE Test Loss: 58.6429557800293 \n",
      "Epoch: 4160 | MAE Train Loss: 61.848087310791016 | MAE Test Loss: 58.63229751586914 \n",
      "Epoch: 4170 | MAE Train Loss: 61.83940124511719 | MAE Test Loss: 58.6215705871582 \n",
      "Epoch: 4180 | MAE Train Loss: 61.83070373535156 | MAE Test Loss: 58.61091232299805 \n",
      "Epoch: 4190 | MAE Train Loss: 61.822021484375 | MAE Test Loss: 58.600257873535156 \n",
      "Epoch: 4200 | MAE Train Loss: 61.81333541870117 | MAE Test Loss: 58.589603424072266 \n",
      "Epoch: 4210 | MAE Train Loss: 61.80463790893555 | MAE Test Loss: 58.578948974609375 \n",
      "Epoch: 4220 | MAE Train Loss: 61.79594421386719 | MAE Test Loss: 58.56822204589844 \n",
      "Epoch: 4230 | MAE Train Loss: 61.787254333496094 | MAE Test Loss: 58.55757141113281 \n",
      "Epoch: 4240 | MAE Train Loss: 61.778560638427734 | MAE Test Loss: 58.546913146972656 \n",
      "Epoch: 4250 | MAE Train Loss: 61.769874572753906 | MAE Test Loss: 58.5362548828125 \n",
      "Epoch: 4260 | MAE Train Loss: 61.76118087768555 | MAE Test Loss: 58.52559280395508 \n",
      "Epoch: 4270 | MAE Train Loss: 61.75249099731445 | MAE Test Loss: 58.51494598388672 \n",
      "Epoch: 4280 | MAE Train Loss: 61.74380874633789 | MAE Test Loss: 58.50429153442383 \n",
      "Epoch: 4290 | MAE Train Loss: 61.73511505126953 | MAE Test Loss: 58.493629455566406 \n",
      "Epoch: 4300 | MAE Train Loss: 61.72642517089844 | MAE Test Loss: 58.482975006103516 \n",
      "Epoch: 4310 | MAE Train Loss: 61.71773147583008 | MAE Test Loss: 58.472251892089844 \n",
      "Epoch: 4320 | MAE Train Loss: 61.70903396606445 | MAE Test Loss: 58.46159744262695 \n",
      "Epoch: 4330 | MAE Train Loss: 61.700347900390625 | MAE Test Loss: 58.45093536376953 \n",
      "Epoch: 4340 | MAE Train Loss: 61.691654205322266 | MAE Test Loss: 58.44028091430664 \n",
      "Epoch: 4350 | MAE Train Loss: 61.68296432495117 | MAE Test Loss: 58.42963409423828 \n",
      "Epoch: 4360 | MAE Train Loss: 61.67427444458008 | MAE Test Loss: 58.419036865234375 \n",
      "Epoch: 4370 | MAE Train Loss: 61.665584564208984 | MAE Test Loss: 58.40837860107422 \n",
      "Epoch: 4380 | MAE Train Loss: 61.656898498535156 | MAE Test Loss: 58.3975830078125 \n",
      "Epoch: 4390 | MAE Train Loss: 61.6482048034668 | MAE Test Loss: 58.386940002441406 \n",
      "Epoch: 4400 | MAE Train Loss: 61.63950729370117 | MAE Test Loss: 58.376277923583984 \n",
      "Epoch: 4410 | MAE Train Loss: 61.630821228027344 | MAE Test Loss: 58.365623474121094 \n",
      "Epoch: 4420 | MAE Train Loss: 61.62215042114258 | MAE Test Loss: 58.355133056640625 \n",
      "Epoch: 4430 | MAE Train Loss: 61.61349868774414 | MAE Test Loss: 58.344791412353516 \n",
      "Epoch: 4440 | MAE Train Loss: 61.60484313964844 | MAE Test Loss: 58.33454513549805 \n",
      "Epoch: 4450 | MAE Train Loss: 61.5963020324707 | MAE Test Loss: 58.32438278198242 \n",
      "Epoch: 4460 | MAE Train Loss: 61.5877799987793 | MAE Test Loss: 58.31437683105469 \n",
      "Epoch: 4470 | MAE Train Loss: 61.579246520996094 | MAE Test Loss: 58.30436325073242 \n",
      "Epoch: 4480 | MAE Train Loss: 61.57072830200195 | MAE Test Loss: 58.294349670410156 \n",
      "Epoch: 4490 | MAE Train Loss: 61.56220626831055 | MAE Test Loss: 58.284332275390625 \n",
      "Epoch: 4500 | MAE Train Loss: 61.553680419921875 | MAE Test Loss: 58.27432632446289 \n",
      "Epoch: 4510 | MAE Train Loss: 61.54515838623047 | MAE Test Loss: 58.264312744140625 \n",
      "Epoch: 4520 | MAE Train Loss: 61.53664016723633 | MAE Test Loss: 58.254310607910156 \n",
      "Epoch: 4530 | MAE Train Loss: 61.528114318847656 | MAE Test Loss: 58.244300842285156 \n",
      "Epoch: 4540 | MAE Train Loss: 61.519588470458984 | MAE Test Loss: 58.23428726196289 \n",
      "Epoch: 4550 | MAE Train Loss: 61.51106643676758 | MAE Test Loss: 58.224273681640625 \n",
      "Epoch: 4560 | MAE Train Loss: 61.502540588378906 | MAE Test Loss: 58.21426773071289 \n",
      "Epoch: 4570 | MAE Train Loss: 61.4940185546875 | MAE Test Loss: 58.204254150390625 \n",
      "Epoch: 4580 | MAE Train Loss: 61.48549270629883 | MAE Test Loss: 58.19424819946289 \n",
      "Epoch: 4590 | MAE Train Loss: 61.47697067260742 | MAE Test Loss: 58.184234619140625 \n",
      "Epoch: 4600 | MAE Train Loss: 61.46845245361328 | MAE Test Loss: 58.174224853515625 \n",
      "Epoch: 4610 | MAE Train Loss: 61.459930419921875 | MAE Test Loss: 58.164215087890625 \n",
      "Epoch: 4620 | MAE Train Loss: 61.4514045715332 | MAE Test Loss: 58.15420913696289 \n",
      "Epoch: 4630 | MAE Train Loss: 61.4428825378418 | MAE Test Loss: 58.144203186035156 \n",
      "Epoch: 4640 | MAE Train Loss: 61.434356689453125 | MAE Test Loss: 58.134185791015625 \n",
      "Epoch: 4650 | MAE Train Loss: 61.425838470458984 | MAE Test Loss: 58.124176025390625 \n",
      "Epoch: 4660 | MAE Train Loss: 61.41730499267578 | MAE Test Loss: 58.11417007446289 \n",
      "Epoch: 4670 | MAE Train Loss: 61.408790588378906 | MAE Test Loss: 58.104164123535156 \n",
      "Epoch: 4680 | MAE Train Loss: 61.400264739990234 | MAE Test Loss: 58.094234466552734 \n",
      "Epoch: 4690 | MAE Train Loss: 61.39174270629883 | MAE Test Loss: 58.08478546142578 \n",
      "Epoch: 4700 | MAE Train Loss: 61.38322067260742 | MAE Test Loss: 58.07533645629883 \n",
      "Epoch: 4710 | MAE Train Loss: 61.37470245361328 | MAE Test Loss: 58.06589126586914 \n",
      "Epoch: 4720 | MAE Train Loss: 61.36616897583008 | MAE Test Loss: 58.05643844604492 \n",
      "Epoch: 4730 | MAE Train Loss: 61.35764694213867 | MAE Test Loss: 58.04698944091797 \n",
      "Epoch: 4740 | MAE Train Loss: 61.34912872314453 | MAE Test Loss: 58.03753662109375 \n",
      "Epoch: 4750 | MAE Train Loss: 61.34060287475586 | MAE Test Loss: 58.02809524536133 \n",
      "Epoch: 4760 | MAE Train Loss: 61.33207702636719 | MAE Test Loss: 58.018646240234375 \n",
      "Epoch: 4770 | MAE Train Loss: 61.32355880737305 | MAE Test Loss: 58.009193420410156 \n",
      "Epoch: 4780 | MAE Train Loss: 61.315032958984375 | MAE Test Loss: 57.999752044677734 \n",
      "Epoch: 4790 | MAE Train Loss: 61.306514739990234 | MAE Test Loss: 57.990299224853516 \n",
      "Epoch: 4800 | MAE Train Loss: 61.29798889160156 | MAE Test Loss: 57.98085403442383 \n",
      "Epoch: 4810 | MAE Train Loss: 61.289466857910156 | MAE Test Loss: 57.971405029296875 \n",
      "Epoch: 4820 | MAE Train Loss: 61.28093338012695 | MAE Test Loss: 57.96196365356445 \n",
      "Epoch: 4830 | MAE Train Loss: 61.27241516113281 | MAE Test Loss: 57.9525032043457 \n",
      "Epoch: 4840 | MAE Train Loss: 61.263893127441406 | MAE Test Loss: 57.94306182861328 \n",
      "Epoch: 4850 | MAE Train Loss: 61.255367279052734 | MAE Test Loss: 57.933616638183594 \n",
      "Epoch: 4860 | MAE Train Loss: 61.24684143066406 | MAE Test Loss: 57.92416763305664 \n",
      "Epoch: 4870 | MAE Train Loss: 61.23832702636719 | MAE Test Loss: 57.91472244262695 \n",
      "Epoch: 4880 | MAE Train Loss: 61.22979736328125 | MAE Test Loss: 57.9052619934082 \n",
      "Epoch: 4890 | MAE Train Loss: 61.22127914428711 | MAE Test Loss: 57.895816802978516 \n",
      "Epoch: 4900 | MAE Train Loss: 61.212745666503906 | MAE Test Loss: 57.88637161254883 \n",
      "Epoch: 4910 | MAE Train Loss: 61.20423126220703 | MAE Test Loss: 57.87692642211914 \n",
      "Epoch: 4920 | MAE Train Loss: 61.19570541381836 | MAE Test Loss: 57.868202209472656 \n",
      "Epoch: 4930 | MAE Train Loss: 61.18717956542969 | MAE Test Loss: 57.85961151123047 \n",
      "Epoch: 4940 | MAE Train Loss: 61.17865753173828 | MAE Test Loss: 57.851009368896484 \n",
      "Epoch: 4950 | MAE Train Loss: 61.17013931274414 | MAE Test Loss: 57.8424186706543 \n",
      "Epoch: 4960 | MAE Train Loss: 61.16160583496094 | MAE Test Loss: 57.83382034301758 \n",
      "Epoch: 4970 | MAE Train Loss: 61.15309143066406 | MAE Test Loss: 57.82522964477539 \n",
      "Epoch: 4980 | MAE Train Loss: 61.14456558227539 | MAE Test Loss: 57.81663131713867 \n",
      "Epoch: 4990 | MAE Train Loss: 61.13603973388672 | MAE Test Loss: 57.808040618896484 \n",
      "Epoch: 5000 | MAE Train Loss: 61.12751007080078 | MAE Test Loss: 57.799442291259766 \n",
      "Epoch: 5010 | MAE Train Loss: 61.11899185180664 | MAE Test Loss: 57.79084396362305 \n",
      "Epoch: 5020 | MAE Train Loss: 61.11046600341797 | MAE Test Loss: 57.782249450683594 \n",
      "Epoch: 5030 | MAE Train Loss: 61.10194396972656 | MAE Test Loss: 57.773658752441406 \n",
      "Epoch: 5040 | MAE Train Loss: 61.09341812133789 | MAE Test Loss: 57.76506423950195 \n",
      "Epoch: 5050 | MAE Train Loss: 61.08489227294922 | MAE Test Loss: 57.7564697265625 \n",
      "Epoch: 5060 | MAE Train Loss: 61.076377868652344 | MAE Test Loss: 57.74787139892578 \n",
      "Epoch: 5070 | MAE Train Loss: 61.06785583496094 | MAE Test Loss: 57.739280700683594 \n",
      "Epoch: 5080 | MAE Train Loss: 61.059329986572266 | MAE Test Loss: 57.730682373046875 \n",
      "Epoch: 5090 | MAE Train Loss: 61.050804138183594 | MAE Test Loss: 57.722084045410156 \n",
      "Epoch: 5100 | MAE Train Loss: 61.04228210449219 | MAE Test Loss: 57.7135009765625 \n",
      "Epoch: 5110 | MAE Train Loss: 61.03376007080078 | MAE Test Loss: 57.70490264892578 \n",
      "Epoch: 5120 | MAE Train Loss: 61.02523422241211 | MAE Test Loss: 57.69630432128906 \n",
      "Epoch: 5130 | MAE Train Loss: 61.01670837402344 | MAE Test Loss: 57.687721252441406 \n",
      "Epoch: 5140 | MAE Train Loss: 61.0081901550293 | MAE Test Loss: 57.67912292480469 \n",
      "Epoch: 5150 | MAE Train Loss: 60.99966812133789 | MAE Test Loss: 57.67052459716797 \n",
      "Epoch: 5160 | MAE Train Loss: 60.99114227294922 | MAE Test Loss: 57.661930084228516 \n",
      "Epoch: 5170 | MAE Train Loss: 60.98262023925781 | MAE Test Loss: 57.65333557128906 \n",
      "Epoch: 5180 | MAE Train Loss: 60.97409439086914 | MAE Test Loss: 57.64474105834961 \n",
      "Epoch: 5190 | MAE Train Loss: 60.965572357177734 | MAE Test Loss: 57.63614273071289 \n",
      "Epoch: 5200 | MAE Train Loss: 60.95704650878906 | MAE Test Loss: 57.6275520324707 \n",
      "Epoch: 5210 | MAE Train Loss: 60.94852828979492 | MAE Test Loss: 57.618953704833984 \n",
      "Epoch: 5220 | MAE Train Loss: 60.94000244140625 | MAE Test Loss: 57.6103630065918 \n",
      "Epoch: 5230 | MAE Train Loss: 60.93153381347656 | MAE Test Loss: 57.60190963745117 \n",
      "Epoch: 5240 | MAE Train Loss: 60.923309326171875 | MAE Test Loss: 57.59379959106445 \n",
      "Epoch: 5250 | MAE Train Loss: 60.91508102416992 | MAE Test Loss: 57.58567810058594 \n",
      "Epoch: 5260 | MAE Train Loss: 60.90685272216797 | MAE Test Loss: 57.57756423950195 \n",
      "Epoch: 5270 | MAE Train Loss: 60.89863204956055 | MAE Test Loss: 57.5694580078125 \n",
      "Epoch: 5280 | MAE Train Loss: 60.89039993286133 | MAE Test Loss: 57.561336517333984 \n",
      "Epoch: 5290 | MAE Train Loss: 60.88217544555664 | MAE Test Loss: 57.553226470947266 \n",
      "Epoch: 5300 | MAE Train Loss: 60.87394714355469 | MAE Test Loss: 57.545108795166016 \n",
      "Epoch: 5310 | MAE Train Loss: 60.86571502685547 | MAE Test Loss: 57.53699493408203 \n",
      "Epoch: 5320 | MAE Train Loss: 60.85749435424805 | MAE Test Loss: 57.52888107299805 \n",
      "Epoch: 5330 | MAE Train Loss: 60.849266052246094 | MAE Test Loss: 57.52076721191406 \n",
      "Epoch: 5340 | MAE Train Loss: 60.84103775024414 | MAE Test Loss: 57.512657165527344 \n",
      "Epoch: 5350 | MAE Train Loss: 60.83281326293945 | MAE Test Loss: 57.50453567504883 \n",
      "Epoch: 5360 | MAE Train Loss: 60.82457733154297 | MAE Test Loss: 57.496429443359375 \n",
      "Epoch: 5370 | MAE Train Loss: 60.81635665893555 | MAE Test Loss: 57.48831558227539 \n",
      "Epoch: 5380 | MAE Train Loss: 60.808128356933594 | MAE Test Loss: 57.480194091796875 \n",
      "Epoch: 5390 | MAE Train Loss: 60.79990005493164 | MAE Test Loss: 57.47208023071289 \n",
      "Epoch: 5400 | MAE Train Loss: 60.79167556762695 | MAE Test Loss: 57.463966369628906 \n",
      "Epoch: 5410 | MAE Train Loss: 60.78364562988281 | MAE Test Loss: 57.455665588378906 \n",
      "Epoch: 5420 | MAE Train Loss: 60.77562713623047 | MAE Test Loss: 57.44735336303711 \n",
      "Epoch: 5430 | MAE Train Loss: 60.76760482788086 | MAE Test Loss: 57.43904113769531 \n",
      "Epoch: 5440 | MAE Train Loss: 60.759578704833984 | MAE Test Loss: 57.43073654174805 \n",
      "Epoch: 5450 | MAE Train Loss: 60.751564025878906 | MAE Test Loss: 57.42243576049805 \n",
      "Epoch: 5460 | MAE Train Loss: 60.74354934692383 | MAE Test Loss: 57.414127349853516 \n",
      "Epoch: 5470 | MAE Train Loss: 60.735530853271484 | MAE Test Loss: 57.40581512451172 \n",
      "Epoch: 5480 | MAE Train Loss: 60.72750473022461 | MAE Test Loss: 57.39751434326172 \n",
      "Epoch: 5490 | MAE Train Loss: 60.719478607177734 | MAE Test Loss: 57.38920593261719 \n",
      "Epoch: 5500 | MAE Train Loss: 60.711463928222656 | MAE Test Loss: 57.38089370727539 \n",
      "Epoch: 5510 | MAE Train Loss: 60.70344543457031 | MAE Test Loss: 57.37258529663086 \n",
      "Epoch: 5520 | MAE Train Loss: 60.69542694091797 | MAE Test Loss: 57.36428451538086 \n",
      "Epoch: 5530 | MAE Train Loss: 60.68740463256836 | MAE Test Loss: 57.35597229003906 \n",
      "Epoch: 5540 | MAE Train Loss: 60.67938995361328 | MAE Test Loss: 57.3476676940918 \n",
      "Epoch: 5550 | MAE Train Loss: 60.67136001586914 | MAE Test Loss: 57.339359283447266 \n",
      "Epoch: 5560 | MAE Train Loss: 60.66339111328125 | MAE Test Loss: 57.331241607666016 \n",
      "Epoch: 5570 | MAE Train Loss: 60.65546417236328 | MAE Test Loss: 57.32319641113281 \n",
      "Epoch: 5580 | MAE Train Loss: 60.64753723144531 | MAE Test Loss: 57.315189361572266 \n",
      "Epoch: 5590 | MAE Train Loss: 60.63961410522461 | MAE Test Loss: 57.30714416503906 \n",
      "Epoch: 5600 | MAE Train Loss: 60.631690979003906 | MAE Test Loss: 57.299137115478516 \n",
      "Epoch: 5610 | MAE Train Loss: 60.623756408691406 | MAE Test Loss: 57.29113006591797 \n",
      "Epoch: 5620 | MAE Train Loss: 60.61583709716797 | MAE Test Loss: 57.2830810546875 \n",
      "Epoch: 5630 | MAE Train Loss: 60.60790252685547 | MAE Test Loss: 57.27507400512695 \n",
      "Epoch: 5640 | MAE Train Loss: 60.60000228881836 | MAE Test Loss: 57.26701736450195 \n",
      "Epoch: 5650 | MAE Train Loss: 60.5921630859375 | MAE Test Loss: 57.25889205932617 \n",
      "Epoch: 5660 | MAE Train Loss: 60.58431625366211 | MAE Test Loss: 57.250797271728516 \n",
      "Epoch: 5670 | MAE Train Loss: 60.57648849487305 | MAE Test Loss: 57.24267578125 \n",
      "Epoch: 5680 | MAE Train Loss: 60.568641662597656 | MAE Test Loss: 57.234554290771484 \n",
      "Epoch: 5690 | MAE Train Loss: 60.56080627441406 | MAE Test Loss: 57.2264404296875 \n",
      "Epoch: 5700 | MAE Train Loss: 60.5529670715332 | MAE Test Loss: 57.21831512451172 \n",
      "Epoch: 5710 | MAE Train Loss: 60.54512023925781 | MAE Test Loss: 57.21022033691406 \n",
      "Epoch: 5720 | MAE Train Loss: 60.53728103637695 | MAE Test Loss: 57.20209884643555 \n",
      "Epoch: 5730 | MAE Train Loss: 60.52944564819336 | MAE Test Loss: 57.193973541259766 \n",
      "Epoch: 5740 | MAE Train Loss: 60.5216064453125 | MAE Test Loss: 57.185855865478516 \n",
      "Epoch: 5750 | MAE Train Loss: 60.51376724243164 | MAE Test Loss: 57.177757263183594 \n",
      "Epoch: 5760 | MAE Train Loss: 60.50593185424805 | MAE Test Loss: 57.16963195800781 \n",
      "Epoch: 5770 | MAE Train Loss: 60.49809265136719 | MAE Test Loss: 57.16150665283203 \n",
      "Epoch: 5780 | MAE Train Loss: 60.49024963378906 | MAE Test Loss: 57.153411865234375 \n",
      "Epoch: 5790 | MAE Train Loss: 60.4824104309082 | MAE Test Loss: 57.145286560058594 \n",
      "Epoch: 5800 | MAE Train Loss: 60.474571228027344 | MAE Test Loss: 57.137168884277344 \n",
      "Epoch: 5810 | MAE Train Loss: 60.46673583984375 | MAE Test Loss: 57.129058837890625 \n",
      "Epoch: 5820 | MAE Train Loss: 60.45888900756836 | MAE Test Loss: 57.120933532714844 \n",
      "Epoch: 5830 | MAE Train Loss: 60.451045989990234 | MAE Test Loss: 57.11283874511719 \n",
      "Epoch: 5840 | MAE Train Loss: 60.443214416503906 | MAE Test Loss: 57.104713439941406 \n",
      "Epoch: 5850 | MAE Train Loss: 60.43537521362305 | MAE Test Loss: 57.09659194946289 \n",
      "Epoch: 5860 | MAE Train Loss: 60.42753601074219 | MAE Test Loss: 57.08848190307617 \n",
      "Epoch: 5870 | MAE Train Loss: 60.419700622558594 | MAE Test Loss: 57.08036422729492 \n",
      "Epoch: 5880 | MAE Train Loss: 60.411861419677734 | MAE Test Loss: 57.072242736816406 \n",
      "Epoch: 5890 | MAE Train Loss: 60.404014587402344 | MAE Test Loss: 57.06414031982422 \n",
      "Epoch: 5900 | MAE Train Loss: 60.396278381347656 | MAE Test Loss: 57.05625534057617 \n",
      "Epoch: 5910 | MAE Train Loss: 60.38857650756836 | MAE Test Loss: 57.048492431640625 \n",
      "Epoch: 5920 | MAE Train Loss: 60.38087463378906 | MAE Test Loss: 57.040679931640625 \n",
      "Epoch: 5930 | MAE Train Loss: 60.3731689453125 | MAE Test Loss: 57.03291320800781 \n",
      "Epoch: 5940 | MAE Train Loss: 60.36547088623047 | MAE Test Loss: 57.02511215209961 \n",
      "Epoch: 5950 | MAE Train Loss: 60.35776901245117 | MAE Test Loss: 57.01734161376953 \n",
      "Epoch: 5960 | MAE Train Loss: 60.350067138671875 | MAE Test Loss: 57.00952911376953 \n",
      "Epoch: 5970 | MAE Train Loss: 60.34237289428711 | MAE Test Loss: 57.001766204833984 \n",
      "Epoch: 5980 | MAE Train Loss: 60.33466339111328 | MAE Test Loss: 56.993953704833984 \n",
      "Epoch: 5990 | MAE Train Loss: 60.326961517333984 | MAE Test Loss: 56.98618698120117 \n",
      "Epoch: 6000 | MAE Train Loss: 60.31926727294922 | MAE Test Loss: 56.97837829589844 \n",
      "Epoch: 6010 | MAE Train Loss: 60.31155776977539 | MAE Test Loss: 56.9705696105957 \n",
      "Epoch: 6020 | MAE Train Loss: 60.303855895996094 | MAE Test Loss: 56.962806701660156 \n",
      "Epoch: 6030 | MAE Train Loss: 60.296165466308594 | MAE Test Loss: 56.954994201660156 \n",
      "Epoch: 6040 | MAE Train Loss: 60.2884521484375 | MAE Test Loss: 56.947227478027344 \n",
      "Epoch: 6050 | MAE Train Loss: 60.28076171875 | MAE Test Loss: 56.93941879272461 \n",
      "Epoch: 6060 | MAE Train Loss: 60.27305603027344 | MAE Test Loss: 56.9316520690918 \n",
      "Epoch: 6070 | MAE Train Loss: 60.265357971191406 | MAE Test Loss: 56.92384338378906 \n",
      "Epoch: 6080 | MAE Train Loss: 60.257652282714844 | MAE Test Loss: 56.91607666015625 \n",
      "Epoch: 6090 | MAE Train Loss: 60.24995422363281 | MAE Test Loss: 56.908267974853516 \n",
      "Epoch: 6100 | MAE Train Loss: 60.24224853515625 | MAE Test Loss: 56.90050506591797 \n",
      "Epoch: 6110 | MAE Train Loss: 60.23455047607422 | MAE Test Loss: 56.89269256591797 \n",
      "Epoch: 6120 | MAE Train Loss: 60.22685623168945 | MAE Test Loss: 56.88492965698242 \n",
      "Epoch: 6130 | MAE Train Loss: 60.219146728515625 | MAE Test Loss: 56.87711715698242 \n",
      "Epoch: 6140 | MAE Train Loss: 60.21145248413086 | MAE Test Loss: 56.86933135986328 \n",
      "Epoch: 6150 | MAE Train Loss: 60.20400619506836 | MAE Test Loss: 56.86136245727539 \n",
      "Epoch: 6160 | MAE Train Loss: 60.19657516479492 | MAE Test Loss: 56.8533821105957 \n",
      "Epoch: 6170 | MAE Train Loss: 60.18913269042969 | MAE Test Loss: 56.845401763916016 \n",
      "Epoch: 6180 | MAE Train Loss: 60.18169021606445 | MAE Test Loss: 56.83742904663086 \n",
      "Epoch: 6190 | MAE Train Loss: 60.17425537109375 | MAE Test Loss: 56.8294563293457 \n",
      "Epoch: 6200 | MAE Train Loss: 60.166812896728516 | MAE Test Loss: 56.82147979736328 \n",
      "Epoch: 6210 | MAE Train Loss: 60.15937423706055 | MAE Test Loss: 56.81351089477539 \n",
      "Epoch: 6220 | MAE Train Loss: 60.151939392089844 | MAE Test Loss: 56.805538177490234 \n",
      "Epoch: 6230 | MAE Train Loss: 60.14449691772461 | MAE Test Loss: 56.79755401611328 \n",
      "Epoch: 6240 | MAE Train Loss: 60.137054443359375 | MAE Test Loss: 56.78958511352539 \n",
      "Epoch: 6250 | MAE Train Loss: 60.12961959838867 | MAE Test Loss: 56.7816047668457 \n",
      "Epoch: 6260 | MAE Train Loss: 60.12217712402344 | MAE Test Loss: 56.77362823486328 \n",
      "Epoch: 6270 | MAE Train Loss: 60.114742279052734 | MAE Test Loss: 56.76565933227539 \n",
      "Epoch: 6280 | MAE Train Loss: 60.107295989990234 | MAE Test Loss: 56.7576789855957 \n",
      "Epoch: 6290 | MAE Train Loss: 60.0998649597168 | MAE Test Loss: 56.74971008300781 \n",
      "Epoch: 6300 | MAE Train Loss: 60.09242630004883 | MAE Test Loss: 56.74173355102539 \n",
      "Epoch: 6310 | MAE Train Loss: 60.08498764038086 | MAE Test Loss: 56.733760833740234 \n",
      "Epoch: 6320 | MAE Train Loss: 60.077537536621094 | MAE Test Loss: 56.72578430175781 \n",
      "Epoch: 6330 | MAE Train Loss: 60.07010269165039 | MAE Test Loss: 56.71780776977539 \n",
      "Epoch: 6340 | MAE Train Loss: 60.06266784667969 | MAE Test Loss: 56.7098274230957 \n",
      "Epoch: 6350 | MAE Train Loss: 60.05521774291992 | MAE Test Loss: 56.70186233520508 \n",
      "Epoch: 6360 | MAE Train Loss: 60.047786712646484 | MAE Test Loss: 56.693885803222656 \n",
      "Epoch: 6370 | MAE Train Loss: 60.04034423828125 | MAE Test Loss: 56.6859130859375 \n",
      "Epoch: 6380 | MAE Train Loss: 60.03290557861328 | MAE Test Loss: 56.67793273925781 \n",
      "Epoch: 6390 | MAE Train Loss: 60.02546691894531 | MAE Test Loss: 56.669960021972656 \n",
      "Epoch: 6400 | MAE Train Loss: 60.01803207397461 | MAE Test Loss: 56.661983489990234 \n",
      "Epoch: 6410 | MAE Train Loss: 60.010589599609375 | MAE Test Loss: 56.65400695800781 \n",
      "Epoch: 6420 | MAE Train Loss: 60.00314712524414 | MAE Test Loss: 56.646034240722656 \n",
      "Epoch: 6430 | MAE Train Loss: 59.995758056640625 | MAE Test Loss: 56.638179779052734 \n",
      "Epoch: 6440 | MAE Train Loss: 59.98847961425781 | MAE Test Loss: 56.63059616088867 \n",
      "Epoch: 6450 | MAE Train Loss: 59.981197357177734 | MAE Test Loss: 56.62301254272461 \n",
      "Epoch: 6460 | MAE Train Loss: 59.97391891479492 | MAE Test Loss: 56.61543273925781 \n",
      "Epoch: 6470 | MAE Train Loss: 59.96664047241211 | MAE Test Loss: 56.607845306396484 \n",
      "Epoch: 6480 | MAE Train Loss: 59.95936584472656 | MAE Test Loss: 56.60026931762695 \n",
      "Epoch: 6490 | MAE Train Loss: 59.952083587646484 | MAE Test Loss: 56.5926628112793 \n",
      "Epoch: 6500 | MAE Train Loss: 59.94480514526367 | MAE Test Loss: 56.5850830078125 \n",
      "Epoch: 6510 | MAE Train Loss: 59.93752670288086 | MAE Test Loss: 56.57749938964844 \n",
      "Epoch: 6520 | MAE Train Loss: 59.930240631103516 | MAE Test Loss: 56.569915771484375 \n",
      "Epoch: 6530 | MAE Train Loss: 59.92296600341797 | MAE Test Loss: 56.562313079833984 \n",
      "Epoch: 6540 | MAE Train Loss: 59.915687561035156 | MAE Test Loss: 56.55473327636719 \n",
      "Epoch: 6550 | MAE Train Loss: 59.90841293334961 | MAE Test Loss: 56.547149658203125 \n",
      "Epoch: 6560 | MAE Train Loss: 59.90113830566406 | MAE Test Loss: 56.53956604003906 \n",
      "Epoch: 6570 | MAE Train Loss: 59.893856048583984 | MAE Test Loss: 56.53196716308594 \n",
      "Epoch: 6580 | MAE Train Loss: 59.886573791503906 | MAE Test Loss: 56.52437973022461 \n",
      "Epoch: 6590 | MAE Train Loss: 59.879295349121094 | MAE Test Loss: 56.51679992675781 \n",
      "Epoch: 6600 | MAE Train Loss: 59.87201690673828 | MAE Test Loss: 56.509185791015625 \n",
      "Epoch: 6610 | MAE Train Loss: 59.864742279052734 | MAE Test Loss: 56.50160217285156 \n",
      "Epoch: 6620 | MAE Train Loss: 59.85746765136719 | MAE Test Loss: 56.494014739990234 \n",
      "Epoch: 6630 | MAE Train Loss: 59.85018539428711 | MAE Test Loss: 56.48643112182617 \n",
      "Epoch: 6640 | MAE Train Loss: 59.84291076660156 | MAE Test Loss: 56.478851318359375 \n",
      "Epoch: 6650 | MAE Train Loss: 59.835628509521484 | MAE Test Loss: 56.471275329589844 \n",
      "Epoch: 6660 | MAE Train Loss: 59.8283576965332 | MAE Test Loss: 56.46369171142578 \n",
      "Epoch: 6670 | MAE Train Loss: 59.821075439453125 | MAE Test Loss: 56.45610427856445 \n",
      "Epoch: 6680 | MAE Train Loss: 59.81379318237305 | MAE Test Loss: 56.44850540161133 \n",
      "Epoch: 6690 | MAE Train Loss: 59.8065185546875 | MAE Test Loss: 56.4409294128418 \n",
      "Epoch: 6700 | MAE Train Loss: 59.79923629760742 | MAE Test Loss: 56.43334197998047 \n",
      "Epoch: 6710 | MAE Train Loss: 59.79196548461914 | MAE Test Loss: 56.425743103027344 \n",
      "Epoch: 6720 | MAE Train Loss: 59.78468704223633 | MAE Test Loss: 56.41816711425781 \n",
      "Epoch: 6730 | MAE Train Loss: 59.77740478515625 | MAE Test Loss: 56.41058349609375 \n",
      "Epoch: 6740 | MAE Train Loss: 59.77012252807617 | MAE Test Loss: 56.40299606323242 \n",
      "Epoch: 6750 | MAE Train Loss: 59.762847900390625 | MAE Test Loss: 56.395381927490234 \n",
      "Epoch: 6760 | MAE Train Loss: 59.75557327270508 | MAE Test Loss: 56.38779830932617 \n",
      "Epoch: 6770 | MAE Train Loss: 59.748291015625 | MAE Test Loss: 56.380210876464844 \n",
      "Epoch: 6780 | MAE Train Loss: 59.74101638793945 | MAE Test Loss: 56.37263107299805 \n",
      "Epoch: 6790 | MAE Train Loss: 59.733734130859375 | MAE Test Loss: 56.365055084228516 \n",
      "Epoch: 6800 | MAE Train Loss: 59.72645568847656 | MAE Test Loss: 56.35747146606445 \n",
      "Epoch: 6810 | MAE Train Loss: 59.71916961669922 | MAE Test Loss: 56.34988784790039 \n",
      "Epoch: 6820 | MAE Train Loss: 59.71189880371094 | MAE Test Loss: 56.342281341552734 \n",
      "Epoch: 6830 | MAE Train Loss: 59.70462417602539 | MAE Test Loss: 56.33469772338867 \n",
      "Epoch: 6840 | MAE Train Loss: 59.697349548339844 | MAE Test Loss: 56.327125549316406 \n",
      "Epoch: 6850 | MAE Train Loss: 59.6900634765625 | MAE Test Loss: 56.31954574584961 \n",
      "Epoch: 6860 | MAE Train Loss: 59.68279266357422 | MAE Test Loss: 56.31193923950195 \n",
      "Epoch: 6870 | MAE Train Loss: 59.675514221191406 | MAE Test Loss: 56.304351806640625 \n",
      "Epoch: 6880 | MAE Train Loss: 59.668235778808594 | MAE Test Loss: 56.296775817871094 \n",
      "Epoch: 6890 | MAE Train Loss: 59.66095733642578 | MAE Test Loss: 56.289188385009766 \n",
      "Epoch: 6900 | MAE Train Loss: 59.65367889404297 | MAE Test Loss: 56.28156661987305 \n",
      "Epoch: 6910 | MAE Train Loss: 59.646400451660156 | MAE Test Loss: 56.27398681640625 \n",
      "Epoch: 6920 | MAE Train Loss: 59.63911437988281 | MAE Test Loss: 56.26640319824219 \n",
      "Epoch: 6930 | MAE Train Loss: 59.63184356689453 | MAE Test Loss: 56.258827209472656 \n",
      "Epoch: 6940 | MAE Train Loss: 59.62455749511719 | MAE Test Loss: 56.251243591308594 \n",
      "Epoch: 6950 | MAE Train Loss: 59.617286682128906 | MAE Test Loss: 56.243656158447266 \n",
      "Epoch: 6960 | MAE Train Loss: 59.61000442504883 | MAE Test Loss: 56.236080169677734 \n",
      "Epoch: 6970 | MAE Train Loss: 59.602725982666016 | MAE Test Loss: 56.22848129272461 \n",
      "Epoch: 6980 | MAE Train Loss: 59.5954475402832 | MAE Test Loss: 56.22090148925781 \n",
      "Epoch: 6990 | MAE Train Loss: 59.588172912597656 | MAE Test Loss: 56.21331787109375 \n",
      "Epoch: 7000 | MAE Train Loss: 59.58089828491211 | MAE Test Loss: 56.20573806762695 \n",
      "Epoch: 7010 | MAE Train Loss: 59.5736198425293 | MAE Test Loss: 56.19813919067383 \n",
      "Epoch: 7020 | MAE Train Loss: 59.566341400146484 | MAE Test Loss: 56.1905517578125 \n",
      "Epoch: 7030 | MAE Train Loss: 59.559059143066406 | MAE Test Loss: 56.18296813964844 \n",
      "Epoch: 7040 | MAE Train Loss: 59.55178451538086 | MAE Test Loss: 56.175384521484375 \n",
      "Epoch: 7050 | MAE Train Loss: 59.54450607299805 | MAE Test Loss: 56.16777038574219 \n",
      "Epoch: 7060 | MAE Train Loss: 59.5372314453125 | MAE Test Loss: 56.16019058227539 \n",
      "Epoch: 7070 | MAE Train Loss: 59.529945373535156 | MAE Test Loss: 56.15259552001953 \n",
      "Epoch: 7080 | MAE Train Loss: 59.522666931152344 | MAE Test Loss: 56.145023345947266 \n",
      "Epoch: 7090 | MAE Train Loss: 59.51538848876953 | MAE Test Loss: 56.13744354248047 \n",
      "Epoch: 7100 | MAE Train Loss: 59.50811767578125 | MAE Test Loss: 56.12985610961914 \n",
      "Epoch: 7110 | MAE Train Loss: 59.500831604003906 | MAE Test Loss: 56.12227249145508 \n",
      "Epoch: 7120 | MAE Train Loss: 59.493553161621094 | MAE Test Loss: 56.11466979980469 \n",
      "Epoch: 7130 | MAE Train Loss: 59.48628234863281 | MAE Test Loss: 56.107093811035156 \n",
      "Epoch: 7140 | MAE Train Loss: 59.479007720947266 | MAE Test Loss: 56.099510192871094 \n",
      "Epoch: 7150 | MAE Train Loss: 59.47172546386719 | MAE Test Loss: 56.091922760009766 \n",
      "Epoch: 7160 | MAE Train Loss: 59.464447021484375 | MAE Test Loss: 56.08432388305664 \n",
      "Epoch: 7170 | MAE Train Loss: 59.45716857910156 | MAE Test Loss: 56.07674789428711 \n",
      "Epoch: 7180 | MAE Train Loss: 59.44989013671875 | MAE Test Loss: 56.06916046142578 \n",
      "Epoch: 7190 | MAE Train Loss: 59.44260787963867 | MAE Test Loss: 56.061546325683594 \n",
      "Epoch: 7200 | MAE Train Loss: 59.43532943725586 | MAE Test Loss: 56.053958892822266 \n",
      "Epoch: 7210 | MAE Train Loss: 59.42805480957031 | MAE Test Loss: 56.046382904052734 \n",
      "Epoch: 7220 | MAE Train Loss: 59.420772552490234 | MAE Test Loss: 56.03880310058594 \n",
      "Epoch: 7230 | MAE Train Loss: 59.41349792480469 | MAE Test Loss: 56.03121566772461 \n",
      "Epoch: 7240 | MAE Train Loss: 59.40621566772461 | MAE Test Loss: 56.02363586425781 \n",
      "Epoch: 7250 | MAE Train Loss: 59.39894104003906 | MAE Test Loss: 56.01605224609375 \n",
      "Epoch: 7260 | MAE Train Loss: 59.391666412353516 | MAE Test Loss: 56.00847244262695 \n",
      "Epoch: 7270 | MAE Train Loss: 59.38438415527344 | MAE Test Loss: 56.00087356567383 \n",
      "Epoch: 7280 | MAE Train Loss: 59.37710952758789 | MAE Test Loss: 55.993289947509766 \n",
      "Epoch: 7290 | MAE Train Loss: 59.36983108520508 | MAE Test Loss: 55.9857063293457 \n",
      "Epoch: 7300 | MAE Train Loss: 59.362552642822266 | MAE Test Loss: 55.97810363769531 \n",
      "Epoch: 7310 | MAE Train Loss: 59.35527038574219 | MAE Test Loss: 55.97052764892578 \n",
      "Epoch: 7320 | MAE Train Loss: 59.347999572753906 | MAE Test Loss: 55.96294403076172 \n",
      "Epoch: 7330 | MAE Train Loss: 59.34071350097656 | MAE Test Loss: 55.95536422729492 \n",
      "Epoch: 7340 | MAE Train Loss: 59.33343505859375 | MAE Test Loss: 55.94773864746094 \n",
      "Epoch: 7350 | MAE Train Loss: 59.3261604309082 | MAE Test Loss: 55.940155029296875 \n",
      "Epoch: 7360 | MAE Train Loss: 59.318885803222656 | MAE Test Loss: 55.93257141113281 \n",
      "Epoch: 7370 | MAE Train Loss: 59.31160354614258 | MAE Test Loss: 55.924991607666016 \n",
      "Epoch: 7380 | MAE Train Loss: 59.30436706542969 | MAE Test Loss: 55.917293548583984 \n",
      "Epoch: 7390 | MAE Train Loss: 59.297157287597656 | MAE Test Loss: 55.90950393676758 \n",
      "Epoch: 7400 | MAE Train Loss: 59.289955139160156 | MAE Test Loss: 55.9017448425293 \n",
      "Epoch: 7410 | MAE Train Loss: 59.282745361328125 | MAE Test Loss: 55.89395523071289 \n",
      "Epoch: 7420 | MAE Train Loss: 59.27552795410156 | MAE Test Loss: 55.88619613647461 \n",
      "Epoch: 7430 | MAE Train Loss: 59.26832962036133 | MAE Test Loss: 55.878414154052734 \n",
      "Epoch: 7440 | MAE Train Loss: 59.26111602783203 | MAE Test Loss: 55.87062072753906 \n",
      "Epoch: 7450 | MAE Train Loss: 59.253910064697266 | MAE Test Loss: 55.862857818603516 \n",
      "Epoch: 7460 | MAE Train Loss: 59.246707916259766 | MAE Test Loss: 55.855072021484375 \n",
      "Epoch: 7470 | MAE Train Loss: 59.239498138427734 | MAE Test Loss: 55.84731674194336 \n",
      "Epoch: 7480 | MAE Train Loss: 59.2322883605957 | MAE Test Loss: 55.83953094482422 \n",
      "Epoch: 7490 | MAE Train Loss: 59.22507858276367 | MAE Test Loss: 55.83174133300781 \n",
      "Epoch: 7500 | MAE Train Loss: 59.21787643432617 | MAE Test Loss: 55.823978424072266 \n",
      "Epoch: 7510 | MAE Train Loss: 59.21065902709961 | MAE Test Loss: 55.816184997558594 \n",
      "Epoch: 7520 | MAE Train Loss: 59.20345687866211 | MAE Test Loss: 55.80842971801758 \n",
      "Epoch: 7530 | MAE Train Loss: 59.19625473022461 | MAE Test Loss: 55.8006591796875 \n",
      "Epoch: 7540 | MAE Train Loss: 59.18904495239258 | MAE Test Loss: 55.792869567871094 \n",
      "Epoch: 7550 | MAE Train Loss: 59.18183517456055 | MAE Test Loss: 55.78511047363281 \n",
      "Epoch: 7560 | MAE Train Loss: 59.174625396728516 | MAE Test Loss: 55.777320861816406 \n",
      "Epoch: 7570 | MAE Train Loss: 59.16741943359375 | MAE Test Loss: 55.76953125 \n",
      "Epoch: 7580 | MAE Train Loss: 59.160213470458984 | MAE Test Loss: 55.76177215576172 \n",
      "Epoch: 7590 | MAE Train Loss: 59.15300369262695 | MAE Test Loss: 55.753990173339844 \n",
      "Epoch: 7600 | MAE Train Loss: 59.14579772949219 | MAE Test Loss: 55.7462272644043 \n",
      "Epoch: 7610 | MAE Train Loss: 59.138587951660156 | MAE Test Loss: 55.738441467285156 \n",
      "Epoch: 7620 | MAE Train Loss: 59.131378173828125 | MAE Test Loss: 55.73066711425781 \n",
      "Epoch: 7630 | MAE Train Loss: 59.124168395996094 | MAE Test Loss: 55.72288131713867 \n",
      "Epoch: 7640 | MAE Train Loss: 59.11697006225586 | MAE Test Loss: 55.715118408203125 \n",
      "Epoch: 7650 | MAE Train Loss: 59.10975646972656 | MAE Test Loss: 55.70732879638672 \n",
      "Epoch: 7660 | MAE Train Loss: 59.10255432128906 | MAE Test Loss: 55.69956970214844 \n",
      "Epoch: 7670 | MAE Train Loss: 59.09534454345703 | MAE Test Loss: 55.6917839050293 \n",
      "Epoch: 7680 | MAE Train Loss: 59.088134765625 | MAE Test Loss: 55.68402099609375 \n",
      "Epoch: 7690 | MAE Train Loss: 59.080928802490234 | MAE Test Loss: 55.676231384277344 \n",
      "Epoch: 7700 | MAE Train Loss: 59.0737190246582 | MAE Test Loss: 55.6684455871582 \n",
      "Epoch: 7710 | MAE Train Loss: 59.06651306152344 | MAE Test Loss: 55.66069030761719 \n",
      "Epoch: 7720 | MAE Train Loss: 59.05930709838867 | MAE Test Loss: 55.652915954589844 \n",
      "Epoch: 7730 | MAE Train Loss: 59.05210494995117 | MAE Test Loss: 55.6451301574707 \n",
      "Epoch: 7740 | MAE Train Loss: 59.04488754272461 | MAE Test Loss: 55.637359619140625 \n",
      "Epoch: 7750 | MAE Train Loss: 59.03768539428711 | MAE Test Loss: 55.629573822021484 \n",
      "Epoch: 7760 | MAE Train Loss: 59.03047561645508 | MAE Test Loss: 55.62178421020508 \n",
      "Epoch: 7770 | MAE Train Loss: 59.02326583862305 | MAE Test Loss: 55.61403274536133 \n",
      "Epoch: 7780 | MAE Train Loss: 59.016056060791016 | MAE Test Loss: 55.60623550415039 \n",
      "Epoch: 7790 | MAE Train Loss: 59.008853912353516 | MAE Test Loss: 55.598480224609375 \n",
      "Epoch: 7800 | MAE Train Loss: 59.00163650512695 | MAE Test Loss: 55.5906982421875 \n",
      "Epoch: 7810 | MAE Train Loss: 58.99443817138672 | MAE Test Loss: 55.582916259765625 \n",
      "Epoch: 7820 | MAE Train Loss: 58.98722839355469 | MAE Test Loss: 55.575130462646484 \n",
      "Epoch: 7830 | MAE Train Loss: 58.98002243041992 | MAE Test Loss: 55.5673713684082 \n",
      "Epoch: 7840 | MAE Train Loss: 58.97281265258789 | MAE Test Loss: 55.55958557128906 \n",
      "Epoch: 7850 | MAE Train Loss: 58.965606689453125 | MAE Test Loss: 55.551822662353516 \n",
      "Epoch: 7860 | MAE Train Loss: 58.958396911621094 | MAE Test Loss: 55.54403305053711 \n",
      "Epoch: 7870 | MAE Train Loss: 58.95118713378906 | MAE Test Loss: 55.53628158569336 \n",
      "Epoch: 7880 | MAE Train Loss: 58.94398498535156 | MAE Test Loss: 55.52849197387695 \n",
      "Epoch: 7890 | MAE Train Loss: 58.936771392822266 | MAE Test Loss: 55.52070617675781 \n",
      "Epoch: 7900 | MAE Train Loss: 58.9295654296875 | MAE Test Loss: 55.51292419433594 \n",
      "Epoch: 7910 | MAE Train Loss: 58.92235565185547 | MAE Test Loss: 55.50516891479492 \n",
      "Epoch: 7920 | MAE Train Loss: 58.91514587402344 | MAE Test Loss: 55.49738693237305 \n",
      "Epoch: 7930 | MAE Train Loss: 58.90794372558594 | MAE Test Loss: 55.4896240234375 \n",
      "Epoch: 7940 | MAE Train Loss: 58.90073776245117 | MAE Test Loss: 55.481834411621094 \n",
      "Epoch: 7950 | MAE Train Loss: 58.893524169921875 | MAE Test Loss: 55.47404479980469 \n",
      "Epoch: 7960 | MAE Train Loss: 58.88632583618164 | MAE Test Loss: 55.466285705566406 \n",
      "Epoch: 7970 | MAE Train Loss: 58.87911605834961 | MAE Test Loss: 55.458499908447266 \n",
      "Epoch: 7980 | MAE Train Loss: 58.87190628051758 | MAE Test Loss: 55.45073699951172 \n",
      "Epoch: 7990 | MAE Train Loss: 58.86469650268555 | MAE Test Loss: 55.442962646484375 \n",
      "Epoch: 8000 | MAE Train Loss: 58.857486724853516 | MAE Test Loss: 55.43517303466797 \n",
      "Epoch: 8010 | MAE Train Loss: 58.85028076171875 | MAE Test Loss: 55.42742156982422 \n",
      "Epoch: 8020 | MAE Train Loss: 58.843074798583984 | MAE Test Loss: 55.41963195800781 \n",
      "Epoch: 8030 | MAE Train Loss: 58.83586502075195 | MAE Test Loss: 55.411842346191406 \n",
      "Epoch: 8040 | MAE Train Loss: 58.82865524291992 | MAE Test Loss: 55.404083251953125 \n",
      "Epoch: 8050 | MAE Train Loss: 58.82145309448242 | MAE Test Loss: 55.39628601074219 \n",
      "Epoch: 8060 | MAE Train Loss: 58.81424331665039 | MAE Test Loss: 55.38853454589844 \n",
      "Epoch: 8070 | MAE Train Loss: 58.807037353515625 | MAE Test Loss: 55.38074493408203 \n",
      "Epoch: 8080 | MAE Train Loss: 58.79983139038086 | MAE Test Loss: 55.37297439575195 \n",
      "Epoch: 8090 | MAE Train Loss: 58.7926139831543 | MAE Test Loss: 55.36518478393555 \n",
      "Epoch: 8100 | MAE Train Loss: 58.78541564941406 | MAE Test Loss: 55.357425689697266 \n",
      "Epoch: 8110 | MAE Train Loss: 58.778202056884766 | MAE Test Loss: 55.349632263183594 \n",
      "Epoch: 8120 | MAE Train Loss: 58.77100372314453 | MAE Test Loss: 55.34188461303711 \n",
      "Epoch: 8130 | MAE Train Loss: 58.763797760009766 | MAE Test Loss: 55.33408737182617 \n",
      "Epoch: 8140 | MAE Train Loss: 58.7565803527832 | MAE Test Loss: 55.32633590698242 \n",
      "Epoch: 8150 | MAE Train Loss: 58.74937438964844 | MAE Test Loss: 55.318546295166016 \n",
      "Epoch: 8160 | MAE Train Loss: 58.742164611816406 | MAE Test Loss: 55.31075668334961 \n",
      "Epoch: 8170 | MAE Train Loss: 58.734962463378906 | MAE Test Loss: 55.30299377441406 \n",
      "Epoch: 8180 | MAE Train Loss: 58.727752685546875 | MAE Test Loss: 55.29521942138672 \n",
      "Epoch: 8190 | MAE Train Loss: 58.72054672241211 | MAE Test Loss: 55.28743362426758 \n",
      "Epoch: 8200 | MAE Train Loss: 58.71333312988281 | MAE Test Loss: 55.2796745300293 \n",
      "Epoch: 8210 | MAE Train Loss: 58.70613098144531 | MAE Test Loss: 55.271888732910156 \n",
      "Epoch: 8220 | MAE Train Loss: 58.69892501831055 | MAE Test Loss: 55.26410675048828 \n",
      "Epoch: 8230 | MAE Train Loss: 58.691715240478516 | MAE Test Loss: 55.2563362121582 \n",
      "Epoch: 8240 | MAE Train Loss: 58.684513092041016 | MAE Test Loss: 55.2485466003418 \n",
      "Epoch: 8250 | MAE Train Loss: 58.67729568481445 | MAE Test Loss: 55.24079895019531 \n",
      "Epoch: 8260 | MAE Train Loss: 58.67009353637695 | MAE Test Loss: 55.233001708984375 \n",
      "Epoch: 8270 | MAE Train Loss: 58.66289138793945 | MAE Test Loss: 55.22524642944336 \n",
      "Epoch: 8280 | MAE Train Loss: 58.65568542480469 | MAE Test Loss: 55.21745681762695 \n",
      "Epoch: 8290 | MAE Train Loss: 58.64847183227539 | MAE Test Loss: 55.20967102050781 \n",
      "Epoch: 8300 | MAE Train Loss: 58.641265869140625 | MAE Test Loss: 55.20191192626953 \n",
      "Epoch: 8310 | MAE Train Loss: 58.634056091308594 | MAE Test Loss: 55.194122314453125 \n",
      "Epoch: 8320 | MAE Train Loss: 58.626853942871094 | MAE Test Loss: 55.186363220214844 \n",
      "Epoch: 8330 | MAE Train Loss: 58.619659423828125 | MAE Test Loss: 55.178611755371094 \n",
      "Epoch: 8340 | MAE Train Loss: 58.612571716308594 | MAE Test Loss: 55.17112731933594 \n",
      "Epoch: 8350 | MAE Train Loss: 58.60550308227539 | MAE Test Loss: 55.163612365722656 \n",
      "Epoch: 8360 | MAE Train Loss: 58.598419189453125 | MAE Test Loss: 55.1561279296875 \n",
      "Epoch: 8370 | MAE Train Loss: 58.59135055541992 | MAE Test Loss: 55.14864730834961 \n",
      "Epoch: 8380 | MAE Train Loss: 58.58427047729492 | MAE Test Loss: 55.14112854003906 \n",
      "Epoch: 8390 | MAE Train Loss: 58.57719421386719 | MAE Test Loss: 55.13365173339844 \n",
      "Epoch: 8400 | MAE Train Loss: 58.57011795043945 | MAE Test Loss: 55.126136779785156 \n",
      "Epoch: 8410 | MAE Train Loss: 58.56303787231445 | MAE Test Loss: 55.118648529052734 \n",
      "Epoch: 8420 | MAE Train Loss: 58.555965423583984 | MAE Test Loss: 55.111167907714844 \n",
      "Epoch: 8430 | MAE Train Loss: 58.54888916015625 | MAE Test Loss: 55.1036491394043 \n",
      "Epoch: 8440 | MAE Train Loss: 58.54181671142578 | MAE Test Loss: 55.096168518066406 \n",
      "Epoch: 8450 | MAE Train Loss: 58.53474044799805 | MAE Test Loss: 55.08864212036133 \n",
      "Epoch: 8460 | MAE Train Loss: 58.52766036987305 | MAE Test Loss: 55.0811653137207 \n",
      "Epoch: 8470 | MAE Train Loss: 58.52058792114258 | MAE Test Loss: 55.07368087768555 \n",
      "Epoch: 8480 | MAE Train Loss: 58.51350021362305 | MAE Test Loss: 55.066184997558594 \n",
      "Epoch: 8490 | MAE Train Loss: 58.50642776489258 | MAE Test Loss: 55.058658599853516 \n",
      "Epoch: 8500 | MAE Train Loss: 58.499351501464844 | MAE Test Loss: 55.051177978515625 \n",
      "Epoch: 8510 | MAE Train Loss: 58.49228286743164 | MAE Test Loss: 55.04368209838867 \n",
      "Epoch: 8520 | MAE Train Loss: 58.485198974609375 | MAE Test Loss: 55.036197662353516 \n",
      "Epoch: 8530 | MAE Train Loss: 58.47812271118164 | MAE Test Loss: 55.028682708740234 \n",
      "Epoch: 8540 | MAE Train Loss: 58.47105026245117 | MAE Test Loss: 55.02119827270508 \n",
      "Epoch: 8550 | MAE Train Loss: 58.46397018432617 | MAE Test Loss: 55.013675689697266 \n",
      "Epoch: 8560 | MAE Train Loss: 58.456905364990234 | MAE Test Loss: 55.00619888305664 \n",
      "Epoch: 8570 | MAE Train Loss: 58.44982147216797 | MAE Test Loss: 54.998714447021484 \n",
      "Epoch: 8580 | MAE Train Loss: 58.442745208740234 | MAE Test Loss: 54.99119567871094 \n",
      "Epoch: 8590 | MAE Train Loss: 58.435672760009766 | MAE Test Loss: 54.98371505737305 \n",
      "Epoch: 8600 | MAE Train Loss: 58.428592681884766 | MAE Test Loss: 54.9761962890625 \n",
      "Epoch: 8610 | MAE Train Loss: 58.42151641845703 | MAE Test Loss: 54.96871566772461 \n",
      "Epoch: 8620 | MAE Train Loss: 58.4144401550293 | MAE Test Loss: 54.96122360229492 \n",
      "Epoch: 8630 | MAE Train Loss: 58.40736389160156 | MAE Test Loss: 54.953704833984375 \n",
      "Epoch: 8640 | MAE Train Loss: 58.40028381347656 | MAE Test Loss: 54.94623565673828 \n",
      "Epoch: 8650 | MAE Train Loss: 58.39320373535156 | MAE Test Loss: 54.93871307373047 \n",
      "Epoch: 8660 | MAE Train Loss: 58.386131286621094 | MAE Test Loss: 54.93122863769531 \n",
      "Epoch: 8670 | MAE Train Loss: 58.37906265258789 | MAE Test Loss: 54.92371368408203 \n",
      "Epoch: 8680 | MAE Train Loss: 58.371986389160156 | MAE Test Loss: 54.91622543334961 \n",
      "Epoch: 8690 | MAE Train Loss: 58.36490249633789 | MAE Test Loss: 54.90874481201172 \n",
      "Epoch: 8700 | MAE Train Loss: 58.357826232910156 | MAE Test Loss: 54.90122604370117 \n",
      "Epoch: 8710 | MAE Train Loss: 58.35075378417969 | MAE Test Loss: 54.893741607666016 \n",
      "Epoch: 8720 | MAE Train Loss: 58.34367370605469 | MAE Test Loss: 54.8862419128418 \n",
      "Epoch: 8730 | MAE Train Loss: 58.33660125732422 | MAE Test Loss: 54.87876510620117 \n",
      "Epoch: 8740 | MAE Train Loss: 58.32952117919922 | MAE Test Loss: 54.87124252319336 \n",
      "Epoch: 8750 | MAE Train Loss: 58.32244110107422 | MAE Test Loss: 54.863765716552734 \n",
      "Epoch: 8760 | MAE Train Loss: 58.315372467041016 | MAE Test Loss: 54.85624313354492 \n",
      "Epoch: 8770 | MAE Train Loss: 58.30828857421875 | MAE Test Loss: 54.848758697509766 \n",
      "Epoch: 8780 | MAE Train Loss: 58.30121994018555 | MAE Test Loss: 54.84128189086914 \n",
      "Epoch: 8790 | MAE Train Loss: 58.29413986206055 | MAE Test Loss: 54.83375549316406 \n",
      "Epoch: 8800 | MAE Train Loss: 58.28705978393555 | MAE Test Loss: 54.82627487182617 \n",
      "Epoch: 8810 | MAE Train Loss: 58.27998733520508 | MAE Test Loss: 54.81875991821289 \n",
      "Epoch: 8820 | MAE Train Loss: 58.272911071777344 | MAE Test Loss: 54.811275482177734 \n",
      "Epoch: 8830 | MAE Train Loss: 58.26583480834961 | MAE Test Loss: 54.803794860839844 \n",
      "Epoch: 8840 | MAE Train Loss: 58.258758544921875 | MAE Test Loss: 54.7962760925293 \n",
      "Epoch: 8850 | MAE Train Loss: 58.25168228149414 | MAE Test Loss: 54.788795471191406 \n",
      "Epoch: 8860 | MAE Train Loss: 58.24460983276367 | MAE Test Loss: 54.781272888183594 \n",
      "Epoch: 8870 | MAE Train Loss: 58.23752975463867 | MAE Test Loss: 54.77378845214844 \n",
      "Epoch: 8880 | MAE Train Loss: 58.23045349121094 | MAE Test Loss: 54.766273498535156 \n",
      "Epoch: 8890 | MAE Train Loss: 58.2233772277832 | MAE Test Loss: 54.758792877197266 \n",
      "Epoch: 8900 | MAE Train Loss: 58.2162971496582 | MAE Test Loss: 54.751312255859375 \n",
      "Epoch: 8910 | MAE Train Loss: 58.20922088623047 | MAE Test Loss: 54.74378967285156 \n",
      "Epoch: 8920 | MAE Train Loss: 58.202152252197266 | MAE Test Loss: 54.73631286621094 \n",
      "Epoch: 8930 | MAE Train Loss: 58.195068359375 | MAE Test Loss: 54.72880554199219 \n",
      "Epoch: 8940 | MAE Train Loss: 58.187992095947266 | MAE Test Loss: 54.7213249206543 \n",
      "Epoch: 8950 | MAE Train Loss: 58.18091583251953 | MAE Test Loss: 54.71380615234375 \n",
      "Epoch: 8960 | MAE Train Loss: 58.17384338378906 | MAE Test Loss: 54.706321716308594 \n",
      "Epoch: 8970 | MAE Train Loss: 58.16676712036133 | MAE Test Loss: 54.69880676269531 \n",
      "Epoch: 8980 | MAE Train Loss: 58.15968704223633 | MAE Test Loss: 54.691322326660156 \n",
      "Epoch: 8990 | MAE Train Loss: 58.15261459350586 | MAE Test Loss: 54.683841705322266 \n",
      "Epoch: 9000 | MAE Train Loss: 58.145538330078125 | MAE Test Loss: 54.67632293701172 \n",
      "Epoch: 9010 | MAE Train Loss: 58.13845443725586 | MAE Test Loss: 54.66884231567383 \n",
      "Epoch: 9020 | MAE Train Loss: 58.131378173828125 | MAE Test Loss: 54.661319732666016 \n",
      "Epoch: 9030 | MAE Train Loss: 58.12430191040039 | MAE Test Loss: 54.65383529663086 \n",
      "Epoch: 9040 | MAE Train Loss: 58.11723327636719 | MAE Test Loss: 54.646358489990234 \n",
      "Epoch: 9050 | MAE Train Loss: 58.11015701293945 | MAE Test Loss: 54.63883590698242 \n",
      "Epoch: 9060 | MAE Train Loss: 58.10307693481445 | MAE Test Loss: 54.6313591003418 \n",
      "Epoch: 9070 | MAE Train Loss: 58.09600067138672 | MAE Test Loss: 54.62383270263672 \n",
      "Epoch: 9080 | MAE Train Loss: 58.088924407958984 | MAE Test Loss: 54.61635208129883 \n",
      "Epoch: 9090 | MAE Train Loss: 58.08184814453125 | MAE Test Loss: 54.60883712768555 \n",
      "Epoch: 9100 | MAE Train Loss: 58.07476806640625 | MAE Test Loss: 54.60135269165039 \n",
      "Epoch: 9110 | MAE Train Loss: 58.06769561767578 | MAE Test Loss: 54.5938720703125 \n",
      "Epoch: 9120 | MAE Train Loss: 58.06061935424805 | MAE Test Loss: 54.58634948730469 \n",
      "Epoch: 9130 | MAE Train Loss: 58.05354690551758 | MAE Test Loss: 54.57886505126953 \n",
      "Epoch: 9140 | MAE Train Loss: 58.04645919799805 | MAE Test Loss: 54.57137680053711 \n",
      "Epoch: 9150 | MAE Train Loss: 58.03939437866211 | MAE Test Loss: 54.56388854980469 \n",
      "Epoch: 9160 | MAE Train Loss: 58.032310485839844 | MAE Test Loss: 54.556365966796875 \n",
      "Epoch: 9170 | MAE Train Loss: 58.025230407714844 | MAE Test Loss: 54.54888916015625 \n",
      "Epoch: 9180 | MAE Train Loss: 58.018165588378906 | MAE Test Loss: 54.54136657714844 \n",
      "Epoch: 9190 | MAE Train Loss: 58.01108932495117 | MAE Test Loss: 54.53388214111328 \n",
      "Epoch: 9200 | MAE Train Loss: 58.004005432128906 | MAE Test Loss: 54.526405334472656 \n",
      "Epoch: 9210 | MAE Train Loss: 57.99693298339844 | MAE Test Loss: 54.51887893676758 \n",
      "Epoch: 9220 | MAE Train Loss: 57.9898567199707 | MAE Test Loss: 54.51140213012695 \n",
      "Epoch: 9230 | MAE Train Loss: 57.9827766418457 | MAE Test Loss: 54.50387954711914 \n",
      "Epoch: 9240 | MAE Train Loss: 57.975704193115234 | MAE Test Loss: 54.496402740478516 \n",
      "Epoch: 9250 | MAE Train Loss: 57.968624114990234 | MAE Test Loss: 54.48891830444336 \n",
      "Epoch: 9260 | MAE Train Loss: 57.9615478515625 | MAE Test Loss: 54.48139953613281 \n",
      "Epoch: 9270 | MAE Train Loss: 57.95447540283203 | MAE Test Loss: 54.47391891479492 \n",
      "Epoch: 9280 | MAE Train Loss: 57.9473991394043 | MAE Test Loss: 54.46639633178711 \n",
      "Epoch: 9290 | MAE Train Loss: 57.94032287597656 | MAE Test Loss: 54.458919525146484 \n",
      "Epoch: 9300 | MAE Train Loss: 57.9332389831543 | MAE Test Loss: 54.45139694213867 \n",
      "Epoch: 9310 | MAE Train Loss: 57.926170349121094 | MAE Test Loss: 54.44392013549805 \n",
      "Epoch: 9320 | MAE Train Loss: 57.919097900390625 | MAE Test Loss: 54.436431884765625 \n",
      "Epoch: 9330 | MAE Train Loss: 57.91201400756836 | MAE Test Loss: 54.42891311645508 \n",
      "Epoch: 9340 | MAE Train Loss: 57.904937744140625 | MAE Test Loss: 54.42143630981445 \n",
      "Epoch: 9350 | MAE Train Loss: 57.897857666015625 | MAE Test Loss: 54.4139289855957 \n",
      "Epoch: 9360 | MAE Train Loss: 57.89079284667969 | MAE Test Loss: 54.40645980834961 \n",
      "Epoch: 9370 | MAE Train Loss: 57.88370895385742 | MAE Test Loss: 54.398929595947266 \n",
      "Epoch: 9380 | MAE Train Loss: 57.87663269042969 | MAE Test Loss: 54.391448974609375 \n",
      "Epoch: 9390 | MAE Train Loss: 57.86955642700195 | MAE Test Loss: 54.383949279785156 \n",
      "Epoch: 9400 | MAE Train Loss: 57.86248016357422 | MAE Test Loss: 54.37700653076172 \n",
      "Epoch: 9410 | MAE Train Loss: 57.855403900146484 | MAE Test Loss: 54.37006759643555 \n",
      "Epoch: 9420 | MAE Train Loss: 57.848331451416016 | MAE Test Loss: 54.36302947998047 \n",
      "Epoch: 9430 | MAE Train Loss: 57.84124755859375 | MAE Test Loss: 54.3560905456543 \n",
      "Epoch: 9440 | MAE Train Loss: 57.83417892456055 | MAE Test Loss: 54.34904861450195 \n",
      "Epoch: 9450 | MAE Train Loss: 57.82709503173828 | MAE Test Loss: 54.34210968017578 \n",
      "Epoch: 9460 | MAE Train Loss: 57.82001876831055 | MAE Test Loss: 54.33516311645508 \n",
      "Epoch: 9470 | MAE Train Loss: 57.81294631958008 | MAE Test Loss: 54.328128814697266 \n",
      "Epoch: 9480 | MAE Train Loss: 57.805870056152344 | MAE Test Loss: 54.32118606567383 \n",
      "Epoch: 9490 | MAE Train Loss: 57.79879379272461 | MAE Test Loss: 54.314144134521484 \n",
      "Epoch: 9500 | MAE Train Loss: 57.79171371459961 | MAE Test Loss: 54.30720520019531 \n",
      "Epoch: 9510 | MAE Train Loss: 57.784637451171875 | MAE Test Loss: 54.3001594543457 \n",
      "Epoch: 9520 | MAE Train Loss: 57.77756118774414 | MAE Test Loss: 54.29322052001953 \n",
      "Epoch: 9530 | MAE Train Loss: 57.77048110961914 | MAE Test Loss: 54.286285400390625 \n",
      "Epoch: 9540 | MAE Train Loss: 57.76341247558594 | MAE Test Loss: 54.27923583984375 \n",
      "Epoch: 9550 | MAE Train Loss: 57.7563362121582 | MAE Test Loss: 54.27229690551758 \n",
      "Epoch: 9560 | MAE Train Loss: 57.74925231933594 | MAE Test Loss: 54.26530838012695 \n",
      "Epoch: 9570 | MAE Train Loss: 57.7421760559082 | MAE Test Loss: 54.258365631103516 \n",
      "Epoch: 9580 | MAE Train Loss: 57.735103607177734 | MAE Test Loss: 54.2513313293457 \n",
      "Epoch: 9590 | MAE Train Loss: 57.72802734375 | MAE Test Loss: 54.244388580322266 \n",
      "Epoch: 9600 | MAE Train Loss: 57.720951080322266 | MAE Test Loss: 54.23735046386719 \n",
      "Epoch: 9610 | MAE Train Loss: 57.71388244628906 | MAE Test Loss: 54.23040771484375 \n",
      "Epoch: 9620 | MAE Train Loss: 57.7067985534668 | MAE Test Loss: 54.223472595214844 \n",
      "Epoch: 9630 | MAE Train Loss: 57.6997184753418 | MAE Test Loss: 54.21642303466797 \n",
      "Epoch: 9640 | MAE Train Loss: 57.692649841308594 | MAE Test Loss: 54.2094841003418 \n",
      "Epoch: 9650 | MAE Train Loss: 57.685569763183594 | MAE Test Loss: 54.20244598388672 \n",
      "Epoch: 9660 | MAE Train Loss: 57.67849349975586 | MAE Test Loss: 54.19550323486328 \n",
      "Epoch: 9670 | MAE Train Loss: 57.67143630981445 | MAE Test Loss: 54.18867874145508 \n",
      "Epoch: 9680 | MAE Train Loss: 57.664493560791016 | MAE Test Loss: 54.18180465698242 \n",
      "Epoch: 9690 | MAE Train Loss: 57.65753936767578 | MAE Test Loss: 54.1749382019043 \n",
      "Epoch: 9700 | MAE Train Loss: 57.65060043334961 | MAE Test Loss: 54.168060302734375 \n",
      "Epoch: 9710 | MAE Train Loss: 57.64365768432617 | MAE Test Loss: 54.16118240356445 \n",
      "Epoch: 9720 | MAE Train Loss: 57.6367073059082 | MAE Test Loss: 54.1543083190918 \n",
      "Epoch: 9730 | MAE Train Loss: 57.62974548339844 | MAE Test Loss: 54.14742660522461 \n",
      "Epoch: 9740 | MAE Train Loss: 57.62281036376953 | MAE Test Loss: 54.140560150146484 \n",
      "Epoch: 9750 | MAE Train Loss: 57.61585998535156 | MAE Test Loss: 54.133689880371094 \n",
      "Epoch: 9760 | MAE Train Loss: 57.608909606933594 | MAE Test Loss: 54.12681198120117 \n",
      "Epoch: 9770 | MAE Train Loss: 57.601966857910156 | MAE Test Loss: 54.119937896728516 \n",
      "Epoch: 9780 | MAE Train Loss: 57.59502410888672 | MAE Test Loss: 54.113059997558594 \n",
      "Epoch: 9790 | MAE Train Loss: 57.58807373046875 | MAE Test Loss: 54.10618591308594 \n",
      "Epoch: 9800 | MAE Train Loss: 57.58112335205078 | MAE Test Loss: 54.09931182861328 \n",
      "Epoch: 9810 | MAE Train Loss: 57.57417297363281 | MAE Test Loss: 54.092445373535156 \n",
      "Epoch: 9820 | MAE Train Loss: 57.567230224609375 | MAE Test Loss: 54.08556365966797 \n",
      "Epoch: 9830 | MAE Train Loss: 57.560279846191406 | MAE Test Loss: 54.07868957519531 \n",
      "Epoch: 9840 | MAE Train Loss: 57.55336380004883 | MAE Test Loss: 54.071529388427734 \n",
      "Epoch: 9850 | MAE Train Loss: 57.5465087890625 | MAE Test Loss: 54.06431579589844 \n",
      "Epoch: 9860 | MAE Train Loss: 57.53974151611328 | MAE Test Loss: 54.05741882324219 \n",
      "Epoch: 9870 | MAE Train Loss: 57.532981872558594 | MAE Test Loss: 54.050628662109375 \n",
      "Epoch: 9880 | MAE Train Loss: 57.526222229003906 | MAE Test Loss: 54.04374313354492 \n",
      "Epoch: 9890 | MAE Train Loss: 57.51945495605469 | MAE Test Loss: 54.036956787109375 \n",
      "Epoch: 9900 | MAE Train Loss: 57.51268768310547 | MAE Test Loss: 54.03006362915039 \n",
      "Epoch: 9910 | MAE Train Loss: 57.505924224853516 | MAE Test Loss: 54.02327346801758 \n",
      "Epoch: 9920 | MAE Train Loss: 57.49916458129883 | MAE Test Loss: 54.0164909362793 \n",
      "Epoch: 9930 | MAE Train Loss: 57.49239730834961 | MAE Test Loss: 54.00960159301758 \n",
      "Epoch: 9940 | MAE Train Loss: 57.48563003540039 | MAE Test Loss: 54.0028190612793 \n",
      "Epoch: 9950 | MAE Train Loss: 57.47886276245117 | MAE Test Loss: 53.99592971801758 \n",
      "Epoch: 9960 | MAE Train Loss: 57.47209930419922 | MAE Test Loss: 53.9891357421875 \n",
      "Epoch: 9970 | MAE Train Loss: 57.465335845947266 | MAE Test Loss: 53.98224639892578 \n",
      "Epoch: 9980 | MAE Train Loss: 57.458580017089844 | MAE Test Loss: 53.975460052490234 \n",
      "Epoch: 9990 | MAE Train Loss: 57.45180892944336 | MAE Test Loss: 53.968570709228516 \n",
      "Epoch: 10000 | MAE Train Loss: 57.44504165649414 | MAE Test Loss: 53.9617805480957 \n",
      "Epoch: 10010 | MAE Train Loss: 57.43828201293945 | MAE Test Loss: 53.954891204833984 \n",
      "Epoch: 10020 | MAE Train Loss: 57.431514739990234 | MAE Test Loss: 53.9481086730957 \n",
      "Epoch: 10030 | MAE Train Loss: 57.42475128173828 | MAE Test Loss: 53.941219329833984 \n",
      "Epoch: 10040 | MAE Train Loss: 57.417991638183594 | MAE Test Loss: 53.9344367980957 \n",
      "Epoch: 10050 | MAE Train Loss: 57.411224365234375 | MAE Test Loss: 53.92764663696289 \n",
      "Epoch: 10060 | MAE Train Loss: 57.40446472167969 | MAE Test Loss: 53.92075729370117 \n",
      "Epoch: 10070 | MAE Train Loss: 57.39769744873047 | MAE Test Loss: 53.913970947265625 \n",
      "Epoch: 10080 | MAE Train Loss: 57.39093017578125 | MAE Test Loss: 53.90707778930664 \n",
      "Epoch: 10090 | MAE Train Loss: 57.3841667175293 | MAE Test Loss: 53.900291442871094 \n",
      "Epoch: 10100 | MAE Train Loss: 57.37740707397461 | MAE Test Loss: 53.893402099609375 \n",
      "Epoch: 10110 | MAE Train Loss: 57.37063980102539 | MAE Test Loss: 53.886619567871094 \n",
      "Epoch: 10120 | MAE Train Loss: 57.3638801574707 | MAE Test Loss: 53.879722595214844 \n",
      "Epoch: 10130 | MAE Train Loss: 57.357112884521484 | MAE Test Loss: 53.8729362487793 \n",
      "Epoch: 10140 | MAE Train Loss: 57.350337982177734 | MAE Test Loss: 53.86604690551758 \n",
      "Epoch: 10150 | MAE Train Loss: 57.34358215332031 | MAE Test Loss: 53.85926055908203 \n",
      "Epoch: 10160 | MAE Train Loss: 57.33681869506836 | MAE Test Loss: 53.85236740112305 \n",
      "Epoch: 10170 | MAE Train Loss: 57.33005142211914 | MAE Test Loss: 53.8455810546875 \n",
      "Epoch: 10180 | MAE Train Loss: 57.32328796386719 | MAE Test Loss: 53.83879470825195 \n",
      "Epoch: 10190 | MAE Train Loss: 57.3165283203125 | MAE Test Loss: 53.8319091796875 \n",
      "Epoch: 10200 | MAE Train Loss: 57.30976104736328 | MAE Test Loss: 53.82511901855469 \n",
      "Epoch: 10210 | MAE Train Loss: 57.30299377441406 | MAE Test Loss: 53.8182373046875 \n",
      "Epoch: 10220 | MAE Train Loss: 57.296234130859375 | MAE Test Loss: 53.811439514160156 \n",
      "Epoch: 10230 | MAE Train Loss: 57.289459228515625 | MAE Test Loss: 53.8045539855957 \n",
      "Epoch: 10240 | MAE Train Loss: 57.28272247314453 | MAE Test Loss: 53.79777908325195 \n",
      "Epoch: 10250 | MAE Train Loss: 57.276065826416016 | MAE Test Loss: 53.79121398925781 \n",
      "Epoch: 10260 | MAE Train Loss: 57.26943588256836 | MAE Test Loss: 53.784542083740234 \n",
      "Epoch: 10270 | MAE Train Loss: 57.26280212402344 | MAE Test Loss: 53.77786636352539 \n",
      "Epoch: 10280 | MAE Train Loss: 57.256168365478516 | MAE Test Loss: 53.77119445800781 \n",
      "Epoch: 10290 | MAE Train Loss: 57.249534606933594 | MAE Test Loss: 53.764522552490234 \n",
      "Epoch: 10300 | MAE Train Loss: 57.242897033691406 | MAE Test Loss: 53.757850646972656 \n",
      "Epoch: 10310 | MAE Train Loss: 57.236263275146484 | MAE Test Loss: 53.75117874145508 \n",
      "Epoch: 10320 | MAE Train Loss: 57.22962951660156 | MAE Test Loss: 53.7445068359375 \n",
      "Epoch: 10330 | MAE Train Loss: 57.222991943359375 | MAE Test Loss: 53.73783874511719 \n",
      "Epoch: 10340 | MAE Train Loss: 57.216365814208984 | MAE Test Loss: 53.73116683959961 \n",
      "Epoch: 10350 | MAE Train Loss: 57.209720611572266 | MAE Test Loss: 53.72449493408203 \n",
      "Epoch: 10360 | MAE Train Loss: 57.20309066772461 | MAE Test Loss: 53.71782302856445 \n",
      "Epoch: 10370 | MAE Train Loss: 57.19646453857422 | MAE Test Loss: 53.71114730834961 \n",
      "Epoch: 10380 | MAE Train Loss: 57.18983459472656 | MAE Test Loss: 53.70417785644531 \n",
      "Epoch: 10390 | MAE Train Loss: 57.18321228027344 | MAE Test Loss: 53.697303771972656 \n",
      "Epoch: 10400 | MAE Train Loss: 57.17660140991211 | MAE Test Loss: 53.690433502197266 \n",
      "Epoch: 10410 | MAE Train Loss: 57.1700325012207 | MAE Test Loss: 53.68368148803711 \n",
      "Epoch: 10420 | MAE Train Loss: 57.16364288330078 | MAE Test Loss: 53.676658630371094 \n",
      "Epoch: 10430 | MAE Train Loss: 57.157352447509766 | MAE Test Loss: 53.669883728027344 \n",
      "Epoch: 10440 | MAE Train Loss: 57.151065826416016 | MAE Test Loss: 53.6632080078125 \n",
      "Epoch: 10450 | MAE Train Loss: 57.1447868347168 | MAE Test Loss: 53.656429290771484 \n",
      "Epoch: 10460 | MAE Train Loss: 57.13848876953125 | MAE Test Loss: 53.64965057373047 \n",
      "Epoch: 10470 | MAE Train Loss: 57.1322021484375 | MAE Test Loss: 53.64287567138672 \n",
      "Epoch: 10480 | MAE Train Loss: 57.125911712646484 | MAE Test Loss: 53.63619613647461 \n",
      "Epoch: 10490 | MAE Train Loss: 57.1196403503418 | MAE Test Loss: 53.62942123413086 \n",
      "Epoch: 10500 | MAE Train Loss: 57.113346099853516 | MAE Test Loss: 53.622642517089844 \n",
      "Epoch: 10510 | MAE Train Loss: 57.1070556640625 | MAE Test Loss: 53.61595916748047 \n",
      "Epoch: 10520 | MAE Train Loss: 57.10077667236328 | MAE Test Loss: 53.609188079833984 \n",
      "Epoch: 10530 | MAE Train Loss: 57.09449005126953 | MAE Test Loss: 53.60240173339844 \n",
      "Epoch: 10540 | MAE Train Loss: 57.088199615478516 | MAE Test Loss: 53.59562683105469 \n",
      "Epoch: 10550 | MAE Train Loss: 57.0819206237793 | MAE Test Loss: 53.588951110839844 \n",
      "Epoch: 10560 | MAE Train Loss: 57.07563018798828 | MAE Test Loss: 53.58216857910156 \n",
      "Epoch: 10570 | MAE Train Loss: 57.06935119628906 | MAE Test Loss: 53.57539367675781 \n",
      "Epoch: 10580 | MAE Train Loss: 57.06305694580078 | MAE Test Loss: 53.56871032714844 \n",
      "Epoch: 10590 | MAE Train Loss: 57.0567741394043 | MAE Test Loss: 53.56193923950195 \n",
      "Epoch: 10600 | MAE Train Loss: 57.05048751831055 | MAE Test Loss: 53.555152893066406 \n",
      "Epoch: 10610 | MAE Train Loss: 57.04419708251953 | MAE Test Loss: 53.54847717285156 \n",
      "Epoch: 10620 | MAE Train Loss: 57.03791046142578 | MAE Test Loss: 53.54165267944336 \n",
      "Epoch: 10630 | MAE Train Loss: 57.031620025634766 | MAE Test Loss: 53.534976959228516 \n",
      "Epoch: 10640 | MAE Train Loss: 57.02534484863281 | MAE Test Loss: 53.528194427490234 \n",
      "Epoch: 10650 | MAE Train Loss: 57.0190544128418 | MAE Test Loss: 53.521419525146484 \n",
      "Epoch: 10660 | MAE Train Loss: 57.01277160644531 | MAE Test Loss: 53.514739990234375 \n",
      "Epoch: 10670 | MAE Train Loss: 57.00648498535156 | MAE Test Loss: 53.50796127319336 \n",
      "Epoch: 10680 | MAE Train Loss: 57.00019454956055 | MAE Test Loss: 53.50117874145508 \n",
      "Epoch: 10690 | MAE Train Loss: 56.99391555786133 | MAE Test Loss: 53.49440383911133 \n",
      "Epoch: 10700 | MAE Train Loss: 56.98762130737305 | MAE Test Loss: 53.487728118896484 \n",
      "Epoch: 10710 | MAE Train Loss: 56.98134231567383 | MAE Test Loss: 53.480953216552734 \n",
      "Epoch: 10720 | MAE Train Loss: 56.97505569458008 | MAE Test Loss: 53.47417068481445 \n",
      "Epoch: 10730 | MAE Train Loss: 56.96876525878906 | MAE Test Loss: 53.46749496459961 \n",
      "Epoch: 10740 | MAE Train Loss: 56.962486267089844 | MAE Test Loss: 53.46071243286133 \n",
      "Epoch: 10750 | MAE Train Loss: 56.956199645996094 | MAE Test Loss: 53.45393753051758 \n",
      "Epoch: 10760 | MAE Train Loss: 56.94990539550781 | MAE Test Loss: 53.4472541809082 \n",
      "Epoch: 10770 | MAE Train Loss: 56.94361877441406 | MAE Test Loss: 53.44048309326172 \n",
      "Epoch: 10780 | MAE Train Loss: 56.93733215332031 | MAE Test Loss: 53.433746337890625 \n",
      "Epoch: 10790 | MAE Train Loss: 56.93104934692383 | MAE Test Loss: 53.426979064941406 \n",
      "Epoch: 10800 | MAE Train Loss: 56.92476272583008 | MAE Test Loss: 53.420188903808594 \n",
      "Epoch: 10810 | MAE Train Loss: 56.91847610473633 | MAE Test Loss: 53.41351318359375 \n",
      "Epoch: 10820 | MAE Train Loss: 56.91218566894531 | MAE Test Loss: 53.406742095947266 \n",
      "Epoch: 10830 | MAE Train Loss: 56.905906677246094 | MAE Test Loss: 53.39996337890625 \n",
      "Epoch: 10840 | MAE Train Loss: 56.89961624145508 | MAE Test Loss: 53.39318084716797 \n",
      "Epoch: 10850 | MAE Train Loss: 56.89332962036133 | MAE Test Loss: 53.386505126953125 \n",
      "Epoch: 10860 | MAE Train Loss: 56.887046813964844 | MAE Test Loss: 53.379730224609375 \n",
      "Epoch: 10870 | MAE Train Loss: 56.88076400756836 | MAE Test Loss: 53.372955322265625 \n",
      "Epoch: 10880 | MAE Train Loss: 56.874473571777344 | MAE Test Loss: 53.36626434326172 \n",
      "Epoch: 10890 | MAE Train Loss: 56.86818313598633 | MAE Test Loss: 53.3594970703125 \n",
      "Epoch: 10900 | MAE Train Loss: 56.86190414428711 | MAE Test Loss: 53.35271453857422 \n",
      "Epoch: 10910 | MAE Train Loss: 56.85560607910156 | MAE Test Loss: 53.34604263305664 \n",
      "Epoch: 10920 | MAE Train Loss: 56.849327087402344 | MAE Test Loss: 53.339256286621094 \n",
      "Epoch: 10930 | MAE Train Loss: 56.843048095703125 | MAE Test Loss: 53.332481384277344 \n",
      "Epoch: 10940 | MAE Train Loss: 56.83675765991211 | MAE Test Loss: 53.32575607299805 \n",
      "Epoch: 10950 | MAE Train Loss: 56.83047103881836 | MAE Test Loss: 53.318973541259766 \n",
      "Epoch: 10960 | MAE Train Loss: 56.82418441772461 | MAE Test Loss: 53.31230163574219 \n",
      "Epoch: 10970 | MAE Train Loss: 56.817893981933594 | MAE Test Loss: 53.30551528930664 \n",
      "Epoch: 10980 | MAE Train Loss: 56.811614990234375 | MAE Test Loss: 53.29874038696289 \n",
      "Epoch: 10990 | MAE Train Loss: 56.80532455444336 | MAE Test Loss: 53.29196548461914 \n",
      "Epoch: 11000 | MAE Train Loss: 56.79904556274414 | MAE Test Loss: 53.285282135009766 \n",
      "Epoch: 11010 | MAE Train Loss: 56.79275894165039 | MAE Test Loss: 53.278507232666016 \n",
      "Epoch: 11020 | MAE Train Loss: 56.786460876464844 | MAE Test Loss: 53.271724700927734 \n",
      "Epoch: 11030 | MAE Train Loss: 56.780181884765625 | MAE Test Loss: 53.265052795410156 \n",
      "Epoch: 11040 | MAE Train Loss: 56.773895263671875 | MAE Test Loss: 53.25827407836914 \n",
      "Epoch: 11050 | MAE Train Loss: 56.76760482788086 | MAE Test Loss: 53.25149917602539 \n",
      "Epoch: 11060 | MAE Train Loss: 56.76132583618164 | MAE Test Loss: 53.24471664428711 \n",
      "Epoch: 11070 | MAE Train Loss: 56.755035400390625 | MAE Test Loss: 53.238040924072266 \n",
      "Epoch: 11080 | MAE Train Loss: 56.748748779296875 | MAE Test Loss: 53.231266021728516 \n",
      "Epoch: 11090 | MAE Train Loss: 56.74246597290039 | MAE Test Loss: 53.224483489990234 \n",
      "Epoch: 11100 | MAE Train Loss: 56.73617935180664 | MAE Test Loss: 53.217750549316406 \n",
      "Epoch: 11110 | MAE Train Loss: 56.72989273071289 | MAE Test Loss: 53.210975646972656 \n",
      "Epoch: 11120 | MAE Train Loss: 56.72360610961914 | MAE Test Loss: 53.20429992675781 \n",
      "Epoch: 11130 | MAE Train Loss: 56.717323303222656 | MAE Test Loss: 53.19752502441406 \n",
      "Epoch: 11140 | MAE Train Loss: 56.71102523803711 | MAE Test Loss: 53.190738677978516 \n",
      "Epoch: 11150 | MAE Train Loss: 56.704742431640625 | MAE Test Loss: 53.18406677246094 \n",
      "Epoch: 11160 | MAE Train Loss: 56.69845962524414 | MAE Test Loss: 53.177284240722656 \n",
      "Epoch: 11170 | MAE Train Loss: 56.692176818847656 | MAE Test Loss: 53.170501708984375 \n",
      "Epoch: 11180 | MAE Train Loss: 56.685882568359375 | MAE Test Loss: 53.16383361816406 \n",
      "Epoch: 11190 | MAE Train Loss: 56.679603576660156 | MAE Test Loss: 53.15705108642578 \n",
      "Epoch: 11200 | MAE Train Loss: 56.67332077026367 | MAE Test Loss: 53.15027618408203 \n",
      "Epoch: 11210 | MAE Train Loss: 56.66702651977539 | MAE Test Loss: 53.14349365234375 \n",
      "Epoch: 11220 | MAE Train Loss: 56.66074752807617 | MAE Test Loss: 53.136810302734375 \n",
      "Epoch: 11230 | MAE Train Loss: 56.654457092285156 | MAE Test Loss: 53.130035400390625 \n",
      "Epoch: 11240 | MAE Train Loss: 56.648170471191406 | MAE Test Loss: 53.123260498046875 \n",
      "Epoch: 11250 | MAE Train Loss: 56.64188766479492 | MAE Test Loss: 53.1165885925293 \n",
      "Epoch: 11260 | MAE Train Loss: 56.63560104370117 | MAE Test Loss: 53.1097526550293 \n",
      "Epoch: 11270 | MAE Train Loss: 56.629302978515625 | MAE Test Loss: 53.10307693481445 \n",
      "Epoch: 11280 | MAE Train Loss: 56.623023986816406 | MAE Test Loss: 53.0963020324707 \n",
      "Epoch: 11290 | MAE Train Loss: 56.61674118041992 | MAE Test Loss: 53.08951950073242 \n",
      "Epoch: 11300 | MAE Train Loss: 56.61044692993164 | MAE Test Loss: 53.08284378051758 \n",
      "Epoch: 11310 | MAE Train Loss: 56.60416793823242 | MAE Test Loss: 53.0760612487793 \n",
      "Epoch: 11320 | MAE Train Loss: 56.59788131713867 | MAE Test Loss: 53.06928634643555 \n",
      "Epoch: 11330 | MAE Train Loss: 56.591590881347656 | MAE Test Loss: 53.06261444091797 \n",
      "Epoch: 11340 | MAE Train Loss: 56.58530807495117 | MAE Test Loss: 53.05582809448242 \n",
      "Epoch: 11350 | MAE Train Loss: 56.57902526855469 | MAE Test Loss: 53.04905319213867 \n",
      "Epoch: 11360 | MAE Train Loss: 56.57273483276367 | MAE Test Loss: 53.04227828979492 \n",
      "Epoch: 11370 | MAE Train Loss: 56.56645202636719 | MAE Test Loss: 53.03559494018555 \n",
      "Epoch: 11380 | MAE Train Loss: 56.56016540527344 | MAE Test Loss: 53.028812408447266 \n",
      "Epoch: 11390 | MAE Train Loss: 56.55387496948242 | MAE Test Loss: 53.02204513549805 \n",
      "Epoch: 11400 | MAE Train Loss: 56.54758834838867 | MAE Test Loss: 53.01536178588867 \n",
      "Epoch: 11410 | MAE Train Loss: 56.54130172729492 | MAE Test Loss: 53.00857925415039 \n",
      "Epoch: 11420 | MAE Train Loss: 56.5350227355957 | MAE Test Loss: 53.001861572265625 \n",
      "Epoch: 11430 | MAE Train Loss: 56.52873229980469 | MAE Test Loss: 52.995079040527344 \n",
      "Epoch: 11440 | MAE Train Loss: 56.52244567871094 | MAE Test Loss: 52.988304138183594 \n",
      "Epoch: 11450 | MAE Train Loss: 56.51615524291992 | MAE Test Loss: 52.98162078857422 \n",
      "Epoch: 11460 | MAE Train Loss: 56.5098762512207 | MAE Test Loss: 52.97483825683594 \n",
      "Epoch: 11470 | MAE Train Loss: 56.50358581542969 | MAE Test Loss: 52.96806335449219 \n",
      "Epoch: 11480 | MAE Train Loss: 56.49729919433594 | MAE Test Loss: 52.961387634277344 \n",
      "Epoch: 11490 | MAE Train Loss: 56.49101638793945 | MAE Test Loss: 52.95460510253906 \n",
      "Epoch: 11500 | MAE Train Loss: 56.4847297668457 | MAE Test Loss: 52.94782638549805 \n",
      "Epoch: 11510 | MAE Train Loss: 56.47844314575195 | MAE Test Loss: 52.94105529785156 \n",
      "Epoch: 11520 | MAE Train Loss: 56.4721565246582 | MAE Test Loss: 52.93437194824219 \n",
      "Epoch: 11530 | MAE Train Loss: 56.46587371826172 | MAE Test Loss: 52.92759704589844 \n",
      "Epoch: 11540 | MAE Train Loss: 56.45958709716797 | MAE Test Loss: 52.92082214355469 \n",
      "Epoch: 11550 | MAE Train Loss: 56.45330047607422 | MAE Test Loss: 52.914146423339844 \n",
      "Epoch: 11560 | MAE Train Loss: 56.447017669677734 | MAE Test Loss: 52.90736389160156 \n",
      "Epoch: 11570 | MAE Train Loss: 56.44072723388672 | MAE Test Loss: 52.90058898925781 \n",
      "Epoch: 11580 | MAE Train Loss: 56.43443298339844 | MAE Test Loss: 52.893802642822266 \n",
      "Epoch: 11590 | MAE Train Loss: 56.42815399169922 | MAE Test Loss: 52.88713073730469 \n",
      "Epoch: 11600 | MAE Train Loss: 56.421871185302734 | MAE Test Loss: 52.880348205566406 \n",
      "Epoch: 11610 | MAE Train Loss: 56.41557693481445 | MAE Test Loss: 52.873573303222656 \n",
      "Epoch: 11620 | MAE Train Loss: 56.40929412841797 | MAE Test Loss: 52.86684799194336 \n",
      "Epoch: 11630 | MAE Train Loss: 56.40300750732422 | MAE Test Loss: 52.86006164550781 \n",
      "Epoch: 11640 | MAE Train Loss: 56.39672088623047 | MAE Test Loss: 52.853389739990234 \n",
      "Epoch: 11650 | MAE Train Loss: 56.390438079833984 | MAE Test Loss: 52.84660720825195 \n",
      "Epoch: 11660 | MAE Train Loss: 56.384151458740234 | MAE Test Loss: 52.839839935302734 \n",
      "Epoch: 11670 | MAE Train Loss: 56.377864837646484 | MAE Test Loss: 52.83315658569336 \n",
      "Epoch: 11680 | MAE Train Loss: 56.37158203125 | MAE Test Loss: 52.82637405395508 \n",
      "Epoch: 11690 | MAE Train Loss: 56.36529541015625 | MAE Test Loss: 52.81959915161133 \n",
      "Epoch: 11700 | MAE Train Loss: 56.359004974365234 | MAE Test Loss: 52.812923431396484 \n",
      "Epoch: 11710 | MAE Train Loss: 56.352718353271484 | MAE Test Loss: 52.80613708496094 \n",
      "Epoch: 11720 | MAE Train Loss: 56.346431732177734 | MAE Test Loss: 52.79936599731445 \n",
      "Epoch: 11730 | MAE Train Loss: 56.34014892578125 | MAE Test Loss: 52.79258346557617 \n",
      "Epoch: 11740 | MAE Train Loss: 56.3338623046875 | MAE Test Loss: 52.78590774536133 \n",
      "Epoch: 11750 | MAE Train Loss: 56.32757568359375 | MAE Test Loss: 52.77912521362305 \n",
      "Epoch: 11760 | MAE Train Loss: 56.321292877197266 | MAE Test Loss: 52.77235794067383 \n",
      "Epoch: 11770 | MAE Train Loss: 56.31501007080078 | MAE Test Loss: 52.76567459106445 \n",
      "Epoch: 11780 | MAE Train Loss: 56.3087158203125 | MAE Test Loss: 52.75884246826172 \n",
      "Epoch: 11790 | MAE Train Loss: 56.30243682861328 | MAE Test Loss: 52.752166748046875 \n",
      "Epoch: 11800 | MAE Train Loss: 56.296146392822266 | MAE Test Loss: 52.745384216308594 \n",
      "Epoch: 11810 | MAE Train Loss: 56.289859771728516 | MAE Test Loss: 52.738609313964844 \n",
      "Epoch: 11820 | MAE Train Loss: 56.2835693359375 | MAE Test Loss: 52.73193359375 \n",
      "Epoch: 11830 | MAE Train Loss: 56.277286529541016 | MAE Test Loss: 52.72515106201172 \n",
      "Epoch: 11840 | MAE Train Loss: 56.27099609375 | MAE Test Loss: 52.71837615966797 \n",
      "Epoch: 11850 | MAE Train Loss: 56.264713287353516 | MAE Test Loss: 52.711700439453125 \n",
      "Epoch: 11860 | MAE Train Loss: 56.25843048095703 | MAE Test Loss: 52.70492935180664 \n",
      "Epoch: 11870 | MAE Train Loss: 56.252140045166016 | MAE Test Loss: 52.698143005371094 \n",
      "Epoch: 11880 | MAE Train Loss: 56.24585723876953 | MAE Test Loss: 52.691368103027344 \n",
      "Epoch: 11890 | MAE Train Loss: 56.23956298828125 | MAE Test Loss: 52.68468475341797 \n",
      "Epoch: 11900 | MAE Train Loss: 56.233280181884766 | MAE Test Loss: 52.67790603637695 \n",
      "Epoch: 11910 | MAE Train Loss: 56.226993560791016 | MAE Test Loss: 52.67112731933594 \n",
      "Epoch: 11920 | MAE Train Loss: 56.220703125 | MAE Test Loss: 52.664451599121094 \n",
      "Epoch: 11930 | MAE Train Loss: 56.21442413330078 | MAE Test Loss: 52.65766525268555 \n",
      "Epoch: 11940 | MAE Train Loss: 56.20813751220703 | MAE Test Loss: 52.65095138549805 \n",
      "Epoch: 11950 | MAE Train Loss: 56.20185089111328 | MAE Test Loss: 52.644168853759766 \n",
      "Epoch: 11960 | MAE Train Loss: 56.1955680847168 | MAE Test Loss: 52.637386322021484 \n",
      "Epoch: 11970 | MAE Train Loss: 56.18927764892578 | MAE Test Loss: 52.63071060180664 \n",
      "Epoch: 11980 | MAE Train Loss: 56.1829948425293 | MAE Test Loss: 52.62393569946289 \n",
      "Epoch: 11990 | MAE Train Loss: 56.17670440673828 | MAE Test Loss: 52.61715316772461 \n",
      "Epoch: 12000 | MAE Train Loss: 56.1704216003418 | MAE Test Loss: 52.610477447509766 \n",
      "Epoch: 12010 | MAE Train Loss: 56.164127349853516 | MAE Test Loss: 52.603694915771484 \n",
      "Epoch: 12020 | MAE Train Loss: 56.15785598754883 | MAE Test Loss: 52.596920013427734 \n",
      "Epoch: 12030 | MAE Train Loss: 56.15155792236328 | MAE Test Loss: 52.590145111083984 \n",
      "Epoch: 12040 | MAE Train Loss: 56.14527130126953 | MAE Test Loss: 52.58346939086914 \n",
      "Epoch: 12050 | MAE Train Loss: 56.13898849487305 | MAE Test Loss: 52.57669448852539 \n",
      "Epoch: 12060 | MAE Train Loss: 56.132713317871094 | MAE Test Loss: 52.569820404052734 \n",
      "Epoch: 12070 | MAE Train Loss: 56.12646484375 | MAE Test Loss: 52.562896728515625 \n",
      "Epoch: 12080 | MAE Train Loss: 56.120243072509766 | MAE Test Loss: 52.55583953857422 \n",
      "Epoch: 12090 | MAE Train Loss: 56.1140022277832 | MAE Test Loss: 52.548736572265625 \n",
      "Epoch: 12100 | MAE Train Loss: 56.10776901245117 | MAE Test Loss: 52.541725158691406 \n",
      "Epoch: 12110 | MAE Train Loss: 56.10154724121094 | MAE Test Loss: 52.53461837768555 \n",
      "Epoch: 12120 | MAE Train Loss: 56.095314025878906 | MAE Test Loss: 52.527610778808594 \n",
      "Epoch: 12130 | MAE Train Loss: 56.089080810546875 | MAE Test Loss: 52.52059555053711 \n",
      "Epoch: 12140 | MAE Train Loss: 56.082855224609375 | MAE Test Loss: 52.51349639892578 \n",
      "Epoch: 12150 | MAE Train Loss: 56.07662582397461 | MAE Test Loss: 52.5064811706543 \n",
      "Epoch: 12160 | MAE Train Loss: 56.07038879394531 | MAE Test Loss: 52.4993782043457 \n",
      "Epoch: 12170 | MAE Train Loss: 56.06415939331055 | MAE Test Loss: 52.492366790771484 \n",
      "Epoch: 12180 | MAE Train Loss: 56.05792999267578 | MAE Test Loss: 52.48530578613281 \n",
      "Epoch: 12190 | MAE Train Loss: 56.051700592041016 | MAE Test Loss: 52.478206634521484 \n",
      "Epoch: 12200 | MAE Train Loss: 56.04547119140625 | MAE Test Loss: 52.471195220947266 \n",
      "Epoch: 12210 | MAE Train Loss: 56.03923797607422 | MAE Test Loss: 52.46417999267578 \n",
      "Epoch: 12220 | MAE Train Loss: 56.03300857543945 | MAE Test Loss: 52.45708084106445 \n",
      "Epoch: 12230 | MAE Train Loss: 56.02677917480469 | MAE Test Loss: 52.4500617980957 \n",
      "Epoch: 12240 | MAE Train Loss: 56.02054214477539 | MAE Test Loss: 52.442970275878906 \n",
      "Epoch: 12250 | MAE Train Loss: 56.014312744140625 | MAE Test Loss: 52.43594741821289 \n",
      "Epoch: 12260 | MAE Train Loss: 56.00808334350586 | MAE Test Loss: 52.42884826660156 \n",
      "Epoch: 12270 | MAE Train Loss: 56.00185775756836 | MAE Test Loss: 52.421836853027344 \n",
      "Epoch: 12280 | MAE Train Loss: 55.99562454223633 | MAE Test Loss: 52.414730072021484 \n",
      "Epoch: 12290 | MAE Train Loss: 55.98938751220703 | MAE Test Loss: 52.40771484375 \n",
      "Epoch: 12300 | MAE Train Loss: 55.983158111572266 | MAE Test Loss: 52.40070724487305 \n",
      "Epoch: 12310 | MAE Train Loss: 55.976932525634766 | MAE Test Loss: 52.39360427856445 \n",
      "Epoch: 12320 | MAE Train Loss: 55.970699310302734 | MAE Test Loss: 52.3865966796875 \n",
      "Epoch: 12330 | MAE Train Loss: 55.9644660949707 | MAE Test Loss: 52.379486083984375 \n",
      "Epoch: 12340 | MAE Train Loss: 55.95823669433594 | MAE Test Loss: 52.37247085571289 \n",
      "Epoch: 12350 | MAE Train Loss: 55.95200729370117 | MAE Test Loss: 52.36537170410156 \n",
      "Epoch: 12360 | MAE Train Loss: 55.945777893066406 | MAE Test Loss: 52.35835266113281 \n",
      "Epoch: 12370 | MAE Train Loss: 55.93954849243164 | MAE Test Loss: 52.351261138916016 \n",
      "Epoch: 12380 | MAE Train Loss: 55.933311462402344 | MAE Test Loss: 52.344242095947266 \n",
      "Epoch: 12390 | MAE Train Loss: 55.927085876464844 | MAE Test Loss: 52.33723068237305 \n",
      "Epoch: 12400 | MAE Train Loss: 55.92085647583008 | MAE Test Loss: 52.33013153076172 \n",
      "Epoch: 12410 | MAE Train Loss: 55.91462707519531 | MAE Test Loss: 52.3231201171875 \n",
      "Epoch: 12420 | MAE Train Loss: 55.908390045166016 | MAE Test Loss: 52.31605911254883 \n",
      "Epoch: 12430 | MAE Train Loss: 55.90216064453125 | MAE Test Loss: 52.308956146240234 \n",
      "Epoch: 12440 | MAE Train Loss: 55.895931243896484 | MAE Test Loss: 52.301944732666016 \n",
      "Epoch: 12450 | MAE Train Loss: 55.88969421386719 | MAE Test Loss: 52.294837951660156 \n",
      "Epoch: 12460 | MAE Train Loss: 55.88346481323242 | MAE Test Loss: 52.28782653808594 \n",
      "Epoch: 12470 | MAE Train Loss: 55.877235412597656 | MAE Test Loss: 52.28073501586914 \n",
      "Epoch: 12480 | MAE Train Loss: 55.87100601196289 | MAE Test Loss: 52.273712158203125 \n",
      "Epoch: 12490 | MAE Train Loss: 55.864776611328125 | MAE Test Loss: 52.266700744628906 \n",
      "Epoch: 12500 | MAE Train Loss: 55.858551025390625 | MAE Test Loss: 52.25960159301758 \n",
      "Epoch: 12510 | MAE Train Loss: 55.85232162475586 | MAE Test Loss: 52.25258255004883 \n",
      "Epoch: 12520 | MAE Train Loss: 55.84608459472656 | MAE Test Loss: 52.24552917480469 \n",
      "Epoch: 12530 | MAE Train Loss: 55.8398551940918 | MAE Test Loss: 52.23842239379883 \n",
      "Epoch: 12540 | MAE Train Loss: 55.83362579345703 | MAE Test Loss: 52.23141098022461 \n",
      "Epoch: 12550 | MAE Train Loss: 55.827396392822266 | MAE Test Loss: 52.224308013916016 \n",
      "Epoch: 12560 | MAE Train Loss: 55.821163177490234 | MAE Test Loss: 52.21730041503906 \n",
      "Epoch: 12570 | MAE Train Loss: 55.81493377685547 | MAE Test Loss: 52.21023941040039 \n",
      "Epoch: 12580 | MAE Train Loss: 55.80870056152344 | MAE Test Loss: 52.20322799682617 \n",
      "Epoch: 12590 | MAE Train Loss: 55.802467346191406 | MAE Test Loss: 52.19612503051758 \n",
      "Epoch: 12600 | MAE Train Loss: 55.79623794555664 | MAE Test Loss: 52.189117431640625 \n",
      "Epoch: 12610 | MAE Train Loss: 55.790008544921875 | MAE Test Loss: 52.1820068359375 \n",
      "Epoch: 12620 | MAE Train Loss: 55.78377914428711 | MAE Test Loss: 52.17499542236328 \n",
      "Epoch: 12630 | MAE Train Loss: 55.77754211425781 | MAE Test Loss: 52.16789245605469 \n",
      "Epoch: 12640 | MAE Train Loss: 55.77131652832031 | MAE Test Loss: 52.16088104248047 \n",
      "Epoch: 12650 | MAE Train Loss: 55.76508331298828 | MAE Test Loss: 52.15386962890625 \n",
      "Epoch: 12660 | MAE Train Loss: 55.758853912353516 | MAE Test Loss: 52.14676284790039 \n",
      "Epoch: 12670 | MAE Train Loss: 55.75262451171875 | MAE Test Loss: 52.13970947265625 \n",
      "Epoch: 12680 | MAE Train Loss: 55.74639129638672 | MAE Test Loss: 52.1326904296875 \n",
      "Epoch: 12690 | MAE Train Loss: 55.74016189575195 | MAE Test Loss: 52.1255989074707 \n",
      "Epoch: 12700 | MAE Train Loss: 55.73393249511719 | MAE Test Loss: 52.11857986450195 \n",
      "Epoch: 12710 | MAE Train Loss: 55.72769546508789 | MAE Test Loss: 52.111480712890625 \n",
      "Epoch: 12720 | MAE Train Loss: 55.721473693847656 | MAE Test Loss: 52.10446548461914 \n",
      "Epoch: 12730 | MAE Train Loss: 55.71523666381836 | MAE Test Loss: 52.09736633300781 \n",
      "Epoch: 12740 | MAE Train Loss: 55.70901107788086 | MAE Test Loss: 52.09034729003906 \n",
      "Epoch: 12750 | MAE Train Loss: 55.702781677246094 | MAE Test Loss: 52.083343505859375 \n",
      "Epoch: 12760 | MAE Train Loss: 55.69655227661133 | MAE Test Loss: 52.07623291015625 \n",
      "Epoch: 12770 | MAE Train Loss: 55.69031524658203 | MAE Test Loss: 52.069175720214844 \n",
      "Epoch: 12780 | MAE Train Loss: 55.684085845947266 | MAE Test Loss: 52.062164306640625 \n",
      "Epoch: 12790 | MAE Train Loss: 55.6778564453125 | MAE Test Loss: 52.05506134033203 \n",
      "Epoch: 12800 | MAE Train Loss: 55.671627044677734 | MAE Test Loss: 52.04804229736328 \n",
      "Epoch: 12810 | MAE Train Loss: 55.66539001464844 | MAE Test Loss: 52.040950775146484 \n",
      "Epoch: 12820 | MAE Train Loss: 55.65916061401367 | MAE Test Loss: 52.033931732177734 \n",
      "Epoch: 12830 | MAE Train Loss: 55.652923583984375 | MAE Test Loss: 52.02691650390625 \n",
      "Epoch: 12840 | MAE Train Loss: 55.64670944213867 | MAE Test Loss: 52.01981735229492 \n",
      "Epoch: 12850 | MAE Train Loss: 55.64046859741211 | MAE Test Loss: 52.0128059387207 \n",
      "Epoch: 12860 | MAE Train Loss: 55.634239196777344 | MAE Test Loss: 52.0057487487793 \n",
      "Epoch: 12870 | MAE Train Loss: 55.62800979614258 | MAE Test Loss: 51.9986457824707 \n",
      "Epoch: 12880 | MAE Train Loss: 55.62177276611328 | MAE Test Loss: 51.99162673950195 \n",
      "Epoch: 12890 | MAE Train Loss: 55.615543365478516 | MAE Test Loss: 51.984527587890625 \n",
      "Epoch: 12900 | MAE Train Loss: 55.60931396484375 | MAE Test Loss: 51.977516174316406 \n",
      "Epoch: 12910 | MAE Train Loss: 55.603084564208984 | MAE Test Loss: 51.970462799072266 \n",
      "Epoch: 12920 | MAE Train Loss: 55.59685516357422 | MAE Test Loss: 51.96345138549805 \n",
      "Epoch: 12930 | MAE Train Loss: 55.59062576293945 | MAE Test Loss: 51.95634460449219 \n",
      "Epoch: 12940 | MAE Train Loss: 55.58439254760742 | MAE Test Loss: 51.94933319091797 \n",
      "Epoch: 12950 | MAE Train Loss: 55.57815933227539 | MAE Test Loss: 51.942230224609375 \n",
      "Epoch: 12960 | MAE Train Loss: 55.57193374633789 | MAE Test Loss: 51.935218811035156 \n",
      "Epoch: 12970 | MAE Train Loss: 55.565704345703125 | MAE Test Loss: 51.92811965942383 \n",
      "Epoch: 12980 | MAE Train Loss: 55.55947494506836 | MAE Test Loss: 51.92110824584961 \n",
      "Epoch: 12990 | MAE Train Loss: 55.55323791503906 | MAE Test Loss: 51.91400146484375 \n",
      "Epoch: 13000 | MAE Train Loss: 55.54701232910156 | MAE Test Loss: 51.906986236572266 \n",
      "Epoch: 13010 | MAE Train Loss: 55.5407829284668 | MAE Test Loss: 51.89992904663086 \n",
      "Epoch: 13020 | MAE Train Loss: 55.5345458984375 | MAE Test Loss: 51.89291763305664 \n",
      "Epoch: 13030 | MAE Train Loss: 55.528324127197266 | MAE Test Loss: 51.88581466674805 \n",
      "Epoch: 13040 | MAE Train Loss: 55.52208709716797 | MAE Test Loss: 51.87880325317383 \n",
      "Epoch: 13050 | MAE Train Loss: 55.5158576965332 | MAE Test Loss: 51.8717041015625 \n",
      "Epoch: 13060 | MAE Train Loss: 55.50962829589844 | MAE Test Loss: 51.86468505859375 \n",
      "Epoch: 13070 | MAE Train Loss: 55.50339889526367 | MAE Test Loss: 51.85759353637695 \n",
      "Epoch: 13080 | MAE Train Loss: 55.49716567993164 | MAE Test Loss: 51.85057067871094 \n",
      "Epoch: 13090 | MAE Train Loss: 55.490936279296875 | MAE Test Loss: 51.843563079833984 \n",
      "Epoch: 13100 | MAE Train Loss: 55.484718322753906 | MAE Test Loss: 51.83646011352539 \n",
      "Epoch: 13110 | MAE Train Loss: 55.478477478027344 | MAE Test Loss: 51.82939910888672 \n",
      "Epoch: 13120 | MAE Train Loss: 55.47224807739258 | MAE Test Loss: 51.822391510009766 \n",
      "Epoch: 13130 | MAE Train Loss: 55.46601486206055 | MAE Test Loss: 51.81529235839844 \n",
      "Epoch: 13140 | MAE Train Loss: 55.45978546142578 | MAE Test Loss: 51.80827713012695 \n",
      "Epoch: 13150 | MAE Train Loss: 55.453556060791016 | MAE Test Loss: 51.801177978515625 \n",
      "Epoch: 13160 | MAE Train Loss: 55.44732666015625 | MAE Test Loss: 51.794166564941406 \n",
      "Epoch: 13170 | MAE Train Loss: 55.441097259521484 | MAE Test Loss: 51.78706359863281 \n",
      "Epoch: 13180 | MAE Train Loss: 55.43486785888672 | MAE Test Loss: 51.78004837036133 \n",
      "Epoch: 13190 | MAE Train Loss: 55.42863464355469 | MAE Test Loss: 51.77303695678711 \n",
      "Epoch: 13200 | MAE Train Loss: 55.42241287231445 | MAE Test Loss: 51.76593780517578 \n",
      "Epoch: 13210 | MAE Train Loss: 55.416175842285156 | MAE Test Loss: 51.75887680053711 \n",
      "Epoch: 13220 | MAE Train Loss: 55.40993881225586 | MAE Test Loss: 51.75186538696289 \n",
      "Epoch: 13230 | MAE Train Loss: 55.403709411621094 | MAE Test Loss: 51.7447624206543 \n",
      "Epoch: 13240 | MAE Train Loss: 55.39748764038086 | MAE Test Loss: 51.737754821777344 \n",
      "Epoch: 13250 | MAE Train Loss: 55.39125442504883 | MAE Test Loss: 51.73064422607422 \n",
      "Epoch: 13260 | MAE Train Loss: 55.38502502441406 | MAE Test Loss: 51.723636627197266 \n",
      "Epoch: 13270 | MAE Train Loss: 55.3787956237793 | MAE Test Loss: 51.71662139892578 \n",
      "Epoch: 13280 | MAE Train Loss: 55.37256622314453 | MAE Test Loss: 51.70952224731445 \n",
      "Epoch: 13290 | MAE Train Loss: 55.366329193115234 | MAE Test Loss: 51.702510833740234 \n",
      "Epoch: 13300 | MAE Train Loss: 55.36009979248047 | MAE Test Loss: 51.69545364379883 \n",
      "Epoch: 13310 | MAE Train Loss: 55.3538703918457 | MAE Test Loss: 51.688350677490234 \n",
      "Epoch: 13320 | MAE Train Loss: 55.3476448059082 | MAE Test Loss: 51.681339263916016 \n",
      "Epoch: 13330 | MAE Train Loss: 55.34141540527344 | MAE Test Loss: 51.67424011230469 \n",
      "Epoch: 13340 | MAE Train Loss: 55.33518600463867 | MAE Test Loss: 51.66722106933594 \n",
      "Epoch: 13350 | MAE Train Loss: 55.328948974609375 | MAE Test Loss: 51.660118103027344 \n",
      "Epoch: 13360 | MAE Train Loss: 55.322723388671875 | MAE Test Loss: 51.65311050415039 \n",
      "Epoch: 13370 | MAE Train Loss: 55.316490173339844 | MAE Test Loss: 51.646095275878906 \n",
      "Epoch: 13380 | MAE Train Loss: 55.310264587402344 | MAE Test Loss: 51.638999938964844 \n",
      "Epoch: 13390 | MAE Train Loss: 55.30403518676758 | MAE Test Loss: 51.63198471069336 \n",
      "Epoch: 13400 | MAE Train Loss: 55.29780578613281 | MAE Test Loss: 51.62492752075195 \n",
      "Epoch: 13410 | MAE Train Loss: 55.29156494140625 | MAE Test Loss: 51.61782455444336 \n",
      "Epoch: 13420 | MAE Train Loss: 55.285343170166016 | MAE Test Loss: 51.61081314086914 \n",
      "Epoch: 13430 | MAE Train Loss: 55.279109954833984 | MAE Test Loss: 51.60370635986328 \n",
      "Epoch: 13440 | MAE Train Loss: 55.272884368896484 | MAE Test Loss: 51.5966911315918 \n",
      "Epoch: 13450 | MAE Train Loss: 55.26664733886719 | MAE Test Loss: 51.589683532714844 \n",
      "Epoch: 13460 | MAE Train Loss: 55.26041793823242 | MAE Test Loss: 51.582584381103516 \n",
      "Epoch: 13470 | MAE Train Loss: 55.254188537597656 | MAE Test Loss: 51.5755729675293 \n",
      "Epoch: 13480 | MAE Train Loss: 55.24795913696289 | MAE Test Loss: 51.5684700012207 \n",
      "Epoch: 13490 | MAE Train Loss: 55.241729736328125 | MAE Test Loss: 51.56145095825195 \n",
      "Epoch: 13500 | MAE Train Loss: 55.235504150390625 | MAE Test Loss: 51.55439758300781 \n",
      "Epoch: 13510 | MAE Train Loss: 55.22926712036133 | MAE Test Loss: 51.547298431396484 \n",
      "Epoch: 13520 | MAE Train Loss: 55.223045349121094 | MAE Test Loss: 51.540279388427734 \n",
      "Epoch: 13530 | MAE Train Loss: 55.2168083190918 | MAE Test Loss: 51.53327560424805 \n",
      "Epoch: 13540 | MAE Train Loss: 55.21057891845703 | MAE Test Loss: 51.52616882324219 \n",
      "Epoch: 13550 | MAE Train Loss: 55.204349517822266 | MAE Test Loss: 51.51915740966797 \n",
      "Epoch: 13560 | MAE Train Loss: 55.198116302490234 | MAE Test Loss: 51.51205825805664 \n",
      "Epoch: 13570 | MAE Train Loss: 55.1918830871582 | MAE Test Loss: 51.505043029785156 \n",
      "Epoch: 13580 | MAE Train Loss: 55.1856575012207 | MAE Test Loss: 51.4979362487793 \n",
      "Epoch: 13590 | MAE Train Loss: 55.17942810058594 | MAE Test Loss: 51.49088668823242 \n",
      "Epoch: 13600 | MAE Train Loss: 55.17319869995117 | MAE Test Loss: 51.48387145996094 \n",
      "Epoch: 13610 | MAE Train Loss: 55.16696548461914 | MAE Test Loss: 51.47677230834961 \n",
      "Epoch: 13620 | MAE Train Loss: 55.16073226928711 | MAE Test Loss: 51.46975326538086 \n",
      "Epoch: 13630 | MAE Train Loss: 55.154502868652344 | MAE Test Loss: 51.46274948120117 \n",
      "Epoch: 13640 | MAE Train Loss: 55.148277282714844 | MAE Test Loss: 51.45564270019531 \n",
      "Epoch: 13650 | MAE Train Loss: 55.14204788208008 | MAE Test Loss: 51.448631286621094 \n",
      "Epoch: 13660 | MAE Train Loss: 55.13581085205078 | MAE Test Loss: 51.4415283203125 \n",
      "Epoch: 13670 | MAE Train Loss: 55.129581451416016 | MAE Test Loss: 51.43451690673828 \n",
      "Epoch: 13680 | MAE Train Loss: 55.12335205078125 | MAE Test Loss: 51.42741012573242 \n",
      "Epoch: 13690 | MAE Train Loss: 55.117122650146484 | MAE Test Loss: 51.42035675048828 \n",
      "Epoch: 13700 | MAE Train Loss: 55.110897064208984 | MAE Test Loss: 51.41334915161133 \n",
      "Epoch: 13710 | MAE Train Loss: 55.10466003417969 | MAE Test Loss: 51.40633773803711 \n",
      "Epoch: 13720 | MAE Train Loss: 55.09843063354492 | MAE Test Loss: 51.399234771728516 \n",
      "Epoch: 13730 | MAE Train Loss: 55.092201232910156 | MAE Test Loss: 51.392215728759766 \n",
      "Epoch: 13740 | MAE Train Loss: 55.08597183227539 | MAE Test Loss: 51.38511657714844 \n",
      "Epoch: 13750 | MAE Train Loss: 55.079742431640625 | MAE Test Loss: 51.37810516357422 \n",
      "Epoch: 13760 | MAE Train Loss: 55.073509216308594 | MAE Test Loss: 51.37100601196289 \n",
      "Epoch: 13770 | MAE Train Loss: 55.067352294921875 | MAE Test Loss: 51.364349365234375 \n",
      "Epoch: 13780 | MAE Train Loss: 55.06129837036133 | MAE Test Loss: 51.358062744140625 \n",
      "Epoch: 13790 | MAE Train Loss: 55.05525207519531 | MAE Test Loss: 51.351783752441406 \n",
      "Epoch: 13800 | MAE Train Loss: 55.049198150634766 | MAE Test Loss: 51.34549331665039 \n",
      "Epoch: 13810 | MAE Train Loss: 55.04315185546875 | MAE Test Loss: 51.339202880859375 \n",
      "Epoch: 13820 | MAE Train Loss: 55.037105560302734 | MAE Test Loss: 51.332916259765625 \n",
      "Epoch: 13830 | MAE Train Loss: 55.03105163574219 | MAE Test Loss: 51.32663345336914 \n",
      "Epoch: 13840 | MAE Train Loss: 55.025001525878906 | MAE Test Loss: 51.32034683227539 \n",
      "Epoch: 13850 | MAE Train Loss: 55.01895523071289 | MAE Test Loss: 51.314056396484375 \n",
      "Epoch: 13860 | MAE Train Loss: 55.012901306152344 | MAE Test Loss: 51.307769775390625 \n",
      "Epoch: 13870 | MAE Train Loss: 55.00685119628906 | MAE Test Loss: 51.301483154296875 \n",
      "Epoch: 13880 | MAE Train Loss: 55.00080871582031 | MAE Test Loss: 51.295196533203125 \n",
      "Epoch: 13890 | MAE Train Loss: 54.994754791259766 | MAE Test Loss: 51.28891372680664 \n",
      "Epoch: 13900 | MAE Train Loss: 54.98869705200195 | MAE Test Loss: 51.28262710571289 \n",
      "Epoch: 13910 | MAE Train Loss: 54.9826545715332 | MAE Test Loss: 51.27634048461914 \n",
      "Epoch: 13920 | MAE Train Loss: 54.976600646972656 | MAE Test Loss: 51.27005386352539 \n",
      "Epoch: 13930 | MAE Train Loss: 54.97055435180664 | MAE Test Loss: 51.263763427734375 \n",
      "Epoch: 13940 | MAE Train Loss: 54.964500427246094 | MAE Test Loss: 51.257476806640625 \n",
      "Epoch: 13950 | MAE Train Loss: 54.95845413208008 | MAE Test Loss: 51.251197814941406 \n",
      "Epoch: 13960 | MAE Train Loss: 54.9524040222168 | MAE Test Loss: 51.244903564453125 \n",
      "Epoch: 13970 | MAE Train Loss: 54.946353912353516 | MAE Test Loss: 51.23862075805664 \n",
      "Epoch: 13980 | MAE Train Loss: 54.940303802490234 | MAE Test Loss: 51.23233413696289 \n",
      "Epoch: 13990 | MAE Train Loss: 54.93425750732422 | MAE Test Loss: 51.22604751586914 \n",
      "Epoch: 14000 | MAE Train Loss: 54.928199768066406 | MAE Test Loss: 51.21976089477539 \n",
      "Epoch: 14010 | MAE Train Loss: 54.92215347290039 | MAE Test Loss: 51.213470458984375 \n",
      "Epoch: 14020 | MAE Train Loss: 54.916099548339844 | MAE Test Loss: 51.207183837890625 \n",
      "Epoch: 14030 | MAE Train Loss: 54.910057067871094 | MAE Test Loss: 51.200904846191406 \n",
      "Epoch: 14040 | MAE Train Loss: 54.90400314331055 | MAE Test Loss: 51.194610595703125 \n",
      "Epoch: 14050 | MAE Train Loss: 54.89794921875 | MAE Test Loss: 51.188323974609375 \n",
      "Epoch: 14060 | MAE Train Loss: 54.89190673828125 | MAE Test Loss: 51.182037353515625 \n",
      "Epoch: 14070 | MAE Train Loss: 54.88584899902344 | MAE Test Loss: 51.17575454711914 \n",
      "Epoch: 14080 | MAE Train Loss: 54.87980270385742 | MAE Test Loss: 51.16946792602539 \n",
      "Epoch: 14090 | MAE Train Loss: 54.873748779296875 | MAE Test Loss: 51.16317367553711 \n",
      "Epoch: 14100 | MAE Train Loss: 54.86770248413086 | MAE Test Loss: 51.156898498535156 \n",
      "Epoch: 14110 | MAE Train Loss: 54.861656188964844 | MAE Test Loss: 51.150604248046875 \n",
      "Epoch: 14120 | MAE Train Loss: 54.85560607910156 | MAE Test Loss: 51.144317626953125 \n",
      "Epoch: 14130 | MAE Train Loss: 54.84955978393555 | MAE Test Loss: 51.13803482055664 \n",
      "Epoch: 14140 | MAE Train Loss: 54.8434944152832 | MAE Test Loss: 51.13174819946289 \n",
      "Epoch: 14150 | MAE Train Loss: 54.8375129699707 | MAE Test Loss: 51.12522506713867 \n",
      "Epoch: 14160 | MAE Train Loss: 54.831703186035156 | MAE Test Loss: 51.1181526184082 \n",
      "Epoch: 14170 | MAE Train Loss: 54.82590103149414 | MAE Test Loss: 51.111087799072266 \n",
      "Epoch: 14180 | MAE Train Loss: 54.820091247558594 | MAE Test Loss: 51.10401916503906 \n",
      "Epoch: 14190 | MAE Train Loss: 54.81428146362305 | MAE Test Loss: 51.096946716308594 \n",
      "Epoch: 14200 | MAE Train Loss: 54.80847930908203 | MAE Test Loss: 51.089881896972656 \n",
      "Epoch: 14210 | MAE Train Loss: 54.802669525146484 | MAE Test Loss: 51.082820892333984 \n",
      "Epoch: 14220 | MAE Train Loss: 54.7968635559082 | MAE Test Loss: 51.07574462890625 \n",
      "Epoch: 14230 | MAE Train Loss: 54.79106140136719 | MAE Test Loss: 51.06867599487305 \n",
      "Epoch: 14240 | MAE Train Loss: 54.78524398803711 | MAE Test Loss: 51.06161117553711 \n",
      "Epoch: 14250 | MAE Train Loss: 54.779441833496094 | MAE Test Loss: 51.05454635620117 \n",
      "Epoch: 14260 | MAE Train Loss: 54.77363586425781 | MAE Test Loss: 51.0474739074707 \n",
      "Epoch: 14270 | MAE Train Loss: 54.767826080322266 | MAE Test Loss: 51.0404052734375 \n",
      "Epoch: 14280 | MAE Train Loss: 54.76201629638672 | MAE Test Loss: 51.03334045410156 \n",
      "Epoch: 14290 | MAE Train Loss: 54.75621795654297 | MAE Test Loss: 51.026268005371094 \n",
      "Epoch: 14300 | MAE Train Loss: 54.750404357910156 | MAE Test Loss: 51.019203186035156 \n",
      "Epoch: 14310 | MAE Train Loss: 54.74459457397461 | MAE Test Loss: 51.01213455200195 \n",
      "Epoch: 14320 | MAE Train Loss: 54.73878479003906 | MAE Test Loss: 51.005062103271484 \n",
      "Epoch: 14330 | MAE Train Loss: 54.73297882080078 | MAE Test Loss: 50.99799728393555 \n",
      "Epoch: 14340 | MAE Train Loss: 54.727176666259766 | MAE Test Loss: 50.99092483520508 \n",
      "Epoch: 14350 | MAE Train Loss: 54.72136688232422 | MAE Test Loss: 50.98386001586914 \n",
      "Epoch: 14360 | MAE Train Loss: 54.715553283691406 | MAE Test Loss: 50.97679138183594 \n",
      "Epoch: 14370 | MAE Train Loss: 54.709754943847656 | MAE Test Loss: 50.9697265625 \n",
      "Epoch: 14380 | MAE Train Loss: 54.70394515991211 | MAE Test Loss: 50.96266174316406 \n",
      "Epoch: 14390 | MAE Train Loss: 54.69813537597656 | MAE Test Loss: 50.955589294433594 \n",
      "Epoch: 14400 | MAE Train Loss: 54.69232940673828 | MAE Test Loss: 50.948516845703125 \n",
      "Epoch: 14410 | MAE Train Loss: 54.686527252197266 | MAE Test Loss: 50.94145202636719 \n",
      "Epoch: 14420 | MAE Train Loss: 54.68070983886719 | MAE Test Loss: 50.934383392333984 \n",
      "Epoch: 14430 | MAE Train Loss: 54.67490768432617 | MAE Test Loss: 50.92731857299805 \n",
      "Epoch: 14440 | MAE Train Loss: 54.66910171508789 | MAE Test Loss: 50.92024612426758 \n",
      "Epoch: 14450 | MAE Train Loss: 54.663291931152344 | MAE Test Loss: 50.913185119628906 \n",
      "Epoch: 14460 | MAE Train Loss: 54.6574821472168 | MAE Test Loss: 50.90611267089844 \n",
      "Epoch: 14470 | MAE Train Loss: 54.65167999267578 | MAE Test Loss: 50.89984893798828 \n",
      "Epoch: 14480 | MAE Train Loss: 54.645870208740234 | MAE Test Loss: 50.8936653137207 \n",
      "Epoch: 14490 | MAE Train Loss: 54.64006042480469 | MAE Test Loss: 50.88748550415039 \n",
      "Epoch: 14500 | MAE Train Loss: 54.63426208496094 | MAE Test Loss: 50.88129806518555 \n",
      "Epoch: 14510 | MAE Train Loss: 54.62845230102539 | MAE Test Loss: 50.8751220703125 \n",
      "Epoch: 14520 | MAE Train Loss: 54.622642517089844 | MAE Test Loss: 50.86894226074219 \n",
      "Epoch: 14530 | MAE Train Loss: 54.6168327331543 | MAE Test Loss: 50.862754821777344 \n",
      "Epoch: 14540 | MAE Train Loss: 54.61103057861328 | MAE Test Loss: 50.856571197509766 \n",
      "Epoch: 14550 | MAE Train Loss: 54.605220794677734 | MAE Test Loss: 50.850399017333984 \n",
      "Epoch: 14560 | MAE Train Loss: 54.59941101074219 | MAE Test Loss: 50.84421157836914 \n",
      "Epoch: 14570 | MAE Train Loss: 54.593605041503906 | MAE Test Loss: 50.83803176879883 \n",
      "Epoch: 14580 | MAE Train Loss: 54.58780288696289 | MAE Test Loss: 50.83185577392578 \n",
      "Epoch: 14590 | MAE Train Loss: 54.581993103027344 | MAE Test Loss: 50.82566833496094 \n",
      "Epoch: 14600 | MAE Train Loss: 54.5761833190918 | MAE Test Loss: 50.819488525390625 \n",
      "Epoch: 14610 | MAE Train Loss: 54.570377349853516 | MAE Test Loss: 50.81330490112305 \n",
      "Epoch: 14620 | MAE Train Loss: 54.5645751953125 | MAE Test Loss: 50.807125091552734 \n",
      "Epoch: 14630 | MAE Train Loss: 54.55876159667969 | MAE Test Loss: 50.80093002319336 \n",
      "Epoch: 14640 | MAE Train Loss: 54.55295944213867 | MAE Test Loss: 50.79472351074219 \n",
      "Epoch: 14650 | MAE Train Loss: 54.547157287597656 | MAE Test Loss: 50.78852462768555 \n",
      "Epoch: 14660 | MAE Train Loss: 54.541343688964844 | MAE Test Loss: 50.782310485839844 \n",
      "Epoch: 14670 | MAE Train Loss: 54.535545349121094 | MAE Test Loss: 50.77610397338867 \n",
      "Epoch: 14680 | MAE Train Loss: 54.52973937988281 | MAE Test Loss: 50.76990509033203 \n",
      "Epoch: 14690 | MAE Train Loss: 54.5239372253418 | MAE Test Loss: 50.763694763183594 \n",
      "Epoch: 14700 | MAE Train Loss: 54.51812744140625 | MAE Test Loss: 50.75749588012695 \n",
      "Epoch: 14710 | MAE Train Loss: 54.51232147216797 | MAE Test Loss: 50.75128936767578 \n",
      "Epoch: 14720 | MAE Train Loss: 54.50651168823242 | MAE Test Loss: 50.74508285522461 \n",
      "Epoch: 14730 | MAE Train Loss: 54.500709533691406 | MAE Test Loss: 50.73888397216797 \n",
      "Epoch: 14740 | MAE Train Loss: 54.494903564453125 | MAE Test Loss: 50.73268127441406 \n",
      "Epoch: 14750 | MAE Train Loss: 54.48910140991211 | MAE Test Loss: 50.72647476196289 \n",
      "Epoch: 14760 | MAE Train Loss: 54.48338317871094 | MAE Test Loss: 50.72032928466797 \n",
      "Epoch: 14770 | MAE Train Loss: 54.47773361206055 | MAE Test Loss: 50.71419143676758 \n",
      "Epoch: 14780 | MAE Train Loss: 54.472076416015625 | MAE Test Loss: 50.70805358886719 \n",
      "Epoch: 14790 | MAE Train Loss: 54.466407775878906 | MAE Test Loss: 50.70191192626953 \n",
      "Epoch: 14800 | MAE Train Loss: 54.460750579833984 | MAE Test Loss: 50.69577407836914 \n",
      "Epoch: 14810 | MAE Train Loss: 54.455101013183594 | MAE Test Loss: 50.68962860107422 \n",
      "Epoch: 14820 | MAE Train Loss: 54.449440002441406 | MAE Test Loss: 50.683494567871094 \n",
      "Epoch: 14830 | MAE Train Loss: 54.44377899169922 | MAE Test Loss: 50.67736053466797 \n",
      "Epoch: 14840 | MAE Train Loss: 54.43812942504883 | MAE Test Loss: 50.67121505737305 \n",
      "Epoch: 14850 | MAE Train Loss: 54.432472229003906 | MAE Test Loss: 50.665077209472656 \n",
      "Epoch: 14860 | MAE Train Loss: 54.426815032958984 | MAE Test Loss: 50.658939361572266 \n",
      "Epoch: 14870 | MAE Train Loss: 54.421260833740234 | MAE Test Loss: 50.653099060058594 \n",
      "Epoch: 14880 | MAE Train Loss: 54.41575622558594 | MAE Test Loss: 50.64738464355469 \n",
      "Epoch: 14890 | MAE Train Loss: 54.41026306152344 | MAE Test Loss: 50.64167785644531 \n",
      "Epoch: 14900 | MAE Train Loss: 54.404754638671875 | MAE Test Loss: 50.635963439941406 \n",
      "Epoch: 14910 | MAE Train Loss: 54.39925765991211 | MAE Test Loss: 50.630210876464844 \n",
      "Epoch: 14920 | MAE Train Loss: 54.39375686645508 | MAE Test Loss: 50.62449645996094 \n",
      "Epoch: 14930 | MAE Train Loss: 54.388267517089844 | MAE Test Loss: 50.61876678466797 \n",
      "Epoch: 14940 | MAE Train Loss: 54.382835388183594 | MAE Test Loss: 50.612892150878906 \n",
      "Epoch: 14950 | MAE Train Loss: 54.37739562988281 | MAE Test Loss: 50.607025146484375 \n",
      "Epoch: 14960 | MAE Train Loss: 54.37195587158203 | MAE Test Loss: 50.601158142089844 \n",
      "Epoch: 14970 | MAE Train Loss: 54.36651611328125 | MAE Test Loss: 50.595298767089844 \n",
      "Epoch: 14980 | MAE Train Loss: 54.361083984375 | MAE Test Loss: 50.58940124511719 \n",
      "Epoch: 14990 | MAE Train Loss: 54.35565185546875 | MAE Test Loss: 50.583534240722656 \n",
      "Epoch: 15000 | MAE Train Loss: 54.35021209716797 | MAE Test Loss: 50.57766342163086 \n",
      "Epoch: 15010 | MAE Train Loss: 54.34477996826172 | MAE Test Loss: 50.571800231933594 \n",
      "Epoch: 15020 | MAE Train Loss: 54.33934020996094 | MAE Test Loss: 50.56593322753906 \n",
      "Epoch: 15030 | MAE Train Loss: 54.333900451660156 | MAE Test Loss: 50.560062408447266 \n",
      "Epoch: 15040 | MAE Train Loss: 54.328468322753906 | MAE Test Loss: 50.55417251586914 \n",
      "Epoch: 15050 | MAE Train Loss: 54.323028564453125 | MAE Test Loss: 50.54830551147461 \n",
      "Epoch: 15060 | MAE Train Loss: 54.31760025024414 | MAE Test Loss: 50.54243469238281 \n",
      "Epoch: 15070 | MAE Train Loss: 54.312156677246094 | MAE Test Loss: 50.53657150268555 \n",
      "Epoch: 15080 | MAE Train Loss: 54.30672836303711 | MAE Test Loss: 50.53070068359375 \n",
      "Epoch: 15090 | MAE Train Loss: 54.30128479003906 | MAE Test Loss: 50.52484130859375 \n",
      "Epoch: 15100 | MAE Train Loss: 54.295867919921875 | MAE Test Loss: 50.5189323425293 \n",
      "Epoch: 15110 | MAE Train Loss: 54.29050064086914 | MAE Test Loss: 50.5130500793457 \n",
      "Epoch: 15120 | MAE Train Loss: 54.28512954711914 | MAE Test Loss: 50.50714874267578 \n",
      "Epoch: 15130 | MAE Train Loss: 54.279762268066406 | MAE Test Loss: 50.501243591308594 \n",
      "Epoch: 15140 | MAE Train Loss: 54.27438735961914 | MAE Test Loss: 50.495338439941406 \n",
      "Epoch: 15150 | MAE Train Loss: 54.26902389526367 | MAE Test Loss: 50.48943328857422 \n",
      "Epoch: 15160 | MAE Train Loss: 54.26365661621094 | MAE Test Loss: 50.4835319519043 \n",
      "Epoch: 15170 | MAE Train Loss: 54.258277893066406 | MAE Test Loss: 50.47762680053711 \n",
      "Epoch: 15180 | MAE Train Loss: 54.25292205810547 | MAE Test Loss: 50.47174072265625 \n",
      "Epoch: 15190 | MAE Train Loss: 54.24754333496094 | MAE Test Loss: 50.46583557128906 \n",
      "Epoch: 15200 | MAE Train Loss: 54.2421760559082 | MAE Test Loss: 50.45992660522461 \n",
      "Epoch: 15210 | MAE Train Loss: 54.23680877685547 | MAE Test Loss: 50.45402526855469 \n",
      "Epoch: 15220 | MAE Train Loss: 54.23143005371094 | MAE Test Loss: 50.4481315612793 \n",
      "Epoch: 15230 | MAE Train Loss: 54.226070404052734 | MAE Test Loss: 50.442222595214844 \n",
      "Epoch: 15240 | MAE Train Loss: 54.220699310302734 | MAE Test Loss: 50.43632125854492 \n",
      "Epoch: 15250 | MAE Train Loss: 54.21532440185547 | MAE Test Loss: 50.430416107177734 \n",
      "Epoch: 15260 | MAE Train Loss: 54.209957122802734 | MAE Test Loss: 50.42451858520508 \n",
      "Epoch: 15270 | MAE Train Loss: 54.204586029052734 | MAE Test Loss: 50.418609619140625 \n",
      "Epoch: 15280 | MAE Train Loss: 54.199222564697266 | MAE Test Loss: 50.412723541259766 \n",
      "Epoch: 15290 | MAE Train Loss: 54.1938591003418 | MAE Test Loss: 50.406822204589844 \n",
      "Epoch: 15300 | MAE Train Loss: 54.188480377197266 | MAE Test Loss: 50.400917053222656 \n",
      "Epoch: 15310 | MAE Train Loss: 54.18311309814453 | MAE Test Loss: 50.395015716552734 \n",
      "Epoch: 15320 | MAE Train Loss: 54.177738189697266 | MAE Test Loss: 50.38910675048828 \n",
      "Epoch: 15330 | MAE Train Loss: 54.1723747253418 | MAE Test Loss: 50.383209228515625 \n",
      "Epoch: 15340 | MAE Train Loss: 54.16700744628906 | MAE Test Loss: 50.37730026245117 \n",
      "Epoch: 15350 | MAE Train Loss: 54.1616325378418 | MAE Test Loss: 50.37141036987305 \n",
      "Epoch: 15360 | MAE Train Loss: 54.15626525878906 | MAE Test Loss: 50.365509033203125 \n",
      "Epoch: 15370 | MAE Train Loss: 54.15089416503906 | MAE Test Loss: 50.35960388183594 \n",
      "Epoch: 15380 | MAE Train Loss: 54.14552307128906 | MAE Test Loss: 50.353702545166016 \n",
      "Epoch: 15390 | MAE Train Loss: 54.140159606933594 | MAE Test Loss: 50.34779739379883 \n",
      "Epoch: 15400 | MAE Train Loss: 54.134788513183594 | MAE Test Loss: 50.341888427734375 \n",
      "Epoch: 15410 | MAE Train Loss: 54.12941360473633 | MAE Test Loss: 50.33598709106445 \n",
      "Epoch: 15420 | MAE Train Loss: 54.12405014038086 | MAE Test Loss: 50.330101013183594 \n",
      "Epoch: 15430 | MAE Train Loss: 54.118675231933594 | MAE Test Loss: 50.324195861816406 \n",
      "Epoch: 15440 | MAE Train Loss: 54.113304138183594 | MAE Test Loss: 50.31829833984375 \n",
      "Epoch: 15450 | MAE Train Loss: 54.10793685913086 | MAE Test Loss: 50.3123893737793 \n",
      "Epoch: 15460 | MAE Train Loss: 54.102569580078125 | MAE Test Loss: 50.306488037109375 \n",
      "Epoch: 15470 | MAE Train Loss: 54.097198486328125 | MAE Test Loss: 50.30058288574219 \n",
      "Epoch: 15480 | MAE Train Loss: 54.09182357788086 | MAE Test Loss: 50.294700622558594 \n",
      "Epoch: 15490 | MAE Train Loss: 54.086456298828125 | MAE Test Loss: 50.28879928588867 \n",
      "Epoch: 15500 | MAE Train Loss: 54.08112335205078 | MAE Test Loss: 50.282981872558594 \n",
      "Epoch: 15510 | MAE Train Loss: 54.075843811035156 | MAE Test Loss: 50.27737808227539 \n",
      "Epoch: 15520 | MAE Train Loss: 54.0705680847168 | MAE Test Loss: 50.27174758911133 \n",
      "Epoch: 15530 | MAE Train Loss: 54.06529998779297 | MAE Test Loss: 50.26612854003906 \n",
      "Epoch: 15540 | MAE Train Loss: 54.060020446777344 | MAE Test Loss: 50.26047897338867 \n",
      "Epoch: 15550 | MAE Train Loss: 54.05474853515625 | MAE Test Loss: 50.25486755371094 \n",
      "Epoch: 15560 | MAE Train Loss: 54.049476623535156 | MAE Test Loss: 50.24925231933594 \n",
      "Epoch: 15570 | MAE Train Loss: 54.04419708251953 | MAE Test Loss: 50.2436408996582 \n",
      "Epoch: 15580 | MAE Train Loss: 54.03892517089844 | MAE Test Loss: 50.23799133300781 \n",
      "Epoch: 15590 | MAE Train Loss: 54.03364562988281 | MAE Test Loss: 50.232383728027344 \n",
      "Epoch: 15600 | MAE Train Loss: 54.02837371826172 | MAE Test Loss: 50.22676467895508 \n",
      "Epoch: 15610 | MAE Train Loss: 54.023094177246094 | MAE Test Loss: 50.22115707397461 \n",
      "Epoch: 15620 | MAE Train Loss: 54.017822265625 | MAE Test Loss: 50.21550369262695 \n",
      "Epoch: 15630 | MAE Train Loss: 54.012550354003906 | MAE Test Loss: 50.209896087646484 \n",
      "Epoch: 15640 | MAE Train Loss: 54.00727081298828 | MAE Test Loss: 50.20427703857422 \n",
      "Epoch: 15650 | MAE Train Loss: 54.00199890136719 | MAE Test Loss: 50.19862747192383 \n",
      "Epoch: 15660 | MAE Train Loss: 53.99672317504883 | MAE Test Loss: 50.19301986694336 \n",
      "Epoch: 15670 | MAE Train Loss: 53.991451263427734 | MAE Test Loss: 50.187400817871094 \n",
      "Epoch: 15680 | MAE Train Loss: 53.986167907714844 | MAE Test Loss: 50.181793212890625 \n",
      "Epoch: 15690 | MAE Train Loss: 53.98089599609375 | MAE Test Loss: 50.176143646240234 \n",
      "Epoch: 15700 | MAE Train Loss: 53.97562026977539 | MAE Test Loss: 50.1705322265625 \n",
      "Epoch: 15710 | MAE Train Loss: 53.9703483581543 | MAE Test Loss: 50.1649169921875 \n",
      "Epoch: 15720 | MAE Train Loss: 53.96506881713867 | MAE Test Loss: 50.15926742553711 \n",
      "Epoch: 15730 | MAE Train Loss: 53.95979690551758 | MAE Test Loss: 50.153656005859375 \n",
      "Epoch: 15740 | MAE Train Loss: 53.954524993896484 | MAE Test Loss: 50.148040771484375 \n",
      "Epoch: 15750 | MAE Train Loss: 53.94924545288086 | MAE Test Loss: 50.14242935180664 \n",
      "Epoch: 15760 | MAE Train Loss: 53.943973541259766 | MAE Test Loss: 50.13677978515625 \n",
      "Epoch: 15770 | MAE Train Loss: 53.93870162963867 | MAE Test Loss: 50.131168365478516 \n",
      "Epoch: 15780 | MAE Train Loss: 53.933433532714844 | MAE Test Loss: 50.125526428222656 \n",
      "Epoch: 15790 | MAE Train Loss: 53.9282112121582 | MAE Test Loss: 50.11983108520508 \n",
      "Epoch: 15800 | MAE Train Loss: 53.922977447509766 | MAE Test Loss: 50.11414337158203 \n",
      "Epoch: 15810 | MAE Train Loss: 53.91775894165039 | MAE Test Loss: 50.10845184326172 \n",
      "Epoch: 15820 | MAE Train Loss: 53.91253662109375 | MAE Test Loss: 50.10276412963867 \n",
      "Epoch: 15830 | MAE Train Loss: 53.90730285644531 | MAE Test Loss: 50.097068786621094 \n",
      "Epoch: 15840 | MAE Train Loss: 53.90207290649414 | MAE Test Loss: 50.091373443603516 \n",
      "Epoch: 15850 | MAE Train Loss: 53.896854400634766 | MAE Test Loss: 50.08568572998047 \n",
      "Epoch: 15860 | MAE Train Loss: 53.89162826538086 | MAE Test Loss: 50.07999038696289 \n",
      "Epoch: 15870 | MAE Train Loss: 53.88639831542969 | MAE Test Loss: 50.07429504394531 \n",
      "Epoch: 15880 | MAE Train Loss: 53.881168365478516 | MAE Test Loss: 50.068607330322266 \n",
      "Epoch: 15890 | MAE Train Loss: 53.875946044921875 | MAE Test Loss: 50.06291580200195 \n",
      "Epoch: 15900 | MAE Train Loss: 53.870723724365234 | MAE Test Loss: 50.057220458984375 \n",
      "Epoch: 15910 | MAE Train Loss: 53.86549377441406 | MAE Test Loss: 50.05152893066406 \n",
      "Epoch: 15920 | MAE Train Loss: 53.86027145385742 | MAE Test Loss: 50.04582214355469 \n",
      "Epoch: 15930 | MAE Train Loss: 53.85504913330078 | MAE Test Loss: 50.040130615234375 \n",
      "Epoch: 15940 | MAE Train Loss: 53.84981918334961 | MAE Test Loss: 50.03444290161133 \n",
      "Epoch: 15950 | MAE Train Loss: 53.84459686279297 | MAE Test Loss: 50.02874755859375 \n",
      "Epoch: 15960 | MAE Train Loss: 53.8393669128418 | MAE Test Loss: 50.02306365966797 \n",
      "Epoch: 15970 | MAE Train Loss: 53.834144592285156 | MAE Test Loss: 50.01736831665039 \n",
      "Epoch: 15980 | MAE Train Loss: 53.828914642333984 | MAE Test Loss: 50.01167297363281 \n",
      "Epoch: 15990 | MAE Train Loss: 53.82368850708008 | MAE Test Loss: 50.0059814453125 \n",
      "Epoch: 16000 | MAE Train Loss: 53.81846618652344 | MAE Test Loss: 50.000274658203125 \n",
      "Epoch: 16010 | MAE Train Loss: 53.813236236572266 | MAE Test Loss: 49.994590759277344 \n",
      "Epoch: 16020 | MAE Train Loss: 53.808013916015625 | MAE Test Loss: 49.9888916015625 \n",
      "Epoch: 16030 | MAE Train Loss: 53.80278396606445 | MAE Test Loss: 49.98320007324219 \n",
      "Epoch: 16040 | MAE Train Loss: 53.79756164550781 | MAE Test Loss: 49.97750473022461 \n",
      "Epoch: 16050 | MAE Train Loss: 53.79233169555664 | MAE Test Loss: 49.97181701660156 \n",
      "Epoch: 16060 | MAE Train Loss: 53.787105560302734 | MAE Test Loss: 49.966121673583984 \n",
      "Epoch: 16070 | MAE Train Loss: 53.78187561035156 | MAE Test Loss: 49.960445404052734 \n",
      "Epoch: 16080 | MAE Train Loss: 53.77665710449219 | MAE Test Loss: 49.954750061035156 \n",
      "Epoch: 16090 | MAE Train Loss: 53.771427154541016 | MAE Test Loss: 49.949058532714844 \n",
      "Epoch: 16100 | MAE Train Loss: 53.76620101928711 | MAE Test Loss: 49.9433708190918 \n",
      "Epoch: 16110 | MAE Train Loss: 53.76097106933594 | MAE Test Loss: 49.93767547607422 \n",
      "Epoch: 16120 | MAE Train Loss: 53.75575256347656 | MAE Test Loss: 49.93198776245117 \n",
      "Epoch: 16130 | MAE Train Loss: 53.750526428222656 | MAE Test Loss: 49.926292419433594 \n",
      "Epoch: 16140 | MAE Train Loss: 53.745304107666016 | MAE Test Loss: 49.92060089111328 \n",
      "Epoch: 16150 | MAE Train Loss: 53.740074157714844 | MAE Test Loss: 49.9149055480957 \n",
      "Epoch: 16160 | MAE Train Loss: 53.7348518371582 | MAE Test Loss: 49.90921401977539 \n",
      "Epoch: 16170 | MAE Train Loss: 53.729618072509766 | MAE Test Loss: 49.90352249145508 \n",
      "Epoch: 16180 | MAE Train Loss: 53.72439193725586 | MAE Test Loss: 49.89783477783203 \n",
      "Epoch: 16190 | MAE Train Loss: 53.71916961669922 | MAE Test Loss: 49.89215087890625 \n",
      "Epoch: 16200 | MAE Train Loss: 53.71394729614258 | MAE Test Loss: 49.886444091796875 \n",
      "Epoch: 16210 | MAE Train Loss: 53.70871353149414 | MAE Test Loss: 49.88075637817383 \n",
      "Epoch: 16220 | MAE Train Loss: 53.70348358154297 | MAE Test Loss: 49.875064849853516 \n",
      "Epoch: 16230 | MAE Train Loss: 53.69826889038086 | MAE Test Loss: 49.86936950683594 \n",
      "Epoch: 16240 | MAE Train Loss: 53.69303894042969 | MAE Test Loss: 49.863677978515625 \n",
      "Epoch: 16250 | MAE Train Loss: 53.687808990478516 | MAE Test Loss: 49.857994079589844 \n",
      "Epoch: 16260 | MAE Train Loss: 53.68258285522461 | MAE Test Loss: 49.852291107177734 \n",
      "Epoch: 16270 | MAE Train Loss: 53.677364349365234 | MAE Test Loss: 49.846595764160156 \n",
      "Epoch: 16280 | MAE Train Loss: 53.672142028808594 | MAE Test Loss: 49.84090805053711 \n",
      "Epoch: 16290 | MAE Train Loss: 53.666900634765625 | MAE Test Loss: 49.83522033691406 \n",
      "Epoch: 16300 | MAE Train Loss: 53.66168212890625 | MAE Test Loss: 49.82951354980469 \n",
      "Epoch: 16310 | MAE Train Loss: 53.65646743774414 | MAE Test Loss: 49.823822021484375 \n",
      "Epoch: 16320 | MAE Train Loss: 53.65123748779297 | MAE Test Loss: 49.81813049316406 \n",
      "Epoch: 16330 | MAE Train Loss: 53.64600372314453 | MAE Test Loss: 49.812435150146484 \n",
      "Epoch: 16340 | MAE Train Loss: 53.64078140258789 | MAE Test Loss: 49.80674362182617 \n",
      "Epoch: 16350 | MAE Train Loss: 53.635555267333984 | MAE Test Loss: 49.801055908203125 \n",
      "Epoch: 16360 | MAE Train Loss: 53.630332946777344 | MAE Test Loss: 49.79536056518555 \n",
      "Epoch: 16370 | MAE Train Loss: 53.625099182128906 | MAE Test Loss: 49.78965377807617 \n",
      "Epoch: 16380 | MAE Train Loss: 53.619876861572266 | MAE Test Loss: 49.783966064453125 \n",
      "Epoch: 16390 | MAE Train Loss: 53.614654541015625 | MAE Test Loss: 49.77827072143555 \n",
      "Epoch: 16400 | MAE Train Loss: 53.60942459106445 | MAE Test Loss: 49.7725830078125 \n",
      "Epoch: 16410 | MAE Train Loss: 53.60419464111328 | MAE Test Loss: 49.76688766479492 \n",
      "Epoch: 16420 | MAE Train Loss: 53.59897994995117 | MAE Test Loss: 49.76119613647461 \n",
      "Epoch: 16430 | MAE Train Loss: 53.59375 | MAE Test Loss: 49.7555046081543 \n",
      "Epoch: 16440 | MAE Train Loss: 53.58851623535156 | MAE Test Loss: 49.74980926513672 \n",
      "Epoch: 16450 | MAE Train Loss: 53.58329772949219 | MAE Test Loss: 49.744136810302734 \n",
      "Epoch: 16460 | MAE Train Loss: 53.57807540893555 | MAE Test Loss: 49.73844528198242 \n",
      "Epoch: 16470 | MAE Train Loss: 53.572845458984375 | MAE Test Loss: 49.73274612426758 \n",
      "Epoch: 16480 | MAE Train Loss: 53.56761932373047 | MAE Test Loss: 49.7270622253418 \n",
      "Epoch: 16490 | MAE Train Loss: 53.5623893737793 | MAE Test Loss: 49.72136306762695 \n",
      "Epoch: 16500 | MAE Train Loss: 53.557167053222656 | MAE Test Loss: 49.71567153930664 \n",
      "Epoch: 16510 | MAE Train Loss: 53.551937103271484 | MAE Test Loss: 49.709983825683594 \n",
      "Epoch: 16520 | MAE Train Loss: 53.54670715332031 | MAE Test Loss: 49.704288482666016 \n",
      "Epoch: 16530 | MAE Train Loss: 53.54148483276367 | MAE Test Loss: 49.6985969543457 \n",
      "Epoch: 16540 | MAE Train Loss: 53.53626251220703 | MAE Test Loss: 49.69290542602539 \n",
      "Epoch: 16550 | MAE Train Loss: 53.53104019165039 | MAE Test Loss: 49.68721008300781 \n",
      "Epoch: 16560 | MAE Train Loss: 53.52581024169922 | MAE Test Loss: 49.68152618408203 \n",
      "Epoch: 16570 | MAE Train Loss: 53.52058792114258 | MAE Test Loss: 49.67583084106445 \n",
      "Epoch: 16580 | MAE Train Loss: 53.515357971191406 | MAE Test Loss: 49.670135498046875 \n",
      "Epoch: 16590 | MAE Train Loss: 53.510135650634766 | MAE Test Loss: 49.66444778442383 \n",
      "Epoch: 16600 | MAE Train Loss: 53.50490188598633 | MAE Test Loss: 49.65875244140625 \n",
      "Epoch: 16610 | MAE Train Loss: 53.49967956542969 | MAE Test Loss: 49.65305709838867 \n",
      "Epoch: 16620 | MAE Train Loss: 53.49445724487305 | MAE Test Loss: 49.647369384765625 \n",
      "Epoch: 16630 | MAE Train Loss: 53.489227294921875 | MAE Test Loss: 49.64167404174805 \n",
      "Epoch: 16640 | MAE Train Loss: 53.484004974365234 | MAE Test Loss: 49.635990142822266 \n",
      "Epoch: 16650 | MAE Train Loss: 53.478782653808594 | MAE Test Loss: 49.630287170410156 \n",
      "Epoch: 16660 | MAE Train Loss: 53.47355270385742 | MAE Test Loss: 49.624603271484375 \n",
      "Epoch: 16670 | MAE Train Loss: 53.46833038330078 | MAE Test Loss: 49.618892669677734 \n",
      "Epoch: 16680 | MAE Train Loss: 53.463096618652344 | MAE Test Loss: 49.61320495605469 \n",
      "Epoch: 16690 | MAE Train Loss: 53.45787811279297 | MAE Test Loss: 49.60750961303711 \n",
      "Epoch: 16700 | MAE Train Loss: 53.4526481628418 | MAE Test Loss: 49.60182189941406 \n",
      "Epoch: 16710 | MAE Train Loss: 53.447425842285156 | MAE Test Loss: 49.596126556396484 \n",
      "Epoch: 16720 | MAE Train Loss: 53.442195892333984 | MAE Test Loss: 49.590431213378906 \n",
      "Epoch: 16730 | MAE Train Loss: 53.43696975708008 | MAE Test Loss: 49.584747314453125 \n",
      "Epoch: 16740 | MAE Train Loss: 53.43174743652344 | MAE Test Loss: 49.57905197143555 \n",
      "Epoch: 16750 | MAE Train Loss: 53.426517486572266 | MAE Test Loss: 49.57378387451172 \n",
      "Epoch: 16760 | MAE Train Loss: 53.421287536621094 | MAE Test Loss: 49.56867218017578 \n",
      "Epoch: 16770 | MAE Train Loss: 53.41606521606445 | MAE Test Loss: 49.563560485839844 \n",
      "Epoch: 16780 | MAE Train Loss: 53.41084289550781 | MAE Test Loss: 49.55844497680664 \n",
      "Epoch: 16790 | MAE Train Loss: 53.405609130859375 | MAE Test Loss: 49.5533332824707 \n",
      "Epoch: 16800 | MAE Train Loss: 53.400386810302734 | MAE Test Loss: 49.548213958740234 \n",
      "Epoch: 16810 | MAE Train Loss: 53.39516067504883 | MAE Test Loss: 49.5431022644043 \n",
      "Epoch: 16820 | MAE Train Loss: 53.38993453979492 | MAE Test Loss: 49.53797149658203 \n",
      "Epoch: 16830 | MAE Train Loss: 53.384708404541016 | MAE Test Loss: 49.53285598754883 \n",
      "Epoch: 16840 | MAE Train Loss: 53.379493713378906 | MAE Test Loss: 49.527740478515625 \n",
      "Epoch: 16850 | MAE Train Loss: 53.37425994873047 | MAE Test Loss: 49.52263259887695 \n",
      "Epoch: 16860 | MAE Train Loss: 53.36903381347656 | MAE Test Loss: 49.51751708984375 \n",
      "Epoch: 16870 | MAE Train Loss: 53.363800048828125 | MAE Test Loss: 49.51240921020508 \n",
      "Epoch: 16880 | MAE Train Loss: 53.358577728271484 | MAE Test Loss: 49.50728988647461 \n",
      "Epoch: 16890 | MAE Train Loss: 53.353355407714844 | MAE Test Loss: 49.50217819213867 \n",
      "Epoch: 16900 | MAE Train Loss: 53.34812545776367 | MAE Test Loss: 49.497066497802734 \n",
      "Epoch: 16910 | MAE Train Loss: 53.34291076660156 | MAE Test Loss: 49.49195861816406 \n",
      "Epoch: 16920 | MAE Train Loss: 53.33767318725586 | MAE Test Loss: 49.48684310913086 \n",
      "Epoch: 16930 | MAE Train Loss: 53.33245086669922 | MAE Test Loss: 49.48173141479492 \n",
      "Epoch: 16940 | MAE Train Loss: 53.32722473144531 | MAE Test Loss: 49.47660827636719 \n",
      "Epoch: 16950 | MAE Train Loss: 53.32199478149414 | MAE Test Loss: 49.471500396728516 \n",
      "Epoch: 16960 | MAE Train Loss: 53.3167724609375 | MAE Test Loss: 49.466392517089844 \n",
      "Epoch: 16970 | MAE Train Loss: 53.31155014038086 | MAE Test Loss: 49.461273193359375 \n",
      "Epoch: 16980 | MAE Train Loss: 53.30632019042969 | MAE Test Loss: 49.45615768432617 \n",
      "Epoch: 16990 | MAE Train Loss: 53.30109786987305 | MAE Test Loss: 49.451045989990234 \n",
      "Epoch: 17000 | MAE Train Loss: 53.295867919921875 | MAE Test Loss: 49.44593811035156 \n",
      "Epoch: 17010 | MAE Train Loss: 53.290645599365234 | MAE Test Loss: 49.440826416015625 \n",
      "Epoch: 17020 | MAE Train Loss: 53.2854118347168 | MAE Test Loss: 49.435707092285156 \n",
      "Epoch: 17030 | MAE Train Loss: 53.280189514160156 | MAE Test Loss: 49.43059158325195 \n",
      "Epoch: 17040 | MAE Train Loss: 53.27496337890625 | MAE Test Loss: 49.425479888916016 \n",
      "Epoch: 17050 | MAE Train Loss: 53.26974105834961 | MAE Test Loss: 49.420387268066406 \n",
      "Epoch: 17060 | MAE Train Loss: 53.26450729370117 | MAE Test Loss: 49.41526794433594 \n",
      "Epoch: 17070 | MAE Train Loss: 53.2592887878418 | MAE Test Loss: 49.41015625 \n",
      "Epoch: 17080 | MAE Train Loss: 53.25406265258789 | MAE Test Loss: 49.40504455566406 \n",
      "Epoch: 17090 | MAE Train Loss: 53.24883270263672 | MAE Test Loss: 49.39992904663086 \n",
      "Epoch: 17100 | MAE Train Loss: 53.24361038208008 | MAE Test Loss: 49.39481735229492 \n",
      "Epoch: 17110 | MAE Train Loss: 53.238380432128906 | MAE Test Loss: 49.38970184326172 \n",
      "Epoch: 17120 | MAE Train Loss: 53.233150482177734 | MAE Test Loss: 49.38459014892578 \n",
      "Epoch: 17130 | MAE Train Loss: 53.22792434692383 | MAE Test Loss: 49.379493713378906 \n",
      "Epoch: 17140 | MAE Train Loss: 53.22270202636719 | MAE Test Loss: 49.3743782043457 \n",
      "Epoch: 17150 | MAE Train Loss: 53.21747589111328 | MAE Test Loss: 49.369266510009766 \n",
      "Epoch: 17160 | MAE Train Loss: 53.212249755859375 | MAE Test Loss: 49.364158630371094 \n",
      "Epoch: 17170 | MAE Train Loss: 53.2070198059082 | MAE Test Loss: 49.359046936035156 \n",
      "Epoch: 17180 | MAE Train Loss: 53.20179748535156 | MAE Test Loss: 49.35392761230469 \n",
      "Epoch: 17190 | MAE Train Loss: 53.19656753540039 | MAE Test Loss: 49.348812103271484 \n",
      "Epoch: 17200 | MAE Train Loss: 53.19134521484375 | MAE Test Loss: 49.343685150146484 \n",
      "Epoch: 17210 | MAE Train Loss: 53.18611526489258 | MAE Test Loss: 49.338565826416016 \n",
      "Epoch: 17220 | MAE Train Loss: 53.18089294433594 | MAE Test Loss: 49.333457946777344 \n",
      "Epoch: 17230 | MAE Train Loss: 53.17566680908203 | MAE Test Loss: 49.328338623046875 \n",
      "Epoch: 17240 | MAE Train Loss: 53.17043685913086 | MAE Test Loss: 49.32322692871094 \n",
      "Epoch: 17250 | MAE Train Loss: 53.16521453857422 | MAE Test Loss: 49.318119049072266 \n",
      "Epoch: 17260 | MAE Train Loss: 53.15998458862305 | MAE Test Loss: 49.3129997253418 \n",
      "Epoch: 17270 | MAE Train Loss: 53.154762268066406 | MAE Test Loss: 49.307884216308594 \n",
      "Epoch: 17280 | MAE Train Loss: 53.149532318115234 | MAE Test Loss: 49.30278778076172 \n",
      "Epoch: 17290 | MAE Train Loss: 53.144309997558594 | MAE Test Loss: 49.29767990112305 \n",
      "Epoch: 17300 | MAE Train Loss: 53.139076232910156 | MAE Test Loss: 49.292564392089844 \n",
      "Epoch: 17310 | MAE Train Loss: 53.13385772705078 | MAE Test Loss: 49.28744888305664 \n",
      "Epoch: 17320 | MAE Train Loss: 53.12862777709961 | MAE Test Loss: 49.28234100341797 \n",
      "Epoch: 17330 | MAE Train Loss: 53.1234016418457 | MAE Test Loss: 49.2772216796875 \n",
      "Epoch: 17340 | MAE Train Loss: 53.11817169189453 | MAE Test Loss: 49.27210998535156 \n",
      "Epoch: 17350 | MAE Train Loss: 53.11294937133789 | MAE Test Loss: 49.266998291015625 \n",
      "Epoch: 17360 | MAE Train Loss: 53.10772705078125 | MAE Test Loss: 49.26188278198242 \n",
      "Epoch: 17370 | MAE Train Loss: 53.10249710083008 | MAE Test Loss: 49.256771087646484 \n",
      "Epoch: 17380 | MAE Train Loss: 53.097267150878906 | MAE Test Loss: 49.25165557861328 \n",
      "Epoch: 17390 | MAE Train Loss: 53.092044830322266 | MAE Test Loss: 49.24653625488281 \n",
      "Epoch: 17400 | MAE Train Loss: 53.08681869506836 | MAE Test Loss: 49.241424560546875 \n",
      "Epoch: 17410 | MAE Train Loss: 53.08158874511719 | MAE Test Loss: 49.2363166809082 \n",
      "Epoch: 17420 | MAE Train Loss: 53.07636642456055 | MAE Test Loss: 49.231204986572266 \n",
      "Epoch: 17430 | MAE Train Loss: 53.071136474609375 | MAE Test Loss: 49.22608947753906 \n",
      "Epoch: 17440 | MAE Train Loss: 53.065914154052734 | MAE Test Loss: 49.220977783203125 \n",
      "Epoch: 17450 | MAE Train Loss: 53.06068420410156 | MAE Test Loss: 49.215858459472656 \n",
      "Epoch: 17460 | MAE Train Loss: 53.05546188354492 | MAE Test Loss: 49.210750579833984 \n",
      "Epoch: 17470 | MAE Train Loss: 53.05023193359375 | MAE Test Loss: 49.205631256103516 \n",
      "Epoch: 17480 | MAE Train Loss: 53.04500961303711 | MAE Test Loss: 49.20051956176758 \n",
      "Epoch: 17490 | MAE Train Loss: 53.0397834777832 | MAE Test Loss: 49.195404052734375 \n",
      "Epoch: 17500 | MAE Train Loss: 53.0345573425293 | MAE Test Loss: 49.1902961730957 \n",
      "Epoch: 17510 | MAE Train Loss: 53.02933120727539 | MAE Test Loss: 49.18519592285156 \n",
      "Epoch: 17520 | MAE Train Loss: 53.02410125732422 | MAE Test Loss: 49.18008804321289 \n",
      "Epoch: 17530 | MAE Train Loss: 53.01887130737305 | MAE Test Loss: 49.17496871948242 \n",
      "Epoch: 17540 | MAE Train Loss: 53.01364517211914 | MAE Test Loss: 49.16986083984375 \n",
      "Epoch: 17550 | MAE Train Loss: 53.0084228515625 | MAE Test Loss: 49.16474151611328 \n",
      "Epoch: 17560 | MAE Train Loss: 53.003196716308594 | MAE Test Loss: 49.159629821777344 \n",
      "Epoch: 17570 | MAE Train Loss: 52.99797058105469 | MAE Test Loss: 49.15452194213867 \n",
      "Epoch: 17580 | MAE Train Loss: 52.99274444580078 | MAE Test Loss: 49.1494026184082 \n",
      "Epoch: 17590 | MAE Train Loss: 52.98752212524414 | MAE Test Loss: 49.14427185058594 \n",
      "Epoch: 17600 | MAE Train Loss: 52.9822883605957 | MAE Test Loss: 49.13916015625 \n",
      "Epoch: 17610 | MAE Train Loss: 52.97706604003906 | MAE Test Loss: 49.13404846191406 \n",
      "Epoch: 17620 | MAE Train Loss: 52.97183609008789 | MAE Test Loss: 49.12893295288086 \n",
      "Epoch: 17630 | MAE Train Loss: 52.966609954833984 | MAE Test Loss: 49.12381362915039 \n",
      "Epoch: 17640 | MAE Train Loss: 52.96138381958008 | MAE Test Loss: 49.11870193481445 \n",
      "Epoch: 17650 | MAE Train Loss: 52.95615768432617 | MAE Test Loss: 49.113590240478516 \n",
      "Epoch: 17660 | MAE Train Loss: 52.95093536376953 | MAE Test Loss: 49.108482360839844 \n",
      "Epoch: 17670 | MAE Train Loss: 52.94570541381836 | MAE Test Loss: 49.1033821105957 \n",
      "Epoch: 17680 | MAE Train Loss: 52.94048309326172 | MAE Test Loss: 49.098270416259766 \n",
      "Epoch: 17690 | MAE Train Loss: 52.93525314331055 | MAE Test Loss: 49.09315872192383 \n",
      "Epoch: 17700 | MAE Train Loss: 52.930023193359375 | MAE Test Loss: 49.088043212890625 \n",
      "Epoch: 17710 | MAE Train Loss: 52.924800872802734 | MAE Test Loss: 49.08293151855469 \n",
      "Epoch: 17720 | MAE Train Loss: 52.91957473754883 | MAE Test Loss: 49.07781219482422 \n",
      "Epoch: 17730 | MAE Train Loss: 52.91434860229492 | MAE Test Loss: 49.07270431518555 \n",
      "Epoch: 17740 | MAE Train Loss: 52.909122467041016 | MAE Test Loss: 49.067569732666016 \n",
      "Epoch: 17750 | MAE Train Loss: 52.903892517089844 | MAE Test Loss: 49.06245422363281 \n",
      "Epoch: 17760 | MAE Train Loss: 52.8986701965332 | MAE Test Loss: 49.057342529296875 \n",
      "Epoch: 17770 | MAE Train Loss: 52.89344024658203 | MAE Test Loss: 49.05223083496094 \n",
      "Epoch: 17780 | MAE Train Loss: 52.88821792602539 | MAE Test Loss: 49.047115325927734 \n",
      "Epoch: 17790 | MAE Train Loss: 52.88298797607422 | MAE Test Loss: 49.0420036315918 \n",
      "Epoch: 17800 | MAE Train Loss: 52.87776565551758 | MAE Test Loss: 49.036888122558594 \n",
      "Epoch: 17810 | MAE Train Loss: 52.87253189086914 | MAE Test Loss: 49.031776428222656 \n",
      "Epoch: 17820 | MAE Train Loss: 52.8673095703125 | MAE Test Loss: 49.02667999267578 \n",
      "Epoch: 17830 | MAE Train Loss: 52.862247467041016 | MAE Test Loss: 49.02153015136719 \n",
      "Epoch: 17840 | MAE Train Loss: 52.8571891784668 | MAE Test Loss: 49.01637649536133 \n",
      "Epoch: 17850 | MAE Train Loss: 52.85212707519531 | MAE Test Loss: 49.01123046875 \n",
      "Epoch: 17860 | MAE Train Loss: 52.847076416015625 | MAE Test Loss: 49.006080627441406 \n",
      "Epoch: 17870 | MAE Train Loss: 52.842018127441406 | MAE Test Loss: 49.00092697143555 \n",
      "Epoch: 17880 | MAE Train Loss: 52.83696746826172 | MAE Test Loss: 48.99577713012695 \n",
      "Epoch: 17890 | MAE Train Loss: 52.8319091796875 | MAE Test Loss: 48.990623474121094 \n",
      "Epoch: 17900 | MAE Train Loss: 52.82685089111328 | MAE Test Loss: 48.985477447509766 \n",
      "Epoch: 17910 | MAE Train Loss: 52.82179641723633 | MAE Test Loss: 48.98032760620117 \n",
      "Epoch: 17920 | MAE Train Loss: 52.816741943359375 | MAE Test Loss: 48.97517395019531 \n",
      "Epoch: 17930 | MAE Train Loss: 52.81168746948242 | MAE Test Loss: 48.97001647949219 \n",
      "Epoch: 17940 | MAE Train Loss: 52.806636810302734 | MAE Test Loss: 48.964866638183594 \n",
      "Epoch: 17950 | MAE Train Loss: 52.801570892333984 | MAE Test Loss: 48.959720611572266 \n",
      "Epoch: 17960 | MAE Train Loss: 52.7965202331543 | MAE Test Loss: 48.954566955566406 \n",
      "Epoch: 17970 | MAE Train Loss: 52.79146957397461 | MAE Test Loss: 48.94941711425781 \n",
      "Epoch: 17980 | MAE Train Loss: 52.78641128540039 | MAE Test Loss: 48.944271087646484 \n",
      "Epoch: 17990 | MAE Train Loss: 52.78135681152344 | MAE Test Loss: 48.939117431640625 \n",
      "Epoch: 18000 | MAE Train Loss: 52.77629089355469 | MAE Test Loss: 48.93396759033203 \n",
      "Epoch: 18010 | MAE Train Loss: 52.77124786376953 | MAE Test Loss: 48.92881393432617 \n",
      "Epoch: 18020 | MAE Train Loss: 52.76618957519531 | MAE Test Loss: 48.923667907714844 \n",
      "Epoch: 18030 | MAE Train Loss: 52.761131286621094 | MAE Test Loss: 48.91851043701172 \n",
      "Epoch: 18040 | MAE Train Loss: 52.75607681274414 | MAE Test Loss: 48.913360595703125 \n",
      "Epoch: 18050 | MAE Train Loss: 52.75102233886719 | MAE Test Loss: 48.9082145690918 \n",
      "Epoch: 18060 | MAE Train Loss: 52.745967864990234 | MAE Test Loss: 48.90306091308594 \n",
      "Epoch: 18070 | MAE Train Loss: 52.74091339111328 | MAE Test Loss: 48.897911071777344 \n",
      "Epoch: 18080 | MAE Train Loss: 52.73584747314453 | MAE Test Loss: 48.892757415771484 \n",
      "Epoch: 18090 | MAE Train Loss: 52.73080062866211 | MAE Test Loss: 48.88760757446289 \n",
      "Epoch: 18100 | MAE Train Loss: 52.72574996948242 | MAE Test Loss: 48.8824577331543 \n",
      "Epoch: 18110 | MAE Train Loss: 52.7206916809082 | MAE Test Loss: 48.8773078918457 \n",
      "Epoch: 18120 | MAE Train Loss: 52.71562957763672 | MAE Test Loss: 48.87215805053711 \n",
      "Epoch: 18130 | MAE Train Loss: 52.71057891845703 | MAE Test Loss: 48.867008209228516 \n",
      "Epoch: 18140 | MAE Train Loss: 52.70552444458008 | MAE Test Loss: 48.861854553222656 \n",
      "Epoch: 18150 | MAE Train Loss: 52.700469970703125 | MAE Test Loss: 48.85669708251953 \n",
      "Epoch: 18160 | MAE Train Loss: 52.695411682128906 | MAE Test Loss: 48.851558685302734 \n",
      "Epoch: 18170 | MAE Train Loss: 52.69035339355469 | MAE Test Loss: 48.846405029296875 \n",
      "Epoch: 18180 | MAE Train Loss: 52.685298919677734 | MAE Test Loss: 48.84124755859375 \n",
      "Epoch: 18190 | MAE Train Loss: 52.680240631103516 | MAE Test Loss: 48.83610153198242 \n",
      "Epoch: 18200 | MAE Train Loss: 52.67518997192383 | MAE Test Loss: 48.83095169067383 \n",
      "Epoch: 18210 | MAE Train Loss: 52.67013931274414 | MAE Test Loss: 48.82579803466797 \n",
      "Epoch: 18220 | MAE Train Loss: 52.66507339477539 | MAE Test Loss: 48.820640563964844 \n",
      "Epoch: 18230 | MAE Train Loss: 52.6600227355957 | MAE Test Loss: 48.815494537353516 \n",
      "Epoch: 18240 | MAE Train Loss: 52.65496826171875 | MAE Test Loss: 48.81034469604492 \n",
      "Epoch: 18250 | MAE Train Loss: 52.64990997314453 | MAE Test Loss: 48.80520248413086 \n",
      "Epoch: 18260 | MAE Train Loss: 52.64485168457031 | MAE Test Loss: 48.800045013427734 \n",
      "Epoch: 18270 | MAE Train Loss: 52.639793395996094 | MAE Test Loss: 48.794898986816406 \n",
      "Epoch: 18280 | MAE Train Loss: 52.634742736816406 | MAE Test Loss: 48.78974151611328 \n",
      "Epoch: 18290 | MAE Train Loss: 52.62969207763672 | MAE Test Loss: 48.78459167480469 \n",
      "Epoch: 18300 | MAE Train Loss: 52.6246337890625 | MAE Test Loss: 48.77943801879883 \n",
      "Epoch: 18310 | MAE Train Loss: 52.61957931518555 | MAE Test Loss: 48.7742919921875 \n",
      "Epoch: 18320 | MAE Train Loss: 52.61452102661133 | MAE Test Loss: 48.76914596557617 \n",
      "Epoch: 18330 | MAE Train Loss: 52.60946273803711 | MAE Test Loss: 48.76398849487305 \n",
      "Epoch: 18340 | MAE Train Loss: 52.604408264160156 | MAE Test Loss: 48.75883865356445 \n",
      "Epoch: 18350 | MAE Train Loss: 52.599361419677734 | MAE Test Loss: 48.753684997558594 \n",
      "Epoch: 18360 | MAE Train Loss: 52.594303131103516 | MAE Test Loss: 48.74853515625 \n",
      "Epoch: 18370 | MAE Train Loss: 52.5892448425293 | MAE Test Loss: 48.743385314941406 \n",
      "Epoch: 18380 | MAE Train Loss: 52.58418273925781 | MAE Test Loss: 48.73823547363281 \n",
      "Epoch: 18390 | MAE Train Loss: 52.57914733886719 | MAE Test Loss: 48.733123779296875 \n",
      "Epoch: 18400 | MAE Train Loss: 52.574195861816406 | MAE Test Loss: 48.728275299072266 \n",
      "Epoch: 18410 | MAE Train Loss: 52.569252014160156 | MAE Test Loss: 48.72343063354492 \n",
      "Epoch: 18420 | MAE Train Loss: 52.56429672241211 | MAE Test Loss: 48.71858596801758 \n",
      "Epoch: 18430 | MAE Train Loss: 52.55946350097656 | MAE Test Loss: 48.71366882324219 \n",
      "Epoch: 18440 | MAE Train Loss: 52.5546989440918 | MAE Test Loss: 48.70872116088867 \n",
      "Epoch: 18450 | MAE Train Loss: 52.549930572509766 | MAE Test Loss: 48.703765869140625 \n",
      "Epoch: 18460 | MAE Train Loss: 52.54515838623047 | MAE Test Loss: 48.69881820678711 \n",
      "Epoch: 18470 | MAE Train Loss: 52.54039001464844 | MAE Test Loss: 48.69386291503906 \n",
      "Epoch: 18480 | MAE Train Loss: 52.535621643066406 | MAE Test Loss: 48.68891525268555 \n",
      "Epoch: 18490 | MAE Train Loss: 52.530853271484375 | MAE Test Loss: 48.68396759033203 \n",
      "Epoch: 18500 | MAE Train Loss: 52.52608108520508 | MAE Test Loss: 48.679012298583984 \n",
      "Epoch: 18510 | MAE Train Loss: 52.52131652832031 | MAE Test Loss: 48.67406463623047 \n",
      "Epoch: 18520 | MAE Train Loss: 52.516544342041016 | MAE Test Loss: 48.66911697387695 \n",
      "Epoch: 18530 | MAE Train Loss: 52.511775970458984 | MAE Test Loss: 48.664161682128906 \n",
      "Epoch: 18540 | MAE Train Loss: 52.50700378417969 | MAE Test Loss: 48.659217834472656 \n",
      "Epoch: 18550 | MAE Train Loss: 52.502235412597656 | MAE Test Loss: 48.65426254272461 \n",
      "Epoch: 18560 | MAE Train Loss: 52.49747085571289 | MAE Test Loss: 48.64931106567383 \n",
      "Epoch: 18570 | MAE Train Loss: 52.49270248413086 | MAE Test Loss: 48.64435577392578 \n",
      "Epoch: 18580 | MAE Train Loss: 52.4879264831543 | MAE Test Loss: 48.639408111572266 \n",
      "Epoch: 18590 | MAE Train Loss: 52.48316192626953 | MAE Test Loss: 48.634456634521484 \n",
      "Epoch: 18600 | MAE Train Loss: 52.4783935546875 | MAE Test Loss: 48.6295051574707 \n",
      "Epoch: 18610 | MAE Train Loss: 52.47362518310547 | MAE Test Loss: 48.62455749511719 \n",
      "Epoch: 18620 | MAE Train Loss: 52.4688606262207 | MAE Test Loss: 48.61960220336914 \n",
      "Epoch: 18630 | MAE Train Loss: 52.46408462524414 | MAE Test Loss: 48.614654541015625 \n",
      "Epoch: 18640 | MAE Train Loss: 52.459320068359375 | MAE Test Loss: 48.609703063964844 \n",
      "Epoch: 18650 | MAE Train Loss: 52.454551696777344 | MAE Test Loss: 48.60475540161133 \n",
      "Epoch: 18660 | MAE Train Loss: 52.44977569580078 | MAE Test Loss: 48.59980010986328 \n",
      "Epoch: 18670 | MAE Train Loss: 52.44501495361328 | MAE Test Loss: 48.594852447509766 \n",
      "Epoch: 18680 | MAE Train Loss: 52.440242767333984 | MAE Test Loss: 48.58989715576172 \n",
      "Epoch: 18690 | MAE Train Loss: 52.43547439575195 | MAE Test Loss: 48.584957122802734 \n",
      "Epoch: 18700 | MAE Train Loss: 52.43070602416992 | MAE Test Loss: 48.58000183105469 \n",
      "Epoch: 18710 | MAE Train Loss: 52.42593765258789 | MAE Test Loss: 48.57505416870117 \n",
      "Epoch: 18720 | MAE Train Loss: 52.42117691040039 | MAE Test Loss: 48.570308685302734 \n",
      "Epoch: 18730 | MAE Train Loss: 52.41639709472656 | MAE Test Loss: 48.565895080566406 \n",
      "Epoch: 18740 | MAE Train Loss: 52.4116325378418 | MAE Test Loss: 48.561485290527344 \n",
      "Epoch: 18750 | MAE Train Loss: 52.406864166259766 | MAE Test Loss: 48.55707550048828 \n",
      "Epoch: 18760 | MAE Train Loss: 52.4020881652832 | MAE Test Loss: 48.552669525146484 \n",
      "Epoch: 18770 | MAE Train Loss: 52.39732360839844 | MAE Test Loss: 48.548255920410156 \n",
      "Epoch: 18780 | MAE Train Loss: 52.39255142211914 | MAE Test Loss: 48.543853759765625 \n",
      "Epoch: 18790 | MAE Train Loss: 52.387786865234375 | MAE Test Loss: 48.5394401550293 \n",
      "Epoch: 18800 | MAE Train Loss: 52.38302230834961 | MAE Test Loss: 48.53500747680664 \n",
      "Epoch: 18810 | MAE Train Loss: 52.37831497192383 | MAE Test Loss: 48.53042221069336 \n",
      "Epoch: 18820 | MAE Train Loss: 52.373600006103516 | MAE Test Loss: 48.52582931518555 \n",
      "Epoch: 18830 | MAE Train Loss: 52.368896484375 | MAE Test Loss: 48.52124786376953 \n",
      "Epoch: 18840 | MAE Train Loss: 52.36418151855469 | MAE Test Loss: 48.51665496826172 \n",
      "Epoch: 18850 | MAE Train Loss: 52.35947036743164 | MAE Test Loss: 48.5120735168457 \n",
      "Epoch: 18860 | MAE Train Loss: 52.35479736328125 | MAE Test Loss: 48.50758361816406 \n",
      "Epoch: 18870 | MAE Train Loss: 52.350250244140625 | MAE Test Loss: 48.50331497192383 \n",
      "Epoch: 18880 | MAE Train Loss: 52.345703125 | MAE Test Loss: 48.4990348815918 \n",
      "Epoch: 18890 | MAE Train Loss: 52.341156005859375 | MAE Test Loss: 48.49520492553711 \n",
      "Epoch: 18900 | MAE Train Loss: 52.33660888671875 | MAE Test Loss: 48.49143600463867 \n",
      "Epoch: 18910 | MAE Train Loss: 52.33205795288086 | MAE Test Loss: 48.4876594543457 \n",
      "Epoch: 18920 | MAE Train Loss: 52.3275146484375 | MAE Test Loss: 48.48388671875 \n",
      "Epoch: 18930 | MAE Train Loss: 52.322967529296875 | MAE Test Loss: 48.48011779785156 \n",
      "Epoch: 18940 | MAE Train Loss: 52.31842041015625 | MAE Test Loss: 48.47635269165039 \n",
      "Epoch: 18950 | MAE Train Loss: 52.313873291015625 | MAE Test Loss: 48.472572326660156 \n",
      "Epoch: 18960 | MAE Train Loss: 52.309322357177734 | MAE Test Loss: 48.46880340576172 \n",
      "Epoch: 18970 | MAE Train Loss: 52.30477523803711 | MAE Test Loss: 48.46503448486328 \n",
      "Epoch: 18980 | MAE Train Loss: 52.300228118896484 | MAE Test Loss: 48.46126174926758 \n",
      "Epoch: 18990 | MAE Train Loss: 52.295692443847656 | MAE Test Loss: 48.45749282836914 \n",
      "Epoch: 19000 | MAE Train Loss: 52.29113006591797 | MAE Test Loss: 48.4537239074707 \n",
      "Epoch: 19010 | MAE Train Loss: 52.286582946777344 | MAE Test Loss: 48.449954986572266 \n",
      "Epoch: 19020 | MAE Train Loss: 52.282047271728516 | MAE Test Loss: 48.4461784362793 \n",
      "Epoch: 19030 | MAE Train Loss: 52.27749252319336 | MAE Test Loss: 48.44240951538086 \n",
      "Epoch: 19040 | MAE Train Loss: 52.27294921875 | MAE Test Loss: 48.438636779785156 \n",
      "Epoch: 19050 | MAE Train Loss: 52.26839828491211 | MAE Test Loss: 48.43486785888672 \n",
      "Epoch: 19060 | MAE Train Loss: 52.26385498046875 | MAE Test Loss: 48.43109130859375 \n",
      "Epoch: 19070 | MAE Train Loss: 52.259307861328125 | MAE Test Loss: 48.427330017089844 \n",
      "Epoch: 19080 | MAE Train Loss: 52.254756927490234 | MAE Test Loss: 48.423553466796875 \n",
      "Epoch: 19090 | MAE Train Loss: 52.25020980834961 | MAE Test Loss: 48.41978454589844 \n",
      "Epoch: 19100 | MAE Train Loss: 52.24566650390625 | MAE Test Loss: 48.416011810302734 \n",
      "Epoch: 19110 | MAE Train Loss: 52.24111557006836 | MAE Test Loss: 48.4122428894043 \n",
      "Epoch: 19120 | MAE Train Loss: 52.23656463623047 | MAE Test Loss: 48.408470153808594 \n",
      "Epoch: 19130 | MAE Train Loss: 52.232025146484375 | MAE Test Loss: 48.404701232910156 \n",
      "Epoch: 19140 | MAE Train Loss: 52.227474212646484 | MAE Test Loss: 48.40092849731445 \n",
      "Epoch: 19150 | MAE Train Loss: 52.22292709350586 | MAE Test Loss: 48.397151947021484 \n",
      "Epoch: 19160 | MAE Train Loss: 52.218379974365234 | MAE Test Loss: 48.39338302612305 \n",
      "Epoch: 19170 | MAE Train Loss: 52.21383285522461 | MAE Test Loss: 48.38961410522461 \n",
      "Epoch: 19180 | MAE Train Loss: 52.20928192138672 | MAE Test Loss: 48.3858528137207 \n",
      "Epoch: 19190 | MAE Train Loss: 52.204742431640625 | MAE Test Loss: 48.382076263427734 \n",
      "Epoch: 19200 | MAE Train Loss: 52.200191497802734 | MAE Test Loss: 48.3783073425293 \n",
      "Epoch: 19210 | MAE Train Loss: 52.19564437866211 | MAE Test Loss: 48.374534606933594 \n",
      "Epoch: 19220 | MAE Train Loss: 52.191097259521484 | MAE Test Loss: 48.370765686035156 \n",
      "Epoch: 19230 | MAE Train Loss: 52.18655014038086 | MAE Test Loss: 48.36698913574219 \n",
      "Epoch: 19240 | MAE Train Loss: 52.18199920654297 | MAE Test Loss: 48.36322021484375 \n",
      "Epoch: 19250 | MAE Train Loss: 52.177452087402344 | MAE Test Loss: 48.35945129394531 \n",
      "Epoch: 19260 | MAE Train Loss: 52.172908782958984 | MAE Test Loss: 48.35567855834961 \n",
      "Epoch: 19270 | MAE Train Loss: 52.16836166381836 | MAE Test Loss: 48.35190200805664 \n",
      "Epoch: 19280 | MAE Train Loss: 52.163814544677734 | MAE Test Loss: 48.348140716552734 \n",
      "Epoch: 19290 | MAE Train Loss: 52.159263610839844 | MAE Test Loss: 48.344364166259766 \n",
      "Epoch: 19300 | MAE Train Loss: 52.15471649169922 | MAE Test Loss: 48.34059524536133 \n",
      "Epoch: 19310 | MAE Train Loss: 52.15017318725586 | MAE Test Loss: 48.33682632446289 \n",
      "Epoch: 19320 | MAE Train Loss: 52.14562225341797 | MAE Test Loss: 48.33305358886719 \n",
      "Epoch: 19330 | MAE Train Loss: 52.14107894897461 | MAE Test Loss: 48.329280853271484 \n",
      "Epoch: 19340 | MAE Train Loss: 52.136531829833984 | MAE Test Loss: 48.32550811767578 \n",
      "Epoch: 19350 | MAE Train Loss: 52.131980895996094 | MAE Test Loss: 48.321739196777344 \n",
      "Epoch: 19360 | MAE Train Loss: 52.12743377685547 | MAE Test Loss: 48.317962646484375 \n",
      "Epoch: 19370 | MAE Train Loss: 52.122886657714844 | MAE Test Loss: 48.31420135498047 \n",
      "Epoch: 19380 | MAE Train Loss: 52.11833953857422 | MAE Test Loss: 48.31043243408203 \n",
      "Epoch: 19390 | MAE Train Loss: 52.11379623413086 | MAE Test Loss: 48.30665588378906 \n",
      "Epoch: 19400 | MAE Train Loss: 52.109249114990234 | MAE Test Loss: 48.302886962890625 \n",
      "Epoch: 19410 | MAE Train Loss: 52.104698181152344 | MAE Test Loss: 48.29911422729492 \n",
      "Epoch: 19420 | MAE Train Loss: 52.10015106201172 | MAE Test Loss: 48.29534912109375 \n",
      "Epoch: 19430 | MAE Train Loss: 52.095603942871094 | MAE Test Loss: 48.29157638549805 \n",
      "Epoch: 19440 | MAE Train Loss: 52.091060638427734 | MAE Test Loss: 48.28779983520508 \n",
      "Epoch: 19450 | MAE Train Loss: 52.08651351928711 | MAE Test Loss: 48.28403091430664 \n",
      "Epoch: 19460 | MAE Train Loss: 52.081966400146484 | MAE Test Loss: 48.2802619934082 \n",
      "Epoch: 19470 | MAE Train Loss: 52.077415466308594 | MAE Test Loss: 48.2764892578125 \n",
      "Epoch: 19480 | MAE Train Loss: 52.07286834716797 | MAE Test Loss: 48.27272415161133 \n",
      "Epoch: 19490 | MAE Train Loss: 52.068321228027344 | MAE Test Loss: 48.268943786621094 \n",
      "Epoch: 19500 | MAE Train Loss: 52.06377410888672 | MAE Test Loss: 48.265174865722656 \n",
      "Epoch: 19510 | MAE Train Loss: 52.05922317504883 | MAE Test Loss: 48.26140594482422 \n",
      "Epoch: 19520 | MAE Train Loss: 52.0546760559082 | MAE Test Loss: 48.25763702392578 \n",
      "Epoch: 19530 | MAE Train Loss: 52.050132751464844 | MAE Test Loss: 48.25386047363281 \n",
      "Epoch: 19540 | MAE Train Loss: 52.04558181762695 | MAE Test Loss: 48.250091552734375 \n",
      "Epoch: 19550 | MAE Train Loss: 52.041038513183594 | MAE Test Loss: 48.24631881713867 \n",
      "Epoch: 19560 | MAE Train Loss: 52.03649139404297 | MAE Test Loss: 48.242549896240234 \n",
      "Epoch: 19570 | MAE Train Loss: 52.03193664550781 | MAE Test Loss: 48.238773345947266 \n",
      "Epoch: 19580 | MAE Train Loss: 52.027400970458984 | MAE Test Loss: 48.23501205444336 \n",
      "Epoch: 19590 | MAE Train Loss: 52.02284622192383 | MAE Test Loss: 48.23123550415039 \n",
      "Epoch: 19600 | MAE Train Loss: 52.01830291748047 | MAE Test Loss: 48.22746276855469 \n",
      "Epoch: 19610 | MAE Train Loss: 52.01374816894531 | MAE Test Loss: 48.223697662353516 \n",
      "Epoch: 19620 | MAE Train Loss: 52.00920867919922 | MAE Test Loss: 48.21992492675781 \n",
      "Epoch: 19630 | MAE Train Loss: 52.00465774536133 | MAE Test Loss: 48.216156005859375 \n",
      "Epoch: 19640 | MAE Train Loss: 52.0001106262207 | MAE Test Loss: 48.21238708496094 \n",
      "Epoch: 19650 | MAE Train Loss: 51.995567321777344 | MAE Test Loss: 48.20861053466797 \n",
      "Epoch: 19660 | MAE Train Loss: 51.99101638793945 | MAE Test Loss: 48.20484161376953 \n",
      "Epoch: 19670 | MAE Train Loss: 51.98646545410156 | MAE Test Loss: 48.201072692871094 \n",
      "Epoch: 19680 | MAE Train Loss: 51.9819221496582 | MAE Test Loss: 48.19729995727539 \n",
      "Epoch: 19690 | MAE Train Loss: 51.97737503051758 | MAE Test Loss: 48.19352340698242 \n",
      "Epoch: 19700 | MAE Train Loss: 51.97282791137695 | MAE Test Loss: 48.189762115478516 \n",
      "Epoch: 19710 | MAE Train Loss: 51.96828079223633 | MAE Test Loss: 48.18598937988281 \n",
      "Epoch: 19720 | MAE Train Loss: 51.96372985839844 | MAE Test Loss: 48.18221664428711 \n",
      "Epoch: 19730 | MAE Train Loss: 51.95917892456055 | MAE Test Loss: 48.178443908691406 \n",
      "Epoch: 19740 | MAE Train Loss: 51.95463943481445 | MAE Test Loss: 48.1746711730957 \n",
      "Epoch: 19750 | MAE Train Loss: 51.95008850097656 | MAE Test Loss: 48.1708984375 \n",
      "Epoch: 19760 | MAE Train Loss: 51.9455451965332 | MAE Test Loss: 48.16713333129883 \n",
      "Epoch: 19770 | MAE Train Loss: 51.94099807739258 | MAE Test Loss: 48.163360595703125 \n",
      "Epoch: 19780 | MAE Train Loss: 51.93644714355469 | MAE Test Loss: 48.15959167480469 \n",
      "Epoch: 19790 | MAE Train Loss: 51.93190002441406 | MAE Test Loss: 48.15582275390625 \n",
      "Epoch: 19800 | MAE Train Loss: 51.92735290527344 | MAE Test Loss: 48.15204620361328 \n",
      "Epoch: 19810 | MAE Train Loss: 51.92280960083008 | MAE Test Loss: 48.148277282714844 \n",
      "Epoch: 19820 | MAE Train Loss: 51.91825485229492 | MAE Test Loss: 48.144508361816406 \n",
      "Epoch: 19830 | MAE Train Loss: 51.91371536254883 | MAE Test Loss: 48.1407356262207 \n",
      "Epoch: 19840 | MAE Train Loss: 51.90916442871094 | MAE Test Loss: 48.136966705322266 \n",
      "Epoch: 19850 | MAE Train Loss: 51.90461730957031 | MAE Test Loss: 48.1331901550293 \n",
      "Epoch: 19860 | MAE Train Loss: 51.90007019042969 | MAE Test Loss: 48.12942123413086 \n",
      "Epoch: 19870 | MAE Train Loss: 51.89552307128906 | MAE Test Loss: 48.125648498535156 \n",
      "Epoch: 19880 | MAE Train Loss: 51.8909797668457 | MAE Test Loss: 48.12187957763672 \n",
      "Epoch: 19890 | MAE Train Loss: 51.88643264770508 | MAE Test Loss: 48.11811065673828 \n",
      "Epoch: 19900 | MAE Train Loss: 51.88188171386719 | MAE Test Loss: 48.114341735839844 \n",
      "Epoch: 19910 | MAE Train Loss: 51.87733459472656 | MAE Test Loss: 48.110572814941406 \n",
      "Epoch: 19920 | MAE Train Loss: 51.87278747558594 | MAE Test Loss: 48.1068000793457 \n",
      "Epoch: 19930 | MAE Train Loss: 51.86824035644531 | MAE Test Loss: 48.10302734375 \n",
      "Epoch: 19940 | MAE Train Loss: 51.86369705200195 | MAE Test Loss: 48.09925842285156 \n",
      "Epoch: 19950 | MAE Train Loss: 51.8591423034668 | MAE Test Loss: 48.095481872558594 \n",
      "Epoch: 19960 | MAE Train Loss: 51.85459518432617 | MAE Test Loss: 48.09170913696289 \n",
      "Epoch: 19970 | MAE Train Loss: 51.85005187988281 | MAE Test Loss: 48.08794021606445 \n",
      "Epoch: 19980 | MAE Train Loss: 51.84550476074219 | MAE Test Loss: 48.084171295166016 \n",
      "Epoch: 19990 | MAE Train Loss: 51.84095001220703 | MAE Test Loss: 48.08040237426758 \n",
      "Epoch: 20000 | MAE Train Loss: 51.83640670776367 | MAE Test Loss: 48.07663345336914 \n",
      "Epoch: 20010 | MAE Train Loss: 51.83186340332031 | MAE Test Loss: 48.07285690307617 \n",
      "Epoch: 20020 | MAE Train Loss: 51.82731628417969 | MAE Test Loss: 48.069087982177734 \n",
      "Epoch: 20030 | MAE Train Loss: 51.8227653503418 | MAE Test Loss: 48.06531524658203 \n",
      "Epoch: 20040 | MAE Train Loss: 51.81822204589844 | MAE Test Loss: 48.061546325683594 \n",
      "Epoch: 20050 | MAE Train Loss: 51.81367111206055 | MAE Test Loss: 48.057769775390625 \n",
      "Epoch: 20060 | MAE Train Loss: 51.80912399291992 | MAE Test Loss: 48.05400085449219 \n",
      "Epoch: 20070 | MAE Train Loss: 51.80458068847656 | MAE Test Loss: 48.05023193359375 \n",
      "Epoch: 20080 | MAE Train Loss: 51.80002975463867 | MAE Test Loss: 48.04646301269531 \n",
      "Epoch: 20090 | MAE Train Loss: 51.79547882080078 | MAE Test Loss: 48.042694091796875 \n",
      "Epoch: 20100 | MAE Train Loss: 51.79093933105469 | MAE Test Loss: 48.03892135620117 \n",
      "Epoch: 20110 | MAE Train Loss: 51.7863883972168 | MAE Test Loss: 48.0351448059082 \n",
      "Epoch: 20120 | MAE Train Loss: 51.78184127807617 | MAE Test Loss: 48.0313835144043 \n",
      "Epoch: 20130 | MAE Train Loss: 51.777286529541016 | MAE Test Loss: 48.027610778808594 \n",
      "Epoch: 20140 | MAE Train Loss: 51.77274703979492 | MAE Test Loss: 48.02383804321289 \n",
      "Epoch: 20150 | MAE Train Loss: 51.76820373535156 | MAE Test Loss: 48.02006530761719 \n",
      "Epoch: 20160 | MAE Train Loss: 51.763648986816406 | MAE Test Loss: 48.016292572021484 \n",
      "Epoch: 20170 | MAE Train Loss: 51.75910186767578 | MAE Test Loss: 48.01252365112305 \n",
      "Epoch: 20180 | MAE Train Loss: 51.75455856323242 | MAE Test Loss: 48.00875473022461 \n",
      "Epoch: 20190 | MAE Train Loss: 51.7500114440918 | MAE Test Loss: 48.004981994628906 \n",
      "Epoch: 20200 | MAE Train Loss: 51.74546432495117 | MAE Test Loss: 48.00121307373047 \n",
      "Epoch: 20210 | MAE Train Loss: 51.74091339111328 | MAE Test Loss: 47.9974365234375 \n",
      "Epoch: 20220 | MAE Train Loss: 51.736366271972656 | MAE Test Loss: 47.99366760253906 \n",
      "Epoch: 20230 | MAE Train Loss: 51.73181915283203 | MAE Test Loss: 47.989898681640625 \n",
      "Epoch: 20240 | MAE Train Loss: 51.72727584838867 | MAE Test Loss: 47.98612594604492 \n",
      "Epoch: 20250 | MAE Train Loss: 51.722721099853516 | MAE Test Loss: 47.98234939575195 \n",
      "Epoch: 20260 | MAE Train Loss: 51.71818161010742 | MAE Test Loss: 47.97858810424805 \n",
      "Epoch: 20270 | MAE Train Loss: 51.71363067626953 | MAE Test Loss: 47.97481918334961 \n",
      "Epoch: 20280 | MAE Train Loss: 51.709083557128906 | MAE Test Loss: 47.97104263305664 \n",
      "Epoch: 20290 | MAE Train Loss: 51.70454025268555 | MAE Test Loss: 47.96726989746094 \n",
      "Epoch: 20300 | MAE Train Loss: 51.69999313354492 | MAE Test Loss: 47.963504791259766 \n",
      "Epoch: 20310 | MAE Train Loss: 51.6954460144043 | MAE Test Loss: 47.95973205566406 \n",
      "Epoch: 20320 | MAE Train Loss: 51.69089889526367 | MAE Test Loss: 47.955955505371094 \n",
      "Epoch: 20330 | MAE Train Loss: 51.68634796142578 | MAE Test Loss: 47.952186584472656 \n",
      "Epoch: 20340 | MAE Train Loss: 51.681800842285156 | MAE Test Loss: 47.94841766357422 \n",
      "Epoch: 20350 | MAE Train Loss: 51.67725372314453 | MAE Test Loss: 47.944644927978516 \n",
      "Epoch: 20360 | MAE Train Loss: 51.672706604003906 | MAE Test Loss: 47.94087219238281 \n",
      "Epoch: 20370 | MAE Train Loss: 51.668155670166016 | MAE Test Loss: 47.937103271484375 \n",
      "Epoch: 20380 | MAE Train Loss: 51.66361618041992 | MAE Test Loss: 47.93333053588867 \n",
      "Epoch: 20390 | MAE Train Loss: 51.65906524658203 | MAE Test Loss: 47.929561614990234 \n",
      "Epoch: 20400 | MAE Train Loss: 51.654518127441406 | MAE Test Loss: 47.9257926940918 \n",
      "Epoch: 20410 | MAE Train Loss: 51.64997100830078 | MAE Test Loss: 47.92202377319336 \n",
      "Epoch: 20420 | MAE Train Loss: 51.64542770385742 | MAE Test Loss: 47.91824722290039 \n",
      "Epoch: 20430 | MAE Train Loss: 51.6408805847168 | MAE Test Loss: 47.91447448730469 \n",
      "Epoch: 20440 | MAE Train Loss: 51.636329650878906 | MAE Test Loss: 47.910709381103516 \n",
      "Epoch: 20450 | MAE Train Loss: 51.63178253173828 | MAE Test Loss: 47.90693664550781 \n",
      "Epoch: 20460 | MAE Train Loss: 51.627235412597656 | MAE Test Loss: 47.903167724609375 \n",
      "Epoch: 20470 | MAE Train Loss: 51.62268829345703 | MAE Test Loss: 47.89939880371094 \n",
      "Epoch: 20480 | MAE Train Loss: 51.61813735961914 | MAE Test Loss: 47.89562225341797 \n",
      "Epoch: 20490 | MAE Train Loss: 51.613590240478516 | MAE Test Loss: 47.89185333251953 \n",
      "Epoch: 20500 | MAE Train Loss: 51.60904312133789 | MAE Test Loss: 47.888084411621094 \n",
      "Epoch: 20510 | MAE Train Loss: 51.60449981689453 | MAE Test Loss: 47.884315490722656 \n",
      "Epoch: 20520 | MAE Train Loss: 51.599952697753906 | MAE Test Loss: 47.88054275512695 \n",
      "Epoch: 20530 | MAE Train Loss: 51.59539794921875 | MAE Test Loss: 47.876773834228516 \n",
      "Epoch: 20540 | MAE Train Loss: 51.59085464477539 | MAE Test Loss: 47.87299728393555 \n",
      "Epoch: 20550 | MAE Train Loss: 51.586307525634766 | MAE Test Loss: 47.86922836303711 \n",
      "Epoch: 20560 | MAE Train Loss: 51.581764221191406 | MAE Test Loss: 47.86545944213867 \n",
      "Epoch: 20570 | MAE Train Loss: 51.57721710205078 | MAE Test Loss: 47.8616828918457 \n",
      "Epoch: 20580 | MAE Train Loss: 51.572669982910156 | MAE Test Loss: 47.857913970947266 \n",
      "Epoch: 20590 | MAE Train Loss: 51.568115234375 | MAE Test Loss: 47.85414505004883 \n",
      "Epoch: 20600 | MAE Train Loss: 51.56359100341797 | MAE Test Loss: 47.850074768066406 \n",
      "Epoch: 20610 | MAE Train Loss: 51.559085845947266 | MAE Test Loss: 47.8458137512207 \n",
      "Epoch: 20620 | MAE Train Loss: 51.5545768737793 | MAE Test Loss: 47.84159851074219 \n",
      "Epoch: 20630 | MAE Train Loss: 51.55006790161133 | MAE Test Loss: 47.83732986450195 \n",
      "Epoch: 20640 | MAE Train Loss: 51.54555130004883 | MAE Test Loss: 47.833072662353516 \n",
      "Epoch: 20650 | MAE Train Loss: 51.54104232788086 | MAE Test Loss: 47.82881164550781 \n",
      "Epoch: 20660 | MAE Train Loss: 51.53653335571289 | MAE Test Loss: 47.82464599609375 \n",
      "Epoch: 20670 | MAE Train Loss: 51.532020568847656 | MAE Test Loss: 47.82038497924805 \n",
      "Epoch: 20680 | MAE Train Loss: 51.52751159667969 | MAE Test Loss: 47.81611633300781 \n",
      "Epoch: 20690 | MAE Train Loss: 51.52299880981445 | MAE Test Loss: 47.811851501464844 \n",
      "Epoch: 20700 | MAE Train Loss: 51.51848602294922 | MAE Test Loss: 47.80759048461914 \n",
      "Epoch: 20710 | MAE Train Loss: 51.51397705078125 | MAE Test Loss: 47.80342102050781 \n",
      "Epoch: 20720 | MAE Train Loss: 51.50946807861328 | MAE Test Loss: 47.799156188964844 \n",
      "Epoch: 20730 | MAE Train Loss: 51.50495910644531 | MAE Test Loss: 47.79489517211914 \n",
      "Epoch: 20740 | MAE Train Loss: 51.50044250488281 | MAE Test Loss: 47.79063034057617 \n",
      "Epoch: 20750 | MAE Train Loss: 51.49592590332031 | MAE Test Loss: 47.786460876464844 \n",
      "Epoch: 20760 | MAE Train Loss: 51.491416931152344 | MAE Test Loss: 47.782203674316406 \n",
      "Epoch: 20770 | MAE Train Loss: 51.486907958984375 | MAE Test Loss: 47.7779426574707 \n",
      "Epoch: 20780 | MAE Train Loss: 51.48240661621094 | MAE Test Loss: 47.773677825927734 \n",
      "Epoch: 20790 | MAE Train Loss: 51.47789001464844 | MAE Test Loss: 47.7694091796875 \n",
      "Epoch: 20800 | MAE Train Loss: 51.47338104248047 | MAE Test Loss: 47.7652473449707 \n",
      "Epoch: 20810 | MAE Train Loss: 51.46886444091797 | MAE Test Loss: 47.76097869873047 \n",
      "Epoch: 20820 | MAE Train Loss: 51.46435546875 | MAE Test Loss: 47.7567138671875 \n",
      "Epoch: 20830 | MAE Train Loss: 51.459842681884766 | MAE Test Loss: 47.7524528503418 \n",
      "Epoch: 20840 | MAE Train Loss: 51.45533752441406 | MAE Test Loss: 47.74818801879883 \n",
      "Epoch: 20850 | MAE Train Loss: 51.45082473754883 | MAE Test Loss: 47.7440185546875 \n",
      "Epoch: 20860 | MAE Train Loss: 51.44631576538086 | MAE Test Loss: 47.73976135253906 \n",
      "Epoch: 20870 | MAE Train Loss: 51.441802978515625 | MAE Test Loss: 47.73549270629883 \n",
      "Epoch: 20880 | MAE Train Loss: 51.43729019165039 | MAE Test Loss: 47.731231689453125 \n",
      "Epoch: 20890 | MAE Train Loss: 51.43277359008789 | MAE Test Loss: 47.72706604003906 \n",
      "Epoch: 20900 | MAE Train Loss: 51.42827224731445 | MAE Test Loss: 47.72279739379883 \n",
      "Epoch: 20910 | MAE Train Loss: 51.423763275146484 | MAE Test Loss: 47.71854019165039 \n",
      "Epoch: 20920 | MAE Train Loss: 51.41925048828125 | MAE Test Loss: 47.714271545410156 \n",
      "Epoch: 20930 | MAE Train Loss: 51.41476058959961 | MAE Test Loss: 47.710121154785156 \n",
      "Epoch: 20940 | MAE Train Loss: 51.41042709350586 | MAE Test Loss: 47.70645523071289 \n",
      "Epoch: 20950 | MAE Train Loss: 51.406105041503906 | MAE Test Loss: 47.70280075073242 \n",
      "Epoch: 20960 | MAE Train Loss: 51.401790618896484 | MAE Test Loss: 47.69914245605469 \n",
      "Epoch: 20970 | MAE Train Loss: 51.39746856689453 | MAE Test Loss: 47.69548416137695 \n",
      "Epoch: 20980 | MAE Train Loss: 51.39315414428711 | MAE Test Loss: 47.691829681396484 \n",
      "Epoch: 20990 | MAE Train Loss: 51.38883972167969 | MAE Test Loss: 47.688167572021484 \n",
      "Epoch: 21000 | MAE Train Loss: 51.384521484375 | MAE Test Loss: 47.68451690673828 \n",
      "Epoch: 21010 | MAE Train Loss: 51.38020706176758 | MAE Test Loss: 47.680850982666016 \n",
      "Epoch: 21020 | MAE Train Loss: 51.375885009765625 | MAE Test Loss: 47.67719650268555 \n",
      "Epoch: 21030 | MAE Train Loss: 51.37156295776367 | MAE Test Loss: 47.67353820800781 \n",
      "Epoch: 21040 | MAE Train Loss: 51.36724853515625 | MAE Test Loss: 47.669883728027344 \n",
      "Epoch: 21050 | MAE Train Loss: 51.36293411254883 | MAE Test Loss: 47.66621780395508 \n",
      "Epoch: 21060 | MAE Train Loss: 51.35861587524414 | MAE Test Loss: 47.66256332397461 \n",
      "Epoch: 21070 | MAE Train Loss: 51.35429763793945 | MAE Test Loss: 47.658905029296875 \n",
      "Epoch: 21080 | MAE Train Loss: 51.349979400634766 | MAE Test Loss: 47.655250549316406 \n",
      "Epoch: 21090 | MAE Train Loss: 51.34565734863281 | MAE Test Loss: 47.65159225463867 \n",
      "Epoch: 21100 | MAE Train Loss: 51.34134292602539 | MAE Test Loss: 47.647926330566406 \n",
      "Epoch: 21110 | MAE Train Loss: 51.33702850341797 | MAE Test Loss: 47.64427185058594 \n",
      "Epoch: 21120 | MAE Train Loss: 51.332706451416016 | MAE Test Loss: 47.6406135559082 \n",
      "Epoch: 21130 | MAE Train Loss: 51.328392028808594 | MAE Test Loss: 47.63695526123047 \n",
      "Epoch: 21140 | MAE Train Loss: 51.32408142089844 | MAE Test Loss: 47.63330078125 \n",
      "Epoch: 21150 | MAE Train Loss: 51.319759368896484 | MAE Test Loss: 47.629642486572266 \n",
      "Epoch: 21160 | MAE Train Loss: 51.315433502197266 | MAE Test Loss: 47.6259765625 \n",
      "Epoch: 21170 | MAE Train Loss: 51.31112289428711 | MAE Test Loss: 47.62232208251953 \n",
      "Epoch: 21180 | MAE Train Loss: 51.306800842285156 | MAE Test Loss: 47.6186637878418 \n",
      "Epoch: 21190 | MAE Train Loss: 51.302486419677734 | MAE Test Loss: 47.61500549316406 \n",
      "Epoch: 21200 | MAE Train Loss: 51.29816818237305 | MAE Test Loss: 47.61134338378906 \n",
      "Epoch: 21210 | MAE Train Loss: 51.293853759765625 | MAE Test Loss: 47.607688903808594 \n",
      "Epoch: 21220 | MAE Train Loss: 51.28953170776367 | MAE Test Loss: 47.60403060913086 \n",
      "Epoch: 21230 | MAE Train Loss: 51.28521728515625 | MAE Test Loss: 47.60037612915039 \n",
      "Epoch: 21240 | MAE Train Loss: 51.28090286254883 | MAE Test Loss: 47.596717834472656 \n",
      "Epoch: 21250 | MAE Train Loss: 51.276580810546875 | MAE Test Loss: 47.59305953979492 \n",
      "Epoch: 21260 | MAE Train Loss: 51.27226638793945 | MAE Test Loss: 47.58940124511719 \n",
      "Epoch: 21270 | MAE Train Loss: 51.267948150634766 | MAE Test Loss: 47.58573913574219 \n",
      "Epoch: 21280 | MAE Train Loss: 51.26362609863281 | MAE Test Loss: 47.58208084106445 \n",
      "Epoch: 21290 | MAE Train Loss: 51.259307861328125 | MAE Test Loss: 47.578426361083984 \n",
      "Epoch: 21300 | MAE Train Loss: 51.25498962402344 | MAE Test Loss: 47.57476806640625 \n",
      "Epoch: 21310 | MAE Train Loss: 51.250675201416016 | MAE Test Loss: 47.571109771728516 \n",
      "Epoch: 21320 | MAE Train Loss: 51.24635314941406 | MAE Test Loss: 47.567447662353516 \n",
      "Epoch: 21330 | MAE Train Loss: 51.24203872680664 | MAE Test Loss: 47.56379318237305 \n",
      "Epoch: 21340 | MAE Train Loss: 51.23772430419922 | MAE Test Loss: 47.56013488769531 \n",
      "Epoch: 21350 | MAE Train Loss: 51.233402252197266 | MAE Test Loss: 47.55647659301758 \n",
      "Epoch: 21360 | MAE Train Loss: 51.22908401489258 | MAE Test Loss: 47.552818298339844 \n",
      "Epoch: 21370 | MAE Train Loss: 51.224769592285156 | MAE Test Loss: 47.54961395263672 \n",
      "Epoch: 21380 | MAE Train Loss: 51.2204475402832 | MAE Test Loss: 47.54693603515625 \n",
      "Epoch: 21390 | MAE Train Loss: 51.21613311767578 | MAE Test Loss: 47.54425811767578 \n",
      "Epoch: 21400 | MAE Train Loss: 51.21181869506836 | MAE Test Loss: 47.54158020019531 \n",
      "Epoch: 21410 | MAE Train Loss: 51.207496643066406 | MAE Test Loss: 47.53889846801758 \n",
      "Epoch: 21420 | MAE Train Loss: 51.203182220458984 | MAE Test Loss: 47.536224365234375 \n",
      "Epoch: 21430 | MAE Train Loss: 51.1988639831543 | MAE Test Loss: 47.53354263305664 \n",
      "Epoch: 21440 | MAE Train Loss: 51.194549560546875 | MAE Test Loss: 47.5308723449707 \n",
      "Epoch: 21450 | MAE Train Loss: 51.19022750854492 | MAE Test Loss: 47.5281867980957 \n",
      "Epoch: 21460 | MAE Train Loss: 51.18590545654297 | MAE Test Loss: 47.5255126953125 \n",
      "Epoch: 21470 | MAE Train Loss: 51.18159103393555 | MAE Test Loss: 47.52283477783203 \n",
      "Epoch: 21480 | MAE Train Loss: 51.177268981933594 | MAE Test Loss: 47.52015686035156 \n",
      "Epoch: 21490 | MAE Train Loss: 51.17295455932617 | MAE Test Loss: 47.517478942871094 \n",
      "Epoch: 21500 | MAE Train Loss: 51.16864013671875 | MAE Test Loss: 47.514801025390625 \n",
      "Epoch: 21510 | MAE Train Loss: 51.16432189941406 | MAE Test Loss: 47.512123107910156 \n",
      "Epoch: 21520 | MAE Train Loss: 51.15999984741211 | MAE Test Loss: 47.50944137573242 \n",
      "Epoch: 21530 | MAE Train Loss: 51.15568542480469 | MAE Test Loss: 47.50676345825195 \n",
      "Epoch: 21540 | MAE Train Loss: 51.151371002197266 | MAE Test Loss: 47.504093170166016 \n",
      "Epoch: 21550 | MAE Train Loss: 51.14704895019531 | MAE Test Loss: 47.50141143798828 \n",
      "Epoch: 21560 | MAE Train Loss: 51.142738342285156 | MAE Test Loss: 47.49873352050781 \n",
      "Epoch: 21570 | MAE Train Loss: 51.13841247558594 | MAE Test Loss: 47.496055603027344 \n",
      "Epoch: 21580 | MAE Train Loss: 51.13411331176758 | MAE Test Loss: 47.49288558959961 \n",
      "Epoch: 21590 | MAE Train Loss: 51.12980270385742 | MAE Test Loss: 47.4898796081543 \n",
      "Epoch: 21600 | MAE Train Loss: 51.1254997253418 | MAE Test Loss: 47.4867057800293 \n",
      "Epoch: 21610 | MAE Train Loss: 51.12118148803711 | MAE Test Loss: 47.4835319519043 \n",
      "Epoch: 21620 | MAE Train Loss: 51.11688232421875 | MAE Test Loss: 47.48052215576172 \n",
      "Epoch: 21630 | MAE Train Loss: 51.112579345703125 | MAE Test Loss: 47.47734832763672 \n",
      "Epoch: 21640 | MAE Train Loss: 51.10826873779297 | MAE Test Loss: 47.47417449951172 \n",
      "Epoch: 21650 | MAE Train Loss: 51.10395812988281 | MAE Test Loss: 47.471168518066406 \n",
      "Epoch: 21660 | MAE Train Loss: 51.09965896606445 | MAE Test Loss: 47.46799850463867 \n",
      "Epoch: 21670 | MAE Train Loss: 51.0953483581543 | MAE Test Loss: 47.464820861816406 \n",
      "Epoch: 21680 | MAE Train Loss: 51.09104537963867 | MAE Test Loss: 47.461814880371094 \n",
      "Epoch: 21690 | MAE Train Loss: 51.086734771728516 | MAE Test Loss: 47.45864486694336 \n",
      "Epoch: 21700 | MAE Train Loss: 51.082427978515625 | MAE Test Loss: 47.455474853515625 \n",
      "Epoch: 21710 | MAE Train Loss: 51.078121185302734 | MAE Test Loss: 47.45246505737305 \n",
      "Epoch: 21720 | MAE Train Loss: 51.073814392089844 | MAE Test Loss: 47.44929122924805 \n",
      "Epoch: 21730 | MAE Train Loss: 51.06950378417969 | MAE Test Loss: 47.446285247802734 \n",
      "Epoch: 21740 | MAE Train Loss: 51.06520080566406 | MAE Test Loss: 47.443111419677734 \n",
      "Epoch: 21750 | MAE Train Loss: 51.06089401245117 | MAE Test Loss: 47.43994140625 \n",
      "Epoch: 21760 | MAE Train Loss: 51.056636810302734 | MAE Test Loss: 47.43631362915039 \n",
      "Epoch: 21770 | MAE Train Loss: 51.052425384521484 | MAE Test Loss: 47.43238830566406 \n",
      "Epoch: 21780 | MAE Train Loss: 51.048213958740234 | MAE Test Loss: 47.428470611572266 \n",
      "Epoch: 21790 | MAE Train Loss: 51.044010162353516 | MAE Test Loss: 47.424537658691406 \n",
      "Epoch: 21800 | MAE Train Loss: 51.039791107177734 | MAE Test Loss: 47.420536041259766 \n",
      "Epoch: 21810 | MAE Train Loss: 51.035587310791016 | MAE Test Loss: 47.41660690307617 \n",
      "Epoch: 21820 | MAE Train Loss: 51.0313835144043 | MAE Test Loss: 47.41276168823242 \n",
      "Epoch: 21830 | MAE Train Loss: 51.02716827392578 | MAE Test Loss: 47.4086799621582 \n",
      "Epoch: 21840 | MAE Train Loss: 51.0229606628418 | MAE Test Loss: 47.40483474731445 \n",
      "Epoch: 21850 | MAE Train Loss: 51.01874542236328 | MAE Test Loss: 47.40090560913086 \n",
      "Epoch: 21860 | MAE Train Loss: 51.01454162597656 | MAE Test Loss: 47.39682388305664 \n",
      "Epoch: 21870 | MAE Train Loss: 51.01033020019531 | MAE Test Loss: 47.392906188964844 \n",
      "Epoch: 21880 | MAE Train Loss: 51.006126403808594 | MAE Test Loss: 47.388980865478516 \n",
      "Epoch: 21890 | MAE Train Loss: 51.001914978027344 | MAE Test Loss: 47.38505554199219 \n",
      "Epoch: 21900 | MAE Train Loss: 50.997711181640625 | MAE Test Loss: 47.381126403808594 \n",
      "Epoch: 21910 | MAE Train Loss: 50.993492126464844 | MAE Test Loss: 47.377201080322266 \n",
      "Epoch: 21920 | MAE Train Loss: 50.989288330078125 | MAE Test Loss: 47.37312316894531 \n",
      "Epoch: 21930 | MAE Train Loss: 50.985076904296875 | MAE Test Loss: 47.36919403076172 \n",
      "Epoch: 21940 | MAE Train Loss: 50.980865478515625 | MAE Test Loss: 47.36526870727539 \n",
      "Epoch: 21950 | MAE Train Loss: 50.976661682128906 | MAE Test Loss: 47.36134338378906 \n",
      "Epoch: 21960 | MAE Train Loss: 50.972450256347656 | MAE Test Loss: 47.357421875 \n",
      "Epoch: 21970 | MAE Train Loss: 50.96824645996094 | MAE Test Loss: 47.353492736816406 \n",
      "Epoch: 21980 | MAE Train Loss: 50.96403121948242 | MAE Test Loss: 47.34956359863281 \n",
      "Epoch: 21990 | MAE Train Loss: 50.95981979370117 | MAE Test Loss: 47.345481872558594 \n",
      "Epoch: 22000 | MAE Train Loss: 50.95561599731445 | MAE Test Loss: 47.34156036376953 \n",
      "Epoch: 22010 | MAE Train Loss: 50.95140838623047 | MAE Test Loss: 47.33763885498047 \n",
      "Epoch: 22020 | MAE Train Loss: 50.94719314575195 | MAE Test Loss: 47.333709716796875 \n",
      "Epoch: 22030 | MAE Train Loss: 50.942989349365234 | MAE Test Loss: 47.32978057861328 \n",
      "Epoch: 22040 | MAE Train Loss: 50.938777923583984 | MAE Test Loss: 47.32585906982422 \n",
      "Epoch: 22050 | MAE Train Loss: 50.934566497802734 | MAE Test Loss: 47.32177734375 \n",
      "Epoch: 22060 | MAE Train Loss: 50.93035888671875 | MAE Test Loss: 47.31785583496094 \n",
      "Epoch: 22070 | MAE Train Loss: 50.9261474609375 | MAE Test Loss: 47.31391906738281 \n",
      "Epoch: 22080 | MAE Train Loss: 50.921939849853516 | MAE Test Loss: 47.30992126464844 \n",
      "Epoch: 22090 | MAE Train Loss: 50.91773223876953 | MAE Test Loss: 47.305999755859375 \n",
      "Epoch: 22100 | MAE Train Loss: 50.91352462768555 | MAE Test Loss: 47.302154541015625 \n",
      "Epoch: 22110 | MAE Train Loss: 50.90931701660156 | MAE Test Loss: 47.29822540283203 \n",
      "Epoch: 22120 | MAE Train Loss: 50.90509796142578 | MAE Test Loss: 47.29414367675781 \n",
      "Epoch: 22130 | MAE Train Loss: 50.90089416503906 | MAE Test Loss: 47.29021453857422 \n",
      "Epoch: 22140 | MAE Train Loss: 50.896690368652344 | MAE Test Loss: 47.28629684448242 \n",
      "Epoch: 22150 | MAE Train Loss: 50.892478942871094 | MAE Test Loss: 47.28236770629883 \n",
      "Epoch: 22160 | MAE Train Loss: 50.888267517089844 | MAE Test Loss: 47.27843475341797 \n",
      "Epoch: 22170 | MAE Train Loss: 50.884056091308594 | MAE Test Loss: 47.27451705932617 \n",
      "Epoch: 22180 | MAE Train Loss: 50.87984848022461 | MAE Test Loss: 47.27043151855469 \n",
      "Epoch: 22190 | MAE Train Loss: 50.875640869140625 | MAE Test Loss: 47.266510009765625 \n",
      "Epoch: 22200 | MAE Train Loss: 50.87142562866211 | MAE Test Loss: 47.2625846862793 \n",
      "Epoch: 22210 | MAE Train Loss: 50.867225646972656 | MAE Test Loss: 47.2586555480957 \n",
      "Epoch: 22220 | MAE Train Loss: 50.863014221191406 | MAE Test Loss: 47.254730224609375 \n",
      "Epoch: 22230 | MAE Train Loss: 50.85880661010742 | MAE Test Loss: 47.25080490112305 \n",
      "Epoch: 22240 | MAE Train Loss: 50.85459518432617 | MAE Test Loss: 47.24672317504883 \n",
      "Epoch: 22250 | MAE Train Loss: 50.85038375854492 | MAE Test Loss: 47.242801666259766 \n",
      "Epoch: 22260 | MAE Train Loss: 50.84617233276367 | MAE Test Loss: 47.23887252807617 \n",
      "Epoch: 22270 | MAE Train Loss: 50.84196472167969 | MAE Test Loss: 47.23495101928711 \n",
      "Epoch: 22280 | MAE Train Loss: 50.8379020690918 | MAE Test Loss: 47.23234939575195 \n",
      "Epoch: 22290 | MAE Train Loss: 50.83384704589844 | MAE Test Loss: 47.229583740234375 \n",
      "Epoch: 22300 | MAE Train Loss: 50.82979202270508 | MAE Test Loss: 47.22698974609375 \n",
      "Epoch: 22310 | MAE Train Loss: 50.825767517089844 | MAE Test Loss: 47.224098205566406 \n",
      "Epoch: 22320 | MAE Train Loss: 50.82194519042969 | MAE Test Loss: 47.22004318237305 \n",
      "Epoch: 22330 | MAE Train Loss: 50.818115234375 | MAE Test Loss: 47.215999603271484 \n",
      "Epoch: 22340 | MAE Train Loss: 50.81428146362305 | MAE Test Loss: 47.211952209472656 \n",
      "Epoch: 22350 | MAE Train Loss: 50.81045150756836 | MAE Test Loss: 47.207969665527344 \n",
      "Epoch: 22360 | MAE Train Loss: 50.80662536621094 | MAE Test Loss: 47.20462417602539 \n",
      "Epoch: 22370 | MAE Train Loss: 50.802791595458984 | MAE Test Loss: 47.201271057128906 \n",
      "Epoch: 22380 | MAE Train Loss: 50.7989616394043 | MAE Test Loss: 47.19792938232422 \n",
      "Epoch: 22390 | MAE Train Loss: 50.79513168334961 | MAE Test Loss: 47.19458770751953 \n",
      "Epoch: 22400 | MAE Train Loss: 50.791297912597656 | MAE Test Loss: 47.19124221801758 \n",
      "Epoch: 22410 | MAE Train Loss: 50.7874755859375 | MAE Test Loss: 47.187896728515625 \n",
      "Epoch: 22420 | MAE Train Loss: 50.78364181518555 | MAE Test Loss: 47.184547424316406 \n",
      "Epoch: 22430 | MAE Train Loss: 50.77981185913086 | MAE Test Loss: 47.18120193481445 \n",
      "Epoch: 22440 | MAE Train Loss: 50.775978088378906 | MAE Test Loss: 47.1778564453125 \n",
      "Epoch: 22450 | MAE Train Loss: 50.77214813232422 | MAE Test Loss: 47.17451477050781 \n",
      "Epoch: 22460 | MAE Train Loss: 50.76832580566406 | MAE Test Loss: 47.171302795410156 \n",
      "Epoch: 22470 | MAE Train Loss: 50.764503479003906 | MAE Test Loss: 47.16814422607422 \n",
      "Epoch: 22480 | MAE Train Loss: 50.760677337646484 | MAE Test Loss: 47.16498565673828 \n",
      "Epoch: 22490 | MAE Train Loss: 50.75685119628906 | MAE Test Loss: 47.16187286376953 \n",
      "Epoch: 22500 | MAE Train Loss: 50.75302505493164 | MAE Test Loss: 47.15870666503906 \n",
      "Epoch: 22510 | MAE Train Loss: 50.749202728271484 | MAE Test Loss: 47.15550231933594 \n",
      "Epoch: 22520 | MAE Train Loss: 50.74538040161133 | MAE Test Loss: 47.152347564697266 \n",
      "Epoch: 22530 | MAE Train Loss: 50.74155807495117 | MAE Test Loss: 47.14918518066406 \n",
      "Epoch: 22540 | MAE Train Loss: 50.73773193359375 | MAE Test Loss: 47.14606857299805 \n",
      "Epoch: 22550 | MAE Train Loss: 50.733909606933594 | MAE Test Loss: 47.142906188964844 \n",
      "Epoch: 22560 | MAE Train Loss: 50.73008728027344 | MAE Test Loss: 47.13975143432617 \n",
      "Epoch: 22570 | MAE Train Loss: 50.72626495361328 | MAE Test Loss: 47.136592864990234 \n",
      "Epoch: 22580 | MAE Train Loss: 50.72243881225586 | MAE Test Loss: 47.1334342956543 \n",
      "Epoch: 22590 | MAE Train Loss: 50.7186164855957 | MAE Test Loss: 47.130271911621094 \n",
      "Epoch: 22600 | MAE Train Loss: 50.714786529541016 | MAE Test Loss: 47.127113342285156 \n",
      "Epoch: 22610 | MAE Train Loss: 50.71097183227539 | MAE Test Loss: 47.12395095825195 \n",
      "Epoch: 22620 | MAE Train Loss: 50.7071418762207 | MAE Test Loss: 47.120792388916016 \n",
      "Epoch: 22630 | MAE Train Loss: 50.70331954956055 | MAE Test Loss: 47.11763000488281 \n",
      "Epoch: 22640 | MAE Train Loss: 50.69949722290039 | MAE Test Loss: 47.114471435546875 \n",
      "Epoch: 22650 | MAE Train Loss: 50.69567108154297 | MAE Test Loss: 47.111732482910156 \n",
      "Epoch: 22660 | MAE Train Loss: 50.69184875488281 | MAE Test Loss: 47.10900115966797 \n",
      "Epoch: 22670 | MAE Train Loss: 50.688018798828125 | MAE Test Loss: 47.10630416870117 \n",
      "Epoch: 22680 | MAE Train Loss: 50.6842041015625 | MAE Test Loss: 47.10356903076172 \n",
      "Epoch: 22690 | MAE Train Loss: 50.68037796020508 | MAE Test Loss: 47.10083770751953 \n",
      "Epoch: 22700 | MAE Train Loss: 50.676551818847656 | MAE Test Loss: 47.09811019897461 \n",
      "Epoch: 22710 | MAE Train Loss: 50.672733306884766 | MAE Test Loss: 47.095375061035156 \n",
      "Epoch: 22720 | MAE Train Loss: 50.66890335083008 | MAE Test Loss: 47.092647552490234 \n",
      "Epoch: 22730 | MAE Train Loss: 50.66508483886719 | MAE Test Loss: 47.08991622924805 \n",
      "Epoch: 22740 | MAE Train Loss: 50.661258697509766 | MAE Test Loss: 47.087188720703125 \n",
      "Epoch: 22750 | MAE Train Loss: 50.657432556152344 | MAE Test Loss: 47.08445739746094 \n",
      "Epoch: 22760 | MAE Train Loss: 50.65361022949219 | MAE Test Loss: 47.081722259521484 \n",
      "Epoch: 22770 | MAE Train Loss: 50.64981460571289 | MAE Test Loss: 47.079078674316406 \n",
      "Epoch: 22780 | MAE Train Loss: 50.64603042602539 | MAE Test Loss: 47.07648849487305 \n",
      "Epoch: 22790 | MAE Train Loss: 50.642242431640625 | MAE Test Loss: 47.07386779785156 \n",
      "Epoch: 22800 | MAE Train Loss: 50.63845443725586 | MAE Test Loss: 47.07125473022461 \n",
      "Epoch: 22810 | MAE Train Loss: 50.63467025756836 | MAE Test Loss: 47.068634033203125 \n",
      "Epoch: 22820 | MAE Train Loss: 50.630882263183594 | MAE Test Loss: 47.066009521484375 \n",
      "Epoch: 22830 | MAE Train Loss: 50.627098083496094 | MAE Test Loss: 47.063392639160156 \n",
      "Epoch: 22840 | MAE Train Loss: 50.6233024597168 | MAE Test Loss: 47.06077194213867 \n",
      "Epoch: 22850 | MAE Train Loss: 50.61952209472656 | MAE Test Loss: 47.058189392089844 \n",
      "Epoch: 22860 | MAE Train Loss: 50.6157341003418 | MAE Test Loss: 47.055572509765625 \n",
      "Epoch: 22870 | MAE Train Loss: 50.61194610595703 | MAE Test Loss: 47.052947998046875 \n",
      "Epoch: 22880 | MAE Train Loss: 50.608158111572266 | MAE Test Loss: 47.050331115722656 \n",
      "Epoch: 22890 | MAE Train Loss: 50.604373931884766 | MAE Test Loss: 47.04771423339844 \n",
      "Epoch: 22900 | MAE Train Loss: 50.600589752197266 | MAE Test Loss: 47.04509353637695 \n",
      "Epoch: 22910 | MAE Train Loss: 50.596797943115234 | MAE Test Loss: 47.042484283447266 \n",
      "Epoch: 22920 | MAE Train Loss: 50.59300994873047 | MAE Test Loss: 47.03986740112305 \n",
      "Epoch: 22930 | MAE Train Loss: 50.58922576904297 | MAE Test Loss: 47.03725051879883 \n",
      "Epoch: 22940 | MAE Train Loss: 50.5854377746582 | MAE Test Loss: 47.03466796875 \n",
      "Epoch: 22950 | MAE Train Loss: 50.58164978027344 | MAE Test Loss: 47.032047271728516 \n",
      "Epoch: 22960 | MAE Train Loss: 50.57786560058594 | MAE Test Loss: 47.029422760009766 \n",
      "Epoch: 22970 | MAE Train Loss: 50.57408142089844 | MAE Test Loss: 47.02682876586914 \n",
      "Epoch: 22980 | MAE Train Loss: 50.570289611816406 | MAE Test Loss: 47.02420425415039 \n",
      "Epoch: 22990 | MAE Train Loss: 50.566505432128906 | MAE Test Loss: 47.02158737182617 \n",
      "Epoch: 23000 | MAE Train Loss: 50.56271743774414 | MAE Test Loss: 47.01896667480469 \n",
      "Epoch: 23010 | MAE Train Loss: 50.558929443359375 | MAE Test Loss: 47.01634216308594 \n",
      "Epoch: 23020 | MAE Train Loss: 50.55514144897461 | MAE Test Loss: 47.01372528076172 \n",
      "Epoch: 23030 | MAE Train Loss: 50.55135726928711 | MAE Test Loss: 47.01114273071289 \n",
      "Epoch: 23040 | MAE Train Loss: 50.54757308959961 | MAE Test Loss: 47.00852584838867 \n",
      "Epoch: 23050 | MAE Train Loss: 50.54378128051758 | MAE Test Loss: 47.00590515136719 \n",
      "Epoch: 23060 | MAE Train Loss: 50.54000473022461 | MAE Test Loss: 47.0032844543457 \n",
      "Epoch: 23070 | MAE Train Loss: 50.53620910644531 | MAE Test Loss: 47.00067901611328 \n",
      "Epoch: 23080 | MAE Train Loss: 50.53242111206055 | MAE Test Loss: 46.9980583190918 \n",
      "Epoch: 23090 | MAE Train Loss: 50.52863693237305 | MAE Test Loss: 46.995445251464844 \n",
      "Epoch: 23100 | MAE Train Loss: 50.52484893798828 | MAE Test Loss: 46.99282455444336 \n",
      "Epoch: 23110 | MAE Train Loss: 50.52105712890625 | MAE Test Loss: 46.99020767211914 \n",
      "Epoch: 23120 | MAE Train Loss: 50.51727294921875 | MAE Test Loss: 46.98759078979492 \n",
      "Epoch: 23130 | MAE Train Loss: 50.51348876953125 | MAE Test Loss: 46.984989166259766 \n",
      "Epoch: 23140 | MAE Train Loss: 50.50970458984375 | MAE Test Loss: 46.98237228393555 \n",
      "Epoch: 23150 | MAE Train Loss: 50.50590896606445 | MAE Test Loss: 46.97974395751953 \n",
      "Epoch: 23160 | MAE Train Loss: 50.50212478637695 | MAE Test Loss: 46.97715377807617 \n",
      "Epoch: 23170 | MAE Train Loss: 50.49834060668945 | MAE Test Loss: 46.97453689575195 \n",
      "Epoch: 23180 | MAE Train Loss: 50.49455642700195 | MAE Test Loss: 46.971920013427734 \n",
      "Epoch: 23190 | MAE Train Loss: 50.49077224731445 | MAE Test Loss: 46.969303131103516 \n",
      "Epoch: 23200 | MAE Train Loss: 50.48698043823242 | MAE Test Loss: 46.9666862487793 \n",
      "Epoch: 23210 | MAE Train Loss: 50.48319625854492 | MAE Test Loss: 46.96406555175781 \n",
      "Epoch: 23220 | MAE Train Loss: 50.479408264160156 | MAE Test Loss: 46.96147537231445 \n",
      "Epoch: 23230 | MAE Train Loss: 50.47562026977539 | MAE Test Loss: 46.958858489990234 \n",
      "Epoch: 23240 | MAE Train Loss: 50.47183609008789 | MAE Test Loss: 46.956241607666016 \n",
      "Epoch: 23250 | MAE Train Loss: 50.468048095703125 | MAE Test Loss: 46.9536247253418 \n",
      "Epoch: 23260 | MAE Train Loss: 50.464263916015625 | MAE Test Loss: 46.95100784301758 \n",
      "Epoch: 23270 | MAE Train Loss: 50.460472106933594 | MAE Test Loss: 46.94838333129883 \n",
      "Epoch: 23280 | MAE Train Loss: 50.456687927246094 | MAE Test Loss: 46.945899963378906 \n",
      "Epoch: 23290 | MAE Train Loss: 50.45289993286133 | MAE Test Loss: 46.943607330322266 \n",
      "Epoch: 23300 | MAE Train Loss: 50.44911193847656 | MAE Test Loss: 46.94121551513672 \n",
      "Epoch: 23310 | MAE Train Loss: 50.44532775878906 | MAE Test Loss: 46.938812255859375 \n",
      "Epoch: 23320 | MAE Train Loss: 50.44154357910156 | MAE Test Loss: 46.93642044067383 \n",
      "Epoch: 23330 | MAE Train Loss: 50.4377555847168 | MAE Test Loss: 46.93402099609375 \n",
      "Epoch: 23340 | MAE Train Loss: 50.433963775634766 | MAE Test Loss: 46.93162536621094 \n",
      "Epoch: 23350 | MAE Train Loss: 50.4301872253418 | MAE Test Loss: 46.929325103759766 \n",
      "Epoch: 23360 | MAE Train Loss: 50.426395416259766 | MAE Test Loss: 46.92693328857422 \n",
      "Epoch: 23370 | MAE Train Loss: 50.422611236572266 | MAE Test Loss: 46.924537658691406 \n",
      "Epoch: 23380 | MAE Train Loss: 50.418819427490234 | MAE Test Loss: 46.92213821411133 \n",
      "Epoch: 23390 | MAE Train Loss: 50.415035247802734 | MAE Test Loss: 46.91974639892578 \n",
      "Epoch: 23400 | MAE Train Loss: 50.41124725341797 | MAE Test Loss: 46.9173469543457 \n",
      "Epoch: 23410 | MAE Train Loss: 50.40746307373047 | MAE Test Loss: 46.91505432128906 \n",
      "Epoch: 23420 | MAE Train Loss: 50.40370559692383 | MAE Test Loss: 46.9124870300293 \n",
      "Epoch: 23430 | MAE Train Loss: 50.399959564208984 | MAE Test Loss: 46.909934997558594 \n",
      "Epoch: 23440 | MAE Train Loss: 50.39621353149414 | MAE Test Loss: 46.907386779785156 \n",
      "Epoch: 23450 | MAE Train Loss: 50.39247131347656 | MAE Test Loss: 46.90483093261719 \n",
      "Epoch: 23460 | MAE Train Loss: 50.388729095458984 | MAE Test Loss: 46.902278900146484 \n",
      "Epoch: 23470 | MAE Train Loss: 50.384986877441406 | MAE Test Loss: 46.899723052978516 \n",
      "Epoch: 23480 | MAE Train Loss: 50.38124084472656 | MAE Test Loss: 46.8970832824707 \n",
      "Epoch: 23490 | MAE Train Loss: 50.37749481201172 | MAE Test Loss: 46.894527435302734 \n",
      "Epoch: 23500 | MAE Train Loss: 50.373756408691406 | MAE Test Loss: 46.89197540283203 \n",
      "Epoch: 23510 | MAE Train Loss: 50.37001419067383 | MAE Test Loss: 46.88941955566406 \n",
      "Epoch: 23520 | MAE Train Loss: 50.366268157958984 | MAE Test Loss: 46.88686752319336 \n",
      "Epoch: 23530 | MAE Train Loss: 50.36252212524414 | MAE Test Loss: 46.884315490722656 \n",
      "Epoch: 23540 | MAE Train Loss: 50.3587760925293 | MAE Test Loss: 46.88175964355469 \n",
      "Epoch: 23550 | MAE Train Loss: 50.355037689208984 | MAE Test Loss: 46.87911605834961 \n",
      "Epoch: 23560 | MAE Train Loss: 50.35129165649414 | MAE Test Loss: 46.876564025878906 \n",
      "Epoch: 23570 | MAE Train Loss: 50.34754943847656 | MAE Test Loss: 46.87400817871094 \n",
      "Epoch: 23580 | MAE Train Loss: 50.34381103515625 | MAE Test Loss: 46.871456146240234 \n",
      "Epoch: 23590 | MAE Train Loss: 50.34006118774414 | MAE Test Loss: 46.86890411376953 \n",
      "Epoch: 23600 | MAE Train Loss: 50.33631896972656 | MAE Test Loss: 46.86634826660156 \n",
      "Epoch: 23610 | MAE Train Loss: 50.33257293701172 | MAE Test Loss: 46.86380386352539 \n",
      "Epoch: 23620 | MAE Train Loss: 50.328826904296875 | MAE Test Loss: 46.86115646362305 \n",
      "Epoch: 23630 | MAE Train Loss: 50.32508850097656 | MAE Test Loss: 46.85859680175781 \n",
      "Epoch: 23640 | MAE Train Loss: 50.32134246826172 | MAE Test Loss: 46.856048583984375 \n",
      "Epoch: 23650 | MAE Train Loss: 50.31760025024414 | MAE Test Loss: 46.853492736816406 \n",
      "Epoch: 23660 | MAE Train Loss: 50.31386184692383 | MAE Test Loss: 46.8509407043457 \n",
      "Epoch: 23670 | MAE Train Loss: 50.31010818481445 | MAE Test Loss: 46.84834289550781 \n",
      "Epoch: 23680 | MAE Train Loss: 50.30636978149414 | MAE Test Loss: 46.84579086303711 \n",
      "Epoch: 23690 | MAE Train Loss: 50.3026237487793 | MAE Test Loss: 46.84323501586914 \n",
      "Epoch: 23700 | MAE Train Loss: 50.29888916015625 | MAE Test Loss: 46.8406867980957 \n",
      "Epoch: 23710 | MAE Train Loss: 50.295143127441406 | MAE Test Loss: 46.838130950927734 \n",
      "Epoch: 23720 | MAE Train Loss: 50.29139709472656 | MAE Test Loss: 46.8355827331543 \n",
      "Epoch: 23730 | MAE Train Loss: 50.28765869140625 | MAE Test Loss: 46.83293533325195 \n",
      "Epoch: 23740 | MAE Train Loss: 50.283912658691406 | MAE Test Loss: 46.830379486083984 \n",
      "Epoch: 23750 | MAE Train Loss: 50.28016662597656 | MAE Test Loss: 46.827823638916016 \n",
      "Epoch: 23760 | MAE Train Loss: 50.276424407958984 | MAE Test Loss: 46.825279235839844 \n",
      "Epoch: 23770 | MAE Train Loss: 50.272674560546875 | MAE Test Loss: 46.82271957397461 \n",
      "Epoch: 23780 | MAE Train Loss: 50.2689323425293 | MAE Test Loss: 46.82017135620117 \n",
      "Epoch: 23790 | MAE Train Loss: 50.265193939208984 | MAE Test Loss: 46.81761169433594 \n",
      "Epoch: 23800 | MAE Train Loss: 50.26144790649414 | MAE Test Loss: 46.81496810913086 \n",
      "Epoch: 23810 | MAE Train Loss: 50.2577018737793 | MAE Test Loss: 46.812416076660156 \n",
      "Epoch: 23820 | MAE Train Loss: 50.253963470458984 | MAE Test Loss: 46.80986785888672 \n",
      "Epoch: 23830 | MAE Train Loss: 50.25021743774414 | MAE Test Loss: 46.80735397338867 \n",
      "Epoch: 23840 | MAE Train Loss: 50.2464714050293 | MAE Test Loss: 46.80471420288086 \n",
      "Epoch: 23850 | MAE Train Loss: 50.24272918701172 | MAE Test Loss: 46.80215835571289 \n",
      "Epoch: 23860 | MAE Train Loss: 50.238990783691406 | MAE Test Loss: 46.79960632324219 \n",
      "Epoch: 23870 | MAE Train Loss: 50.23524475097656 | MAE Test Loss: 46.79705047607422 \n",
      "Epoch: 23880 | MAE Train Loss: 50.231502532958984 | MAE Test Loss: 46.794498443603516 \n",
      "Epoch: 23890 | MAE Train Loss: 50.22776412963867 | MAE Test Loss: 46.79194641113281 \n",
      "Epoch: 23900 | MAE Train Loss: 50.22401809692383 | MAE Test Loss: 46.789398193359375 \n",
      "Epoch: 23910 | MAE Train Loss: 50.22026443481445 | MAE Test Loss: 46.786746978759766 \n",
      "Epoch: 23920 | MAE Train Loss: 50.21652603149414 | MAE Test Loss: 46.784202575683594 \n",
      "Epoch: 23930 | MAE Train Loss: 50.21278381347656 | MAE Test Loss: 46.781646728515625 \n",
      "Epoch: 23940 | MAE Train Loss: 50.209041595458984 | MAE Test Loss: 46.77909469604492 \n",
      "Epoch: 23950 | MAE Train Loss: 50.205299377441406 | MAE Test Loss: 46.77654266357422 \n",
      "Epoch: 23960 | MAE Train Loss: 50.20155334472656 | MAE Test Loss: 46.77397918701172 \n",
      "Epoch: 23970 | MAE Train Loss: 50.19780731201172 | MAE Test Loss: 46.77143096923828 \n",
      "Epoch: 23980 | MAE Train Loss: 50.194061279296875 | MAE Test Loss: 46.76878356933594 \n",
      "Epoch: 23990 | MAE Train Loss: 50.19032287597656 | MAE Test Loss: 46.7662353515625 \n",
      "Epoch: 24000 | MAE Train Loss: 50.18657684326172 | MAE Test Loss: 46.76372528076172 \n",
      "Epoch: 24010 | MAE Train Loss: 50.18283462524414 | MAE Test Loss: 46.76117706298828 \n",
      "Epoch: 24020 | MAE Train Loss: 50.1790885925293 | MAE Test Loss: 46.75852966308594 \n",
      "Epoch: 24030 | MAE Train Loss: 50.175350189208984 | MAE Test Loss: 46.75597381591797 \n",
      "Epoch: 24040 | MAE Train Loss: 50.171607971191406 | MAE Test Loss: 46.7534294128418 \n",
      "Epoch: 24050 | MAE Train Loss: 50.167869567871094 | MAE Test Loss: 46.75087356567383 \n",
      "Epoch: 24060 | MAE Train Loss: 50.16412353515625 | MAE Test Loss: 46.748313903808594 \n",
      "Epoch: 24070 | MAE Train Loss: 50.160377502441406 | MAE Test Loss: 46.745765686035156 \n",
      "Epoch: 24080 | MAE Train Loss: 50.15663146972656 | MAE Test Loss: 46.74321365356445 \n",
      "Epoch: 24090 | MAE Train Loss: 50.15288543701172 | MAE Test Loss: 46.740562438964844 \n",
      "Epoch: 24100 | MAE Train Loss: 50.149139404296875 | MAE Test Loss: 46.738014221191406 \n",
      "Epoch: 24110 | MAE Train Loss: 50.14540100097656 | MAE Test Loss: 46.7354621887207 \n",
      "Epoch: 24120 | MAE Train Loss: 50.14165496826172 | MAE Test Loss: 46.732906341552734 \n",
      "Epoch: 24130 | MAE Train Loss: 50.13791275024414 | MAE Test Loss: 46.73035430908203 \n",
      "Epoch: 24140 | MAE Train Loss: 50.13417434692383 | MAE Test Loss: 46.72780227661133 \n",
      "Epoch: 24150 | MAE Train Loss: 50.130428314208984 | MAE Test Loss: 46.725250244140625 \n",
      "Epoch: 24160 | MAE Train Loss: 50.12667465209961 | MAE Test Loss: 46.722652435302734 \n",
      "Epoch: 24170 | MAE Train Loss: 50.12294006347656 | MAE Test Loss: 46.7200927734375 \n",
      "Epoch: 24180 | MAE Train Loss: 50.119197845458984 | MAE Test Loss: 46.71754455566406 \n",
      "Epoch: 24190 | MAE Train Loss: 50.11545181274414 | MAE Test Loss: 46.71499252319336 \n",
      "Epoch: 24200 | MAE Train Loss: 50.11170959472656 | MAE Test Loss: 46.71234893798828 \n",
      "Epoch: 24210 | MAE Train Loss: 50.10796356201172 | MAE Test Loss: 46.70978927612305 \n",
      "Epoch: 24220 | MAE Train Loss: 50.10422897338867 | MAE Test Loss: 46.70724105834961 \n",
      "Epoch: 24230 | MAE Train Loss: 50.10047912597656 | MAE Test Loss: 46.704681396484375 \n",
      "Epoch: 24240 | MAE Train Loss: 50.096736907958984 | MAE Test Loss: 46.7021369934082 \n",
      "Epoch: 24250 | MAE Train Loss: 50.09299087524414 | MAE Test Loss: 46.699581146240234 \n",
      "Epoch: 24260 | MAE Train Loss: 50.0893440246582 | MAE Test Loss: 46.697357177734375 \n",
      "Epoch: 24270 | MAE Train Loss: 50.08582305908203 | MAE Test Loss: 46.695552825927734 \n",
      "Epoch: 24280 | MAE Train Loss: 50.082298278808594 | MAE Test Loss: 46.69375991821289 \n",
      "Epoch: 24290 | MAE Train Loss: 50.078765869140625 | MAE Test Loss: 46.69195556640625 \n",
      "Epoch: 24300 | MAE Train Loss: 50.07524871826172 | MAE Test Loss: 46.690155029296875 \n",
      "Epoch: 24310 | MAE Train Loss: 50.07171630859375 | MAE Test Loss: 46.688350677490234 \n",
      "Epoch: 24320 | MAE Train Loss: 50.06818771362305 | MAE Test Loss: 46.68655014038086 \n",
      "Epoch: 24330 | MAE Train Loss: 50.06466293334961 | MAE Test Loss: 46.68474578857422 \n",
      "Epoch: 24340 | MAE Train Loss: 50.061134338378906 | MAE Test Loss: 46.682945251464844 \n",
      "Epoch: 24350 | MAE Train Loss: 50.05760192871094 | MAE Test Loss: 46.6811408996582 \n",
      "Epoch: 24360 | MAE Train Loss: 50.054073333740234 | MAE Test Loss: 46.67934036254883 \n",
      "Epoch: 24370 | MAE Train Loss: 50.0505485534668 | MAE Test Loss: 46.67753601074219 \n",
      "Epoch: 24380 | MAE Train Loss: 50.047019958496094 | MAE Test Loss: 46.67573547363281 \n",
      "Epoch: 24390 | MAE Train Loss: 50.04349899291992 | MAE Test Loss: 46.67393112182617 \n",
      "Epoch: 24400 | MAE Train Loss: 50.03997039794922 | MAE Test Loss: 46.67213439941406 \n",
      "Epoch: 24410 | MAE Train Loss: 50.03644561767578 | MAE Test Loss: 46.67033386230469 \n",
      "Epoch: 24420 | MAE Train Loss: 50.03290939331055 | MAE Test Loss: 46.66853332519531 \n",
      "Epoch: 24430 | MAE Train Loss: 50.02939224243164 | MAE Test Loss: 46.66673278808594 \n",
      "Epoch: 24440 | MAE Train Loss: 50.025856018066406 | MAE Test Loss: 46.6649284362793 \n",
      "Epoch: 24450 | MAE Train Loss: 50.02233123779297 | MAE Test Loss: 46.66313171386719 \n",
      "Epoch: 24460 | MAE Train Loss: 50.01880645751953 | MAE Test Loss: 46.66132354736328 \n",
      "Epoch: 24470 | MAE Train Loss: 50.01527786254883 | MAE Test Loss: 46.65952682495117 \n",
      "Epoch: 24480 | MAE Train Loss: 50.01175308227539 | MAE Test Loss: 46.657718658447266 \n",
      "Epoch: 24490 | MAE Train Loss: 50.0082893371582 | MAE Test Loss: 46.65547180175781 \n",
      "Epoch: 24500 | MAE Train Loss: 50.004878997802734 | MAE Test Loss: 46.652957916259766 \n",
      "Epoch: 24510 | MAE Train Loss: 50.0014762878418 | MAE Test Loss: 46.650352478027344 \n",
      "Epoch: 24520 | MAE Train Loss: 49.99807357788086 | MAE Test Loss: 46.64773941040039 \n",
      "Epoch: 24530 | MAE Train Loss: 49.994667053222656 | MAE Test Loss: 46.64522171020508 \n",
      "Epoch: 24540 | MAE Train Loss: 49.99125671386719 | MAE Test Loss: 46.642616271972656 \n",
      "Epoch: 24550 | MAE Train Loss: 49.98786163330078 | MAE Test Loss: 46.640010833740234 \n",
      "Epoch: 24560 | MAE Train Loss: 49.984458923339844 | MAE Test Loss: 46.63749694824219 \n",
      "Epoch: 24570 | MAE Train Loss: 49.981048583984375 | MAE Test Loss: 46.6348876953125 \n",
      "Epoch: 24580 | MAE Train Loss: 49.97764587402344 | MAE Test Loss: 46.63227844238281 \n",
      "Epoch: 24590 | MAE Train Loss: 49.9742431640625 | MAE Test Loss: 46.6297607421875 \n",
      "Epoch: 24600 | MAE Train Loss: 49.9708366394043 | MAE Test Loss: 46.62716293334961 \n",
      "Epoch: 24610 | MAE Train Loss: 49.96743392944336 | MAE Test Loss: 46.6246452331543 \n",
      "Epoch: 24620 | MAE Train Loss: 49.96403121948242 | MAE Test Loss: 46.622032165527344 \n",
      "Epoch: 24630 | MAE Train Loss: 49.96061706542969 | MAE Test Loss: 46.61943054199219 \n",
      "Epoch: 24640 | MAE Train Loss: 49.957218170166016 | MAE Test Loss: 46.61690902709961 \n",
      "Epoch: 24650 | MAE Train Loss: 49.95382308959961 | MAE Test Loss: 46.61430358886719 \n",
      "Epoch: 24660 | MAE Train Loss: 49.950408935546875 | MAE Test Loss: 46.61204147338867 \n",
      "Epoch: 24670 | MAE Train Loss: 49.946998596191406 | MAE Test Loss: 46.6099967956543 \n",
      "Epoch: 24680 | MAE Train Loss: 49.943603515625 | MAE Test Loss: 46.6079216003418 \n",
      "Epoch: 24690 | MAE Train Loss: 49.94019317626953 | MAE Test Loss: 46.60584259033203 \n",
      "Epoch: 24700 | MAE Train Loss: 49.936790466308594 | MAE Test Loss: 46.603790283203125 \n",
      "Epoch: 24710 | MAE Train Loss: 49.933387756347656 | MAE Test Loss: 46.60171127319336 \n",
      "Epoch: 24720 | MAE Train Loss: 49.92998504638672 | MAE Test Loss: 46.59965515136719 \n",
      "Epoch: 24730 | MAE Train Loss: 49.926578521728516 | MAE Test Loss: 46.597572326660156 \n",
      "Epoch: 24740 | MAE Train Loss: 49.92316818237305 | MAE Test Loss: 46.59551239013672 \n",
      "Epoch: 24750 | MAE Train Loss: 49.91976547241211 | MAE Test Loss: 46.593441009521484 \n",
      "Epoch: 24760 | MAE Train Loss: 49.91636276245117 | MAE Test Loss: 46.59138107299805 \n",
      "Epoch: 24770 | MAE Train Loss: 49.912960052490234 | MAE Test Loss: 46.589317321777344 \n",
      "Epoch: 24780 | MAE Train Loss: 49.9095573425293 | MAE Test Loss: 46.58725357055664 \n",
      "Epoch: 24790 | MAE Train Loss: 49.90615463256836 | MAE Test Loss: 46.58518981933594 \n",
      "Epoch: 24800 | MAE Train Loss: 49.902748107910156 | MAE Test Loss: 46.583106994628906 \n",
      "Epoch: 24810 | MAE Train Loss: 49.89933776855469 | MAE Test Loss: 46.581050872802734 \n",
      "Epoch: 24820 | MAE Train Loss: 49.89593505859375 | MAE Test Loss: 46.578975677490234 \n",
      "Epoch: 24830 | MAE Train Loss: 49.89253234863281 | MAE Test Loss: 46.57689666748047 \n",
      "Epoch: 24840 | MAE Train Loss: 49.88912582397461 | MAE Test Loss: 46.57484436035156 \n",
      "Epoch: 24850 | MAE Train Loss: 49.88572311401367 | MAE Test Loss: 46.57276916503906 \n",
      "Epoch: 24860 | MAE Train Loss: 49.882320404052734 | MAE Test Loss: 46.570716857910156 \n",
      "Epoch: 24870 | MAE Train Loss: 49.8789176940918 | MAE Test Loss: 46.56864547729492 \n",
      "Epoch: 24880 | MAE Train Loss: 49.87550735473633 | MAE Test Loss: 46.566566467285156 \n",
      "Epoch: 24890 | MAE Train Loss: 49.87210464477539 | MAE Test Loss: 46.56451416015625 \n",
      "Epoch: 24900 | MAE Train Loss: 49.86870193481445 | MAE Test Loss: 46.562435150146484 \n",
      "Epoch: 24910 | MAE Train Loss: 49.865299224853516 | MAE Test Loss: 46.560359954833984 \n",
      "Epoch: 24920 | MAE Train Loss: 49.86189651489258 | MAE Test Loss: 46.55830764770508 \n",
      "Epoch: 24930 | MAE Train Loss: 49.858489990234375 | MAE Test Loss: 46.55622863769531 \n",
      "Epoch: 24940 | MAE Train Loss: 49.855079650878906 | MAE Test Loss: 46.554161071777344 \n",
      "Epoch: 24950 | MAE Train Loss: 49.85167694091797 | MAE Test Loss: 46.55210876464844 \n",
      "Epoch: 24960 | MAE Train Loss: 49.84827423095703 | MAE Test Loss: 46.55003356933594 \n",
      "Epoch: 24970 | MAE Train Loss: 49.844871520996094 | MAE Test Loss: 46.547977447509766 \n",
      "Epoch: 24980 | MAE Train Loss: 49.841468811035156 | MAE Test Loss: 46.5458984375 \n",
      "Epoch: 24990 | MAE Train Loss: 49.83806228637695 | MAE Test Loss: 46.54383087158203 \n",
      "Epoch: 25000 | MAE Train Loss: 49.834659576416016 | MAE Test Loss: 46.541778564453125 \n",
      "Epoch: 25010 | MAE Train Loss: 49.83124923706055 | MAE Test Loss: 46.53969955444336 \n",
      "Epoch: 25020 | MAE Train Loss: 49.827842712402344 | MAE Test Loss: 46.537620544433594 \n",
      "Epoch: 25030 | MAE Train Loss: 49.824440002441406 | MAE Test Loss: 46.53556823730469 \n",
      "Epoch: 25040 | MAE Train Loss: 49.82103729248047 | MAE Test Loss: 46.53349304199219 \n",
      "Epoch: 25050 | MAE Train Loss: 49.81773376464844 | MAE Test Loss: 46.53142547607422 \n",
      "Epoch: 25060 | MAE Train Loss: 49.81450271606445 | MAE Test Loss: 46.529361724853516 \n",
      "Epoch: 25070 | MAE Train Loss: 49.811275482177734 | MAE Test Loss: 46.527305603027344 \n",
      "Epoch: 25080 | MAE Train Loss: 49.808040618896484 | MAE Test Loss: 46.5252571105957 \n",
      "Epoch: 25090 | MAE Train Loss: 49.8048095703125 | MAE Test Loss: 46.523197174072266 \n",
      "Epoch: 25100 | MAE Train Loss: 49.80158233642578 | MAE Test Loss: 46.52113723754883 \n",
      "Epoch: 25110 | MAE Train Loss: 49.79834747314453 | MAE Test Loss: 46.51908874511719 \n",
      "Epoch: 25120 | MAE Train Loss: 49.79512023925781 | MAE Test Loss: 46.517024993896484 \n",
      "Epoch: 25130 | MAE Train Loss: 49.79188919067383 | MAE Test Loss: 46.51497268676758 \n",
      "Epoch: 25140 | MAE Train Loss: 49.788658142089844 | MAE Test Loss: 46.512916564941406 \n",
      "Epoch: 25150 | MAE Train Loss: 49.78543472290039 | MAE Test Loss: 46.51085662841797 \n",
      "Epoch: 25160 | MAE Train Loss: 49.78219985961914 | MAE Test Loss: 46.508792877197266 \n",
      "Epoch: 25170 | MAE Train Loss: 49.778968811035156 | MAE Test Loss: 46.506744384765625 \n",
      "Epoch: 25180 | MAE Train Loss: 49.77573776245117 | MAE Test Loss: 46.50468444824219 \n",
      "Epoch: 25190 | MAE Train Loss: 49.77250671386719 | MAE Test Loss: 46.502628326416016 \n",
      "Epoch: 25200 | MAE Train Loss: 49.7692756652832 | MAE Test Loss: 46.50057601928711 \n",
      "Epoch: 25210 | MAE Train Loss: 49.76604461669922 | MAE Test Loss: 46.498512268066406 \n",
      "Epoch: 25220 | MAE Train Loss: 49.762813568115234 | MAE Test Loss: 46.496456146240234 \n",
      "Epoch: 25230 | MAE Train Loss: 49.75959014892578 | MAE Test Loss: 46.494407653808594 \n",
      "Epoch: 25240 | MAE Train Loss: 49.7563591003418 | MAE Test Loss: 46.49235153198242 \n",
      "Epoch: 25250 | MAE Train Loss: 49.75313186645508 | MAE Test Loss: 46.49028778076172 \n",
      "Epoch: 25260 | MAE Train Loss: 49.74989318847656 | MAE Test Loss: 46.48823165893555 \n",
      "Epoch: 25270 | MAE Train Loss: 49.74666976928711 | MAE Test Loss: 46.486175537109375 \n",
      "Epoch: 25280 | MAE Train Loss: 49.743438720703125 | MAE Test Loss: 46.48414993286133 \n",
      "Epoch: 25290 | MAE Train Loss: 49.7402229309082 | MAE Test Loss: 46.482173919677734 \n",
      "Epoch: 25300 | MAE Train Loss: 49.73700714111328 | MAE Test Loss: 46.48020553588867 \n",
      "Epoch: 25310 | MAE Train Loss: 49.733795166015625 | MAE Test Loss: 46.47826385498047 \n",
      "Epoch: 25320 | MAE Train Loss: 49.7305793762207 | MAE Test Loss: 46.47629928588867 \n",
      "Epoch: 25330 | MAE Train Loss: 49.72736358642578 | MAE Test Loss: 46.47431945800781 \n",
      "Epoch: 25340 | MAE Train Loss: 49.724151611328125 | MAE Test Loss: 46.472347259521484 \n",
      "Epoch: 25350 | MAE Train Loss: 49.7209358215332 | MAE Test Loss: 46.47037887573242 \n",
      "Epoch: 25360 | MAE Train Loss: 49.717716217041016 | MAE Test Loss: 46.46840286254883 \n",
      "Epoch: 25370 | MAE Train Loss: 49.714500427246094 | MAE Test Loss: 46.466434478759766 \n",
      "Epoch: 25380 | MAE Train Loss: 49.71128463745117 | MAE Test Loss: 46.4644660949707 \n",
      "Epoch: 25390 | MAE Train Loss: 49.70807647705078 | MAE Test Loss: 46.46250534057617 \n",
      "Epoch: 25400 | MAE Train Loss: 49.704856872558594 | MAE Test Loss: 46.460540771484375 \n",
      "Epoch: 25410 | MAE Train Loss: 49.701637268066406 | MAE Test Loss: 46.45856857299805 \n",
      "Epoch: 25420 | MAE Train Loss: 49.698421478271484 | MAE Test Loss: 46.45659637451172 \n",
      "Epoch: 25430 | MAE Train Loss: 49.69520568847656 | MAE Test Loss: 46.45461654663086 \n",
      "Epoch: 25440 | MAE Train Loss: 49.691993713378906 | MAE Test Loss: 46.45265197753906 \n",
      "Epoch: 25450 | MAE Train Loss: 49.688777923583984 | MAE Test Loss: 46.450679779052734 \n",
      "Epoch: 25460 | MAE Train Loss: 49.68556213378906 | MAE Test Loss: 46.44868469238281 \n",
      "Epoch: 25470 | MAE Train Loss: 49.68238067626953 | MAE Test Loss: 46.44672393798828 \n",
      "Epoch: 25480 | MAE Train Loss: 49.67919921875 | MAE Test Loss: 46.4447135925293 \n",
      "Epoch: 25490 | MAE Train Loss: 49.676025390625 | MAE Test Loss: 46.44272994995117 \n",
      "Epoch: 25500 | MAE Train Loss: 49.672847747802734 | MAE Test Loss: 46.44074630737305 \n",
      "Epoch: 25510 | MAE Train Loss: 49.669677734375 | MAE Test Loss: 46.43873977661133 \n",
      "Epoch: 25520 | MAE Train Loss: 49.6664924621582 | MAE Test Loss: 46.43675231933594 \n",
      "Epoch: 25530 | MAE Train Loss: 49.66331481933594 | MAE Test Loss: 46.43477249145508 \n",
      "Epoch: 25540 | MAE Train Loss: 49.66014099121094 | MAE Test Loss: 46.43275833129883 \n",
      "Epoch: 25550 | MAE Train Loss: 49.65696334838867 | MAE Test Loss: 46.4307861328125 \n",
      "Epoch: 25560 | MAE Train Loss: 49.65378189086914 | MAE Test Loss: 46.42876434326172 \n",
      "Epoch: 25570 | MAE Train Loss: 49.6506462097168 | MAE Test Loss: 46.42686080932617 \n",
      "Epoch: 25580 | MAE Train Loss: 49.64763641357422 | MAE Test Loss: 46.425209045410156 \n",
      "Epoch: 25590 | MAE Train Loss: 49.6446418762207 | MAE Test Loss: 46.423526763916016 \n",
      "Epoch: 25600 | MAE Train Loss: 49.64170837402344 | MAE Test Loss: 46.42166519165039 \n",
      "Epoch: 25610 | MAE Train Loss: 49.63878631591797 | MAE Test Loss: 46.41981887817383 \n",
      "Epoch: 25620 | MAE Train Loss: 49.635860443115234 | MAE Test Loss: 46.417964935302734 \n",
      "Epoch: 25630 | MAE Train Loss: 49.6329345703125 | MAE Test Loss: 46.416107177734375 \n",
      "Epoch: 25640 | MAE Train Loss: 49.63005828857422 | MAE Test Loss: 46.414371490478516 \n",
      "Epoch: 25650 | MAE Train Loss: 49.6272087097168 | MAE Test Loss: 46.41271209716797 \n",
      "Epoch: 25660 | MAE Train Loss: 49.62436294555664 | MAE Test Loss: 46.4110107421875 \n",
      "Epoch: 25670 | MAE Train Loss: 49.62151336669922 | MAE Test Loss: 46.40935516357422 \n",
      "Epoch: 25680 | MAE Train Loss: 49.6186637878418 | MAE Test Loss: 46.40769958496094 \n",
      "Epoch: 25690 | MAE Train Loss: 49.615821838378906 | MAE Test Loss: 46.406002044677734 \n",
      "Epoch: 25700 | MAE Train Loss: 49.612972259521484 | MAE Test Loss: 46.40434265136719 \n",
      "Epoch: 25710 | MAE Train Loss: 49.61012268066406 | MAE Test Loss: 46.40268325805664 \n",
      "Epoch: 25720 | MAE Train Loss: 49.607276916503906 | MAE Test Loss: 46.4009895324707 \n",
      "Epoch: 25730 | MAE Train Loss: 49.604434967041016 | MAE Test Loss: 46.39932632446289 \n",
      "Epoch: 25740 | MAE Train Loss: 49.60157775878906 | MAE Test Loss: 46.397674560546875 \n",
      "Epoch: 25750 | MAE Train Loss: 49.59873580932617 | MAE Test Loss: 46.39598083496094 \n",
      "Epoch: 25760 | MAE Train Loss: 49.59588623046875 | MAE Test Loss: 46.394317626953125 \n",
      "Epoch: 25770 | MAE Train Loss: 49.593048095703125 | MAE Test Loss: 46.39265441894531 \n",
      "Epoch: 25780 | MAE Train Loss: 49.5901985168457 | MAE Test Loss: 46.390960693359375 \n",
      "Epoch: 25790 | MAE Train Loss: 49.58734893798828 | MAE Test Loss: 46.38930892944336 \n",
      "Epoch: 25800 | MAE Train Loss: 49.58449935913086 | MAE Test Loss: 46.38764572143555 \n",
      "Epoch: 25810 | MAE Train Loss: 49.581661224365234 | MAE Test Loss: 46.38595199584961 \n",
      "Epoch: 25820 | MAE Train Loss: 49.57881164550781 | MAE Test Loss: 46.3842887878418 \n",
      "Epoch: 25830 | MAE Train Loss: 49.57596206665039 | MAE Test Loss: 46.382633209228516 \n",
      "Epoch: 25840 | MAE Train Loss: 49.573116302490234 | MAE Test Loss: 46.38093566894531 \n",
      "Epoch: 25850 | MAE Train Loss: 49.57026672363281 | MAE Test Loss: 46.379268646240234 \n",
      "Epoch: 25860 | MAE Train Loss: 49.56741714477539 | MAE Test Loss: 46.37761306762695 \n",
      "Epoch: 25870 | MAE Train Loss: 49.5645751953125 | MAE Test Loss: 46.37592315673828 \n",
      "Epoch: 25880 | MAE Train Loss: 49.56172561645508 | MAE Test Loss: 46.37425994873047 \n",
      "Epoch: 25890 | MAE Train Loss: 49.558876037597656 | MAE Test Loss: 46.372596740722656 \n",
      "Epoch: 25900 | MAE Train Loss: 49.55603790283203 | MAE Test Loss: 46.370906829833984 \n",
      "Epoch: 25910 | MAE Train Loss: 49.55318832397461 | MAE Test Loss: 46.3692512512207 \n",
      "Epoch: 25920 | MAE Train Loss: 49.55033874511719 | MAE Test Loss: 46.36758804321289 \n",
      "Epoch: 25930 | MAE Train Loss: 49.54749298095703 | MAE Test Loss: 46.36589431762695 \n",
      "Epoch: 25940 | MAE Train Loss: 49.54465103149414 | MAE Test Loss: 46.36423110961914 \n",
      "Epoch: 25950 | MAE Train Loss: 49.54179763793945 | MAE Test Loss: 46.362571716308594 \n",
      "Epoch: 25960 | MAE Train Loss: 49.5389518737793 | MAE Test Loss: 46.360877990722656 \n",
      "Epoch: 25970 | MAE Train Loss: 49.53610610961914 | MAE Test Loss: 46.359222412109375 \n",
      "Epoch: 25980 | MAE Train Loss: 49.533260345458984 | MAE Test Loss: 46.35755920410156 \n",
      "Epoch: 25990 | MAE Train Loss: 49.53041076660156 | MAE Test Loss: 46.355865478515625 \n",
      "Epoch: 26000 | MAE Train Loss: 49.527565002441406 | MAE Test Loss: 46.35420227050781 \n",
      "Epoch: 26010 | MAE Train Loss: 49.52471923828125 | MAE Test Loss: 46.352542877197266 \n",
      "Epoch: 26020 | MAE Train Loss: 49.521873474121094 | MAE Test Loss: 46.350852966308594 \n",
      "Epoch: 26030 | MAE Train Loss: 49.51902389526367 | MAE Test Loss: 46.34919357299805 \n",
      "Epoch: 26040 | MAE Train Loss: 49.51617431640625 | MAE Test Loss: 46.3475341796875 \n",
      "Epoch: 26050 | MAE Train Loss: 49.513336181640625 | MAE Test Loss: 46.34584045410156 \n",
      "Epoch: 26060 | MAE Train Loss: 49.5104866027832 | MAE Test Loss: 46.34417724609375 \n",
      "Epoch: 26070 | MAE Train Loss: 49.50763702392578 | MAE Test Loss: 46.34252166748047 \n",
      "Epoch: 26080 | MAE Train Loss: 49.504791259765625 | MAE Test Loss: 46.340824127197266 \n",
      "Epoch: 26090 | MAE Train Loss: 49.5019416809082 | MAE Test Loss: 46.33916473388672 \n",
      "Epoch: 26100 | MAE Train Loss: 49.49909210205078 | MAE Test Loss: 46.33750534057617 \n",
      "Epoch: 26110 | MAE Train Loss: 49.49626922607422 | MAE Test Loss: 46.335777282714844 \n",
      "Epoch: 26120 | MAE Train Loss: 49.49348831176758 | MAE Test Loss: 46.333984375 \n",
      "Epoch: 26130 | MAE Train Loss: 49.490699768066406 | MAE Test Loss: 46.332218170166016 \n",
      "Epoch: 26140 | MAE Train Loss: 49.4879150390625 | MAE Test Loss: 46.33042907714844 \n",
      "Epoch: 26150 | MAE Train Loss: 49.48512268066406 | MAE Test Loss: 46.32866668701172 \n",
      "Epoch: 26160 | MAE Train Loss: 49.48233413696289 | MAE Test Loss: 46.326900482177734 \n",
      "Epoch: 26170 | MAE Train Loss: 49.479549407958984 | MAE Test Loss: 46.325111389160156 \n",
      "Epoch: 26180 | MAE Train Loss: 49.47676086425781 | MAE Test Loss: 46.32334518432617 \n",
      "Epoch: 26190 | MAE Train Loss: 49.47397232055664 | MAE Test Loss: 46.32158660888672 \n",
      "Epoch: 26200 | MAE Train Loss: 49.47118377685547 | MAE Test Loss: 46.31978988647461 \n",
      "Epoch: 26210 | MAE Train Loss: 49.4683952331543 | MAE Test Loss: 46.318031311035156 \n",
      "Epoch: 26220 | MAE Train Loss: 49.465606689453125 | MAE Test Loss: 46.31626892089844 \n",
      "Epoch: 26230 | MAE Train Loss: 49.46281814575195 | MAE Test Loss: 46.314476013183594 \n",
      "Epoch: 26240 | MAE Train Loss: 49.46002960205078 | MAE Test Loss: 46.312713623046875 \n",
      "Epoch: 26250 | MAE Train Loss: 49.45724105834961 | MAE Test Loss: 46.3109130859375 \n",
      "Epoch: 26260 | MAE Train Loss: 49.45445251464844 | MAE Test Loss: 46.30915832519531 \n",
      "Epoch: 26270 | MAE Train Loss: 49.451663970947266 | MAE Test Loss: 46.30739212036133 \n",
      "Epoch: 26280 | MAE Train Loss: 49.448875427246094 | MAE Test Loss: 46.30560302734375 \n",
      "Epoch: 26290 | MAE Train Loss: 49.44608688354492 | MAE Test Loss: 46.3038444519043 \n",
      "Epoch: 26300 | MAE Train Loss: 49.443302154541016 | MAE Test Loss: 46.30207443237305 \n",
      "Epoch: 26310 | MAE Train Loss: 49.440513610839844 | MAE Test Loss: 46.300289154052734 \n",
      "Epoch: 26320 | MAE Train Loss: 49.43772506713867 | MAE Test Loss: 46.298519134521484 \n",
      "Epoch: 26330 | MAE Train Loss: 49.4349365234375 | MAE Test Loss: 46.29672622680664 \n",
      "Epoch: 26340 | MAE Train Loss: 49.43214797973633 | MAE Test Loss: 46.29496765136719 \n",
      "Epoch: 26350 | MAE Train Loss: 49.42936706542969 | MAE Test Loss: 46.29319763183594 \n",
      "Epoch: 26360 | MAE Train Loss: 49.426570892333984 | MAE Test Loss: 46.291412353515625 \n",
      "Epoch: 26370 | MAE Train Loss: 49.423789978027344 | MAE Test Loss: 46.289642333984375 \n",
      "Epoch: 26380 | MAE Train Loss: 49.42100143432617 | MAE Test Loss: 46.28788375854492 \n",
      "Epoch: 26390 | MAE Train Loss: 49.418212890625 | MAE Test Loss: 46.28608703613281 \n",
      "Epoch: 26400 | MAE Train Loss: 49.41542434692383 | MAE Test Loss: 46.28432846069336 \n",
      "Epoch: 26410 | MAE Train Loss: 49.412635803222656 | MAE Test Loss: 46.282535552978516 \n",
      "Epoch: 26420 | MAE Train Loss: 49.409847259521484 | MAE Test Loss: 46.2807731628418 \n",
      "Epoch: 26430 | MAE Train Loss: 49.40705871582031 | MAE Test Loss: 46.27901077270508 \n",
      "Epoch: 26440 | MAE Train Loss: 49.40426254272461 | MAE Test Loss: 46.2772216796875 \n",
      "Epoch: 26450 | MAE Train Loss: 49.401485443115234 | MAE Test Loss: 46.275455474853516 \n",
      "Epoch: 26460 | MAE Train Loss: 49.39869689941406 | MAE Test Loss: 46.27368927001953 \n",
      "Epoch: 26470 | MAE Train Loss: 49.395904541015625 | MAE Test Loss: 46.27190017700195 \n",
      "Epoch: 26480 | MAE Train Loss: 49.39311981201172 | MAE Test Loss: 46.27013397216797 \n",
      "Epoch: 26490 | MAE Train Loss: 49.39032745361328 | MAE Test Loss: 46.26837921142578 \n",
      "Epoch: 26500 | MAE Train Loss: 49.38753890991211 | MAE Test Loss: 46.266578674316406 \n",
      "Epoch: 26510 | MAE Train Loss: 49.3847541809082 | MAE Test Loss: 46.264808654785156 \n",
      "Epoch: 26520 | MAE Train Loss: 49.38196563720703 | MAE Test Loss: 46.26304626464844 \n",
      "Epoch: 26530 | MAE Train Loss: 49.379173278808594 | MAE Test Loss: 46.26128005981445 \n",
      "Epoch: 26540 | MAE Train Loss: 49.37638854980469 | MAE Test Loss: 46.259490966796875 \n",
      "Epoch: 26550 | MAE Train Loss: 49.373600006103516 | MAE Test Loss: 46.25772476196289 \n",
      "Epoch: 26560 | MAE Train Loss: 49.37081527709961 | MAE Test Loss: 46.25593185424805 \n",
      "Epoch: 26570 | MAE Train Loss: 49.36802291870117 | MAE Test Loss: 46.25416946411133 \n",
      "Epoch: 26580 | MAE Train Loss: 49.365234375 | MAE Test Loss: 46.25239181518555 \n",
      "Epoch: 26590 | MAE Train Loss: 49.362449645996094 | MAE Test Loss: 46.25062942504883 \n",
      "Epoch: 26600 | MAE Train Loss: 49.35966110229492 | MAE Test Loss: 46.248836517333984 \n",
      "Epoch: 26610 | MAE Train Loss: 49.35687255859375 | MAE Test Loss: 46.2470703125 \n",
      "Epoch: 26620 | MAE Train Loss: 49.35408401489258 | MAE Test Loss: 46.24530792236328 \n",
      "Epoch: 26630 | MAE Train Loss: 49.351295471191406 | MAE Test Loss: 46.24351501464844 \n",
      "Epoch: 26640 | MAE Train Loss: 49.348506927490234 | MAE Test Loss: 46.24174499511719 \n",
      "Epoch: 26650 | MAE Train Loss: 49.34571838378906 | MAE Test Loss: 46.23997497558594 \n",
      "Epoch: 26660 | MAE Train Loss: 49.34292984008789 | MAE Test Loss: 46.238216400146484 \n",
      "Epoch: 26670 | MAE Train Loss: 49.34014129638672 | MAE Test Loss: 46.236419677734375 \n",
      "Epoch: 26680 | MAE Train Loss: 49.33735275268555 | MAE Test Loss: 46.23466110229492 \n",
      "Epoch: 26690 | MAE Train Loss: 49.334564208984375 | MAE Test Loss: 46.23289489746094 \n",
      "Epoch: 26700 | MAE Train Loss: 49.331787109375 | MAE Test Loss: 46.23110580444336 \n",
      "Epoch: 26710 | MAE Train Loss: 49.32898712158203 | MAE Test Loss: 46.22932815551758 \n",
      "Epoch: 26720 | MAE Train Loss: 49.32620620727539 | MAE Test Loss: 46.227561950683594 \n",
      "Epoch: 26730 | MAE Train Loss: 49.32341003417969 | MAE Test Loss: 46.225799560546875 \n",
      "Epoch: 26740 | MAE Train Loss: 49.32062911987305 | MAE Test Loss: 46.22400665283203 \n",
      "Epoch: 26750 | MAE Train Loss: 49.317840576171875 | MAE Test Loss: 46.222251892089844 \n",
      "Epoch: 26760 | MAE Train Loss: 49.3150520324707 | MAE Test Loss: 46.220481872558594 \n",
      "Epoch: 26770 | MAE Train Loss: 49.31226348876953 | MAE Test Loss: 46.21868896484375 \n",
      "Epoch: 26780 | MAE Train Loss: 49.309478759765625 | MAE Test Loss: 46.2169189453125 \n",
      "Epoch: 26790 | MAE Train Loss: 49.30669021606445 | MAE Test Loss: 46.215152740478516 \n",
      "Epoch: 26800 | MAE Train Loss: 49.303897857666016 | MAE Test Loss: 46.213382720947266 \n",
      "Epoch: 26810 | MAE Train Loss: 49.301116943359375 | MAE Test Loss: 46.21159744262695 \n",
      "Epoch: 26820 | MAE Train Loss: 49.29832458496094 | MAE Test Loss: 46.209835052490234 \n",
      "Epoch: 26830 | MAE Train Loss: 49.2955322265625 | MAE Test Loss: 46.20804214477539 \n",
      "Epoch: 26840 | MAE Train Loss: 49.292747497558594 | MAE Test Loss: 46.206275939941406 \n",
      "Epoch: 26850 | MAE Train Loss: 49.28995895385742 | MAE Test Loss: 46.20450210571289 \n",
      "Epoch: 26860 | MAE Train Loss: 49.28717041015625 | MAE Test Loss: 46.202735900878906 \n",
      "Epoch: 26870 | MAE Train Loss: 49.28438186645508 | MAE Test Loss: 46.20094680786133 \n",
      "Epoch: 26880 | MAE Train Loss: 49.281593322753906 | MAE Test Loss: 46.199180603027344 \n",
      "Epoch: 26890 | MAE Train Loss: 49.27880859375 | MAE Test Loss: 46.197418212890625 \n",
      "Epoch: 26900 | MAE Train Loss: 49.27602005004883 | MAE Test Loss: 46.19562530517578 \n",
      "Epoch: 26910 | MAE Train Loss: 49.27322769165039 | MAE Test Loss: 46.19384765625 \n",
      "Epoch: 26920 | MAE Train Loss: 49.270442962646484 | MAE Test Loss: 46.19208526611328 \n",
      "Epoch: 26930 | MAE Train Loss: 49.26765441894531 | MAE Test Loss: 46.1903190612793 \n",
      "Epoch: 26940 | MAE Train Loss: 49.26486587524414 | MAE Test Loss: 46.18852996826172 \n",
      "Epoch: 26950 | MAE Train Loss: 49.26207733154297 | MAE Test Loss: 46.186771392822266 \n",
      "Epoch: 26960 | MAE Train Loss: 49.2592887878418 | MAE Test Loss: 46.18499755859375 \n",
      "Epoch: 26970 | MAE Train Loss: 49.256507873535156 | MAE Test Loss: 46.1832160949707 \n",
      "Epoch: 26980 | MAE Train Loss: 49.253719329833984 | MAE Test Loss: 46.18144989013672 \n",
      "Epoch: 26990 | MAE Train Loss: 49.25092315673828 | MAE Test Loss: 46.17966079711914 \n",
      "Epoch: 27000 | MAE Train Loss: 49.24814224243164 | MAE Test Loss: 46.177894592285156 \n",
      "Epoch: 27010 | MAE Train Loss: 49.24535369873047 | MAE Test Loss: 46.17613220214844 \n",
      "Epoch: 27020 | MAE Train Loss: 49.2425651550293 | MAE Test Loss: 46.174339294433594 \n",
      "Epoch: 27030 | MAE Train Loss: 49.239776611328125 | MAE Test Loss: 46.172576904296875 \n",
      "Epoch: 27040 | MAE Train Loss: 49.23698806762695 | MAE Test Loss: 46.170814514160156 \n",
      "Epoch: 27050 | MAE Train Loss: 49.23419952392578 | MAE Test Loss: 46.16901779174805 \n",
      "Epoch: 27060 | MAE Train Loss: 49.23141098022461 | MAE Test Loss: 46.167259216308594 \n",
      "Epoch: 27070 | MAE Train Loss: 49.22862243652344 | MAE Test Loss: 46.165489196777344 \n",
      "Epoch: 27080 | MAE Train Loss: 49.22583770751953 | MAE Test Loss: 46.163700103759766 \n",
      "Epoch: 27090 | MAE Train Loss: 49.223045349121094 | MAE Test Loss: 46.16194534301758 \n",
      "Epoch: 27100 | MAE Train Loss: 49.22025680541992 | MAE Test Loss: 46.160152435302734 \n",
      "Epoch: 27110 | MAE Train Loss: 49.217472076416016 | MAE Test Loss: 46.158382415771484 \n",
      "Epoch: 27120 | MAE Train Loss: 49.21467590332031 | MAE Test Loss: 46.15662384033203 \n",
      "Epoch: 27130 | MAE Train Loss: 49.21189498901367 | MAE Test Loss: 46.15483093261719 \n",
      "Epoch: 27140 | MAE Train Loss: 49.209110260009766 | MAE Test Loss: 46.15306091308594 \n",
      "Epoch: 27150 | MAE Train Loss: 49.206321716308594 | MAE Test Loss: 46.15134048461914 \n",
      "Epoch: 27160 | MAE Train Loss: 49.2036018371582 | MAE Test Loss: 46.14970016479492 \n",
      "Epoch: 27170 | MAE Train Loss: 49.200889587402344 | MAE Test Loss: 46.14805221557617 \n",
      "Epoch: 27180 | MAE Train Loss: 49.19816589355469 | MAE Test Loss: 46.146446228027344 \n",
      "Epoch: 27190 | MAE Train Loss: 49.19544982910156 | MAE Test Loss: 46.14480972290039 \n",
      "Epoch: 27200 | MAE Train Loss: 49.19273376464844 | MAE Test Loss: 46.1431999206543 \n",
      "Epoch: 27210 | MAE Train Loss: 49.19002151489258 | MAE Test Loss: 46.141563415527344 \n",
      "Epoch: 27220 | MAE Train Loss: 49.18730545043945 | MAE Test Loss: 46.139949798583984 \n",
      "Epoch: 27230 | MAE Train Loss: 49.18458938598633 | MAE Test Loss: 46.1383171081543 \n",
      "Epoch: 27240 | MAE Train Loss: 49.18186569213867 | MAE Test Loss: 46.1367073059082 \n",
      "Epoch: 27250 | MAE Train Loss: 49.17915725708008 | MAE Test Loss: 46.135066986083984 \n",
      "Epoch: 27260 | MAE Train Loss: 49.17643356323242 | MAE Test Loss: 46.133460998535156 \n",
      "Epoch: 27270 | MAE Train Loss: 49.17372131347656 | MAE Test Loss: 46.13182067871094 \n",
      "Epoch: 27280 | MAE Train Loss: 49.17100524902344 | MAE Test Loss: 46.130210876464844 \n",
      "Epoch: 27290 | MAE Train Loss: 49.16828918457031 | MAE Test Loss: 46.128570556640625 \n",
      "Epoch: 27300 | MAE Train Loss: 49.16556930541992 | MAE Test Loss: 46.126956939697266 \n",
      "Epoch: 27310 | MAE Train Loss: 49.16286087036133 | MAE Test Loss: 46.12532424926758 \n",
      "Epoch: 27320 | MAE Train Loss: 49.16014099121094 | MAE Test Loss: 46.123714447021484 \n",
      "Epoch: 27330 | MAE Train Loss: 49.15742874145508 | MAE Test Loss: 46.122074127197266 \n",
      "Epoch: 27340 | MAE Train Loss: 49.15471267700195 | MAE Test Loss: 46.12046813964844 \n",
      "Epoch: 27350 | MAE Train Loss: 49.15199661254883 | MAE Test Loss: 46.11882781982422 \n",
      "Epoch: 27360 | MAE Train Loss: 49.14927673339844 | MAE Test Loss: 46.117225646972656 \n",
      "Epoch: 27370 | MAE Train Loss: 49.14655685424805 | MAE Test Loss: 46.11558151245117 \n",
      "Epoch: 27380 | MAE Train Loss: 49.14384460449219 | MAE Test Loss: 46.11397933959961 \n",
      "Epoch: 27390 | MAE Train Loss: 49.14113235473633 | MAE Test Loss: 46.11233901977539 \n",
      "Epoch: 27400 | MAE Train Loss: 49.13841247558594 | MAE Test Loss: 46.1107292175293 \n",
      "Epoch: 27410 | MAE Train Loss: 49.13569641113281 | MAE Test Loss: 46.109100341796875 \n",
      "Epoch: 27420 | MAE Train Loss: 49.13298034667969 | MAE Test Loss: 46.107460021972656 \n",
      "Epoch: 27430 | MAE Train Loss: 49.13025665283203 | MAE Test Loss: 46.10585403442383 \n",
      "Epoch: 27440 | MAE Train Loss: 49.12754440307617 | MAE Test Loss: 46.10420608520508 \n",
      "Epoch: 27450 | MAE Train Loss: 49.12482833862305 | MAE Test Loss: 46.10261154174805 \n",
      "Epoch: 27460 | MAE Train Loss: 49.12211608886719 | MAE Test Loss: 46.10097122192383 \n",
      "Epoch: 27470 | MAE Train Loss: 49.11940002441406 | MAE Test Loss: 46.099361419677734 \n",
      "Epoch: 27480 | MAE Train Loss: 49.11668014526367 | MAE Test Loss: 46.09771728515625 \n",
      "Epoch: 27490 | MAE Train Loss: 49.11396026611328 | MAE Test Loss: 46.096107482910156 \n",
      "Epoch: 27500 | MAE Train Loss: 49.11125183105469 | MAE Test Loss: 46.09447479248047 \n",
      "Epoch: 27510 | MAE Train Loss: 49.10852813720703 | MAE Test Loss: 46.092864990234375 \n",
      "Epoch: 27520 | MAE Train Loss: 49.10581588745117 | MAE Test Loss: 46.09122085571289 \n",
      "Epoch: 27530 | MAE Train Loss: 49.10309982299805 | MAE Test Loss: 46.08961486816406 \n",
      "Epoch: 27540 | MAE Train Loss: 49.10038375854492 | MAE Test Loss: 46.087974548339844 \n",
      "Epoch: 27550 | MAE Train Loss: 49.0976676940918 | MAE Test Loss: 46.08636474609375 \n",
      "Epoch: 27560 | MAE Train Loss: 49.09495544433594 | MAE Test Loss: 46.08473205566406 \n",
      "Epoch: 27570 | MAE Train Loss: 49.09223556518555 | MAE Test Loss: 46.0831298828125 \n",
      "Epoch: 27580 | MAE Train Loss: 49.089515686035156 | MAE Test Loss: 46.08148193359375 \n",
      "Epoch: 27590 | MAE Train Loss: 49.08679962158203 | MAE Test Loss: 46.07986831665039 \n",
      "Epoch: 27600 | MAE Train Loss: 49.084083557128906 | MAE Test Loss: 46.07823944091797 \n",
      "Epoch: 27610 | MAE Train Loss: 49.08137130737305 | MAE Test Loss: 46.07662582397461 \n",
      "Epoch: 27620 | MAE Train Loss: 49.07865524291992 | MAE Test Loss: 46.07498550415039 \n",
      "Epoch: 27630 | MAE Train Loss: 49.0759391784668 | MAE Test Loss: 46.0733757019043 \n",
      "Epoch: 27640 | MAE Train Loss: 49.07322311401367 | MAE Test Loss: 46.071739196777344 \n",
      "Epoch: 27650 | MAE Train Loss: 49.07050704956055 | MAE Test Loss: 46.070133209228516 \n",
      "Epoch: 27660 | MAE Train Loss: 49.06779098510742 | MAE Test Loss: 46.0684928894043 \n",
      "Epoch: 27670 | MAE Train Loss: 49.06507110595703 | MAE Test Loss: 46.066890716552734 \n",
      "Epoch: 27680 | MAE Train Loss: 49.062355041503906 | MAE Test Loss: 46.065250396728516 \n",
      "Epoch: 27690 | MAE Train Loss: 49.05963897705078 | MAE Test Loss: 46.063636779785156 \n",
      "Epoch: 27700 | MAE Train Loss: 49.056922912597656 | MAE Test Loss: 46.06199645996094 \n",
      "Epoch: 27710 | MAE Train Loss: 49.05420684814453 | MAE Test Loss: 46.060386657714844 \n",
      "Epoch: 27720 | MAE Train Loss: 49.05149459838867 | MAE Test Loss: 46.058746337890625 \n",
      "Epoch: 27730 | MAE Train Loss: 49.04877853393555 | MAE Test Loss: 46.05715560913086 \n",
      "Epoch: 27740 | MAE Train Loss: 49.04605484008789 | MAE Test Loss: 46.05551528930664 \n",
      "Epoch: 27750 | MAE Train Loss: 49.0433464050293 | MAE Test Loss: 46.05390930175781 \n",
      "Epoch: 27760 | MAE Train Loss: 49.040626525878906 | MAE Test Loss: 46.052268981933594 \n",
      "Epoch: 27770 | MAE Train Loss: 49.037906646728516 | MAE Test Loss: 46.0506591796875 \n",
      "Epoch: 27780 | MAE Train Loss: 49.035194396972656 | MAE Test Loss: 46.04901885986328 \n",
      "Epoch: 27790 | MAE Train Loss: 49.03247833251953 | MAE Test Loss: 46.04741287231445 \n",
      "Epoch: 27800 | MAE Train Loss: 49.029762268066406 | MAE Test Loss: 46.045772552490234 \n",
      "Epoch: 27810 | MAE Train Loss: 49.02704620361328 | MAE Test Loss: 46.044166564941406 \n",
      "Epoch: 27820 | MAE Train Loss: 49.024330139160156 | MAE Test Loss: 46.04252624511719 \n",
      "Epoch: 27830 | MAE Train Loss: 49.021610260009766 | MAE Test Loss: 46.040924072265625 \n",
      "Epoch: 27840 | MAE Train Loss: 49.01890182495117 | MAE Test Loss: 46.039283752441406 \n",
      "Epoch: 27850 | MAE Train Loss: 49.016178131103516 | MAE Test Loss: 46.03767013549805 \n",
      "Epoch: 27860 | MAE Train Loss: 49.013465881347656 | MAE Test Loss: 46.03602981567383 \n",
      "Epoch: 27870 | MAE Train Loss: 49.010746002197266 | MAE Test Loss: 46.034420013427734 \n",
      "Epoch: 27880 | MAE Train Loss: 49.008033752441406 | MAE Test Loss: 46.03278732299805 \n",
      "Epoch: 27890 | MAE Train Loss: 49.00531005859375 | MAE Test Loss: 46.03117752075195 \n",
      "Epoch: 27900 | MAE Train Loss: 49.002601623535156 | MAE Test Loss: 46.029537200927734 \n",
      "Epoch: 27910 | MAE Train Loss: 48.99988555908203 | MAE Test Loss: 46.027931213378906 \n",
      "Epoch: 27920 | MAE Train Loss: 48.99716567993164 | MAE Test Loss: 46.026283264160156 \n",
      "Epoch: 27930 | MAE Train Loss: 48.994449615478516 | MAE Test Loss: 46.02467727661133 \n",
      "Epoch: 27940 | MAE Train Loss: 48.99173355102539 | MAE Test Loss: 46.023040771484375 \n",
      "Epoch: 27950 | MAE Train Loss: 48.989017486572266 | MAE Test Loss: 46.02143859863281 \n",
      "Epoch: 27960 | MAE Train Loss: 48.986305236816406 | MAE Test Loss: 46.01979064941406 \n",
      "Epoch: 27970 | MAE Train Loss: 48.983585357666016 | MAE Test Loss: 46.0181884765625 \n",
      "Epoch: 27980 | MAE Train Loss: 48.980865478515625 | MAE Test Loss: 46.01654815673828 \n",
      "Epoch: 27990 | MAE Train Loss: 48.97815704345703 | MAE Test Loss: 46.01493835449219 \n",
      "Epoch: 28000 | MAE Train Loss: 48.975440979003906 | MAE Test Loss: 46.0132942199707 \n",
      "Epoch: 28010 | MAE Train Loss: 48.972721099853516 | MAE Test Loss: 46.01169204711914 \n",
      "Epoch: 28020 | MAE Train Loss: 48.97000503540039 | MAE Test Loss: 46.01005172729492 \n",
      "Epoch: 28030 | MAE Train Loss: 48.967288970947266 | MAE Test Loss: 46.00844192504883 \n",
      "Epoch: 28040 | MAE Train Loss: 48.96457290649414 | MAE Test Loss: 46.00680160522461 \n",
      "Epoch: 28050 | MAE Train Loss: 48.96186065673828 | MAE Test Loss: 46.00518035888672 \n",
      "Epoch: 28060 | MAE Train Loss: 48.95913314819336 | MAE Test Loss: 46.003570556640625 \n",
      "Epoch: 28070 | MAE Train Loss: 48.9564208984375 | MAE Test Loss: 46.00193405151367 \n",
      "Epoch: 28080 | MAE Train Loss: 48.953712463378906 | MAE Test Loss: 46.00032043457031 \n",
      "Epoch: 28090 | MAE Train Loss: 48.95098876953125 | MAE Test Loss: 45.99868392944336 \n",
      "Epoch: 28100 | MAE Train Loss: 48.94827651977539 | MAE Test Loss: 45.997074127197266 \n",
      "Epoch: 28110 | MAE Train Loss: 48.945556640625 | MAE Test Loss: 45.99543762207031 \n",
      "Epoch: 28120 | MAE Train Loss: 48.94284439086914 | MAE Test Loss: 45.993831634521484 \n",
      "Epoch: 28130 | MAE Train Loss: 48.940128326416016 | MAE Test Loss: 45.992191314697266 \n",
      "Epoch: 28140 | MAE Train Loss: 48.93741226196289 | MAE Test Loss: 45.99058151245117 \n",
      "Epoch: 28150 | MAE Train Loss: 48.934696197509766 | MAE Test Loss: 45.98894500732422 \n",
      "Epoch: 28160 | MAE Train Loss: 48.931976318359375 | MAE Test Loss: 45.98733901977539 \n",
      "Epoch: 28170 | MAE Train Loss: 48.92926025390625 | MAE Test Loss: 45.985694885253906 \n",
      "Epoch: 28180 | MAE Train Loss: 48.926544189453125 | MAE Test Loss: 45.98408508300781 \n",
      "Epoch: 28190 | MAE Train Loss: 48.923824310302734 | MAE Test Loss: 45.98244857788086 \n",
      "Epoch: 28200 | MAE Train Loss: 48.921112060546875 | MAE Test Loss: 45.980838775634766 \n",
      "Epoch: 28210 | MAE Train Loss: 48.91839599609375 | MAE Test Loss: 45.97920227050781 \n",
      "Epoch: 28220 | MAE Train Loss: 48.915679931640625 | MAE Test Loss: 45.97759246826172 \n",
      "Epoch: 28230 | MAE Train Loss: 48.91300582885742 | MAE Test Loss: 45.975860595703125 \n",
      "Epoch: 28240 | MAE Train Loss: 48.91037368774414 | MAE Test Loss: 45.97411346435547 \n",
      "Epoch: 28250 | MAE Train Loss: 48.9077262878418 | MAE Test Loss: 45.97235870361328 \n",
      "Epoch: 28260 | MAE Train Loss: 48.905086517333984 | MAE Test Loss: 45.97060012817383 \n",
      "Epoch: 28270 | MAE Train Loss: 48.90245056152344 | MAE Test Loss: 45.968814849853516 \n",
      "Epoch: 28280 | MAE Train Loss: 48.899803161621094 | MAE Test Loss: 45.96706008911133 \n",
      "Epoch: 28290 | MAE Train Loss: 48.89717102050781 | MAE Test Loss: 45.965309143066406 \n",
      "Epoch: 28300 | MAE Train Loss: 48.894527435302734 | MAE Test Loss: 45.96355438232422 \n",
      "Epoch: 28310 | MAE Train Loss: 48.89188766479492 | MAE Test Loss: 45.96177291870117 \n",
      "Epoch: 28320 | MAE Train Loss: 48.88924789428711 | MAE Test Loss: 45.960018157958984 \n",
      "Epoch: 28330 | MAE Train Loss: 48.8866081237793 | MAE Test Loss: 45.95826721191406 \n",
      "Epoch: 28340 | MAE Train Loss: 48.88396453857422 | MAE Test Loss: 45.95650863647461 \n",
      "Epoch: 28350 | MAE Train Loss: 48.881324768066406 | MAE Test Loss: 45.95473861694336 \n",
      "Epoch: 28360 | MAE Train Loss: 48.878684997558594 | MAE Test Loss: 45.95298385620117 \n",
      "Epoch: 28370 | MAE Train Loss: 48.876041412353516 | MAE Test Loss: 45.95123291015625 \n",
      "Epoch: 28380 | MAE Train Loss: 48.8734016418457 | MAE Test Loss: 45.94944763183594 \n",
      "Epoch: 28390 | MAE Train Loss: 48.87076187133789 | MAE Test Loss: 45.94769287109375 \n",
      "Epoch: 28400 | MAE Train Loss: 48.86812210083008 | MAE Test Loss: 45.94593811035156 \n",
      "Epoch: 28410 | MAE Train Loss: 48.865482330322266 | MAE Test Loss: 45.944183349609375 \n",
      "Epoch: 28420 | MAE Train Loss: 48.86284255981445 | MAE Test Loss: 45.94240951538086 \n",
      "Epoch: 28430 | MAE Train Loss: 48.860206604003906 | MAE Test Loss: 45.94065856933594 \n",
      "Epoch: 28440 | MAE Train Loss: 48.85755920410156 | MAE Test Loss: 45.938873291015625 \n",
      "Epoch: 28450 | MAE Train Loss: 48.85491943359375 | MAE Test Loss: 45.9371223449707 \n",
      "Epoch: 28460 | MAE Train Loss: 48.8522834777832 | MAE Test Loss: 45.935367584228516 \n",
      "Epoch: 28470 | MAE Train Loss: 48.84963607788086 | MAE Test Loss: 45.93360900878906 \n",
      "Epoch: 28480 | MAE Train Loss: 48.84700393676758 | MAE Test Loss: 45.931827545166016 \n",
      "Epoch: 28490 | MAE Train Loss: 48.8443603515625 | MAE Test Loss: 45.93007278442383 \n",
      "Epoch: 28500 | MAE Train Loss: 48.84172439575195 | MAE Test Loss: 45.928314208984375 \n",
      "Epoch: 28510 | MAE Train Loss: 48.839080810546875 | MAE Test Loss: 45.92656707763672 \n",
      "Epoch: 28520 | MAE Train Loss: 48.8364372253418 | MAE Test Loss: 45.92478561401367 \n",
      "Epoch: 28530 | MAE Train Loss: 48.833797454833984 | MAE Test Loss: 45.92302703857422 \n",
      "Epoch: 28540 | MAE Train Loss: 48.83115768432617 | MAE Test Loss: 45.92127227783203 \n",
      "Epoch: 28550 | MAE Train Loss: 48.82851791381836 | MAE Test Loss: 45.919517517089844 \n",
      "Epoch: 28560 | MAE Train Loss: 48.82587432861328 | MAE Test Loss: 45.91773223876953 \n",
      "Epoch: 28570 | MAE Train Loss: 48.82323455810547 | MAE Test Loss: 45.91598129272461 \n",
      "Epoch: 28580 | MAE Train Loss: 48.820594787597656 | MAE Test Loss: 45.914222717285156 \n",
      "Epoch: 28590 | MAE Train Loss: 48.817955017089844 | MAE Test Loss: 45.91245651245117 \n",
      "Epoch: 28600 | MAE Train Loss: 48.81531524658203 | MAE Test Loss: 45.91069793701172 \n",
      "Epoch: 28610 | MAE Train Loss: 48.81267547607422 | MAE Test Loss: 45.9089469909668 \n",
      "Epoch: 28620 | MAE Train Loss: 48.81003189086914 | MAE Test Loss: 45.90719223022461 \n",
      "Epoch: 28630 | MAE Train Loss: 48.80739212036133 | MAE Test Loss: 45.9054069519043 \n",
      "Epoch: 28640 | MAE Train Loss: 48.80475997924805 | MAE Test Loss: 45.903656005859375 \n",
      "Epoch: 28650 | MAE Train Loss: 48.80211639404297 | MAE Test Loss: 45.90190124511719 \n",
      "Epoch: 28660 | MAE Train Loss: 48.799476623535156 | MAE Test Loss: 45.90012741088867 \n",
      "Epoch: 28670 | MAE Train Loss: 48.79682922363281 | MAE Test Loss: 45.898372650146484 \n",
      "Epoch: 28680 | MAE Train Loss: 48.794193267822266 | MAE Test Loss: 45.89662170410156 \n",
      "Epoch: 28690 | MAE Train Loss: 48.79155731201172 | MAE Test Loss: 45.89484405517578 \n",
      "Epoch: 28700 | MAE Train Loss: 48.78891372680664 | MAE Test Loss: 45.89308166503906 \n",
      "Epoch: 28710 | MAE Train Loss: 48.78627395629883 | MAE Test Loss: 45.891326904296875 \n",
      "Epoch: 28720 | MAE Train Loss: 48.78363037109375 | MAE Test Loss: 45.88957977294922 \n",
      "Epoch: 28730 | MAE Train Loss: 48.78099060058594 | MAE Test Loss: 45.8878059387207 \n",
      "Epoch: 28740 | MAE Train Loss: 48.778350830078125 | MAE Test Loss: 45.88604736328125 \n",
      "Epoch: 28750 | MAE Train Loss: 48.77570724487305 | MAE Test Loss: 45.8842658996582 \n",
      "Epoch: 28760 | MAE Train Loss: 48.7730712890625 | MAE Test Loss: 45.88251495361328 \n",
      "Epoch: 28770 | MAE Train Loss: 48.77043151855469 | MAE Test Loss: 45.88075637817383 \n",
      "Epoch: 28780 | MAE Train Loss: 48.76779556274414 | MAE Test Loss: 45.879005432128906 \n",
      "Epoch: 28790 | MAE Train Loss: 48.7651481628418 | MAE Test Loss: 45.877235412597656 \n",
      "Epoch: 28800 | MAE Train Loss: 48.762508392333984 | MAE Test Loss: 45.87548065185547 \n",
      "Epoch: 28810 | MAE Train Loss: 48.75987243652344 | MAE Test Loss: 45.87372589111328 \n",
      "Epoch: 28820 | MAE Train Loss: 48.757225036621094 | MAE Test Loss: 45.8719367980957 \n",
      "Epoch: 28830 | MAE Train Loss: 48.75459289550781 | MAE Test Loss: 45.870182037353516 \n",
      "Epoch: 28840 | MAE Train Loss: 48.751953125 | MAE Test Loss: 45.868431091308594 \n",
      "Epoch: 28850 | MAE Train Loss: 48.74930953979492 | MAE Test Loss: 45.866676330566406 \n",
      "Epoch: 28860 | MAE Train Loss: 48.74666976928711 | MAE Test Loss: 45.864906311035156 \n",
      "Epoch: 28870 | MAE Train Loss: 48.74402618408203 | MAE Test Loss: 45.863155364990234 \n",
      "Epoch: 28880 | MAE Train Loss: 48.74138641357422 | MAE Test Loss: 45.86137008666992 \n",
      "Epoch: 28890 | MAE Train Loss: 48.73875045776367 | MAE Test Loss: 45.859615325927734 \n",
      "Epoch: 28900 | MAE Train Loss: 48.73611068725586 | MAE Test Loss: 45.85786056518555 \n",
      "Epoch: 28910 | MAE Train Loss: 48.73346710205078 | MAE Test Loss: 45.856109619140625 \n",
      "Epoch: 28920 | MAE Train Loss: 48.7308235168457 | MAE Test Loss: 45.85432052612305 \n",
      "Epoch: 28930 | MAE Train Loss: 48.72818374633789 | MAE Test Loss: 45.85256576538086 \n",
      "Epoch: 28940 | MAE Train Loss: 48.72554397583008 | MAE Test Loss: 45.85081481933594 \n",
      "Epoch: 28950 | MAE Train Loss: 48.722904205322266 | MAE Test Loss: 45.84906005859375 \n",
      "Epoch: 28960 | MAE Train Loss: 48.72026443481445 | MAE Test Loss: 45.8472785949707 \n",
      "Epoch: 28970 | MAE Train Loss: 48.717628479003906 | MAE Test Loss: 45.845523834228516 \n",
      "Epoch: 28980 | MAE Train Loss: 48.71498107910156 | MAE Test Loss: 45.84376525878906 \n",
      "Epoch: 28990 | MAE Train Loss: 48.71234130859375 | MAE Test Loss: 45.842010498046875 \n",
      "Epoch: 29000 | MAE Train Loss: 48.70969772338867 | MAE Test Loss: 45.84022521972656 \n",
      "Epoch: 29010 | MAE Train Loss: 48.70705795288086 | MAE Test Loss: 45.83847427368164 \n",
      "Epoch: 29020 | MAE Train Loss: 48.70441818237305 | MAE Test Loss: 45.83671951293945 \n",
      "Epoch: 29030 | MAE Train Loss: 48.701786041259766 | MAE Test Loss: 45.83494567871094 \n",
      "Epoch: 29040 | MAE Train Loss: 48.69914245605469 | MAE Test Loss: 45.83319854736328 \n",
      "Epoch: 29050 | MAE Train Loss: 48.696502685546875 | MAE Test Loss: 45.83143997192383 \n",
      "Epoch: 29060 | MAE Train Loss: 48.6938591003418 | MAE Test Loss: 45.829689025878906 \n",
      "Epoch: 29070 | MAE Train Loss: 48.691219329833984 | MAE Test Loss: 45.82789993286133 \n",
      "Epoch: 29080 | MAE Train Loss: 48.68858337402344 | MAE Test Loss: 45.826148986816406 \n",
      "Epoch: 29090 | MAE Train Loss: 48.68593978881836 | MAE Test Loss: 45.82439041137695 \n",
      "Epoch: 29100 | MAE Train Loss: 48.68330001831055 | MAE Test Loss: 45.822628021240234 \n",
      "Epoch: 29110 | MAE Train Loss: 48.680667877197266 | MAE Test Loss: 45.82087326049805 \n",
      "Epoch: 29120 | MAE Train Loss: 48.678016662597656 | MAE Test Loss: 45.819114685058594 \n",
      "Epoch: 29130 | MAE Train Loss: 48.67543411254883 | MAE Test Loss: 45.817317962646484 \n",
      "Epoch: 29140 | MAE Train Loss: 48.672882080078125 | MAE Test Loss: 45.81551742553711 \n",
      "Epoch: 29150 | MAE Train Loss: 48.67033767700195 | MAE Test Loss: 45.813716888427734 \n",
      "Epoch: 29160 | MAE Train Loss: 48.66778564453125 | MAE Test Loss: 45.81191635131836 \n",
      "Epoch: 29170 | MAE Train Loss: 48.66522979736328 | MAE Test Loss: 45.81011962890625 \n",
      "Epoch: 29180 | MAE Train Loss: 48.66267776489258 | MAE Test Loss: 45.808319091796875 \n",
      "Epoch: 29190 | MAE Train Loss: 48.66012191772461 | MAE Test Loss: 45.8065185546875 \n",
      "Epoch: 29200 | MAE Train Loss: 48.65757751464844 | MAE Test Loss: 45.80472183227539 \n",
      "Epoch: 29210 | MAE Train Loss: 48.65502166748047 | MAE Test Loss: 45.802921295166016 \n",
      "Epoch: 29220 | MAE Train Loss: 48.652469635009766 | MAE Test Loss: 45.80112075805664 \n",
      "Epoch: 29230 | MAE Train Loss: 48.64992141723633 | MAE Test Loss: 45.799320220947266 \n",
      "Epoch: 29240 | MAE Train Loss: 48.647377014160156 | MAE Test Loss: 45.797523498535156 \n",
      "Epoch: 29250 | MAE Train Loss: 48.64481735229492 | MAE Test Loss: 45.795719146728516 \n",
      "Epoch: 29260 | MAE Train Loss: 48.642269134521484 | MAE Test Loss: 45.79391860961914 \n",
      "Epoch: 29270 | MAE Train Loss: 48.63971710205078 | MAE Test Loss: 45.7921257019043 \n",
      "Epoch: 29280 | MAE Train Loss: 48.63716506958008 | MAE Test Loss: 45.790321350097656 \n",
      "Epoch: 29290 | MAE Train Loss: 48.63460922241211 | MAE Test Loss: 45.78852462768555 \n",
      "Epoch: 29300 | MAE Train Loss: 48.63206481933594 | MAE Test Loss: 45.78672409057617 \n",
      "Epoch: 29310 | MAE Train Loss: 48.6295166015625 | MAE Test Loss: 45.78492736816406 \n",
      "Epoch: 29320 | MAE Train Loss: 48.6269645690918 | MAE Test Loss: 45.78312301635742 \n",
      "Epoch: 29330 | MAE Train Loss: 48.62440872192383 | MAE Test Loss: 45.78132629394531 \n",
      "Epoch: 29340 | MAE Train Loss: 48.621856689453125 | MAE Test Loss: 45.77952575683594 \n",
      "Epoch: 29350 | MAE Train Loss: 48.61930847167969 | MAE Test Loss: 45.77772903442383 \n",
      "Epoch: 29360 | MAE Train Loss: 48.616756439208984 | MAE Test Loss: 45.77592468261719 \n",
      "Epoch: 29370 | MAE Train Loss: 48.614200592041016 | MAE Test Loss: 45.77412796020508 \n",
      "Epoch: 29380 | MAE Train Loss: 48.61164855957031 | MAE Test Loss: 45.7723274230957 \n",
      "Epoch: 29390 | MAE Train Loss: 48.60909652709961 | MAE Test Loss: 45.770530700683594 \n",
      "Epoch: 29400 | MAE Train Loss: 48.60655212402344 | MAE Test Loss: 45.76873016357422 \n",
      "Epoch: 29410 | MAE Train Loss: 48.60399627685547 | MAE Test Loss: 45.76693344116211 \n",
      "Epoch: 29420 | MAE Train Loss: 48.60144805908203 | MAE Test Loss: 45.76512908935547 \n",
      "Epoch: 29430 | MAE Train Loss: 48.59889602661133 | MAE Test Loss: 45.76333236694336 \n",
      "Epoch: 29440 | MAE Train Loss: 48.596343994140625 | MAE Test Loss: 45.761531829833984 \n",
      "Epoch: 29450 | MAE Train Loss: 48.593788146972656 | MAE Test Loss: 45.75973129272461 \n",
      "Epoch: 29460 | MAE Train Loss: 48.59123992919922 | MAE Test Loss: 45.757930755615234 \n",
      "Epoch: 29470 | MAE Train Loss: 48.588687896728516 | MAE Test Loss: 45.756168365478516 \n",
      "Epoch: 29480 | MAE Train Loss: 48.58624267578125 | MAE Test Loss: 45.754669189453125 \n",
      "Epoch: 29490 | MAE Train Loss: 48.583797454833984 | MAE Test Loss: 45.75316619873047 \n",
      "Epoch: 29500 | MAE Train Loss: 48.58135223388672 | MAE Test Loss: 45.75166320800781 \n",
      "Epoch: 29510 | MAE Train Loss: 48.57891082763672 | MAE Test Loss: 45.75015640258789 \n",
      "Epoch: 29520 | MAE Train Loss: 48.57645797729492 | MAE Test Loss: 45.7486572265625 \n",
      "Epoch: 29530 | MAE Train Loss: 48.574012756347656 | MAE Test Loss: 45.74715042114258 \n",
      "Epoch: 29540 | MAE Train Loss: 48.57156753540039 | MAE Test Loss: 45.74565124511719 \n",
      "Epoch: 29550 | MAE Train Loss: 48.569122314453125 | MAE Test Loss: 45.744144439697266 \n",
      "Epoch: 29560 | MAE Train Loss: 48.566673278808594 | MAE Test Loss: 45.74264144897461 \n",
      "Epoch: 29570 | MAE Train Loss: 48.56422805786133 | MAE Test Loss: 45.74113464355469 \n",
      "Epoch: 29580 | MAE Train Loss: 48.5617790222168 | MAE Test Loss: 45.7396354675293 \n",
      "Epoch: 29590 | MAE Train Loss: 48.55934143066406 | MAE Test Loss: 45.73813247680664 \n",
      "Epoch: 29600 | MAE Train Loss: 48.5568962097168 | MAE Test Loss: 45.736629486083984 \n",
      "Epoch: 29610 | MAE Train Loss: 48.554443359375 | MAE Test Loss: 45.735130310058594 \n",
      "Epoch: 29620 | MAE Train Loss: 48.552005767822266 | MAE Test Loss: 45.733642578125 \n",
      "Epoch: 29630 | MAE Train Loss: 48.54955291748047 | MAE Test Loss: 45.73213577270508 \n",
      "Epoch: 29640 | MAE Train Loss: 48.5471076965332 | MAE Test Loss: 45.73063659667969 \n",
      "Epoch: 29650 | MAE Train Loss: 48.54469680786133 | MAE Test Loss: 45.72907638549805 \n",
      "Epoch: 29660 | MAE Train Loss: 48.542320251464844 | MAE Test Loss: 45.72743606567383 \n",
      "Epoch: 29670 | MAE Train Loss: 48.539955139160156 | MAE Test Loss: 45.72575759887695 \n",
      "Epoch: 29680 | MAE Train Loss: 48.5375862121582 | MAE Test Loss: 45.72411346435547 \n",
      "Epoch: 29690 | MAE Train Loss: 48.535221099853516 | MAE Test Loss: 45.722469329833984 \n",
      "Epoch: 29700 | MAE Train Loss: 48.53285598754883 | MAE Test Loss: 45.7208251953125 \n",
      "Epoch: 29710 | MAE Train Loss: 48.53049087524414 | MAE Test Loss: 45.71917724609375 \n",
      "Epoch: 29720 | MAE Train Loss: 48.528114318847656 | MAE Test Loss: 45.71753692626953 \n",
      "Epoch: 29730 | MAE Train Loss: 48.5257453918457 | MAE Test Loss: 45.71586608886719 \n",
      "Epoch: 29740 | MAE Train Loss: 48.52337646484375 | MAE Test Loss: 45.71421432495117 \n",
      "Epoch: 29750 | MAE Train Loss: 48.5210075378418 | MAE Test Loss: 45.71257019042969 \n",
      "Epoch: 29760 | MAE Train Loss: 48.518638610839844 | MAE Test Loss: 45.7109260559082 \n",
      "Epoch: 29770 | MAE Train Loss: 48.51627731323242 | MAE Test Loss: 45.70928192138672 \n",
      "Epoch: 29780 | MAE Train Loss: 48.5139045715332 | MAE Test Loss: 45.7076416015625 \n",
      "Epoch: 29790 | MAE Train Loss: 48.51153564453125 | MAE Test Loss: 45.705963134765625 \n",
      "Epoch: 29800 | MAE Train Loss: 48.50917434692383 | MAE Test Loss: 45.704322814941406 \n",
      "Epoch: 29810 | MAE Train Loss: 48.50680160522461 | MAE Test Loss: 45.702674865722656 \n",
      "Epoch: 29820 | MAE Train Loss: 48.504432678222656 | MAE Test Loss: 45.70103073120117 \n",
      "Epoch: 29830 | MAE Train Loss: 48.50206756591797 | MAE Test Loss: 45.69939041137695 \n",
      "Epoch: 29840 | MAE Train Loss: 48.49970245361328 | MAE Test Loss: 45.697750091552734 \n",
      "Epoch: 29850 | MAE Train Loss: 48.49733352661133 | MAE Test Loss: 45.69610595703125 \n",
      "Epoch: 29860 | MAE Train Loss: 48.494972229003906 | MAE Test Loss: 45.694427490234375 \n",
      "Epoch: 29870 | MAE Train Loss: 48.49259567260742 | MAE Test Loss: 45.692787170410156 \n",
      "Epoch: 29880 | MAE Train Loss: 48.490234375 | MAE Test Loss: 45.69114303588867 \n",
      "Epoch: 29890 | MAE Train Loss: 48.48786544799805 | MAE Test Loss: 45.68949890136719 \n",
      "Epoch: 29900 | MAE Train Loss: 48.485504150390625 | MAE Test Loss: 45.68785858154297 \n",
      "Epoch: 29910 | MAE Train Loss: 48.4831428527832 | MAE Test Loss: 45.686214447021484 \n",
      "Epoch: 29920 | MAE Train Loss: 48.48076629638672 | MAE Test Loss: 45.68453598022461 \n",
      "Epoch: 29930 | MAE Train Loss: 48.4784049987793 | MAE Test Loss: 45.68289566040039 \n",
      "Epoch: 29940 | MAE Train Loss: 48.476036071777344 | MAE Test Loss: 45.68126678466797 \n",
      "Epoch: 29950 | MAE Train Loss: 48.47366714477539 | MAE Test Loss: 45.679595947265625 \n",
      "Epoch: 29960 | MAE Train Loss: 48.4713020324707 | MAE Test Loss: 45.677955627441406 \n",
      "Epoch: 29970 | MAE Train Loss: 48.468936920166016 | MAE Test Loss: 45.676307678222656 \n",
      "Epoch: 29980 | MAE Train Loss: 48.46657180786133 | MAE Test Loss: 45.67466735839844 \n",
      "Epoch: 29990 | MAE Train Loss: 48.46420669555664 | MAE Test Loss: 45.67301940917969 \n",
      "Epoch: 30000 | MAE Train Loss: 48.46183776855469 | MAE Test Loss: 45.671382904052734 \n",
      "Epoch: 30010 | MAE Train Loss: 48.45947265625 | MAE Test Loss: 45.669708251953125 \n",
      "Epoch: 30020 | MAE Train Loss: 48.45710754394531 | MAE Test Loss: 45.668060302734375 \n",
      "Epoch: 30030 | MAE Train Loss: 48.454742431640625 | MAE Test Loss: 45.666419982910156 \n",
      "Epoch: 30040 | MAE Train Loss: 48.45237350463867 | MAE Test Loss: 45.66477584838867 \n",
      "Epoch: 30050 | MAE Train Loss: 48.45000457763672 | MAE Test Loss: 45.66313552856445 \n",
      "Epoch: 30060 | MAE Train Loss: 48.4476432800293 | MAE Test Loss: 45.66149139404297 \n",
      "Epoch: 30070 | MAE Train Loss: 48.445274353027344 | MAE Test Loss: 45.659820556640625 \n",
      "Epoch: 30080 | MAE Train Loss: 48.44290542602539 | MAE Test Loss: 45.65817642211914 \n",
      "Epoch: 30090 | MAE Train Loss: 48.44054412841797 | MAE Test Loss: 45.65653610229492 \n",
      "Epoch: 30100 | MAE Train Loss: 48.438175201416016 | MAE Test Loss: 45.65488815307617 \n",
      "Epoch: 30110 | MAE Train Loss: 48.43580627441406 | MAE Test Loss: 45.65324401855469 \n",
      "Epoch: 30120 | MAE Train Loss: 48.43343734741211 | MAE Test Loss: 45.65160369873047 \n",
      "Epoch: 30130 | MAE Train Loss: 48.43107223510742 | MAE Test Loss: 45.649940490722656 \n",
      "Epoch: 30140 | MAE Train Loss: 48.428714752197266 | MAE Test Loss: 45.64830017089844 \n",
      "Epoch: 30150 | MAE Train Loss: 48.42634582519531 | MAE Test Loss: 45.64665603637695 \n",
      "Epoch: 30160 | MAE Train Loss: 48.42397689819336 | MAE Test Loss: 45.645015716552734 \n",
      "Epoch: 30170 | MAE Train Loss: 48.421607971191406 | MAE Test Loss: 45.643341064453125 \n",
      "Epoch: 30180 | MAE Train Loss: 48.41924285888672 | MAE Test Loss: 45.64169692993164 \n",
      "Epoch: 30190 | MAE Train Loss: 48.416873931884766 | MAE Test Loss: 45.640052795410156 \n",
      "Epoch: 30200 | MAE Train Loss: 48.41450881958008 | MAE Test Loss: 45.63841247558594 \n",
      "Epoch: 30210 | MAE Train Loss: 48.412147521972656 | MAE Test Loss: 45.63676834106445 \n",
      "Epoch: 30220 | MAE Train Loss: 48.4097785949707 | MAE Test Loss: 45.635128021240234 \n",
      "Epoch: 30230 | MAE Train Loss: 48.407413482666016 | MAE Test Loss: 45.633453369140625 \n",
      "Epoch: 30240 | MAE Train Loss: 48.40504837036133 | MAE Test Loss: 45.63180923461914 \n",
      "Epoch: 30250 | MAE Train Loss: 48.402679443359375 | MAE Test Loss: 45.630165100097656 \n",
      "Epoch: 30260 | MAE Train Loss: 48.40031433105469 | MAE Test Loss: 45.62852096557617 \n",
      "Epoch: 30270 | MAE Train Loss: 48.39794921875 | MAE Test Loss: 45.62687683105469 \n",
      "Epoch: 30280 | MAE Train Loss: 48.39558410644531 | MAE Test Loss: 45.62523651123047 \n",
      "Epoch: 30290 | MAE Train Loss: 48.39321517944336 | MAE Test Loss: 45.62356185913086 \n",
      "Epoch: 30300 | MAE Train Loss: 48.390846252441406 | MAE Test Loss: 45.62192153930664 \n",
      "Epoch: 30310 | MAE Train Loss: 48.388484954833984 | MAE Test Loss: 45.620277404785156 \n",
      "Epoch: 30320 | MAE Train Loss: 48.38611602783203 | MAE Test Loss: 45.618629455566406 \n",
      "Epoch: 30330 | MAE Train Loss: 48.38374710083008 | MAE Test Loss: 45.61697769165039 \n",
      "Epoch: 30340 | MAE Train Loss: 48.381378173828125 | MAE Test Loss: 45.61532974243164 \n",
      "Epoch: 30350 | MAE Train Loss: 48.3790168762207 | MAE Test Loss: 45.613685607910156 \n",
      "Epoch: 30360 | MAE Train Loss: 48.37665557861328 | MAE Test Loss: 45.6120491027832 \n",
      "Epoch: 30370 | MAE Train Loss: 48.3742790222168 | MAE Test Loss: 45.61040496826172 \n",
      "Epoch: 30380 | MAE Train Loss: 48.37191390991211 | MAE Test Loss: 45.608726501464844 \n",
      "Epoch: 30390 | MAE Train Loss: 48.36954879760742 | MAE Test Loss: 45.60708999633789 \n",
      "Epoch: 30400 | MAE Train Loss: 48.367183685302734 | MAE Test Loss: 45.60544204711914 \n",
      "Epoch: 30410 | MAE Train Loss: 48.36481475830078 | MAE Test Loss: 45.60380172729492 \n",
      "Epoch: 30420 | MAE Train Loss: 48.362449645996094 | MAE Test Loss: 45.60215759277344 \n",
      "Epoch: 30430 | MAE Train Loss: 48.360084533691406 | MAE Test Loss: 45.60051345825195 \n",
      "Epoch: 30440 | MAE Train Loss: 48.35771560668945 | MAE Test Loss: 45.59886932373047 \n",
      "Epoch: 30450 | MAE Train Loss: 48.35535430908203 | MAE Test Loss: 45.59719467163086 \n",
      "Epoch: 30460 | MAE Train Loss: 48.35298538208008 | MAE Test Loss: 45.59555435180664 \n",
      "Epoch: 30470 | MAE Train Loss: 48.35062026977539 | MAE Test Loss: 45.593910217285156 \n",
      "Epoch: 30480 | MAE Train Loss: 48.3482551574707 | MAE Test Loss: 45.59226989746094 \n",
      "Epoch: 30490 | MAE Train Loss: 48.34587860107422 | MAE Test Loss: 45.59062957763672 \n",
      "Epoch: 30500 | MAE Train Loss: 48.3435173034668 | MAE Test Loss: 45.5889778137207 \n",
      "Epoch: 30510 | MAE Train Loss: 48.341156005859375 | MAE Test Loss: 45.587310791015625 \n",
      "Epoch: 30520 | MAE Train Loss: 48.33878707885742 | MAE Test Loss: 45.585670471191406 \n",
      "Epoch: 30530 | MAE Train Loss: 48.33641815185547 | MAE Test Loss: 45.58403778076172 \n",
      "Epoch: 30540 | MAE Train Loss: 48.33405685424805 | MAE Test Loss: 45.58236312866211 \n",
      "Epoch: 30550 | MAE Train Loss: 48.331687927246094 | MAE Test Loss: 45.58072280883789 \n",
      "Epoch: 30560 | MAE Train Loss: 48.32931900024414 | MAE Test Loss: 45.579078674316406 \n",
      "Epoch: 30570 | MAE Train Loss: 48.32695388793945 | MAE Test Loss: 45.57743453979492 \n",
      "Epoch: 30580 | MAE Train Loss: 48.324588775634766 | MAE Test Loss: 45.57579040527344 \n",
      "Epoch: 30590 | MAE Train Loss: 48.32221984863281 | MAE Test Loss: 45.57414627075195 \n",
      "Epoch: 30600 | MAE Train Loss: 48.319854736328125 | MAE Test Loss: 45.57247543334961 \n",
      "Epoch: 30610 | MAE Train Loss: 48.31748580932617 | MAE Test Loss: 45.57083511352539 \n",
      "Epoch: 30620 | MAE Train Loss: 48.31512451171875 | MAE Test Loss: 45.56918716430664 \n",
      "Epoch: 30630 | MAE Train Loss: 48.31275939941406 | MAE Test Loss: 45.567543029785156 \n",
      "Epoch: 30640 | MAE Train Loss: 48.310386657714844 | MAE Test Loss: 45.56590270996094 \n",
      "Epoch: 30650 | MAE Train Loss: 48.30801773071289 | MAE Test Loss: 45.56425857543945 \n",
      "Epoch: 30660 | MAE Train Loss: 48.30565643310547 | MAE Test Loss: 45.562583923339844 \n",
      "Epoch: 30670 | MAE Train Loss: 48.30329132080078 | MAE Test Loss: 45.560943603515625 \n",
      "Epoch: 30680 | MAE Train Loss: 48.300926208496094 | MAE Test Loss: 45.559295654296875 \n",
      "Epoch: 30690 | MAE Train Loss: 48.2985725402832 | MAE Test Loss: 45.55769729614258 \n",
      "Epoch: 30700 | MAE Train Loss: 48.29632568359375 | MAE Test Loss: 45.556297302246094 \n",
      "Epoch: 30710 | MAE Train Loss: 48.294097900390625 | MAE Test Loss: 45.554901123046875 \n",
      "Epoch: 30720 | MAE Train Loss: 48.29185485839844 | MAE Test Loss: 45.55354309082031 \n",
      "Epoch: 30730 | MAE Train Loss: 48.28961944580078 | MAE Test Loss: 45.55214309692383 \n",
      "Epoch: 30740 | MAE Train Loss: 48.287391662597656 | MAE Test Loss: 45.550785064697266 \n",
      "Epoch: 30750 | MAE Train Loss: 48.28515625 | MAE Test Loss: 45.54938888549805 \n",
      "Epoch: 30760 | MAE Train Loss: 48.282920837402344 | MAE Test Loss: 45.548038482666016 \n",
      "Epoch: 30770 | MAE Train Loss: 48.28068542480469 | MAE Test Loss: 45.54663848876953 \n",
      "Epoch: 30780 | MAE Train Loss: 48.27845764160156 | MAE Test Loss: 45.54524230957031 \n",
      "Epoch: 30790 | MAE Train Loss: 48.276222229003906 | MAE Test Loss: 45.54388427734375 \n",
      "Epoch: 30800 | MAE Train Loss: 48.27397918701172 | MAE Test Loss: 45.542484283447266 \n",
      "Epoch: 30810 | MAE Train Loss: 48.27175521850586 | MAE Test Loss: 45.5411262512207 \n",
      "Epoch: 30820 | MAE Train Loss: 48.2695198059082 | MAE Test Loss: 45.539730072021484 \n",
      "Epoch: 30830 | MAE Train Loss: 48.26728439331055 | MAE Test Loss: 45.538333892822266 \n",
      "Epoch: 30840 | MAE Train Loss: 48.265045166015625 | MAE Test Loss: 45.5369758605957 \n",
      "Epoch: 30850 | MAE Train Loss: 48.262813568115234 | MAE Test Loss: 45.535579681396484 \n",
      "Epoch: 30860 | MAE Train Loss: 48.26058578491211 | MAE Test Loss: 45.53422546386719 \n",
      "Epoch: 30870 | MAE Train Loss: 48.25835037231445 | MAE Test Loss: 45.53282928466797 \n",
      "Epoch: 30880 | MAE Train Loss: 48.2561149597168 | MAE Test Loss: 45.53146743774414 \n",
      "Epoch: 30890 | MAE Train Loss: 48.25387954711914 | MAE Test Loss: 45.53007125854492 \n",
      "Epoch: 30900 | MAE Train Loss: 48.251644134521484 | MAE Test Loss: 45.5286750793457 \n",
      "Epoch: 30910 | MAE Train Loss: 48.24940872192383 | MAE Test Loss: 45.52731704711914 \n",
      "Epoch: 30920 | MAE Train Loss: 48.24717712402344 | MAE Test Loss: 45.52592086791992 \n",
      "Epoch: 30930 | MAE Train Loss: 48.24494171142578 | MAE Test Loss: 45.52456283569336 \n",
      "Epoch: 30940 | MAE Train Loss: 48.242706298828125 | MAE Test Loss: 45.523170471191406 \n",
      "Epoch: 30950 | MAE Train Loss: 48.240478515625 | MAE Test Loss: 45.521766662597656 \n",
      "Epoch: 30960 | MAE Train Loss: 48.23823547363281 | MAE Test Loss: 45.52041244506836 \n",
      "Epoch: 30970 | MAE Train Loss: 48.23600769042969 | MAE Test Loss: 45.51901626586914 \n",
      "Epoch: 30980 | MAE Train Loss: 48.23377227783203 | MAE Test Loss: 45.51765060424805 \n",
      "Epoch: 30990 | MAE Train Loss: 48.23154067993164 | MAE Test Loss: 45.51626205444336 \n",
      "Epoch: 31000 | MAE Train Loss: 48.229305267333984 | MAE Test Loss: 45.51490020751953 \n",
      "Epoch: 31010 | MAE Train Loss: 48.22706985473633 | MAE Test Loss: 45.513484954833984 \n",
      "Epoch: 31020 | MAE Train Loss: 48.22483444213867 | MAE Test Loss: 45.51212692260742 \n",
      "Epoch: 31030 | MAE Train Loss: 48.222599029541016 | MAE Test Loss: 45.5107307434082 \n",
      "Epoch: 31040 | MAE Train Loss: 48.22037124633789 | MAE Test Loss: 45.509376525878906 \n",
      "Epoch: 31050 | MAE Train Loss: 48.218135833740234 | MAE Test Loss: 45.50797653198242 \n",
      "Epoch: 31060 | MAE Train Loss: 48.21590042114258 | MAE Test Loss: 45.506614685058594 \n",
      "Epoch: 31070 | MAE Train Loss: 48.21366500854492 | MAE Test Loss: 45.505218505859375 \n",
      "Epoch: 31080 | MAE Train Loss: 48.211429595947266 | MAE Test Loss: 45.50382614135742 \n",
      "Epoch: 31090 | MAE Train Loss: 48.20920181274414 | MAE Test Loss: 45.502464294433594 \n",
      "Epoch: 31100 | MAE Train Loss: 48.206966400146484 | MAE Test Loss: 45.50107192993164 \n",
      "Epoch: 31110 | MAE Train Loss: 48.20473098754883 | MAE Test Loss: 45.49971008300781 \n",
      "Epoch: 31120 | MAE Train Loss: 48.20249938964844 | MAE Test Loss: 45.498313903808594 \n",
      "Epoch: 31130 | MAE Train Loss: 48.200260162353516 | MAE Test Loss: 45.496925354003906 \n",
      "Epoch: 31140 | MAE Train Loss: 48.19802474975586 | MAE Test Loss: 45.49555969238281 \n",
      "Epoch: 31150 | MAE Train Loss: 48.19579315185547 | MAE Test Loss: 45.494163513183594 \n",
      "Epoch: 31160 | MAE Train Loss: 48.19355773925781 | MAE Test Loss: 45.492801666259766 \n",
      "Epoch: 31170 | MAE Train Loss: 48.19132995605469 | MAE Test Loss: 45.49140930175781 \n",
      "Epoch: 31180 | MAE Train Loss: 48.1890869140625 | MAE Test Loss: 45.490055084228516 \n",
      "Epoch: 31190 | MAE Train Loss: 48.186859130859375 | MAE Test Loss: 45.48865509033203 \n",
      "Epoch: 31200 | MAE Train Loss: 48.18462371826172 | MAE Test Loss: 45.48725891113281 \n",
      "Epoch: 31210 | MAE Train Loss: 48.18238830566406 | MAE Test Loss: 45.485904693603516 \n",
      "Epoch: 31220 | MAE Train Loss: 48.18015670776367 | MAE Test Loss: 45.4845085144043 \n",
      "Epoch: 31230 | MAE Train Loss: 48.17791748046875 | MAE Test Loss: 45.48314666748047 \n",
      "Epoch: 31240 | MAE Train Loss: 48.175682067871094 | MAE Test Loss: 45.481746673583984 \n",
      "Epoch: 31250 | MAE Train Loss: 48.1734504699707 | MAE Test Loss: 45.48039245605469 \n",
      "Epoch: 31260 | MAE Train Loss: 48.17122268676758 | MAE Test Loss: 45.4789924621582 \n",
      "Epoch: 31270 | MAE Train Loss: 48.16897964477539 | MAE Test Loss: 45.477603912353516 \n",
      "Epoch: 31280 | MAE Train Loss: 48.166751861572266 | MAE Test Loss: 45.47624206542969 \n",
      "Epoch: 31290 | MAE Train Loss: 48.16451644897461 | MAE Test Loss: 45.47484588623047 \n",
      "Epoch: 31300 | MAE Train Loss: 48.16228103637695 | MAE Test Loss: 45.47349166870117 \n",
      "Epoch: 31310 | MAE Train Loss: 48.16004943847656 | MAE Test Loss: 45.47208786010742 \n",
      "Epoch: 31320 | MAE Train Loss: 48.15781021118164 | MAE Test Loss: 45.47069549560547 \n",
      "Epoch: 31330 | MAE Train Loss: 48.15557861328125 | MAE Test Loss: 45.46933364868164 \n",
      "Epoch: 31340 | MAE Train Loss: 48.15334701538086 | MAE Test Loss: 45.46793746948242 \n",
      "Epoch: 31350 | MAE Train Loss: 48.1511116027832 | MAE Test Loss: 45.46657943725586 \n",
      "Epoch: 31360 | MAE Train Loss: 48.14888000488281 | MAE Test Loss: 45.46518325805664 \n",
      "Epoch: 31370 | MAE Train Loss: 48.146644592285156 | MAE Test Loss: 45.46382522583008 \n",
      "Epoch: 31380 | MAE Train Loss: 48.144405364990234 | MAE Test Loss: 45.46242904663086 \n",
      "Epoch: 31390 | MAE Train Loss: 48.142173767089844 | MAE Test Loss: 45.461029052734375 \n",
      "Epoch: 31400 | MAE Train Loss: 48.13993835449219 | MAE Test Loss: 45.45967102050781 \n",
      "Epoch: 31410 | MAE Train Loss: 48.13770294189453 | MAE Test Loss: 45.45827865600586 \n",
      "Epoch: 31420 | MAE Train Loss: 48.135475158691406 | MAE Test Loss: 45.4569206237793 \n",
      "Epoch: 31430 | MAE Train Loss: 48.13323974609375 | MAE Test Loss: 45.45552062988281 \n",
      "Epoch: 31440 | MAE Train Loss: 48.13100814819336 | MAE Test Loss: 45.454124450683594 \n",
      "Epoch: 31450 | MAE Train Loss: 48.1287727355957 | MAE Test Loss: 45.4527702331543 \n",
      "Epoch: 31460 | MAE Train Loss: 48.12653732299805 | MAE Test Loss: 45.45137023925781 \n",
      "Epoch: 31470 | MAE Train Loss: 48.12430953979492 | MAE Test Loss: 45.45001220703125 \n",
      "Epoch: 31480 | MAE Train Loss: 48.122066497802734 | MAE Test Loss: 45.44861602783203 \n",
      "Epoch: 31490 | MAE Train Loss: 48.11983871459961 | MAE Test Loss: 45.44725799560547 \n",
      "Epoch: 31500 | MAE Train Loss: 48.11759567260742 | MAE Test Loss: 45.44586181640625 \n",
      "Epoch: 31510 | MAE Train Loss: 48.11537170410156 | MAE Test Loss: 45.4444694519043 \n",
      "Epoch: 31520 | MAE Train Loss: 48.11313247680664 | MAE Test Loss: 45.443111419677734 \n",
      "Epoch: 31530 | MAE Train Loss: 48.110897064208984 | MAE Test Loss: 45.44171142578125 \n",
      "Epoch: 31540 | MAE Train Loss: 48.108665466308594 | MAE Test Loss: 45.44035339355469 \n",
      "Epoch: 31550 | MAE Train Loss: 48.10643005371094 | MAE Test Loss: 45.43895721435547 \n",
      "Epoch: 31560 | MAE Train Loss: 48.10419464111328 | MAE Test Loss: 45.43756103515625 \n",
      "Epoch: 31570 | MAE Train Loss: 48.10195541381836 | MAE Test Loss: 45.43619918823242 \n",
      "Epoch: 31580 | MAE Train Loss: 48.09972381591797 | MAE Test Loss: 45.4348030090332 \n",
      "Epoch: 31590 | MAE Train Loss: 48.097496032714844 | MAE Test Loss: 45.43344497680664 \n",
      "Epoch: 31600 | MAE Train Loss: 48.09526062011719 | MAE Test Loss: 45.43205261230469 \n",
      "Epoch: 31610 | MAE Train Loss: 48.09302520751953 | MAE Test Loss: 45.43069076538086 \n",
      "Epoch: 31620 | MAE Train Loss: 48.090789794921875 | MAE Test Loss: 45.429298400878906 \n",
      "Epoch: 31630 | MAE Train Loss: 48.08856201171875 | MAE Test Loss: 45.42789840698242 \n",
      "Epoch: 31640 | MAE Train Loss: 48.08631896972656 | MAE Test Loss: 45.42654037475586 \n",
      "Epoch: 31650 | MAE Train Loss: 48.08409118652344 | MAE Test Loss: 45.42514419555664 \n",
      "Epoch: 31660 | MAE Train Loss: 48.08185577392578 | MAE Test Loss: 45.42378616333008 \n",
      "Epoch: 31670 | MAE Train Loss: 48.079620361328125 | MAE Test Loss: 45.422386169433594 \n",
      "Epoch: 31680 | MAE Train Loss: 48.077388763427734 | MAE Test Loss: 45.42101287841797 \n",
      "Epoch: 31690 | MAE Train Loss: 48.07516098022461 | MAE Test Loss: 45.41961669921875 \n",
      "Epoch: 31700 | MAE Train Loss: 48.07291793823242 | MAE Test Loss: 45.41825866699219 \n",
      "Epoch: 31710 | MAE Train Loss: 48.070682525634766 | MAE Test Loss: 45.416866302490234 \n",
      "Epoch: 31720 | MAE Train Loss: 48.06844711303711 | MAE Test Loss: 45.415504455566406 \n",
      "Epoch: 31730 | MAE Train Loss: 48.066219329833984 | MAE Test Loss: 45.414127349853516 \n",
      "Epoch: 31740 | MAE Train Loss: 48.06398391723633 | MAE Test Loss: 45.4127311706543 \n",
      "Epoch: 31750 | MAE Train Loss: 48.06175231933594 | MAE Test Loss: 45.41133499145508 \n",
      "Epoch: 31760 | MAE Train Loss: 48.059513092041016 | MAE Test Loss: 45.409976959228516 \n",
      "Epoch: 31770 | MAE Train Loss: 48.05727767944336 | MAE Test Loss: 45.408599853515625 \n",
      "Epoch: 31780 | MAE Train Loss: 48.05504608154297 | MAE Test Loss: 45.407203674316406 \n",
      "Epoch: 31790 | MAE Train Loss: 48.05281066894531 | MAE Test Loss: 45.405845642089844 \n",
      "Epoch: 31800 | MAE Train Loss: 48.050575256347656 | MAE Test Loss: 45.404449462890625 \n",
      "Epoch: 31810 | MAE Train Loss: 48.04833984375 | MAE Test Loss: 45.403053283691406 \n",
      "Epoch: 31820 | MAE Train Loss: 48.046104431152344 | MAE Test Loss: 45.40169143676758 \n",
      "Epoch: 31830 | MAE Train Loss: 48.043880462646484 | MAE Test Loss: 45.400299072265625 \n",
      "Epoch: 31840 | MAE Train Loss: 48.04164123535156 | MAE Test Loss: 45.3989372253418 \n",
      "Epoch: 31850 | MAE Train Loss: 48.0394172668457 | MAE Test Loss: 45.39751052856445 \n",
      "Epoch: 31860 | MAE Train Loss: 48.03722381591797 | MAE Test Loss: 45.3959846496582 \n",
      "Epoch: 31870 | MAE Train Loss: 48.0350456237793 | MAE Test Loss: 45.39442825317383 \n",
      "Epoch: 31880 | MAE Train Loss: 48.032859802246094 | MAE Test Loss: 45.392906188964844 \n",
      "Epoch: 31890 | MAE Train Loss: 48.030670166015625 | MAE Test Loss: 45.39134979248047 \n",
      "Epoch: 31900 | MAE Train Loss: 48.02848434448242 | MAE Test Loss: 45.389827728271484 \n",
      "Epoch: 31910 | MAE Train Loss: 48.02629852294922 | MAE Test Loss: 45.3883056640625 \n",
      "Epoch: 31920 | MAE Train Loss: 48.024112701416016 | MAE Test Loss: 45.38674545288086 \n",
      "Epoch: 31930 | MAE Train Loss: 48.02192687988281 | MAE Test Loss: 45.385223388671875 \n",
      "Epoch: 31940 | MAE Train Loss: 48.01974105834961 | MAE Test Loss: 45.3836669921875 \n",
      "Epoch: 31950 | MAE Train Loss: 48.017555236816406 | MAE Test Loss: 45.38214111328125 \n",
      "Epoch: 31960 | MAE Train Loss: 48.01536560058594 | MAE Test Loss: 45.380619049072266 \n",
      "Epoch: 31970 | MAE Train Loss: 48.01318359375 | MAE Test Loss: 45.379058837890625 \n",
      "Epoch: 31980 | MAE Train Loss: 48.01099395751953 | MAE Test Loss: 45.377532958984375 \n",
      "Epoch: 31990 | MAE Train Loss: 48.00880813598633 | MAE Test Loss: 45.375980377197266 \n",
      "Epoch: 32000 | MAE Train Loss: 48.006622314453125 | MAE Test Loss: 45.37446212768555 \n",
      "Epoch: 32010 | MAE Train Loss: 48.00443649291992 | MAE Test Loss: 45.3729362487793 \n",
      "Epoch: 32020 | MAE Train Loss: 48.00225067138672 | MAE Test Loss: 45.37137985229492 \n",
      "Epoch: 32030 | MAE Train Loss: 48.000064849853516 | MAE Test Loss: 45.36985778808594 \n",
      "Epoch: 32040 | MAE Train Loss: 47.99787521362305 | MAE Test Loss: 45.3682975769043 \n",
      "Epoch: 32050 | MAE Train Loss: 47.995697021484375 | MAE Test Loss: 45.36677932739258 \n",
      "Epoch: 32060 | MAE Train Loss: 47.99350357055664 | MAE Test Loss: 45.36525344848633 \n",
      "Epoch: 32070 | MAE Train Loss: 47.99131774902344 | MAE Test Loss: 45.36369705200195 \n",
      "Epoch: 32080 | MAE Train Loss: 47.989131927490234 | MAE Test Loss: 45.36217498779297 \n",
      "Epoch: 32090 | MAE Train Loss: 47.98694610595703 | MAE Test Loss: 45.360618591308594 \n",
      "Epoch: 32100 | MAE Train Loss: 47.984764099121094 | MAE Test Loss: 45.35909652709961 \n",
      "Epoch: 32110 | MAE Train Loss: 47.98257064819336 | MAE Test Loss: 45.3575439453125 \n",
      "Epoch: 32120 | MAE Train Loss: 47.98039245605469 | MAE Test Loss: 45.35601806640625 \n",
      "Epoch: 32130 | MAE Train Loss: 47.97819900512695 | MAE Test Loss: 45.3544921875 \n",
      "Epoch: 32140 | MAE Train Loss: 47.97601318359375 | MAE Test Loss: 45.352935791015625 \n",
      "Epoch: 32150 | MAE Train Loss: 47.97382736206055 | MAE Test Loss: 45.35141372680664 \n",
      "Epoch: 32160 | MAE Train Loss: 47.97164535522461 | MAE Test Loss: 45.349853515625 \n",
      "Epoch: 32170 | MAE Train Loss: 47.969459533691406 | MAE Test Loss: 45.34833526611328 \n",
      "Epoch: 32180 | MAE Train Loss: 47.96726608276367 | MAE Test Loss: 45.34680938720703 \n",
      "Epoch: 32190 | MAE Train Loss: 47.965087890625 | MAE Test Loss: 45.34525680541992 \n",
      "Epoch: 32200 | MAE Train Loss: 47.9629020690918 | MAE Test Loss: 45.343727111816406 \n",
      "Epoch: 32210 | MAE Train Loss: 47.96071243286133 | MAE Test Loss: 45.3421745300293 \n",
      "Epoch: 32220 | MAE Train Loss: 47.95853042602539 | MAE Test Loss: 45.34064865112305 \n",
      "Epoch: 32230 | MAE Train Loss: 47.95634078979492 | MAE Test Loss: 45.33912658691406 \n",
      "Epoch: 32240 | MAE Train Loss: 47.954158782958984 | MAE Test Loss: 45.33757400512695 \n",
      "Epoch: 32250 | MAE Train Loss: 47.951969146728516 | MAE Test Loss: 45.3360481262207 \n",
      "Epoch: 32260 | MAE Train Loss: 47.94978332519531 | MAE Test Loss: 45.33448791503906 \n",
      "Epoch: 32270 | MAE Train Loss: 47.94759750366211 | MAE Test Loss: 45.332969665527344 \n",
      "Epoch: 32280 | MAE Train Loss: 47.945411682128906 | MAE Test Loss: 45.33144760131836 \n",
      "Epoch: 32290 | MAE Train Loss: 47.9432258605957 | MAE Test Loss: 45.32988739013672 \n",
      "Epoch: 32300 | MAE Train Loss: 47.941036224365234 | MAE Test Loss: 45.328365325927734 \n",
      "Epoch: 32310 | MAE Train Loss: 47.93885040283203 | MAE Test Loss: 45.32680892944336 \n",
      "Epoch: 32320 | MAE Train Loss: 47.936668395996094 | MAE Test Loss: 45.325286865234375 \n",
      "Epoch: 32330 | MAE Train Loss: 47.934478759765625 | MAE Test Loss: 45.32373046875 \n",
      "Epoch: 32340 | MAE Train Loss: 47.93229293823242 | MAE Test Loss: 45.322208404541016 \n",
      "Epoch: 32350 | MAE Train Loss: 47.93010711669922 | MAE Test Loss: 45.3206787109375 \n",
      "Epoch: 32360 | MAE Train Loss: 47.927921295166016 | MAE Test Loss: 45.31912612915039 \n",
      "Epoch: 32370 | MAE Train Loss: 47.92573547363281 | MAE Test Loss: 45.317604064941406 \n",
      "Epoch: 32380 | MAE Train Loss: 47.923545837402344 | MAE Test Loss: 45.316043853759766 \n",
      "Epoch: 32390 | MAE Train Loss: 47.92136764526367 | MAE Test Loss: 45.31452560424805 \n",
      "Epoch: 32400 | MAE Train Loss: 47.91917419433594 | MAE Test Loss: 45.31298065185547 \n",
      "Epoch: 32410 | MAE Train Loss: 47.916988372802734 | MAE Test Loss: 45.311458587646484 \n",
      "Epoch: 32420 | MAE Train Loss: 47.91486358642578 | MAE Test Loss: 45.310035705566406 \n",
      "Epoch: 32430 | MAE Train Loss: 47.91276931762695 | MAE Test Loss: 45.30869674682617 \n",
      "Epoch: 32440 | MAE Train Loss: 47.91065979003906 | MAE Test Loss: 45.307315826416016 \n",
      "Epoch: 32450 | MAE Train Loss: 47.90855026245117 | MAE Test Loss: 45.30592727661133 \n",
      "Epoch: 32460 | MAE Train Loss: 47.906455993652344 | MAE Test Loss: 45.304588317871094 \n",
      "Epoch: 32470 | MAE Train Loss: 47.90434646606445 | MAE Test Loss: 45.30320358276367 \n",
      "Epoch: 32480 | MAE Train Loss: 47.902244567871094 | MAE Test Loss: 45.30182647705078 \n",
      "Epoch: 32490 | MAE Train Loss: 47.900142669677734 | MAE Test Loss: 45.30048370361328 \n",
      "Epoch: 32500 | MAE Train Loss: 47.89804458618164 | MAE Test Loss: 45.29911804199219 \n",
      "Epoch: 32510 | MAE Train Loss: 47.89593505859375 | MAE Test Loss: 45.2977409362793 \n",
      "Epoch: 32520 | MAE Train Loss: 47.89383316040039 | MAE Test Loss: 45.29635238647461 \n",
      "Epoch: 32530 | MAE Train Loss: 47.89173126220703 | MAE Test Loss: 45.295013427734375 \n",
      "Epoch: 32540 | MAE Train Loss: 47.88963317871094 | MAE Test Loss: 45.29362869262695 \n",
      "Epoch: 32550 | MAE Train Loss: 47.88752746582031 | MAE Test Loss: 45.2922477722168 \n",
      "Epoch: 32560 | MAE Train Loss: 47.88549041748047 | MAE Test Loss: 45.29076385498047 \n",
      "Epoch: 32570 | MAE Train Loss: 47.88347244262695 | MAE Test Loss: 45.289215087890625 \n",
      "Epoch: 32580 | MAE Train Loss: 47.88146209716797 | MAE Test Loss: 45.287696838378906 \n",
      "Epoch: 32590 | MAE Train Loss: 47.87943649291992 | MAE Test Loss: 45.28617858886719 \n",
      "Epoch: 32600 | MAE Train Loss: 47.87742233276367 | MAE Test Loss: 45.28462600708008 \n",
      "Epoch: 32610 | MAE Train Loss: 47.875404357910156 | MAE Test Loss: 45.283111572265625 \n",
      "Epoch: 32620 | MAE Train Loss: 47.873390197753906 | MAE Test Loss: 45.28156280517578 \n",
      "Epoch: 32630 | MAE Train Loss: 47.871376037597656 | MAE Test Loss: 45.28004455566406 \n",
      "Epoch: 32640 | MAE Train Loss: 47.86935806274414 | MAE Test Loss: 45.27849578857422 \n",
      "Epoch: 32650 | MAE Train Loss: 47.86734390258789 | MAE Test Loss: 45.2769775390625 \n",
      "Epoch: 32660 | MAE Train Loss: 47.86532211303711 | MAE Test Loss: 45.275428771972656 \n",
      "Epoch: 32670 | MAE Train Loss: 47.863304138183594 | MAE Test Loss: 45.273902893066406 \n",
      "Epoch: 32680 | MAE Train Loss: 47.86134338378906 | MAE Test Loss: 45.27251052856445 \n",
      "Epoch: 32690 | MAE Train Loss: 47.85940170288086 | MAE Test Loss: 45.27118682861328 \n",
      "Epoch: 32700 | MAE Train Loss: 47.85748291015625 | MAE Test Loss: 45.26987838745117 \n",
      "Epoch: 32710 | MAE Train Loss: 47.85554504394531 | MAE Test Loss: 45.2685546875 \n",
      "Epoch: 32720 | MAE Train Loss: 47.8536262512207 | MAE Test Loss: 45.2672004699707 \n",
      "Epoch: 32730 | MAE Train Loss: 47.851707458496094 | MAE Test Loss: 45.26588439941406 \n",
      "Epoch: 32740 | MAE Train Loss: 47.84978485107422 | MAE Test Loss: 45.264583587646484 \n",
      "Epoch: 32750 | MAE Train Loss: 47.84787368774414 | MAE Test Loss: 45.263267517089844 \n",
      "Epoch: 32760 | MAE Train Loss: 47.845947265625 | MAE Test Loss: 45.26195526123047 \n",
      "Epoch: 32770 | MAE Train Loss: 47.844032287597656 | MAE Test Loss: 45.2606315612793 \n",
      "Epoch: 32780 | MAE Train Loss: 47.84211349487305 | MAE Test Loss: 45.25931930541992 \n",
      "Epoch: 32790 | MAE Train Loss: 47.84019088745117 | MAE Test Loss: 45.25802230834961 \n",
      "Epoch: 32800 | MAE Train Loss: 47.83827209472656 | MAE Test Loss: 45.25669860839844 \n",
      "Epoch: 32810 | MAE Train Loss: 47.83635330200195 | MAE Test Loss: 45.25538635253906 \n",
      "Epoch: 32820 | MAE Train Loss: 47.83443832397461 | MAE Test Loss: 45.25406265258789 \n",
      "Epoch: 32830 | MAE Train Loss: 47.83251953125 | MAE Test Loss: 45.252750396728516 \n",
      "Epoch: 32840 | MAE Train Loss: 47.830596923828125 | MAE Test Loss: 45.251434326171875 \n",
      "Epoch: 32850 | MAE Train Loss: 47.828678131103516 | MAE Test Loss: 45.250152587890625 \n",
      "Epoch: 32860 | MAE Train Loss: 47.826759338378906 | MAE Test Loss: 45.248836517333984 \n",
      "Epoch: 32870 | MAE Train Loss: 47.82484436035156 | MAE Test Loss: 45.24751281738281 \n",
      "Epoch: 32880 | MAE Train Loss: 47.82292556762695 | MAE Test Loss: 45.24619674682617 \n",
      "Epoch: 32890 | MAE Train Loss: 47.82099914550781 | MAE Test Loss: 45.24488067626953 \n",
      "Epoch: 32900 | MAE Train Loss: 47.81908416748047 | MAE Test Loss: 45.24356460571289 \n",
      "Epoch: 32910 | MAE Train Loss: 47.81715774536133 | MAE Test Loss: 45.24224853515625 \n",
      "Epoch: 32920 | MAE Train Loss: 47.815242767333984 | MAE Test Loss: 45.24093246459961 \n",
      "Epoch: 32930 | MAE Train Loss: 47.813331604003906 | MAE Test Loss: 45.2396125793457 \n",
      "Epoch: 32940 | MAE Train Loss: 47.811405181884766 | MAE Test Loss: 45.23829650878906 \n",
      "Epoch: 32950 | MAE Train Loss: 47.80950164794922 | MAE Test Loss: 45.23695373535156 \n",
      "Epoch: 32960 | MAE Train Loss: 47.80762481689453 | MAE Test Loss: 45.235530853271484 \n",
      "Epoch: 32970 | MAE Train Loss: 47.80574417114258 | MAE Test Loss: 45.23410415649414 \n",
      "Epoch: 32980 | MAE Train Loss: 47.80387878417969 | MAE Test Loss: 45.232704162597656 \n",
      "Epoch: 32990 | MAE Train Loss: 47.80199432373047 | MAE Test Loss: 45.23127365112305 \n",
      "Epoch: 33000 | MAE Train Loss: 47.80016326904297 | MAE Test Loss: 45.229957580566406 \n",
      "Epoch: 33010 | MAE Train Loss: 47.79834747314453 | MAE Test Loss: 45.22865295410156 \n",
      "Epoch: 33020 | MAE Train Loss: 47.79652786254883 | MAE Test Loss: 45.227386474609375 \n",
      "Epoch: 33030 | MAE Train Loss: 47.79470443725586 | MAE Test Loss: 45.2260856628418 \n",
      "Epoch: 33040 | MAE Train Loss: 47.79289245605469 | MAE Test Loss: 45.22478103637695 \n",
      "Epoch: 33050 | MAE Train Loss: 47.791072845458984 | MAE Test Loss: 45.223480224609375 \n",
      "Epoch: 33060 | MAE Train Loss: 47.789249420166016 | MAE Test Loss: 45.22221374511719 \n",
      "Epoch: 33070 | MAE Train Loss: 47.78742980957031 | MAE Test Loss: 45.220909118652344 \n",
      "Epoch: 33080 | MAE Train Loss: 47.785614013671875 | MAE Test Loss: 45.219608306884766 \n",
      "Epoch: 33090 | MAE Train Loss: 47.78379440307617 | MAE Test Loss: 45.21834182739258 \n",
      "Epoch: 33100 | MAE Train Loss: 47.781978607177734 | MAE Test Loss: 45.217037200927734 \n",
      "Epoch: 33110 | MAE Train Loss: 47.78015899658203 | MAE Test Loss: 45.215736389160156 \n",
      "Epoch: 33120 | MAE Train Loss: 47.77833938598633 | MAE Test Loss: 45.21443176269531 \n",
      "Epoch: 33130 | MAE Train Loss: 47.776512145996094 | MAE Test Loss: 45.213165283203125 \n",
      "Epoch: 33140 | MAE Train Loss: 47.77470016479492 | MAE Test Loss: 45.21186065673828 \n",
      "Epoch: 33150 | MAE Train Loss: 47.77288055419922 | MAE Test Loss: 45.2105598449707 \n",
      "Epoch: 33160 | MAE Train Loss: 47.77105712890625 | MAE Test Loss: 45.20929718017578 \n",
      "Epoch: 33170 | MAE Train Loss: 47.76924514770508 | MAE Test Loss: 45.20799255371094 \n",
      "Epoch: 33180 | MAE Train Loss: 47.76742172241211 | MAE Test Loss: 45.206687927246094 \n",
      "Epoch: 33190 | MAE Train Loss: 47.765602111816406 | MAE Test Loss: 45.20542526245117 \n",
      "Epoch: 33200 | MAE Train Loss: 47.76378631591797 | MAE Test Loss: 45.20412063598633 \n",
      "Epoch: 33210 | MAE Train Loss: 47.761966705322266 | MAE Test Loss: 45.202816009521484 \n",
      "Epoch: 33220 | MAE Train Loss: 47.76014709472656 | MAE Test Loss: 45.201515197753906 \n",
      "Epoch: 33230 | MAE Train Loss: 47.758331298828125 | MAE Test Loss: 45.20024490356445 \n",
      "Epoch: 33240 | MAE Train Loss: 47.756507873535156 | MAE Test Loss: 45.19894790649414 \n",
      "Epoch: 33250 | MAE Train Loss: 47.75469207763672 | MAE Test Loss: 45.1976432800293 \n",
      "Epoch: 33260 | MAE Train Loss: 47.752872467041016 | MAE Test Loss: 45.196372985839844 \n",
      "Epoch: 33270 | MAE Train Loss: 47.75105667114258 | MAE Test Loss: 45.195072174072266 \n",
      "Epoch: 33280 | MAE Train Loss: 47.749237060546875 | MAE Test Loss: 45.19377136230469 \n",
      "Epoch: 33290 | MAE Train Loss: 47.74741744995117 | MAE Test Loss: 45.192466735839844 \n",
      "Epoch: 33300 | MAE Train Loss: 47.745601654052734 | MAE Test Loss: 45.19120788574219 \n",
      "Epoch: 33310 | MAE Train Loss: 47.74378204345703 | MAE Test Loss: 45.18989944458008 \n",
      "Epoch: 33320 | MAE Train Loss: 47.74196243286133 | MAE Test Loss: 45.1885986328125 \n",
      "Epoch: 33330 | MAE Train Loss: 47.74013900756836 | MAE Test Loss: 45.18733215332031 \n",
      "Epoch: 33340 | MAE Train Loss: 47.738319396972656 | MAE Test Loss: 45.186031341552734 \n",
      "Epoch: 33350 | MAE Train Loss: 47.73650360107422 | MAE Test Loss: 45.18472671508789 \n",
      "Epoch: 33360 | MAE Train Loss: 47.734683990478516 | MAE Test Loss: 45.1834602355957 \n",
      "Epoch: 33370 | MAE Train Loss: 47.73286819458008 | MAE Test Loss: 45.18215560913086 \n",
      "Epoch: 33380 | MAE Train Loss: 47.731048583984375 | MAE Test Loss: 45.18085479736328 \n",
      "Epoch: 33390 | MAE Train Loss: 47.729225158691406 | MAE Test Loss: 45.17955017089844 \n",
      "Epoch: 33400 | MAE Train Loss: 47.727413177490234 | MAE Test Loss: 45.17828369140625 \n",
      "Epoch: 33410 | MAE Train Loss: 47.725589752197266 | MAE Test Loss: 45.176979064941406 \n",
      "Epoch: 33420 | MAE Train Loss: 47.723777770996094 | MAE Test Loss: 45.17567443847656 \n",
      "Epoch: 33430 | MAE Train Loss: 47.721946716308594 | MAE Test Loss: 45.174415588378906 \n",
      "Epoch: 33440 | MAE Train Loss: 47.72013854980469 | MAE Test Loss: 45.17311096191406 \n",
      "Epoch: 33450 | MAE Train Loss: 47.718318939208984 | MAE Test Loss: 45.17180633544922 \n",
      "Epoch: 33460 | MAE Train Loss: 47.71649169921875 | MAE Test Loss: 45.17050552368164 \n",
      "Epoch: 33470 | MAE Train Loss: 47.71467590332031 | MAE Test Loss: 45.16923522949219 \n",
      "Epoch: 33480 | MAE Train Loss: 47.71286392211914 | MAE Test Loss: 45.16793441772461 \n",
      "Epoch: 33490 | MAE Train Loss: 47.71104431152344 | MAE Test Loss: 45.16663360595703 \n",
      "Epoch: 33500 | MAE Train Loss: 47.70922088623047 | MAE Test Loss: 45.165367126464844 \n",
      "Epoch: 33510 | MAE Train Loss: 47.7074089050293 | MAE Test Loss: 45.1640625 \n",
      "Epoch: 33520 | MAE Train Loss: 47.70558547973633 | MAE Test Loss: 45.162757873535156 \n",
      "Epoch: 33530 | MAE Train Loss: 47.703765869140625 | MAE Test Loss: 45.16145706176758 \n",
      "Epoch: 33540 | MAE Train Loss: 47.70194625854492 | MAE Test Loss: 45.16019058227539 \n",
      "Epoch: 33550 | MAE Train Loss: 47.700130462646484 | MAE Test Loss: 45.15888977050781 \n",
      "Epoch: 33560 | MAE Train Loss: 47.69831085205078 | MAE Test Loss: 45.157588958740234 \n",
      "Epoch: 33570 | MAE Train Loss: 47.69648361206055 | MAE Test Loss: 45.15632247924805 \n",
      "Epoch: 33580 | MAE Train Loss: 47.694671630859375 | MAE Test Loss: 45.1550178527832 \n",
      "Epoch: 33590 | MAE Train Loss: 47.69285583496094 | MAE Test Loss: 45.153717041015625 \n",
      "Epoch: 33600 | MAE Train Loss: 47.691036224365234 | MAE Test Loss: 45.15244674682617 \n",
      "Epoch: 33610 | MAE Train Loss: 47.68921661376953 | MAE Test Loss: 45.15114974975586 \n",
      "Epoch: 33620 | MAE Train Loss: 47.68739318847656 | MAE Test Loss: 45.14984130859375 \n",
      "Epoch: 33630 | MAE Train Loss: 47.68557357788086 | MAE Test Loss: 45.14854049682617 \n",
      "Epoch: 33640 | MAE Train Loss: 47.68376159667969 | MAE Test Loss: 45.147274017333984 \n",
      "Epoch: 33650 | MAE Train Loss: 47.68194580078125 | MAE Test Loss: 45.145973205566406 \n",
      "Epoch: 33660 | MAE Train Loss: 47.68013000488281 | MAE Test Loss: 45.14466857910156 \n",
      "Epoch: 33670 | MAE Train Loss: 47.67830276489258 | MAE Test Loss: 45.14340591430664 \n",
      "Epoch: 33680 | MAE Train Loss: 47.676490783691406 | MAE Test Loss: 45.1421012878418 \n",
      "Epoch: 33690 | MAE Train Loss: 47.67466354370117 | MAE Test Loss: 45.14079666137695 \n",
      "Epoch: 33700 | MAE Train Loss: 47.672847747802734 | MAE Test Loss: 45.13949203491211 \n",
      "Epoch: 33710 | MAE Train Loss: 47.67102813720703 | MAE Test Loss: 45.13823318481445 \n",
      "Epoch: 33720 | MAE Train Loss: 47.66920852661133 | MAE Test Loss: 45.136924743652344 \n",
      "Epoch: 33730 | MAE Train Loss: 47.667388916015625 | MAE Test Loss: 45.135623931884766 \n",
      "Epoch: 33740 | MAE Train Loss: 47.66556930541992 | MAE Test Loss: 45.13435363769531 \n",
      "Epoch: 33750 | MAE Train Loss: 47.663753509521484 | MAE Test Loss: 45.133052825927734 \n",
      "Epoch: 33760 | MAE Train Loss: 47.66193771362305 | MAE Test Loss: 45.131744384765625 \n",
      "Epoch: 33770 | MAE Train Loss: 47.660118103027344 | MAE Test Loss: 45.13048553466797 \n",
      "Epoch: 33780 | MAE Train Loss: 47.65829849243164 | MAE Test Loss: 45.12918472290039 \n",
      "Epoch: 33790 | MAE Train Loss: 47.65648651123047 | MAE Test Loss: 45.12788009643555 \n",
      "Epoch: 33800 | MAE Train Loss: 47.654666900634766 | MAE Test Loss: 45.126583099365234 \n",
      "Epoch: 33810 | MAE Train Loss: 47.65284729003906 | MAE Test Loss: 45.12531661987305 \n",
      "Epoch: 33820 | MAE Train Loss: 47.65102767944336 | MAE Test Loss: 45.12401580810547 \n",
      "Epoch: 33830 | MAE Train Loss: 47.64921188354492 | MAE Test Loss: 45.122718811035156 \n",
      "Epoch: 33840 | MAE Train Loss: 47.64739227294922 | MAE Test Loss: 45.1214485168457 \n",
      "Epoch: 33850 | MAE Train Loss: 47.64558410644531 | MAE Test Loss: 45.12015151977539 \n",
      "Epoch: 33860 | MAE Train Loss: 47.643768310546875 | MAE Test Loss: 45.11884307861328 \n",
      "Epoch: 33870 | MAE Train Loss: 47.64194107055664 | MAE Test Loss: 45.11754608154297 \n",
      "Epoch: 33880 | MAE Train Loss: 47.6401252746582 | MAE Test Loss: 45.11628341674805 \n",
      "Epoch: 33890 | MAE Train Loss: 47.6383056640625 | MAE Test Loss: 45.1149787902832 \n",
      "Epoch: 33900 | MAE Train Loss: 47.63649368286133 | MAE Test Loss: 45.113677978515625 \n",
      "Epoch: 33910 | MAE Train Loss: 47.63467025756836 | MAE Test Loss: 45.11241149902344 \n",
      "Epoch: 33920 | MAE Train Loss: 47.63286209106445 | MAE Test Loss: 45.11111068725586 \n",
      "Epoch: 33930 | MAE Train Loss: 47.63104248046875 | MAE Test Loss: 45.10981369018555 \n",
      "Epoch: 33940 | MAE Train Loss: 47.62922286987305 | MAE Test Loss: 45.1085090637207 \n",
      "Epoch: 33950 | MAE Train Loss: 47.62740707397461 | MAE Test Loss: 45.10725021362305 \n",
      "Epoch: 33960 | MAE Train Loss: 47.625587463378906 | MAE Test Loss: 45.10596466064453 \n",
      "Epoch: 33970 | MAE Train Loss: 47.62377166748047 | MAE Test Loss: 45.10466003417969 \n",
      "Epoch: 33980 | MAE Train Loss: 47.621952056884766 | MAE Test Loss: 45.10337829589844 \n",
      "Epoch: 33990 | MAE Train Loss: 47.62013626098633 | MAE Test Loss: 45.10207748413086 \n",
      "Epoch: 34000 | MAE Train Loss: 47.618316650390625 | MAE Test Loss: 45.10077667236328 \n",
      "Epoch: 34010 | MAE Train Loss: 47.61650085449219 | MAE Test Loss: 45.09951400756836 \n",
      "Epoch: 34020 | MAE Train Loss: 47.614681243896484 | MAE Test Loss: 45.098209381103516 \n",
      "Epoch: 34030 | MAE Train Loss: 47.61287307739258 | MAE Test Loss: 45.09690856933594 \n",
      "Epoch: 34040 | MAE Train Loss: 47.61104965209961 | MAE Test Loss: 45.09560775756836 \n",
      "Epoch: 34050 | MAE Train Loss: 47.609230041503906 | MAE Test Loss: 45.09434127807617 \n",
      "Epoch: 34060 | MAE Train Loss: 47.607418060302734 | MAE Test Loss: 45.093040466308594 \n",
      "Epoch: 34070 | MAE Train Loss: 47.605594635009766 | MAE Test Loss: 45.091739654541016 \n",
      "Epoch: 34080 | MAE Train Loss: 47.60377502441406 | MAE Test Loss: 45.09048080444336 \n",
      "Epoch: 34090 | MAE Train Loss: 47.601959228515625 | MAE Test Loss: 45.08917999267578 \n",
      "Epoch: 34100 | MAE Train Loss: 47.60014724731445 | MAE Test Loss: 45.08787536621094 \n",
      "Epoch: 34110 | MAE Train Loss: 47.59832000732422 | MAE Test Loss: 45.08657455444336 \n",
      "Epoch: 34120 | MAE Train Loss: 47.59650421142578 | MAE Test Loss: 45.08530807495117 \n",
      "Epoch: 34130 | MAE Train Loss: 47.59469223022461 | MAE Test Loss: 45.084007263183594 \n",
      "Epoch: 34140 | MAE Train Loss: 47.59287643432617 | MAE Test Loss: 45.082706451416016 \n",
      "Epoch: 34150 | MAE Train Loss: 47.591121673583984 | MAE Test Loss: 45.08135986328125 \n",
      "Epoch: 34160 | MAE Train Loss: 47.58943557739258 | MAE Test Loss: 45.079952239990234 \n",
      "Epoch: 34170 | MAE Train Loss: 47.58774185180664 | MAE Test Loss: 45.07855224609375 \n",
      "Epoch: 34180 | MAE Train Loss: 47.58605194091797 | MAE Test Loss: 45.077144622802734 \n",
      "Epoch: 34190 | MAE Train Loss: 47.5843620300293 | MAE Test Loss: 45.07572937011719 \n",
      "Epoch: 34200 | MAE Train Loss: 47.582672119140625 | MAE Test Loss: 45.07432174682617 \n",
      "Epoch: 34210 | MAE Train Loss: 47.58097839355469 | MAE Test Loss: 45.07291793823242 \n",
      "Epoch: 34220 | MAE Train Loss: 47.57929611206055 | MAE Test Loss: 45.071502685546875 \n",
      "Epoch: 34230 | MAE Train Loss: 47.57761001586914 | MAE Test Loss: 45.070098876953125 \n",
      "Epoch: 34240 | MAE Train Loss: 47.5759162902832 | MAE Test Loss: 45.068695068359375 \n",
      "Epoch: 34250 | MAE Train Loss: 47.5742301940918 | MAE Test Loss: 45.067298889160156 \n",
      "Epoch: 34260 | MAE Train Loss: 47.57254409790039 | MAE Test Loss: 45.06587219238281 \n",
      "Epoch: 34270 | MAE Train Loss: 47.57085037231445 | MAE Test Loss: 45.06447219848633 \n",
      "Epoch: 34280 | MAE Train Loss: 47.56916046142578 | MAE Test Loss: 45.06307601928711 \n",
      "Epoch: 34290 | MAE Train Loss: 47.567474365234375 | MAE Test Loss: 45.061668395996094 \n",
      "Epoch: 34300 | MAE Train Loss: 47.56578063964844 | MAE Test Loss: 45.06025314331055 \n",
      "Epoch: 34310 | MAE Train Loss: 47.56409454345703 | MAE Test Loss: 45.058841705322266 \n",
      "Epoch: 34320 | MAE Train Loss: 47.56240463256836 | MAE Test Loss: 45.05744552612305 \n",
      "Epoch: 34330 | MAE Train Loss: 47.56071472167969 | MAE Test Loss: 45.05603790283203 \n",
      "Epoch: 34340 | MAE Train Loss: 47.559024810791016 | MAE Test Loss: 45.05463409423828 \n",
      "Epoch: 34350 | MAE Train Loss: 47.55733871459961 | MAE Test Loss: 45.05320739746094 \n",
      "Epoch: 34360 | MAE Train Loss: 47.55564880371094 | MAE Test Loss: 45.05180358886719 \n",
      "Epoch: 34370 | MAE Train Loss: 47.553958892822266 | MAE Test Loss: 45.05039596557617 \n",
      "Epoch: 34380 | MAE Train Loss: 47.552268981933594 | MAE Test Loss: 45.04899215698242 \n",
      "Epoch: 34390 | MAE Train Loss: 47.55058288574219 | MAE Test Loss: 45.047584533691406 \n",
      "Epoch: 34400 | MAE Train Loss: 47.54888916015625 | MAE Test Loss: 45.04618453979492 \n",
      "Epoch: 34410 | MAE Train Loss: 47.5472412109375 | MAE Test Loss: 45.044898986816406 \n",
      "Epoch: 34420 | MAE Train Loss: 47.545631408691406 | MAE Test Loss: 45.04371643066406 \n",
      "Epoch: 34430 | MAE Train Loss: 47.544010162353516 | MAE Test Loss: 45.042537689208984 \n",
      "Epoch: 34440 | MAE Train Loss: 47.54240036010742 | MAE Test Loss: 45.041358947753906 \n",
      "Epoch: 34450 | MAE Train Loss: 47.5407829284668 | MAE Test Loss: 45.04014205932617 \n",
      "Epoch: 34460 | MAE Train Loss: 47.53916931152344 | MAE Test Loss: 45.03895950317383 \n",
      "Epoch: 34470 | MAE Train Loss: 47.53755187988281 | MAE Test Loss: 45.03778076171875 \n",
      "Epoch: 34480 | MAE Train Loss: 47.53593826293945 | MAE Test Loss: 45.03660202026367 \n",
      "Epoch: 34490 | MAE Train Loss: 47.53432083129883 | MAE Test Loss: 45.035423278808594 \n",
      "Epoch: 34500 | MAE Train Loss: 47.532711029052734 | MAE Test Loss: 45.03423309326172 \n",
      "Epoch: 34510 | MAE Train Loss: 47.531089782714844 | MAE Test Loss: 45.03306198120117 \n",
      "Epoch: 34520 | MAE Train Loss: 47.52947998046875 | MAE Test Loss: 45.03184127807617 \n",
      "Epoch: 34530 | MAE Train Loss: 47.527862548828125 | MAE Test Loss: 45.03066635131836 \n",
      "Epoch: 34540 | MAE Train Loss: 47.52625274658203 | MAE Test Loss: 45.029483795166016 \n",
      "Epoch: 34550 | MAE Train Loss: 47.52463150024414 | MAE Test Loss: 45.02830505371094 \n",
      "Epoch: 34560 | MAE Train Loss: 47.52302169799805 | MAE Test Loss: 45.02712631225586 \n",
      "Epoch: 34570 | MAE Train Loss: 47.52140808105469 | MAE Test Loss: 45.02594757080078 \n",
      "Epoch: 34580 | MAE Train Loss: 47.51979064941406 | MAE Test Loss: 45.0247688293457 \n",
      "Epoch: 34590 | MAE Train Loss: 47.51816940307617 | MAE Test Loss: 45.0235481262207 \n",
      "Epoch: 34600 | MAE Train Loss: 47.51655960083008 | MAE Test Loss: 45.022369384765625 \n",
      "Epoch: 34610 | MAE Train Loss: 47.51494598388672 | MAE Test Loss: 45.02118682861328 \n",
      "Epoch: 34620 | MAE Train Loss: 47.513336181640625 | MAE Test Loss: 45.0200080871582 \n",
      "Epoch: 34630 | MAE Train Loss: 47.51171875 | MAE Test Loss: 45.018829345703125 \n",
      "Epoch: 34640 | MAE Train Loss: 47.510101318359375 | MAE Test Loss: 45.01765060424805 \n",
      "Epoch: 34650 | MAE Train Loss: 47.50848388671875 | MAE Test Loss: 45.0164680480957 \n",
      "Epoch: 34660 | MAE Train Loss: 47.506866455078125 | MAE Test Loss: 45.01525115966797 \n",
      "Epoch: 34670 | MAE Train Loss: 47.50525665283203 | MAE Test Loss: 45.014076232910156 \n",
      "Epoch: 34680 | MAE Train Loss: 47.503639221191406 | MAE Test Loss: 45.01289367675781 \n",
      "Epoch: 34690 | MAE Train Loss: 47.50202941894531 | MAE Test Loss: 45.011714935302734 \n",
      "Epoch: 34700 | MAE Train Loss: 47.50041580200195 | MAE Test Loss: 45.01053237915039 \n",
      "Epoch: 34710 | MAE Train Loss: 47.49879455566406 | MAE Test Loss: 45.00935363769531 \n",
      "Epoch: 34720 | MAE Train Loss: 47.49718475341797 | MAE Test Loss: 45.008174896240234 \n",
      "Epoch: 34730 | MAE Train Loss: 47.495567321777344 | MAE Test Loss: 45.0069580078125 \n",
      "Epoch: 34740 | MAE Train Loss: 47.49395751953125 | MAE Test Loss: 45.005775451660156 \n",
      "Epoch: 34750 | MAE Train Loss: 47.49234390258789 | MAE Test Loss: 45.00459671020508 \n",
      "Epoch: 34760 | MAE Train Loss: 47.490726470947266 | MAE Test Loss: 45.003421783447266 \n",
      "Epoch: 34770 | MAE Train Loss: 47.489112854003906 | MAE Test Loss: 45.00223922729492 \n",
      "Epoch: 34780 | MAE Train Loss: 47.48749542236328 | MAE Test Loss: 45.001060485839844 \n",
      "Epoch: 34790 | MAE Train Loss: 47.48587417602539 | MAE Test Loss: 44.999881744384766 \n",
      "Epoch: 34800 | MAE Train Loss: 47.4842643737793 | MAE Test Loss: 44.998661041259766 \n",
      "Epoch: 34810 | MAE Train Loss: 47.48264694213867 | MAE Test Loss: 44.99748229980469 \n",
      "Epoch: 34820 | MAE Train Loss: 47.48103713989258 | MAE Test Loss: 44.99630355834961 \n",
      "Epoch: 34830 | MAE Train Loss: 47.47942352294922 | MAE Test Loss: 44.995121002197266 \n",
      "Epoch: 34840 | MAE Train Loss: 47.47785186767578 | MAE Test Loss: 44.993865966796875 \n",
      "Epoch: 34850 | MAE Train Loss: 47.47629165649414 | MAE Test Loss: 44.992584228515625 \n",
      "Epoch: 34860 | MAE Train Loss: 47.47472381591797 | MAE Test Loss: 44.991302490234375 \n",
      "Epoch: 34870 | MAE Train Loss: 47.47317123413086 | MAE Test Loss: 44.990047454833984 \n",
      "Epoch: 34880 | MAE Train Loss: 47.47160339355469 | MAE Test Loss: 44.98878479003906 \n",
      "Epoch: 34890 | MAE Train Loss: 47.47004318237305 | MAE Test Loss: 44.98749923706055 \n",
      "Epoch: 34900 | MAE Train Loss: 47.468482971191406 | MAE Test Loss: 44.9862174987793 \n",
      "Epoch: 34910 | MAE Train Loss: 47.466922760009766 | MAE Test Loss: 44.984947204589844 \n",
      "Epoch: 34920 | MAE Train Loss: 47.465362548828125 | MAE Test Loss: 44.98369598388672 \n",
      "Epoch: 34930 | MAE Train Loss: 47.463802337646484 | MAE Test Loss: 44.9824333190918 \n",
      "Epoch: 34940 | MAE Train Loss: 47.462242126464844 | MAE Test Loss: 44.98114776611328 \n",
      "Epoch: 34950 | MAE Train Loss: 47.4606819152832 | MAE Test Loss: 44.9798698425293 \n",
      "Epoch: 34960 | MAE Train Loss: 47.45912170410156 | MAE Test Loss: 44.978614807128906 \n",
      "Epoch: 34970 | MAE Train Loss: 47.45756149291992 | MAE Test Loss: 44.977333068847656 \n",
      "Epoch: 34980 | MAE Train Loss: 47.45600128173828 | MAE Test Loss: 44.9760856628418 \n",
      "Epoch: 34990 | MAE Train Loss: 47.45444107055664 | MAE Test Loss: 44.97480010986328 \n",
      "Epoch: 35000 | MAE Train Loss: 47.452880859375 | MAE Test Loss: 44.97351837158203 \n",
      "Epoch: 35010 | MAE Train Loss: 47.45132064819336 | MAE Test Loss: 44.972259521484375 \n",
      "Epoch: 35020 | MAE Train Loss: 47.44975662231445 | MAE Test Loss: 44.97098159790039 \n",
      "Epoch: 35030 | MAE Train Loss: 47.44819641113281 | MAE Test Loss: 44.969730377197266 \n",
      "Epoch: 35040 | MAE Train Loss: 47.44663619995117 | MAE Test Loss: 44.968448638916016 \n",
      "Epoch: 35050 | MAE Train Loss: 47.44507598876953 | MAE Test Loss: 44.9671630859375 \n",
      "Epoch: 35060 | MAE Train Loss: 47.443519592285156 | MAE Test Loss: 44.96591567993164 \n",
      "Epoch: 35070 | MAE Train Loss: 47.44195556640625 | MAE Test Loss: 44.964630126953125 \n",
      "Epoch: 35080 | MAE Train Loss: 47.44039535522461 | MAE Test Loss: 44.963375091552734 \n",
      "Epoch: 35090 | MAE Train Loss: 47.43883514404297 | MAE Test Loss: 44.962100982666016 \n",
      "Epoch: 35100 | MAE Train Loss: 47.43727493286133 | MAE Test Loss: 44.96083068847656 \n",
      "Epoch: 35110 | MAE Train Loss: 47.435707092285156 | MAE Test Loss: 44.95954513549805 \n",
      "Epoch: 35120 | MAE Train Loss: 47.43415069580078 | MAE Test Loss: 44.95829772949219 \n",
      "Epoch: 35130 | MAE Train Loss: 47.432586669921875 | MAE Test Loss: 44.957027435302734 \n",
      "Epoch: 35140 | MAE Train Loss: 47.4310302734375 | MAE Test Loss: 44.955745697021484 \n",
      "Epoch: 35150 | MAE Train Loss: 47.429466247558594 | MAE Test Loss: 44.95449447631836 \n",
      "Epoch: 35160 | MAE Train Loss: 47.42790985107422 | MAE Test Loss: 44.95321273803711 \n",
      "Epoch: 35170 | MAE Train Loss: 47.42634582519531 | MAE Test Loss: 44.951927185058594 \n",
      "Epoch: 35180 | MAE Train Loss: 47.42478561401367 | MAE Test Loss: 44.950679779052734 \n",
      "Epoch: 35190 | MAE Train Loss: 47.42322540283203 | MAE Test Loss: 44.94939041137695 \n",
      "Epoch: 35200 | MAE Train Loss: 47.42165756225586 | MAE Test Loss: 44.94813919067383 \n",
      "Epoch: 35210 | MAE Train Loss: 47.420108795166016 | MAE Test Loss: 44.946861267089844 \n",
      "Epoch: 35220 | MAE Train Loss: 47.41854476928711 | MAE Test Loss: 44.945579528808594 \n",
      "Epoch: 35230 | MAE Train Loss: 47.41698455810547 | MAE Test Loss: 44.9443244934082 \n",
      "Epoch: 35240 | MAE Train Loss: 47.41542434692383 | MAE Test Loss: 44.94304656982422 \n",
      "Epoch: 35250 | MAE Train Loss: 47.41386413574219 | MAE Test Loss: 44.94179153442383 \n",
      "Epoch: 35260 | MAE Train Loss: 47.412296295166016 | MAE Test Loss: 44.94050979614258 \n",
      "Epoch: 35270 | MAE Train Loss: 47.410736083984375 | MAE Test Loss: 44.93922424316406 \n",
      "Epoch: 35280 | MAE Train Loss: 47.409183502197266 | MAE Test Loss: 44.9379768371582 \n",
      "Epoch: 35290 | MAE Train Loss: 47.407615661621094 | MAE Test Loss: 44.93669509887695 \n",
      "Epoch: 35300 | MAE Train Loss: 47.406063079833984 | MAE Test Loss: 44.9354248046875 \n",
      "Epoch: 35310 | MAE Train Loss: 47.404502868652344 | MAE Test Loss: 44.934139251708984 \n",
      "Epoch: 35320 | MAE Train Loss: 47.40293502807617 | MAE Test Loss: 44.93289566040039 \n",
      "Epoch: 35330 | MAE Train Loss: 47.40137481689453 | MAE Test Loss: 44.93162536621094 \n",
      "Epoch: 35340 | MAE Train Loss: 47.39981460571289 | MAE Test Loss: 44.93034362792969 \n",
      "Epoch: 35350 | MAE Train Loss: 47.39825439453125 | MAE Test Loss: 44.9290771484375 \n",
      "Epoch: 35360 | MAE Train Loss: 47.39669418334961 | MAE Test Loss: 44.927791595458984 \n",
      "Epoch: 35370 | MAE Train Loss: 47.39513397216797 | MAE Test Loss: 44.92654037475586 \n",
      "Epoch: 35380 | MAE Train Loss: 47.39357376098633 | MAE Test Loss: 44.925254821777344 \n",
      "Epoch: 35390 | MAE Train Loss: 47.39201354980469 | MAE Test Loss: 44.924007415771484 \n",
      "Epoch: 35400 | MAE Train Loss: 47.39045333862305 | MAE Test Loss: 44.92272186279297 \n",
      "Epoch: 35410 | MAE Train Loss: 47.38888931274414 | MAE Test Loss: 44.92144012451172 \n",
      "Epoch: 35420 | MAE Train Loss: 47.387332916259766 | MAE Test Loss: 44.920188903808594 \n",
      "Epoch: 35430 | MAE Train Loss: 47.38576889038086 | MAE Test Loss: 44.918907165527344 \n",
      "Epoch: 35440 | MAE Train Loss: 47.384212493896484 | MAE Test Loss: 44.917659759521484 \n",
      "Epoch: 35450 | MAE Train Loss: 47.38264465332031 | MAE Test Loss: 44.9163703918457 \n",
      "Epoch: 35460 | MAE Train Loss: 47.38108444213867 | MAE Test Loss: 44.91509246826172 \n",
      "Epoch: 35470 | MAE Train Loss: 47.37953186035156 | MAE Test Loss: 44.91383743286133 \n",
      "Epoch: 35480 | MAE Train Loss: 47.37796401977539 | MAE Test Loss: 44.91255569458008 \n",
      "Epoch: 35490 | MAE Train Loss: 47.37640380859375 | MAE Test Loss: 44.91130447387695 \n",
      "Epoch: 35500 | MAE Train Loss: 47.37484359741211 | MAE Test Loss: 44.91001892089844 \n",
      "Epoch: 35510 | MAE Train Loss: 47.37328338623047 | MAE Test Loss: 44.90874099731445 \n",
      "Epoch: 35520 | MAE Train Loss: 47.37172317504883 | MAE Test Loss: 44.907474517822266 \n",
      "Epoch: 35530 | MAE Train Loss: 47.37016296386719 | MAE Test Loss: 44.90622329711914 \n",
      "Epoch: 35540 | MAE Train Loss: 47.36860275268555 | MAE Test Loss: 44.904937744140625 \n",
      "Epoch: 35550 | MAE Train Loss: 47.367042541503906 | MAE Test Loss: 44.90367126464844 \n",
      "Epoch: 35560 | MAE Train Loss: 47.365482330322266 | MAE Test Loss: 44.90238952636719 \n",
      "Epoch: 35570 | MAE Train Loss: 47.363922119140625 | MAE Test Loss: 44.90113830566406 \n",
      "Epoch: 35580 | MAE Train Loss: 47.36235809326172 | MAE Test Loss: 44.89985656738281 \n",
      "Epoch: 35590 | MAE Train Loss: 47.36081314086914 | MAE Test Loss: 44.89864730834961 \n",
      "Epoch: 35600 | MAE Train Loss: 47.35932540893555 | MAE Test Loss: 44.89753723144531 \n",
      "Epoch: 35610 | MAE Train Loss: 47.357826232910156 | MAE Test Loss: 44.896427154541016 \n",
      "Epoch: 35620 | MAE Train Loss: 47.35633850097656 | MAE Test Loss: 44.89533233642578 \n",
      "Epoch: 35630 | MAE Train Loss: 47.35484313964844 | MAE Test Loss: 44.89421844482422 \n",
      "Epoch: 35640 | MAE Train Loss: 47.35334777832031 | MAE Test Loss: 44.89314651489258 \n",
      "Epoch: 35650 | MAE Train Loss: 47.35185623168945 | MAE Test Loss: 44.89203643798828 \n",
      "Epoch: 35660 | MAE Train Loss: 47.35036087036133 | MAE Test Loss: 44.89092254638672 \n",
      "Epoch: 35670 | MAE Train Loss: 47.348907470703125 | MAE Test Loss: 44.88975524902344 \n",
      "Epoch: 35680 | MAE Train Loss: 47.3475341796875 | MAE Test Loss: 44.88856506347656 \n",
      "Epoch: 35690 | MAE Train Loss: 47.346160888671875 | MAE Test Loss: 44.88735580444336 \n",
      "Epoch: 35700 | MAE Train Loss: 47.344783782958984 | MAE Test Loss: 44.88614273071289 \n",
      "Epoch: 35710 | MAE Train Loss: 47.343406677246094 | MAE Test Loss: 44.88493347167969 \n",
      "Epoch: 35720 | MAE Train Loss: 47.34203338623047 | MAE Test Loss: 44.88372039794922 \n",
      "Epoch: 35730 | MAE Train Loss: 47.34065628051758 | MAE Test Loss: 44.882530212402344 \n",
      "Epoch: 35740 | MAE Train Loss: 47.33927917480469 | MAE Test Loss: 44.881317138671875 \n",
      "Epoch: 35750 | MAE Train Loss: 47.33790588378906 | MAE Test Loss: 44.88010787963867 \n",
      "Epoch: 35760 | MAE Train Loss: 47.3365364074707 | MAE Test Loss: 44.878910064697266 \n",
      "Epoch: 35770 | MAE Train Loss: 47.33515548706055 | MAE Test Loss: 44.8776969909668 \n",
      "Epoch: 35780 | MAE Train Loss: 47.333778381347656 | MAE Test Loss: 44.87648391723633 \n",
      "Epoch: 35790 | MAE Train Loss: 47.3324089050293 | MAE Test Loss: 44.875335693359375 \n",
      "Epoch: 35800 | MAE Train Loss: 47.331050872802734 | MAE Test Loss: 44.87418746948242 \n",
      "Epoch: 35810 | MAE Train Loss: 47.32969665527344 | MAE Test Loss: 44.873069763183594 \n",
      "Epoch: 35820 | MAE Train Loss: 47.32834243774414 | MAE Test Loss: 44.87195587158203 \n",
      "Epoch: 35830 | MAE Train Loss: 47.32698440551758 | MAE Test Loss: 44.87081527709961 \n",
      "Epoch: 35840 | MAE Train Loss: 47.32563018798828 | MAE Test Loss: 44.869693756103516 \n",
      "Epoch: 35850 | MAE Train Loss: 47.32426834106445 | MAE Test Loss: 44.86857986450195 \n",
      "Epoch: 35860 | MAE Train Loss: 47.322914123535156 | MAE Test Loss: 44.867435455322266 \n",
      "Epoch: 35870 | MAE Train Loss: 47.321563720703125 | MAE Test Loss: 44.86631393432617 \n",
      "Epoch: 35880 | MAE Train Loss: 47.32019805908203 | MAE Test Loss: 44.865169525146484 \n",
      "Epoch: 35890 | MAE Train Loss: 47.31884002685547 | MAE Test Loss: 44.86405563354492 \n",
      "Epoch: 35900 | MAE Train Loss: 47.31748962402344 | MAE Test Loss: 44.862937927246094 \n",
      "Epoch: 35910 | MAE Train Loss: 47.31612777709961 | MAE Test Loss: 44.861793518066406 \n",
      "Epoch: 35920 | MAE Train Loss: 47.31477355957031 | MAE Test Loss: 44.860679626464844 \n",
      "Epoch: 35930 | MAE Train Loss: 47.313419342041016 | MAE Test Loss: 44.859561920166016 \n",
      "Epoch: 35940 | MAE Train Loss: 47.31205749511719 | MAE Test Loss: 44.85841369628906 \n",
      "Epoch: 35950 | MAE Train Loss: 47.31070327758789 | MAE Test Loss: 44.8572998046875 \n",
      "Epoch: 35960 | MAE Train Loss: 47.30934143066406 | MAE Test Loss: 44.85618591308594 \n",
      "Epoch: 35970 | MAE Train Loss: 47.30799102783203 | MAE Test Loss: 44.85505294799805 \n",
      "Epoch: 35980 | MAE Train Loss: 47.3066291809082 | MAE Test Loss: 44.85390853881836 \n",
      "Epoch: 35990 | MAE Train Loss: 47.30527877807617 | MAE Test Loss: 44.85279083251953 \n",
      "Epoch: 36000 | MAE Train Loss: 47.303916931152344 | MAE Test Loss: 44.85167694091797 \n",
      "Epoch: 36010 | MAE Train Loss: 47.30256271362305 | MAE Test Loss: 44.850528717041016 \n",
      "Epoch: 36020 | MAE Train Loss: 47.30120849609375 | MAE Test Loss: 44.84941101074219 \n",
      "Epoch: 36030 | MAE Train Loss: 47.29984664916992 | MAE Test Loss: 44.848297119140625 \n",
      "Epoch: 36040 | MAE Train Loss: 47.298492431640625 | MAE Test Loss: 44.84715270996094 \n",
      "Epoch: 36050 | MAE Train Loss: 47.29713439941406 | MAE Test Loss: 44.846038818359375 \n",
      "Epoch: 36060 | MAE Train Loss: 47.295772552490234 | MAE Test Loss: 44.844886779785156 \n",
      "Epoch: 36070 | MAE Train Loss: 47.29441833496094 | MAE Test Loss: 44.843772888183594 \n",
      "Epoch: 36080 | MAE Train Loss: 47.293067932128906 | MAE Test Loss: 44.8426628112793 \n",
      "Epoch: 36090 | MAE Train Loss: 47.29170608520508 | MAE Test Loss: 44.84152603149414 \n",
      "Epoch: 36100 | MAE Train Loss: 47.29034423828125 | MAE Test Loss: 44.84041213989258 \n",
      "Epoch: 36110 | MAE Train Loss: 47.28899002075195 | MAE Test Loss: 44.839263916015625 \n",
      "Epoch: 36120 | MAE Train Loss: 47.287635803222656 | MAE Test Loss: 44.83815383911133 \n",
      "Epoch: 36130 | MAE Train Loss: 47.286277770996094 | MAE Test Loss: 44.837005615234375 \n",
      "Epoch: 36140 | MAE Train Loss: 47.2849235534668 | MAE Test Loss: 44.8359260559082 \n",
      "Epoch: 36150 | MAE Train Loss: 47.2835693359375 | MAE Test Loss: 44.834999084472656 \n",
      "Epoch: 36160 | MAE Train Loss: 47.28221130371094 | MAE Test Loss: 44.83409881591797 \n",
      "Epoch: 36170 | MAE Train Loss: 47.28085708618164 | MAE Test Loss: 44.833168029785156 \n",
      "Epoch: 36180 | MAE Train Loss: 47.279502868652344 | MAE Test Loss: 44.83224105834961 \n",
      "Epoch: 36190 | MAE Train Loss: 47.278141021728516 | MAE Test Loss: 44.83134078979492 \n",
      "Epoch: 36200 | MAE Train Loss: 47.27678680419922 | MAE Test Loss: 44.83042907714844 \n",
      "Epoch: 36210 | MAE Train Loss: 47.27542495727539 | MAE Test Loss: 44.829498291015625 \n",
      "Epoch: 36220 | MAE Train Loss: 47.27407455444336 | MAE Test Loss: 44.82856750488281 \n",
      "Epoch: 36230 | MAE Train Loss: 47.272708892822266 | MAE Test Loss: 44.82767105102539 \n",
      "Epoch: 36240 | MAE Train Loss: 47.271358489990234 | MAE Test Loss: 44.82674026489258 \n",
      "Epoch: 36250 | MAE Train Loss: 47.27000045776367 | MAE Test Loss: 44.825809478759766 \n",
      "Epoch: 36260 | MAE Train Loss: 47.268638610839844 | MAE Test Loss: 44.82491683959961 \n",
      "Epoch: 36270 | MAE Train Loss: 47.26728439331055 | MAE Test Loss: 44.82398223876953 \n",
      "Epoch: 36280 | MAE Train Loss: 47.26593017578125 | MAE Test Loss: 44.82305145263672 \n",
      "Epoch: 36290 | MAE Train Loss: 47.26457214355469 | MAE Test Loss: 44.8221549987793 \n",
      "Epoch: 36300 | MAE Train Loss: 47.26321792602539 | MAE Test Loss: 44.82123947143555 \n",
      "Epoch: 36310 | MAE Train Loss: 47.261863708496094 | MAE Test Loss: 44.820308685302734 \n",
      "Epoch: 36320 | MAE Train Loss: 47.260501861572266 | MAE Test Loss: 44.81937789916992 \n",
      "Epoch: 36330 | MAE Train Loss: 47.259151458740234 | MAE Test Loss: 44.818485260009766 \n",
      "Epoch: 36340 | MAE Train Loss: 47.257789611816406 | MAE Test Loss: 44.81754684448242 \n",
      "Epoch: 36350 | MAE Train Loss: 47.25642776489258 | MAE Test Loss: 44.81662368774414 \n",
      "Epoch: 36360 | MAE Train Loss: 47.25507354736328 | MAE Test Loss: 44.81572723388672 \n",
      "Epoch: 36370 | MAE Train Loss: 47.253719329833984 | MAE Test Loss: 44.81479263305664 \n",
      "Epoch: 36380 | MAE Train Loss: 47.252357482910156 | MAE Test Loss: 44.813899993896484 \n",
      "Epoch: 36390 | MAE Train Loss: 47.25100326538086 | MAE Test Loss: 44.812965393066406 \n",
      "Epoch: 36400 | MAE Train Loss: 47.24965286254883 | MAE Test Loss: 44.812034606933594 \n",
      "Epoch: 36410 | MAE Train Loss: 47.248291015625 | MAE Test Loss: 44.81114196777344 \n",
      "Epoch: 36420 | MAE Train Loss: 47.24693298339844 | MAE Test Loss: 44.81019592285156 \n",
      "Epoch: 36430 | MAE Train Loss: 47.245574951171875 | MAE Test Loss: 44.80929183959961 \n",
      "Epoch: 36440 | MAE Train Loss: 47.244224548339844 | MAE Test Loss: 44.80836486816406 \n",
      "Epoch: 36450 | MAE Train Loss: 47.242862701416016 | MAE Test Loss: 44.807464599609375 \n",
      "Epoch: 36460 | MAE Train Loss: 47.24150848388672 | MAE Test Loss: 44.80653762817383 \n",
      "Epoch: 36470 | MAE Train Loss: 47.240150451660156 | MAE Test Loss: 44.80561065673828 \n",
      "Epoch: 36480 | MAE Train Loss: 47.23878860473633 | MAE Test Loss: 44.80471420288086 \n",
      "Epoch: 36490 | MAE Train Loss: 47.23743438720703 | MAE Test Loss: 44.80377960205078 \n",
      "Epoch: 36500 | MAE Train Loss: 47.236080169677734 | MAE Test Loss: 44.80284881591797 \n",
      "Epoch: 36510 | MAE Train Loss: 47.23472213745117 | MAE Test Loss: 44.80194854736328 \n",
      "Epoch: 36520 | MAE Train Loss: 47.233367919921875 | MAE Test Loss: 44.801021575927734 \n",
      "Epoch: 36530 | MAE Train Loss: 47.23200607299805 | MAE Test Loss: 44.800113677978516 \n",
      "Epoch: 36540 | MAE Train Loss: 47.23065185546875 | MAE Test Loss: 44.79917526245117 \n",
      "Epoch: 36550 | MAE Train Loss: 47.22929763793945 | MAE Test Loss: 44.798282623291016 \n",
      "Epoch: 36560 | MAE Train Loss: 47.22793960571289 | MAE Test Loss: 44.79734802246094 \n",
      "Epoch: 36570 | MAE Train Loss: 47.226585388183594 | MAE Test Loss: 44.796417236328125 \n",
      "Epoch: 36580 | MAE Train Loss: 47.225223541259766 | MAE Test Loss: 44.7955207824707 \n",
      "Epoch: 36590 | MAE Train Loss: 47.223873138427734 | MAE Test Loss: 44.79458999633789 \n",
      "Epoch: 36600 | MAE Train Loss: 47.222511291503906 | MAE Test Loss: 44.79365921020508 \n",
      "Epoch: 36610 | MAE Train Loss: 47.22115707397461 | MAE Test Loss: 44.79276657104492 \n",
      "Epoch: 36620 | MAE Train Loss: 47.21980285644531 | MAE Test Loss: 44.79183578491211 \n",
      "Epoch: 36630 | MAE Train Loss: 47.218441009521484 | MAE Test Loss: 44.79092025756836 \n",
      "Epoch: 36640 | MAE Train Loss: 47.21708297729492 | MAE Test Loss: 44.78998947143555 \n",
      "Epoch: 36650 | MAE Train Loss: 47.215728759765625 | MAE Test Loss: 44.78908920288086 \n",
      "Epoch: 36660 | MAE Train Loss: 47.21437454223633 | MAE Test Loss: 44.78816223144531 \n",
      "Epoch: 36670 | MAE Train Loss: 47.213077545166016 | MAE Test Loss: 44.78715896606445 \n",
      "Epoch: 36680 | MAE Train Loss: 47.21178436279297 | MAE Test Loss: 44.786155700683594 \n",
      "Epoch: 36690 | MAE Train Loss: 47.21048355102539 | MAE Test Loss: 44.78515625 \n",
      "Epoch: 36700 | MAE Train Loss: 47.209190368652344 | MAE Test Loss: 44.784122467041016 \n",
      "Epoch: 36710 | MAE Train Loss: 47.20790100097656 | MAE Test Loss: 44.783119201660156 \n",
      "Epoch: 36720 | MAE Train Loss: 47.20660400390625 | MAE Test Loss: 44.78211975097656 \n",
      "Epoch: 36730 | MAE Train Loss: 47.2053108215332 | MAE Test Loss: 44.7811164855957 \n",
      "Epoch: 36740 | MAE Train Loss: 47.204010009765625 | MAE Test Loss: 44.78011703491211 \n",
      "Epoch: 36750 | MAE Train Loss: 47.202720642089844 | MAE Test Loss: 44.77910614013672 \n",
      "Epoch: 36760 | MAE Train Loss: 47.2014274597168 | MAE Test Loss: 44.778079986572266 \n",
      "Epoch: 36770 | MAE Train Loss: 47.200130462646484 | MAE Test Loss: 44.777076721191406 \n",
      "Epoch: 36780 | MAE Train Loss: 47.19883728027344 | MAE Test Loss: 44.77606964111328 \n",
      "Epoch: 36790 | MAE Train Loss: 47.19754409790039 | MAE Test Loss: 44.77507019042969 \n",
      "Epoch: 36800 | MAE Train Loss: 47.19625473022461 | MAE Test Loss: 44.77406692504883 \n",
      "Epoch: 36810 | MAE Train Loss: 47.1949577331543 | MAE Test Loss: 44.773033142089844 \n",
      "Epoch: 36820 | MAE Train Loss: 47.19365692138672 | MAE Test Loss: 44.772037506103516 \n",
      "Epoch: 36830 | MAE Train Loss: 47.19236373901367 | MAE Test Loss: 44.77103042602539 \n",
      "Epoch: 36840 | MAE Train Loss: 47.19107437133789 | MAE Test Loss: 44.77002716064453 \n",
      "Epoch: 36850 | MAE Train Loss: 47.189781188964844 | MAE Test Loss: 44.76902770996094 \n",
      "Epoch: 36860 | MAE Train Loss: 47.18848419189453 | MAE Test Loss: 44.76802062988281 \n",
      "Epoch: 36870 | MAE Train Loss: 47.18718338012695 | MAE Test Loss: 44.766990661621094 \n",
      "Epoch: 36880 | MAE Train Loss: 47.18589401245117 | MAE Test Loss: 44.765987396240234 \n",
      "Epoch: 36890 | MAE Train Loss: 47.184600830078125 | MAE Test Loss: 44.764984130859375 \n",
      "Epoch: 36900 | MAE Train Loss: 47.183311462402344 | MAE Test Loss: 44.763980865478516 \n",
      "Epoch: 36910 | MAE Train Loss: 47.182010650634766 | MAE Test Loss: 44.76298522949219 \n",
      "Epoch: 36920 | MAE Train Loss: 47.18071746826172 | MAE Test Loss: 44.76197814941406 \n",
      "Epoch: 36930 | MAE Train Loss: 47.179420471191406 | MAE Test Loss: 44.76094055175781 \n",
      "Epoch: 36940 | MAE Train Loss: 47.178131103515625 | MAE Test Loss: 44.759944915771484 \n",
      "Epoch: 36950 | MAE Train Loss: 47.17683792114258 | MAE Test Loss: 44.758941650390625 \n",
      "Epoch: 36960 | MAE Train Loss: 47.175537109375 | MAE Test Loss: 44.7579231262207 \n",
      "Epoch: 36970 | MAE Train Loss: 47.17424392700195 | MAE Test Loss: 44.756919860839844 \n",
      "Epoch: 36980 | MAE Train Loss: 47.17295455932617 | MAE Test Loss: 44.75592041015625 \n",
      "Epoch: 36990 | MAE Train Loss: 47.17165756225586 | MAE Test Loss: 44.75491714477539 \n",
      "Epoch: 37000 | MAE Train Loss: 47.17036437988281 | MAE Test Loss: 44.75391387939453 \n",
      "Epoch: 37010 | MAE Train Loss: 47.169071197509766 | MAE Test Loss: 44.752906799316406 \n",
      "Epoch: 37020 | MAE Train Loss: 47.16777038574219 | MAE Test Loss: 44.75188064575195 \n",
      "Epoch: 37030 | MAE Train Loss: 47.166481018066406 | MAE Test Loss: 44.750877380371094 \n",
      "Epoch: 37040 | MAE Train Loss: 47.165184020996094 | MAE Test Loss: 44.74989318847656 \n",
      "Epoch: 37050 | MAE Train Loss: 47.16389083862305 | MAE Test Loss: 44.74885940551758 \n",
      "Epoch: 37060 | MAE Train Loss: 47.162601470947266 | MAE Test Loss: 44.74785614013672 \n",
      "Epoch: 37070 | MAE Train Loss: 47.16130828857422 | MAE Test Loss: 44.746849060058594 \n",
      "Epoch: 37080 | MAE Train Loss: 47.160011291503906 | MAE Test Loss: 44.745845794677734 \n",
      "Epoch: 37090 | MAE Train Loss: 47.15871810913086 | MAE Test Loss: 44.74483871459961 \n",
      "Epoch: 37100 | MAE Train Loss: 47.15741729736328 | MAE Test Loss: 44.74384307861328 \n",
      "Epoch: 37110 | MAE Train Loss: 47.1561279296875 | MAE Test Loss: 44.742828369140625 \n",
      "Epoch: 37120 | MAE Train Loss: 47.15483856201172 | MAE Test Loss: 44.741825103759766 \n",
      "Epoch: 37130 | MAE Train Loss: 47.15353775024414 | MAE Test Loss: 44.740821838378906 \n",
      "Epoch: 37140 | MAE Train Loss: 47.152244567871094 | MAE Test Loss: 44.73979187011719 \n",
      "Epoch: 37150 | MAE Train Loss: 47.15095520019531 | MAE Test Loss: 44.73878860473633 \n",
      "Epoch: 37160 | MAE Train Loss: 47.149654388427734 | MAE Test Loss: 44.7377815246582 \n",
      "Epoch: 37170 | MAE Train Loss: 47.14836502075195 | MAE Test Loss: 44.736778259277344 \n",
      "Epoch: 37180 | MAE Train Loss: 47.147071838378906 | MAE Test Loss: 44.73577880859375 \n",
      "Epoch: 37190 | MAE Train Loss: 47.14577102661133 | MAE Test Loss: 44.73474884033203 \n",
      "Epoch: 37200 | MAE Train Loss: 47.144474029541016 | MAE Test Loss: 44.73374557495117 \n",
      "Epoch: 37210 | MAE Train Loss: 47.1431884765625 | MAE Test Loss: 44.73274230957031 \n",
      "Epoch: 37220 | MAE Train Loss: 47.14189910888672 | MAE Test Loss: 44.73173904418945 \n",
      "Epoch: 37230 | MAE Train Loss: 47.14059829711914 | MAE Test Loss: 44.730735778808594 \n",
      "Epoch: 37240 | MAE Train Loss: 47.13930130004883 | MAE Test Loss: 44.729736328125 \n",
      "Epoch: 37250 | MAE Train Loss: 47.13800811767578 | MAE Test Loss: 44.728702545166016 \n",
      "Epoch: 37260 | MAE Train Loss: 47.13671875 | MAE Test Loss: 44.727699279785156 \n",
      "Epoch: 37270 | MAE Train Loss: 47.13542556762695 | MAE Test Loss: 44.72670364379883 \n",
      "Epoch: 37280 | MAE Train Loss: 47.13412857055664 | MAE Test Loss: 44.72569274902344 \n",
      "Epoch: 37290 | MAE Train Loss: 47.13282775878906 | MAE Test Loss: 44.72467803955078 \n",
      "Epoch: 37300 | MAE Train Loss: 47.13153839111328 | MAE Test Loss: 44.72367477416992 \n",
      "Epoch: 37310 | MAE Train Loss: 47.130245208740234 | MAE Test Loss: 44.72267150878906 \n",
      "Epoch: 37320 | MAE Train Loss: 47.12895202636719 | MAE Test Loss: 44.7216682434082 \n",
      "Epoch: 37330 | MAE Train Loss: 47.127655029296875 | MAE Test Loss: 44.72066879272461 \n",
      "Epoch: 37340 | MAE Train Loss: 47.12636184692383 | MAE Test Loss: 44.71963882446289 \n",
      "Epoch: 37350 | MAE Train Loss: 47.125064849853516 | MAE Test Loss: 44.71863555908203 \n",
      "Epoch: 37360 | MAE Train Loss: 47.12377166748047 | MAE Test Loss: 44.71763229370117 \n",
      "Epoch: 37370 | MAE Train Loss: 47.12248229980469 | MAE Test Loss: 44.71662521362305 \n",
      "Epoch: 37380 | MAE Train Loss: 47.12118911743164 | MAE Test Loss: 44.71562576293945 \n",
      "Epoch: 37390 | MAE Train Loss: 47.11988830566406 | MAE Test Loss: 44.714622497558594 \n",
      "Epoch: 37400 | MAE Train Loss: 47.11859130859375 | MAE Test Loss: 44.71358871459961 \n",
      "Epoch: 37410 | MAE Train Loss: 47.11730194091797 | MAE Test Loss: 44.712581634521484 \n",
      "Epoch: 37420 | MAE Train Loss: 47.11600875854492 | MAE Test Loss: 44.711578369140625 \n",
      "Epoch: 37430 | MAE Train Loss: 47.114715576171875 | MAE Test Loss: 44.7105827331543 \n",
      "Epoch: 37440 | MAE Train Loss: 47.11341857910156 | MAE Test Loss: 44.70957946777344 \n",
      "Epoch: 37450 | MAE Train Loss: 47.112125396728516 | MAE Test Loss: 44.708580017089844 \n",
      "Epoch: 37460 | MAE Train Loss: 47.1108283996582 | MAE Test Loss: 44.70754623413086 \n",
      "Epoch: 37470 | MAE Train Loss: 47.109535217285156 | MAE Test Loss: 44.70654296875 \n",
      "Epoch: 37480 | MAE Train Loss: 47.108245849609375 | MAE Test Loss: 44.705543518066406 \n",
      "Epoch: 37490 | MAE Train Loss: 47.10695266723633 | MAE Test Loss: 44.70453643798828 \n",
      "Epoch: 37500 | MAE Train Loss: 47.105655670166016 | MAE Test Loss: 44.70353698730469 \n",
      "Epoch: 37510 | MAE Train Loss: 47.10435485839844 | MAE Test Loss: 44.7025032043457 \n",
      "Epoch: 37520 | MAE Train Loss: 47.10306930541992 | MAE Test Loss: 44.70150375366211 \n",
      "Epoch: 37530 | MAE Train Loss: 47.101768493652344 | MAE Test Loss: 44.700496673583984 \n",
      "Epoch: 37540 | MAE Train Loss: 47.10047912597656 | MAE Test Loss: 44.69949722290039 \n",
      "Epoch: 37550 | MAE Train Loss: 47.09918975830078 | MAE Test Loss: 44.69849395751953 \n",
      "Epoch: 37560 | MAE Train Loss: 47.09788131713867 | MAE Test Loss: 44.69749069213867 \n",
      "Epoch: 37570 | MAE Train Loss: 47.096595764160156 | MAE Test Loss: 44.69645309448242 \n",
      "Epoch: 37580 | MAE Train Loss: 47.095298767089844 | MAE Test Loss: 44.69545364379883 \n",
      "Epoch: 37590 | MAE Train Loss: 47.0940055847168 | MAE Test Loss: 44.6944580078125 \n",
      "Epoch: 37600 | MAE Train Loss: 47.092716217041016 | MAE Test Loss: 44.693450927734375 \n",
      "Epoch: 37610 | MAE Train Loss: 47.0914192199707 | MAE Test Loss: 44.692447662353516 \n",
      "Epoch: 37620 | MAE Train Loss: 47.09012222290039 | MAE Test Loss: 44.691444396972656 \n",
      "Epoch: 37630 | MAE Train Loss: 47.08882522583008 | MAE Test Loss: 44.69041442871094 \n",
      "Epoch: 37640 | MAE Train Loss: 47.08753204345703 | MAE Test Loss: 44.68940734863281 \n",
      "Epoch: 37650 | MAE Train Loss: 47.086246490478516 | MAE Test Loss: 44.68840408325195 \n",
      "Epoch: 37660 | MAE Train Loss: 47.08495330810547 | MAE Test Loss: 44.68740463256836 \n",
      "Epoch: 37670 | MAE Train Loss: 47.083648681640625 | MAE Test Loss: 44.6864013671875 \n",
      "Epoch: 37680 | MAE Train Loss: 47.082359313964844 | MAE Test Loss: 44.68539810180664 \n",
      "Epoch: 37690 | MAE Train Loss: 47.08106231689453 | MAE Test Loss: 44.68437194824219 \n",
      "Epoch: 37700 | MAE Train Loss: 47.079769134521484 | MAE Test Loss: 44.68336486816406 \n",
      "Epoch: 37710 | MAE Train Loss: 47.07847213745117 | MAE Test Loss: 44.682376861572266 \n",
      "Epoch: 37720 | MAE Train Loss: 47.077178955078125 | MAE Test Loss: 44.68134307861328 \n",
      "Epoch: 37730 | MAE Train Loss: 47.07588577270508 | MAE Test Loss: 44.68034362792969 \n",
      "Epoch: 37740 | MAE Train Loss: 47.074588775634766 | MAE Test Loss: 44.67934036254883 \n",
      "Epoch: 37750 | MAE Train Loss: 47.073299407958984 | MAE Test Loss: 44.678340911865234 \n",
      "Epoch: 37760 | MAE Train Loss: 47.07200622558594 | MAE Test Loss: 44.677337646484375 \n",
      "Epoch: 37770 | MAE Train Loss: 47.070709228515625 | MAE Test Loss: 44.676334381103516 \n",
      "Epoch: 37780 | MAE Train Loss: 47.06941604614258 | MAE Test Loss: 44.67530059814453 \n",
      "Epoch: 37790 | MAE Train Loss: 47.06812286376953 | MAE Test Loss: 44.674312591552734 \n",
      "Epoch: 37800 | MAE Train Loss: 47.06682586669922 | MAE Test Loss: 44.673309326171875 \n",
      "Epoch: 37810 | MAE Train Loss: 47.06553268432617 | MAE Test Loss: 44.672279357910156 \n",
      "Epoch: 37820 | MAE Train Loss: 47.06423568725586 | MAE Test Loss: 44.6712760925293 \n",
      "Epoch: 37830 | MAE Train Loss: 47.06294250488281 | MAE Test Loss: 44.67027282714844 \n",
      "Epoch: 37840 | MAE Train Loss: 47.06165313720703 | MAE Test Loss: 44.66926956176758 \n",
      "Epoch: 37850 | MAE Train Loss: 47.06039810180664 | MAE Test Loss: 44.66835403442383 \n",
      "Epoch: 37860 | MAE Train Loss: 47.05918502807617 | MAE Test Loss: 44.66753387451172 \n",
      "Epoch: 37870 | MAE Train Loss: 47.05796813964844 | MAE Test Loss: 44.666717529296875 \n",
      "Epoch: 37880 | MAE Train Loss: 47.05675506591797 | MAE Test Loss: 44.665870666503906 \n",
      "Epoch: 37890 | MAE Train Loss: 47.055538177490234 | MAE Test Loss: 44.66505813598633 \n",
      "Epoch: 37900 | MAE Train Loss: 47.05432891845703 | MAE Test Loss: 44.664207458496094 \n",
      "Epoch: 37910 | MAE Train Loss: 47.05311584472656 | MAE Test Loss: 44.663394927978516 \n",
      "Epoch: 37920 | MAE Train Loss: 47.05189895629883 | MAE Test Loss: 44.662574768066406 \n",
      "Epoch: 37930 | MAE Train Loss: 47.05069351196289 | MAE Test Loss: 44.66172790527344 \n",
      "Epoch: 37940 | MAE Train Loss: 47.049476623535156 | MAE Test Loss: 44.660911560058594 \n",
      "Epoch: 37950 | MAE Train Loss: 47.04827117919922 | MAE Test Loss: 44.66006088256836 \n",
      "Epoch: 37960 | MAE Train Loss: 47.04705047607422 | MAE Test Loss: 44.65925216674805 \n",
      "Epoch: 37970 | MAE Train Loss: 47.045833587646484 | MAE Test Loss: 44.65843200683594 \n",
      "Epoch: 37980 | MAE Train Loss: 47.04462814331055 | MAE Test Loss: 44.65758514404297 \n",
      "Epoch: 37990 | MAE Train Loss: 47.04341125488281 | MAE Test Loss: 44.65677261352539 \n",
      "Epoch: 38000 | MAE Train Loss: 47.042198181152344 | MAE Test Loss: 44.655921936035156 \n",
      "Epoch: 38010 | MAE Train Loss: 47.04098129272461 | MAE Test Loss: 44.65510940551758 \n",
      "Epoch: 38020 | MAE Train Loss: 47.039764404296875 | MAE Test Loss: 44.654273986816406 \n",
      "Epoch: 38030 | MAE Train Loss: 47.03855514526367 | MAE Test Loss: 44.65346145629883 \n",
      "Epoch: 38040 | MAE Train Loss: 47.03734588623047 | MAE Test Loss: 44.65260696411133 \n",
      "Epoch: 38050 | MAE Train Loss: 47.036128997802734 | MAE Test Loss: 44.651798248291016 \n",
      "Epoch: 38060 | MAE Train Loss: 47.03491973876953 | MAE Test Loss: 44.65094757080078 \n",
      "Epoch: 38070 | MAE Train Loss: 47.0337028503418 | MAE Test Loss: 44.65013122558594 \n",
      "Epoch: 38080 | MAE Train Loss: 47.03248977661133 | MAE Test Loss: 44.649314880371094 \n",
      "Epoch: 38090 | MAE Train Loss: 47.03128433227539 | MAE Test Loss: 44.64846420288086 \n",
      "Epoch: 38100 | MAE Train Loss: 47.030067443847656 | MAE Test Loss: 44.64765167236328 \n",
      "Epoch: 38110 | MAE Train Loss: 47.02885055541992 | MAE Test Loss: 44.64680099487305 \n",
      "Epoch: 38120 | MAE Train Loss: 47.02764129638672 | MAE Test Loss: 44.645992279052734 \n",
      "Epoch: 38130 | MAE Train Loss: 47.026424407958984 | MAE Test Loss: 44.645172119140625 \n",
      "Epoch: 38140 | MAE Train Loss: 47.02520751953125 | MAE Test Loss: 44.64432144165039 \n",
      "Epoch: 38150 | MAE Train Loss: 47.02399444580078 | MAE Test Loss: 44.64350891113281 \n",
      "Epoch: 38160 | MAE Train Loss: 47.02278518676758 | MAE Test Loss: 44.642662048339844 \n",
      "Epoch: 38170 | MAE Train Loss: 47.02157974243164 | MAE Test Loss: 44.641845703125 \n",
      "Epoch: 38180 | MAE Train Loss: 47.020362854003906 | MAE Test Loss: 44.641029357910156 \n",
      "Epoch: 38190 | MAE Train Loss: 47.019142150878906 | MAE Test Loss: 44.64018249511719 \n",
      "Epoch: 38200 | MAE Train Loss: 47.0179328918457 | MAE Test Loss: 44.63935089111328 \n",
      "Epoch: 38210 | MAE Train Loss: 47.016719818115234 | MAE Test Loss: 44.63853454589844 \n",
      "Epoch: 38220 | MAE Train Loss: 47.0155029296875 | MAE Test Loss: 44.637691497802734 \n",
      "Epoch: 38230 | MAE Train Loss: 47.01429748535156 | MAE Test Loss: 44.636871337890625 \n",
      "Epoch: 38240 | MAE Train Loss: 47.01308059692383 | MAE Test Loss: 44.63605880737305 \n",
      "Epoch: 38250 | MAE Train Loss: 47.01186752319336 | MAE Test Loss: 44.63520812988281 \n",
      "Epoch: 38260 | MAE Train Loss: 47.010650634765625 | MAE Test Loss: 44.63439178466797 \n",
      "Epoch: 38270 | MAE Train Loss: 47.009437561035156 | MAE Test Loss: 44.633541107177734 \n",
      "Epoch: 38280 | MAE Train Loss: 47.00822830200195 | MAE Test Loss: 44.632728576660156 \n",
      "Epoch: 38290 | MAE Train Loss: 47.00701141357422 | MAE Test Loss: 44.63191604614258 \n",
      "Epoch: 38300 | MAE Train Loss: 47.00579833984375 | MAE Test Loss: 44.631065368652344 \n",
      "Epoch: 38310 | MAE Train Loss: 47.00458526611328 | MAE Test Loss: 44.6302490234375 \n",
      "Epoch: 38320 | MAE Train Loss: 47.00336837768555 | MAE Test Loss: 44.62940216064453 \n",
      "Epoch: 38330 | MAE Train Loss: 47.002159118652344 | MAE Test Loss: 44.62858963012695 \n",
      "Epoch: 38340 | MAE Train Loss: 47.00094985961914 | MAE Test Loss: 44.627769470214844 \n",
      "Epoch: 38350 | MAE Train Loss: 46.999732971191406 | MAE Test Loss: 44.62693786621094 \n",
      "Epoch: 38360 | MAE Train Loss: 46.9985237121582 | MAE Test Loss: 44.62609100341797 \n",
      "Epoch: 38370 | MAE Train Loss: 46.99730682373047 | MAE Test Loss: 44.625274658203125 \n",
      "Epoch: 38380 | MAE Train Loss: 46.99609375 | MAE Test Loss: 44.62445831298828 \n",
      "Epoch: 38390 | MAE Train Loss: 46.99488067626953 | MAE Test Loss: 44.62361145019531 \n",
      "Epoch: 38400 | MAE Train Loss: 46.99367141723633 | MAE Test Loss: 44.622798919677734 \n",
      "Epoch: 38410 | MAE Train Loss: 46.992454528808594 | MAE Test Loss: 44.6219482421875 \n",
      "Epoch: 38420 | MAE Train Loss: 46.991241455078125 | MAE Test Loss: 44.62113571166992 \n",
      "Epoch: 38430 | MAE Train Loss: 46.99002456665039 | MAE Test Loss: 44.62031936645508 \n",
      "Epoch: 38440 | MAE Train Loss: 46.98881149291992 | MAE Test Loss: 44.619468688964844 \n",
      "Epoch: 38450 | MAE Train Loss: 46.98760223388672 | MAE Test Loss: 44.618656158447266 \n",
      "Epoch: 38460 | MAE Train Loss: 46.986392974853516 | MAE Test Loss: 44.6178092956543 \n",
      "Epoch: 38470 | MAE Train Loss: 46.985172271728516 | MAE Test Loss: 44.61699676513672 \n",
      "Epoch: 38480 | MAE Train Loss: 46.98395919799805 | MAE Test Loss: 44.61617660522461 \n",
      "Epoch: 38490 | MAE Train Loss: 46.982749938964844 | MAE Test Loss: 44.615325927734375 \n",
      "Epoch: 38500 | MAE Train Loss: 46.981536865234375 | MAE Test Loss: 44.6145133972168 \n",
      "Epoch: 38510 | MAE Train Loss: 46.98031997680664 | MAE Test Loss: 44.613677978515625 \n",
      "Epoch: 38520 | MAE Train Loss: 46.97910690307617 | MAE Test Loss: 44.612831115722656 \n",
      "Epoch: 38530 | MAE Train Loss: 46.97789764404297 | MAE Test Loss: 44.61201858520508 \n",
      "Epoch: 38540 | MAE Train Loss: 46.97667694091797 | MAE Test Loss: 44.61119842529297 \n",
      "Epoch: 38550 | MAE Train Loss: 46.975467681884766 | MAE Test Loss: 44.610355377197266 \n",
      "Epoch: 38560 | MAE Train Loss: 46.9742546081543 | MAE Test Loss: 44.60954284667969 \n",
      "Epoch: 38570 | MAE Train Loss: 46.973045349121094 | MAE Test Loss: 44.60869598388672 \n",
      "Epoch: 38580 | MAE Train Loss: 46.971824645996094 | MAE Test Loss: 44.60787582397461 \n",
      "Epoch: 38590 | MAE Train Loss: 46.97061538696289 | MAE Test Loss: 44.6070556640625 \n",
      "Epoch: 38600 | MAE Train Loss: 46.96940231323242 | MAE Test Loss: 44.606204986572266 \n",
      "Epoch: 38610 | MAE Train Loss: 46.96818542480469 | MAE Test Loss: 44.60539627075195 \n",
      "Epoch: 38620 | MAE Train Loss: 46.96697235107422 | MAE Test Loss: 44.60454559326172 \n",
      "Epoch: 38630 | MAE Train Loss: 46.965763092041016 | MAE Test Loss: 44.603736877441406 \n",
      "Epoch: 38640 | MAE Train Loss: 46.96454620361328 | MAE Test Loss: 44.60291290283203 \n",
      "Epoch: 38650 | MAE Train Loss: 46.96333694458008 | MAE Test Loss: 44.60206604003906 \n",
      "Epoch: 38660 | MAE Train Loss: 46.962120056152344 | MAE Test Loss: 44.60123825073242 \n",
      "Epoch: 38670 | MAE Train Loss: 46.96091079711914 | MAE Test Loss: 44.600425720214844 \n",
      "Epoch: 38680 | MAE Train Loss: 46.95969772338867 | MAE Test Loss: 44.599605560302734 \n",
      "Epoch: 38690 | MAE Train Loss: 46.95853805541992 | MAE Test Loss: 44.59867858886719 \n",
      "Epoch: 38700 | MAE Train Loss: 46.9573860168457 | MAE Test Loss: 44.59774398803711 \n",
      "Epoch: 38710 | MAE Train Loss: 46.956241607666016 | MAE Test Loss: 44.59683609008789 \n",
      "Epoch: 38720 | MAE Train Loss: 46.95509338378906 | MAE Test Loss: 44.59590148925781 \n",
      "Epoch: 38730 | MAE Train Loss: 46.953948974609375 | MAE Test Loss: 44.594966888427734 \n",
      "Epoch: 38740 | MAE Train Loss: 46.952796936035156 | MAE Test Loss: 44.59403610229492 \n",
      "Epoch: 38750 | MAE Train Loss: 46.95166015625 | MAE Test Loss: 44.59310531616211 \n",
      "Epoch: 38760 | MAE Train Loss: 46.95050048828125 | MAE Test Loss: 44.59219741821289 \n",
      "Epoch: 38770 | MAE Train Loss: 46.949363708496094 | MAE Test Loss: 44.59126281738281 \n",
      "Epoch: 38780 | MAE Train Loss: 46.94821548461914 | MAE Test Loss: 44.59033203125 \n",
      "Epoch: 38790 | MAE Train Loss: 46.94706726074219 | MAE Test Loss: 44.58940887451172 \n",
      "Epoch: 38800 | MAE Train Loss: 46.9459228515625 | MAE Test Loss: 44.588470458984375 \n",
      "Epoch: 38810 | MAE Train Loss: 46.94477462768555 | MAE Test Loss: 44.58754348754883 \n",
      "Epoch: 38820 | MAE Train Loss: 46.94363021850586 | MAE Test Loss: 44.58660888671875 \n",
      "Epoch: 38830 | MAE Train Loss: 46.94248580932617 | MAE Test Loss: 44.585670471191406 \n",
      "Epoch: 38840 | MAE Train Loss: 46.94133377075195 | MAE Test Loss: 44.58476638793945 \n",
      "Epoch: 38850 | MAE Train Loss: 46.940189361572266 | MAE Test Loss: 44.58382034301758 \n",
      "Epoch: 38860 | MAE Train Loss: 46.93903732299805 | MAE Test Loss: 44.5828857421875 \n",
      "Epoch: 38870 | MAE Train Loss: 46.937896728515625 | MAE Test Loss: 44.58198165893555 \n",
      "Epoch: 38880 | MAE Train Loss: 46.93675994873047 | MAE Test Loss: 44.5810432434082 \n",
      "Epoch: 38890 | MAE Train Loss: 46.93560791015625 | MAE Test Loss: 44.58011245727539 \n",
      "Epoch: 38900 | MAE Train Loss: 46.93445587158203 | MAE Test Loss: 44.57917404174805 \n",
      "Epoch: 38910 | MAE Train Loss: 46.93331527709961 | MAE Test Loss: 44.578243255615234 \n",
      "Epoch: 38920 | MAE Train Loss: 46.93217086791992 | MAE Test Loss: 44.577335357666016 \n",
      "Epoch: 38930 | MAE Train Loss: 46.931026458740234 | MAE Test Loss: 44.57640075683594 \n",
      "Epoch: 38940 | MAE Train Loss: 46.929874420166016 | MAE Test Loss: 44.575462341308594 \n",
      "Epoch: 38950 | MAE Train Loss: 46.92873001098633 | MAE Test Loss: 44.57453536987305 \n",
      "Epoch: 38960 | MAE Train Loss: 46.92758560180664 | MAE Test Loss: 44.573612213134766 \n",
      "Epoch: 38970 | MAE Train Loss: 46.92644500732422 | MAE Test Loss: 44.57267761230469 \n",
      "Epoch: 38980 | MAE Train Loss: 46.92529296875 | MAE Test Loss: 44.571746826171875 \n",
      "Epoch: 38990 | MAE Train Loss: 46.92414474487305 | MAE Test Loss: 44.5708122253418 \n",
      "Epoch: 39000 | MAE Train Loss: 46.923004150390625 | MAE Test Loss: 44.56990432739258 \n",
      "Epoch: 39010 | MAE Train Loss: 46.92185974121094 | MAE Test Loss: 44.5689697265625 \n",
      "Epoch: 39020 | MAE Train Loss: 46.920711517333984 | MAE Test Loss: 44.56803894042969 \n",
      "Epoch: 39030 | MAE Train Loss: 46.91956329345703 | MAE Test Loss: 44.56710433959961 \n",
      "Epoch: 39040 | MAE Train Loss: 46.91841506958008 | MAE Test Loss: 44.56616973876953 \n",
      "Epoch: 39050 | MAE Train Loss: 46.917266845703125 | MAE Test Loss: 44.56526565551758 \n",
      "Epoch: 39060 | MAE Train Loss: 46.9161262512207 | MAE Test Loss: 44.5643310546875 \n",
      "Epoch: 39070 | MAE Train Loss: 46.914981842041016 | MAE Test Loss: 44.563392639160156 \n",
      "Epoch: 39080 | MAE Train Loss: 46.9138298034668 | MAE Test Loss: 44.56245803833008 \n",
      "Epoch: 39090 | MAE Train Loss: 46.91268539428711 | MAE Test Loss: 44.561527252197266 \n",
      "Epoch: 39100 | MAE Train Loss: 46.91154098510742 | MAE Test Loss: 44.56061935424805 \n",
      "Epoch: 39110 | MAE Train Loss: 46.91039276123047 | MAE Test Loss: 44.559688568115234 \n",
      "Epoch: 39120 | MAE Train Loss: 46.90924835205078 | MAE Test Loss: 44.558753967285156 \n",
      "Epoch: 39130 | MAE Train Loss: 46.908103942871094 | MAE Test Loss: 44.55781555175781 \n",
      "Epoch: 39140 | MAE Train Loss: 46.906951904296875 | MAE Test Loss: 44.556888580322266 \n",
      "Epoch: 39150 | MAE Train Loss: 46.90580749511719 | MAE Test Loss: 44.55595397949219 \n",
      "Epoch: 39160 | MAE Train Loss: 46.9046630859375 | MAE Test Loss: 44.555049896240234 \n",
      "Epoch: 39170 | MAE Train Loss: 46.90352249145508 | MAE Test Loss: 44.554115295410156 \n",
      "Epoch: 39180 | MAE Train Loss: 46.90237045288086 | MAE Test Loss: 44.55317687988281 \n",
      "Epoch: 39190 | MAE Train Loss: 46.90122604370117 | MAE Test Loss: 44.552242279052734 \n",
      "Epoch: 39200 | MAE Train Loss: 46.90007400512695 | MAE Test Loss: 44.551307678222656 \n",
      "Epoch: 39210 | MAE Train Loss: 46.898929595947266 | MAE Test Loss: 44.5504035949707 \n",
      "Epoch: 39220 | MAE Train Loss: 46.89778518676758 | MAE Test Loss: 44.549468994140625 \n",
      "Epoch: 39230 | MAE Train Loss: 46.89664077758789 | MAE Test Loss: 44.54853820800781 \n",
      "Epoch: 39240 | MAE Train Loss: 46.89549255371094 | MAE Test Loss: 44.5475959777832 \n",
      "Epoch: 39250 | MAE Train Loss: 46.894344329833984 | MAE Test Loss: 44.546669006347656 \n",
      "Epoch: 39260 | MAE Train Loss: 46.89320373535156 | MAE Test Loss: 44.54576110839844 \n",
      "Epoch: 39270 | MAE Train Loss: 46.892059326171875 | MAE Test Loss: 44.544830322265625 \n",
      "Epoch: 39280 | MAE Train Loss: 46.89091110229492 | MAE Test Loss: 44.54389190673828 \n",
      "Epoch: 39290 | MAE Train Loss: 46.889766693115234 | MAE Test Loss: 44.54296112060547 \n",
      "Epoch: 39300 | MAE Train Loss: 46.888614654541016 | MAE Test Loss: 44.542022705078125 \n",
      "Epoch: 39310 | MAE Train Loss: 46.88747024536133 | MAE Test Loss: 44.54111862182617 \n",
      "Epoch: 39320 | MAE Train Loss: 46.88632583618164 | MAE Test Loss: 44.54018783569336 \n",
      "Epoch: 39330 | MAE Train Loss: 46.88518142700195 | MAE Test Loss: 44.53925323486328 \n",
      "Epoch: 39340 | MAE Train Loss: 46.884029388427734 | MAE Test Loss: 44.5383186340332 \n",
      "Epoch: 39350 | MAE Train Loss: 46.88288497924805 | MAE Test Loss: 44.53738021850586 \n",
      "Epoch: 39360 | MAE Train Loss: 46.88174057006836 | MAE Test Loss: 44.53644943237305 \n",
      "Epoch: 39370 | MAE Train Loss: 46.88059997558594 | MAE Test Loss: 44.53554153442383 \n",
      "Epoch: 39380 | MAE Train Loss: 46.87945556640625 | MAE Test Loss: 44.53460693359375 \n",
      "Epoch: 39390 | MAE Train Loss: 46.8783073425293 | MAE Test Loss: 44.53367614746094 \n",
      "Epoch: 39400 | MAE Train Loss: 46.877159118652344 | MAE Test Loss: 44.53274154663086 \n",
      "Epoch: 39410 | MAE Train Loss: 46.876007080078125 | MAE Test Loss: 44.53180694580078 \n",
      "Epoch: 39420 | MAE Train Loss: 46.87486267089844 | MAE Test Loss: 44.53090286254883 \n",
      "Epoch: 39430 | MAE Train Loss: 46.873722076416016 | MAE Test Loss: 44.529964447021484 \n",
      "Epoch: 39440 | MAE Train Loss: 46.87257766723633 | MAE Test Loss: 44.529029846191406 \n",
      "Epoch: 39450 | MAE Train Loss: 46.87142562866211 | MAE Test Loss: 44.52809524536133 \n",
      "Epoch: 39460 | MAE Train Loss: 46.87028121948242 | MAE Test Loss: 44.527164459228516 \n",
      "Epoch: 39470 | MAE Train Loss: 46.8691291809082 | MAE Test Loss: 44.5262565612793 \n",
      "Epoch: 39480 | MAE Train Loss: 46.86798858642578 | MAE Test Loss: 44.525325775146484 \n",
      "Epoch: 39490 | MAE Train Loss: 46.866844177246094 | MAE Test Loss: 44.524391174316406 \n",
      "Epoch: 39500 | MAE Train Loss: 46.865692138671875 | MAE Test Loss: 44.52345657348633 \n",
      "Epoch: 39510 | MAE Train Loss: 46.86454772949219 | MAE Test Loss: 44.52252197265625 \n",
      "Epoch: 39520 | MAE Train Loss: 46.8634033203125 | MAE Test Loss: 44.5216178894043 \n",
      "Epoch: 39530 | MAE Train Loss: 46.86225891113281 | MAE Test Loss: 44.52067947387695 \n",
      "Epoch: 39540 | MAE Train Loss: 46.86111068725586 | MAE Test Loss: 44.519744873046875 \n",
      "Epoch: 39550 | MAE Train Loss: 46.85996627807617 | MAE Test Loss: 44.51881408691406 \n",
      "Epoch: 39560 | MAE Train Loss: 46.85881805419922 | MAE Test Loss: 44.51788330078125 \n",
      "Epoch: 39570 | MAE Train Loss: 46.857669830322266 | MAE Test Loss: 44.51694869995117 \n",
      "Epoch: 39580 | MAE Train Loss: 46.85652542114258 | MAE Test Loss: 44.51604080200195 \n",
      "Epoch: 39590 | MAE Train Loss: 46.85538101196289 | MAE Test Loss: 44.515106201171875 \n",
      "Epoch: 39600 | MAE Train Loss: 46.8542366027832 | MAE Test Loss: 44.5141716003418 \n",
      "Epoch: 39610 | MAE Train Loss: 46.85308837890625 | MAE Test Loss: 44.51323699951172 \n",
      "Epoch: 39620 | MAE Train Loss: 46.8519401550293 | MAE Test Loss: 44.512306213378906 \n",
      "Epoch: 39630 | MAE Train Loss: 46.850799560546875 | MAE Test Loss: 44.51139831542969 \n",
      "Epoch: 39640 | MAE Train Loss: 46.849647521972656 | MAE Test Loss: 44.51046371459961 \n",
      "Epoch: 39650 | MAE Train Loss: 46.84850311279297 | MAE Test Loss: 44.50952911376953 \n",
      "Epoch: 39660 | MAE Train Loss: 46.84736251831055 | MAE Test Loss: 44.50859832763672 \n",
      "Epoch: 39670 | MAE Train Loss: 46.84621047973633 | MAE Test Loss: 44.50766372680664 \n",
      "Epoch: 39680 | MAE Train Loss: 46.84506607055664 | MAE Test Loss: 44.50675582885742 \n",
      "Epoch: 39690 | MAE Train Loss: 46.84391784667969 | MAE Test Loss: 44.505821228027344 \n",
      "Epoch: 39700 | MAE Train Loss: 46.842777252197266 | MAE Test Loss: 44.5048828125 \n",
      "Epoch: 39710 | MAE Train Loss: 46.84162521362305 | MAE Test Loss: 44.50396728515625 \n",
      "Epoch: 39720 | MAE Train Loss: 46.840484619140625 | MAE Test Loss: 44.50303268432617 \n",
      "Epoch: 39730 | MAE Train Loss: 46.83933639526367 | MAE Test Loss: 44.502098083496094 \n",
      "Epoch: 39740 | MAE Train Loss: 46.83818435668945 | MAE Test Loss: 44.50116729736328 \n",
      "Epoch: 39750 | MAE Train Loss: 46.83704376220703 | MAE Test Loss: 44.5002326965332 \n",
      "Epoch: 39760 | MAE Train Loss: 46.83589172363281 | MAE Test Loss: 44.499324798583984 \n",
      "Epoch: 39770 | MAE Train Loss: 46.834747314453125 | MAE Test Loss: 44.49839401245117 \n",
      "Epoch: 39780 | MAE Train Loss: 46.83360290527344 | MAE Test Loss: 44.49745559692383 \n",
      "Epoch: 39790 | MAE Train Loss: 46.83245849609375 | MAE Test Loss: 44.496524810791016 \n",
      "Epoch: 39800 | MAE Train Loss: 46.8313102722168 | MAE Test Loss: 44.49559020996094 \n",
      "Epoch: 39810 | MAE Train Loss: 46.83017349243164 | MAE Test Loss: 44.49468231201172 \n",
      "Epoch: 39820 | MAE Train Loss: 46.82902145385742 | MAE Test Loss: 44.493751525878906 \n",
      "Epoch: 39830 | MAE Train Loss: 46.8278694152832 | MAE Test Loss: 44.49281692504883 \n",
      "Epoch: 39840 | MAE Train Loss: 46.82672882080078 | MAE Test Loss: 44.491878509521484 \n",
      "Epoch: 39850 | MAE Train Loss: 46.82558059692383 | MAE Test Loss: 44.49094772338867 \n",
      "Epoch: 39860 | MAE Train Loss: 46.82443618774414 | MAE Test Loss: 44.490013122558594 \n",
      "Epoch: 39870 | MAE Train Loss: 46.82328796386719 | MAE Test Loss: 44.489105224609375 \n",
      "Epoch: 39880 | MAE Train Loss: 46.82215118408203 | MAE Test Loss: 44.4881706237793 \n",
      "Epoch: 39890 | MAE Train Loss: 46.82099151611328 | MAE Test Loss: 44.487239837646484 \n",
      "Epoch: 39900 | MAE Train Loss: 46.819847106933594 | MAE Test Loss: 44.486305236816406 \n",
      "Epoch: 39910 | MAE Train Loss: 46.818702697753906 | MAE Test Loss: 44.485374450683594 \n",
      "Epoch: 39920 | MAE Train Loss: 46.81755828857422 | MAE Test Loss: 44.48446273803711 \n",
      "Epoch: 39930 | MAE Train Loss: 46.8164176940918 | MAE Test Loss: 44.4835319519043 \n",
      "Epoch: 39940 | MAE Train Loss: 46.81526565551758 | MAE Test Loss: 44.48259353637695 \n",
      "Epoch: 39950 | MAE Train Loss: 46.81412124633789 | MAE Test Loss: 44.481666564941406 \n",
      "Epoch: 39960 | MAE Train Loss: 46.81296920776367 | MAE Test Loss: 44.48072814941406 \n",
      "Epoch: 39970 | MAE Train Loss: 46.81182861328125 | MAE Test Loss: 44.479820251464844 \n",
      "Epoch: 39980 | MAE Train Loss: 46.81068420410156 | MAE Test Loss: 44.47888946533203 \n",
      "Epoch: 39990 | MAE Train Loss: 46.809539794921875 | MAE Test Loss: 44.47795486450195 \n",
      "Epoch: 40000 | MAE Train Loss: 46.80839538574219 | MAE Test Loss: 44.47702407836914 \n",
      "Epoch: 40010 | MAE Train Loss: 46.80724334716797 | MAE Test Loss: 44.4760856628418 \n",
      "Epoch: 40020 | MAE Train Loss: 46.80609893798828 | MAE Test Loss: 44.47518539428711 \n",
      "Epoch: 40030 | MAE Train Loss: 46.804954528808594 | MAE Test Loss: 44.47425079345703 \n",
      "Epoch: 40040 | MAE Train Loss: 46.80380630493164 | MAE Test Loss: 44.47331619262695 \n",
      "Epoch: 40050 | MAE Train Loss: 46.80266189575195 | MAE Test Loss: 44.47237777709961 \n",
      "Epoch: 40060 | MAE Train Loss: 46.801509857177734 | MAE Test Loss: 44.47144317626953 \n",
      "Epoch: 40070 | MAE Train Loss: 46.80036544799805 | MAE Test Loss: 44.47050857543945 \n",
      "Epoch: 40080 | MAE Train Loss: 46.79922103881836 | MAE Test Loss: 44.469600677490234 \n",
      "Epoch: 40090 | MAE Train Loss: 46.79807662963867 | MAE Test Loss: 44.468666076660156 \n",
      "Epoch: 40100 | MAE Train Loss: 46.796932220458984 | MAE Test Loss: 44.46773910522461 \n",
      "Epoch: 40110 | MAE Train Loss: 46.795780181884766 | MAE Test Loss: 44.466800689697266 \n",
      "Epoch: 40120 | MAE Train Loss: 46.79463577270508 | MAE Test Loss: 44.46586990356445 \n",
      "Epoch: 40130 | MAE Train Loss: 46.793495178222656 | MAE Test Loss: 44.464962005615234 \n",
      "Epoch: 40140 | MAE Train Loss: 46.79234313964844 | MAE Test Loss: 44.464027404785156 \n",
      "Epoch: 40150 | MAE Train Loss: 46.79119873046875 | MAE Test Loss: 44.463096618652344 \n",
      "Epoch: 40160 | MAE Train Loss: 46.79005432128906 | MAE Test Loss: 44.462162017822266 \n",
      "Epoch: 40170 | MAE Train Loss: 46.788902282714844 | MAE Test Loss: 44.46122741699219 \n",
      "Epoch: 40180 | MAE Train Loss: 46.787757873535156 | MAE Test Loss: 44.46031951904297 \n",
      "Epoch: 40190 | MAE Train Loss: 46.786617279052734 | MAE Test Loss: 44.45938491821289 \n",
      "Epoch: 40200 | MAE Train Loss: 46.785465240478516 | MAE Test Loss: 44.45845031738281 \n",
      "Epoch: 40210 | MAE Train Loss: 46.78432083129883 | MAE Test Loss: 44.457515716552734 \n",
      "Epoch: 40220 | MAE Train Loss: 46.78317642211914 | MAE Test Loss: 44.45658874511719 \n",
      "Epoch: 40230 | MAE Train Loss: 46.78203201293945 | MAE Test Loss: 44.4556770324707 \n",
      "Epoch: 40240 | MAE Train Loss: 46.7808837890625 | MAE Test Loss: 44.454742431640625 \n",
      "Epoch: 40250 | MAE Train Loss: 46.77973937988281 | MAE Test Loss: 44.45381164550781 \n",
      "Epoch: 40260 | MAE Train Loss: 46.778587341308594 | MAE Test Loss: 44.45287322998047 \n",
      "Epoch: 40270 | MAE Train Loss: 46.77745056152344 | MAE Test Loss: 44.451942443847656 \n",
      "Epoch: 40280 | MAE Train Loss: 46.77629852294922 | MAE Test Loss: 44.45100784301758 \n",
      "Epoch: 40290 | MAE Train Loss: 46.775146484375 | MAE Test Loss: 44.450103759765625 \n",
      "Epoch: 40300 | MAE Train Loss: 46.77401351928711 | MAE Test Loss: 44.44916534423828 \n",
      "Epoch: 40310 | MAE Train Loss: 46.77286148071289 | MAE Test Loss: 44.4482307434082 \n",
      "Epoch: 40320 | MAE Train Loss: 46.7717170715332 | MAE Test Loss: 44.447303771972656 \n",
      "Epoch: 40330 | MAE Train Loss: 46.770565032958984 | MAE Test Loss: 44.446372985839844 \n",
      "Epoch: 40340 | MAE Train Loss: 46.76942443847656 | MAE Test Loss: 44.445457458496094 \n",
      "Epoch: 40350 | MAE Train Loss: 46.768280029296875 | MAE Test Loss: 44.44452667236328 \n",
      "Epoch: 40360 | MAE Train Loss: 46.76713180541992 | MAE Test Loss: 44.44359588623047 \n",
      "Epoch: 40370 | MAE Train Loss: 46.76598358154297 | MAE Test Loss: 44.442657470703125 \n",
      "Epoch: 40380 | MAE Train Loss: 46.76483917236328 | MAE Test Loss: 44.44172286987305 \n",
      "Epoch: 40390 | MAE Train Loss: 46.763694763183594 | MAE Test Loss: 44.44081497192383 \n",
      "Epoch: 40400 | MAE Train Loss: 46.762550354003906 | MAE Test Loss: 44.439884185791016 \n",
      "Epoch: 40410 | MAE Train Loss: 46.76140213012695 | MAE Test Loss: 44.43894958496094 \n",
      "Epoch: 40420 | MAE Train Loss: 46.76025390625 | MAE Test Loss: 44.43801498413086 \n",
      "Epoch: 40430 | MAE Train Loss: 46.75910568237305 | MAE Test Loss: 44.437076568603516 \n",
      "Epoch: 40440 | MAE Train Loss: 46.75796127319336 | MAE Test Loss: 44.43617630004883 \n",
      "Epoch: 40450 | MAE Train Loss: 46.75681686401367 | MAE Test Loss: 44.43524169921875 \n",
      "Epoch: 40460 | MAE Train Loss: 46.755672454833984 | MAE Test Loss: 44.43431091308594 \n",
      "Epoch: 40470 | MAE Train Loss: 46.75452423095703 | MAE Test Loss: 44.433372497558594 \n",
      "Epoch: 40480 | MAE Train Loss: 46.75337600708008 | MAE Test Loss: 44.432437896728516 \n",
      "Epoch: 40490 | MAE Train Loss: 46.75223159790039 | MAE Test Loss: 44.4315071105957 \n",
      "Epoch: 40500 | MAE Train Loss: 46.75108337402344 | MAE Test Loss: 44.430599212646484 \n",
      "Epoch: 40510 | MAE Train Loss: 46.74993896484375 | MAE Test Loss: 44.429664611816406 \n",
      "Epoch: 40520 | MAE Train Loss: 46.74878692626953 | MAE Test Loss: 44.428733825683594 \n",
      "Epoch: 40530 | MAE Train Loss: 46.747650146484375 | MAE Test Loss: 44.427799224853516 \n",
      "Epoch: 40540 | MAE Train Loss: 46.74650192260742 | MAE Test Loss: 44.42686080932617 \n",
      "Epoch: 40550 | MAE Train Loss: 46.74535369873047 | MAE Test Loss: 44.42595672607422 \n",
      "Epoch: 40560 | MAE Train Loss: 46.74421310424805 | MAE Test Loss: 44.42502212524414 \n",
      "Epoch: 40570 | MAE Train Loss: 46.74306106567383 | MAE Test Loss: 44.42408752441406 \n",
      "Epoch: 40580 | MAE Train Loss: 46.74191665649414 | MAE Test Loss: 44.42315673828125 \n",
      "Epoch: 40590 | MAE Train Loss: 46.74076461791992 | MAE Test Loss: 44.42222213745117 \n",
      "Epoch: 40600 | MAE Train Loss: 46.739620208740234 | MAE Test Loss: 44.42131423950195 \n",
      "Epoch: 40610 | MAE Train Loss: 46.73847961425781 | MAE Test Loss: 44.42038345336914 \n",
      "Epoch: 40620 | MAE Train Loss: 46.737335205078125 | MAE Test Loss: 44.41944885253906 \n",
      "Epoch: 40630 | MAE Train Loss: 46.73619079589844 | MAE Test Loss: 44.418521881103516 \n",
      "Epoch: 40640 | MAE Train Loss: 46.73503875732422 | MAE Test Loss: 44.417598724365234 \n",
      "Epoch: 40650 | MAE Train Loss: 46.73389434814453 | MAE Test Loss: 44.41666030883789 \n",
      "Epoch: 40660 | MAE Train Loss: 46.73274230957031 | MAE Test Loss: 44.41572570800781 \n",
      "Epoch: 40670 | MAE Train Loss: 46.73160171508789 | MAE Test Loss: 44.414791107177734 \n",
      "Epoch: 40680 | MAE Train Loss: 46.7304573059082 | MAE Test Loss: 44.413883209228516 \n",
      "Epoch: 40690 | MAE Train Loss: 46.729305267333984 | MAE Test Loss: 44.4129524230957 \n",
      "Epoch: 40700 | MAE Train Loss: 46.72816848754883 | MAE Test Loss: 44.412017822265625 \n",
      "Epoch: 40710 | MAE Train Loss: 46.72701644897461 | MAE Test Loss: 44.41107940673828 \n",
      "Epoch: 40720 | MAE Train Loss: 46.72587203979492 | MAE Test Loss: 44.4101448059082 \n",
      "Epoch: 40730 | MAE Train Loss: 46.7247200012207 | MAE Test Loss: 44.409244537353516 \n",
      "Epoch: 40740 | MAE Train Loss: 46.723575592041016 | MAE Test Loss: 44.408294677734375 \n",
      "Epoch: 40750 | MAE Train Loss: 46.72243118286133 | MAE Test Loss: 44.4073600769043 \n",
      "Epoch: 40760 | MAE Train Loss: 46.721290588378906 | MAE Test Loss: 44.40645217895508 \n",
      "Epoch: 40770 | MAE Train Loss: 46.72014617919922 | MAE Test Loss: 44.405521392822266 \n",
      "Epoch: 40780 | MAE Train Loss: 46.718994140625 | MAE Test Loss: 44.40458679199219 \n",
      "Epoch: 40790 | MAE Train Loss: 46.71784973144531 | MAE Test Loss: 44.403648376464844 \n",
      "Epoch: 40800 | MAE Train Loss: 46.71670150756836 | MAE Test Loss: 44.402713775634766 \n",
      "Epoch: 40810 | MAE Train Loss: 46.71555709838867 | MAE Test Loss: 44.40180969238281 \n",
      "Epoch: 40820 | MAE Train Loss: 46.714412689208984 | MAE Test Loss: 44.40087890625 \n",
      "Epoch: 40830 | MAE Train Loss: 46.7132682800293 | MAE Test Loss: 44.39994430541992 \n",
      "Epoch: 40840 | MAE Train Loss: 46.712120056152344 | MAE Test Loss: 44.399024963378906 \n",
      "Epoch: 40850 | MAE Train Loss: 46.710975646972656 | MAE Test Loss: 44.39809036254883 \n",
      "Epoch: 40860 | MAE Train Loss: 46.70983123779297 | MAE Test Loss: 44.397151947021484 \n",
      "Epoch: 40870 | MAE Train Loss: 46.70868682861328 | MAE Test Loss: 44.39622116088867 \n",
      "Epoch: 40880 | MAE Train Loss: 46.70753479003906 | MAE Test Loss: 44.395286560058594 \n",
      "Epoch: 40890 | MAE Train Loss: 46.70639419555664 | MAE Test Loss: 44.394386291503906 \n",
      "Epoch: 40900 | MAE Train Loss: 46.70524978637695 | MAE Test Loss: 44.39344787597656 \n",
      "Epoch: 40910 | MAE Train Loss: 46.704097747802734 | MAE Test Loss: 44.392513275146484 \n",
      "Epoch: 40920 | MAE Train Loss: 46.70295333862305 | MAE Test Loss: 44.391578674316406 \n",
      "Epoch: 40930 | MAE Train Loss: 46.70180892944336 | MAE Test Loss: 44.39065170288086 \n",
      "Epoch: 40940 | MAE Train Loss: 46.70066452026367 | MAE Test Loss: 44.38974380493164 \n",
      "Epoch: 40950 | MAE Train Loss: 46.69951629638672 | MAE Test Loss: 44.38880920410156 \n",
      "Epoch: 40960 | MAE Train Loss: 46.69837188720703 | MAE Test Loss: 44.387874603271484 \n",
      "Epoch: 40970 | MAE Train Loss: 46.697227478027344 | MAE Test Loss: 44.38693618774414 \n",
      "Epoch: 40980 | MAE Train Loss: 46.696083068847656 | MAE Test Loss: 44.38600540161133 \n",
      "Epoch: 40990 | MAE Train Loss: 46.69493103027344 | MAE Test Loss: 44.38507080078125 \n",
      "Epoch: 41000 | MAE Train Loss: 46.693790435791016 | MAE Test Loss: 44.3841667175293 \n",
      "Epoch: 41010 | MAE Train Loss: 46.69264602661133 | MAE Test Loss: 44.38323211669922 \n",
      "Epoch: 41020 | MAE Train Loss: 46.69150161743164 | MAE Test Loss: 44.382293701171875 \n",
      "Epoch: 41030 | MAE Train Loss: 46.69034957885742 | MAE Test Loss: 44.38136672973633 \n",
      "Epoch: 41040 | MAE Train Loss: 46.6891975402832 | MAE Test Loss: 44.380428314208984 \n",
      "Epoch: 41050 | MAE Train Loss: 46.68805694580078 | MAE Test Loss: 44.37952423095703 \n",
      "Epoch: 41060 | MAE Train Loss: 46.686920166015625 | MAE Test Loss: 44.37858963012695 \n",
      "Epoch: 41070 | MAE Train Loss: 46.685768127441406 | MAE Test Loss: 44.377655029296875 \n",
      "Epoch: 41080 | MAE Train Loss: 46.68461608886719 | MAE Test Loss: 44.37672424316406 \n",
      "Epoch: 41090 | MAE Train Loss: 46.68347930908203 | MAE Test Loss: 44.37578582763672 \n",
      "Epoch: 41100 | MAE Train Loss: 46.68232727050781 | MAE Test Loss: 44.374881744384766 \n",
      "Epoch: 41110 | MAE Train Loss: 46.68118667602539 | MAE Test Loss: 44.37394332885742 \n",
      "Epoch: 41120 | MAE Train Loss: 46.68003463745117 | MAE Test Loss: 44.37301254272461 \n",
      "Epoch: 41130 | MAE Train Loss: 46.678890228271484 | MAE Test Loss: 44.3720817565918 \n",
      "Epoch: 41140 | MAE Train Loss: 46.6777458190918 | MAE Test Loss: 44.37114334106445 \n",
      "Epoch: 41150 | MAE Train Loss: 46.67660140991211 | MAE Test Loss: 44.3702392578125 \n",
      "Epoch: 41160 | MAE Train Loss: 46.675453186035156 | MAE Test Loss: 44.36930847167969 \n",
      "Epoch: 41170 | MAE Train Loss: 46.67430877685547 | MAE Test Loss: 44.36837387084961 \n",
      "Epoch: 41180 | MAE Train Loss: 46.67316436767578 | MAE Test Loss: 44.36743927001953 \n",
      "Epoch: 41190 | MAE Train Loss: 46.672019958496094 | MAE Test Loss: 44.36650466918945 \n",
      "Epoch: 41200 | MAE Train Loss: 46.67087173461914 | MAE Test Loss: 44.36558151245117 \n",
      "Epoch: 41210 | MAE Train Loss: 46.66972351074219 | MAE Test Loss: 44.364646911621094 \n",
      "Epoch: 41220 | MAE Train Loss: 46.668582916259766 | MAE Test Loss: 44.36371612548828 \n",
      "Epoch: 41230 | MAE Train Loss: 46.66743087768555 | MAE Test Loss: 44.36280822753906 \n",
      "Epoch: 41240 | MAE Train Loss: 46.66629409790039 | MAE Test Loss: 44.361873626708984 \n",
      "Epoch: 41250 | MAE Train Loss: 46.66514205932617 | MAE Test Loss: 44.36094284057617 \n",
      "Epoch: 41260 | MAE Train Loss: 46.663997650146484 | MAE Test Loss: 44.360008239746094 \n",
      "Epoch: 41270 | MAE Train Loss: 46.66284942626953 | MAE Test Loss: 44.359073638916016 \n",
      "Epoch: 41280 | MAE Train Loss: 46.661705017089844 | MAE Test Loss: 44.35816955566406 \n",
      "Epoch: 41290 | MAE Train Loss: 46.660560607910156 | MAE Test Loss: 44.35723114013672 \n",
      "Epoch: 41300 | MAE Train Loss: 46.65941619873047 | MAE Test Loss: 44.35630416870117 \n",
      "Epoch: 41310 | MAE Train Loss: 46.658267974853516 | MAE Test Loss: 44.35536575317383 \n",
      "Epoch: 41320 | MAE Train Loss: 46.65712356567383 | MAE Test Loss: 44.35443115234375 \n",
      "Epoch: 41330 | MAE Train Loss: 46.65597915649414 | MAE Test Loss: 44.35349655151367 \n",
      "Epoch: 41340 | MAE Train Loss: 46.65483474731445 | MAE Test Loss: 44.35259246826172 \n",
      "Epoch: 41350 | MAE Train Loss: 46.6536865234375 | MAE Test Loss: 44.351661682128906 \n",
      "Epoch: 41360 | MAE Train Loss: 46.65254211425781 | MAE Test Loss: 44.35073471069336 \n",
      "Epoch: 41370 | MAE Train Loss: 46.651397705078125 | MAE Test Loss: 44.34980392456055 \n",
      "Epoch: 41380 | MAE Train Loss: 46.6502571105957 | MAE Test Loss: 44.34891128540039 \n",
      "Epoch: 41390 | MAE Train Loss: 46.649147033691406 | MAE Test Loss: 44.34807205200195 \n",
      "Epoch: 41400 | MAE Train Loss: 46.64802932739258 | MAE Test Loss: 44.347259521484375 \n",
      "Epoch: 41410 | MAE Train Loss: 46.64691162109375 | MAE Test Loss: 44.34642028808594 \n",
      "Epoch: 41420 | MAE Train Loss: 46.64579391479492 | MAE Test Loss: 44.345611572265625 \n",
      "Epoch: 41430 | MAE Train Loss: 46.64468002319336 | MAE Test Loss: 44.34477233886719 \n",
      "Epoch: 41440 | MAE Train Loss: 46.64356231689453 | MAE Test Loss: 44.343929290771484 \n",
      "Epoch: 41450 | MAE Train Loss: 46.6424446105957 | MAE Test Loss: 44.34312438964844 \n",
      "Epoch: 41460 | MAE Train Loss: 46.641334533691406 | MAE Test Loss: 44.342281341552734 \n",
      "Epoch: 41470 | MAE Train Loss: 46.64020919799805 | MAE Test Loss: 44.34143829345703 \n",
      "Epoch: 41480 | MAE Train Loss: 46.639102935791016 | MAE Test Loss: 44.34062957763672 \n",
      "Epoch: 41490 | MAE Train Loss: 46.63798522949219 | MAE Test Loss: 44.33979034423828 \n",
      "Epoch: 41500 | MAE Train Loss: 46.63686752319336 | MAE Test Loss: 44.33898162841797 \n",
      "Epoch: 41510 | MAE Train Loss: 46.63574981689453 | MAE Test Loss: 44.338138580322266 \n",
      "Epoch: 41520 | MAE Train Loss: 46.6346321105957 | MAE Test Loss: 44.337318420410156 \n",
      "Epoch: 41530 | MAE Train Loss: 46.633514404296875 | MAE Test Loss: 44.33647537231445 \n",
      "Epoch: 41540 | MAE Train Loss: 46.63239669799805 | MAE Test Loss: 44.335628509521484 \n",
      "Epoch: 41550 | MAE Train Loss: 46.63128662109375 | MAE Test Loss: 44.33482360839844 \n",
      "Epoch: 41560 | MAE Train Loss: 46.63016891479492 | MAE Test Loss: 44.333984375 \n",
      "Epoch: 41570 | MAE Train Loss: 46.629051208496094 | MAE Test Loss: 44.33317184448242 \n",
      "Epoch: 41580 | MAE Train Loss: 46.62793731689453 | MAE Test Loss: 44.332332611083984 \n",
      "Epoch: 41590 | MAE Train Loss: 46.6268196105957 | MAE Test Loss: 44.33150863647461 \n",
      "Epoch: 41600 | MAE Train Loss: 46.625709533691406 | MAE Test Loss: 44.330665588378906 \n",
      "Epoch: 41610 | MAE Train Loss: 46.62459182739258 | MAE Test Loss: 44.329856872558594 \n",
      "Epoch: 41620 | MAE Train Loss: 46.62347412109375 | MAE Test Loss: 44.32901382446289 \n",
      "Epoch: 41630 | MAE Train Loss: 46.62235641479492 | MAE Test Loss: 44.32817840576172 \n",
      "Epoch: 41640 | MAE Train Loss: 46.62124252319336 | MAE Test Loss: 44.327369689941406 \n",
      "Epoch: 41650 | MAE Train Loss: 46.62013244628906 | MAE Test Loss: 44.3265266418457 \n",
      "Epoch: 41660 | MAE Train Loss: 46.61900329589844 | MAE Test Loss: 44.32568359375 \n",
      "Epoch: 41670 | MAE Train Loss: 46.617897033691406 | MAE Test Loss: 44.32487869262695 \n",
      "Epoch: 41680 | MAE Train Loss: 46.61677932739258 | MAE Test Loss: 44.324031829833984 \n",
      "Epoch: 41690 | MAE Train Loss: 46.61566162109375 | MAE Test Loss: 44.32322692871094 \n",
      "Epoch: 41700 | MAE Train Loss: 46.61454391479492 | MAE Test Loss: 44.322383880615234 \n",
      "Epoch: 41710 | MAE Train Loss: 46.61343002319336 | MAE Test Loss: 44.3215446472168 \n",
      "Epoch: 41720 | MAE Train Loss: 46.612308502197266 | MAE Test Loss: 44.320735931396484 \n",
      "Epoch: 41730 | MAE Train Loss: 46.6111946105957 | MAE Test Loss: 44.31989288330078 \n",
      "Epoch: 41740 | MAE Train Loss: 46.610084533691406 | MAE Test Loss: 44.31904983520508 \n",
      "Epoch: 41750 | MAE Train Loss: 46.60896682739258 | MAE Test Loss: 44.3182258605957 \n",
      "Epoch: 41760 | MAE Train Loss: 46.60784912109375 | MAE Test Loss: 44.317420959472656 \n",
      "Epoch: 41770 | MAE Train Loss: 46.60673522949219 | MAE Test Loss: 44.31657791137695 \n",
      "Epoch: 41780 | MAE Train Loss: 46.605613708496094 | MAE Test Loss: 44.315738677978516 \n",
      "Epoch: 41790 | MAE Train Loss: 46.60449981689453 | MAE Test Loss: 44.3149299621582 \n",
      "Epoch: 41800 | MAE Train Loss: 46.603389739990234 | MAE Test Loss: 44.3140869140625 \n",
      "Epoch: 41810 | MAE Train Loss: 46.602272033691406 | MAE Test Loss: 44.31324768066406 \n",
      "Epoch: 41820 | MAE Train Loss: 46.60115432739258 | MAE Test Loss: 44.312416076660156 \n",
      "Epoch: 41830 | MAE Train Loss: 46.60003662109375 | MAE Test Loss: 44.31161117553711 \n",
      "Epoch: 41840 | MAE Train Loss: 46.59892272949219 | MAE Test Loss: 44.31077194213867 \n",
      "Epoch: 41850 | MAE Train Loss: 46.597801208496094 | MAE Test Loss: 44.3099250793457 \n",
      "Epoch: 41860 | MAE Train Loss: 46.59668731689453 | MAE Test Loss: 44.30912399291992 \n",
      "Epoch: 41870 | MAE Train Loss: 46.5955696105957 | MAE Test Loss: 44.30828094482422 \n",
      "Epoch: 41880 | MAE Train Loss: 46.594451904296875 | MAE Test Loss: 44.307456970214844 \n",
      "Epoch: 41890 | MAE Train Loss: 46.59333419799805 | MAE Test Loss: 44.30661392211914 \n",
      "Epoch: 41900 | MAE Train Loss: 46.59222412109375 | MAE Test Loss: 44.305809020996094 \n",
      "Epoch: 41910 | MAE Train Loss: 46.59111022949219 | MAE Test Loss: 44.30496597290039 \n",
      "Epoch: 41920 | MAE Train Loss: 46.589988708496094 | MAE Test Loss: 44.30412292480469 \n",
      "Epoch: 41930 | MAE Train Loss: 46.58887481689453 | MAE Test Loss: 44.303314208984375 \n",
      "Epoch: 41940 | MAE Train Loss: 46.5877571105957 | MAE Test Loss: 44.30247497558594 \n",
      "Epoch: 41950 | MAE Train Loss: 46.586639404296875 | MAE Test Loss: 44.301666259765625 \n",
      "Epoch: 41960 | MAE Train Loss: 46.58552932739258 | MAE Test Loss: 44.30082321166992 \n",
      "Epoch: 41970 | MAE Train Loss: 46.58441162109375 | MAE Test Loss: 44.299983978271484 \n",
      "Epoch: 41980 | MAE Train Loss: 46.58329391479492 | MAE Test Loss: 44.29917526245117 \n",
      "Epoch: 41990 | MAE Train Loss: 46.58218002319336 | MAE Test Loss: 44.298336029052734 \n",
      "Epoch: 42000 | MAE Train Loss: 46.58106231689453 | MAE Test Loss: 44.29749298095703 \n",
      "Epoch: 42010 | MAE Train Loss: 46.5799446105957 | MAE Test Loss: 44.29668426513672 \n",
      "Epoch: 42020 | MAE Train Loss: 46.578826904296875 | MAE Test Loss: 44.295841217041016 \n",
      "Epoch: 42030 | MAE Train Loss: 46.57771682739258 | MAE Test Loss: 44.2950325012207 \n",
      "Epoch: 42040 | MAE Train Loss: 46.57659912109375 | MAE Test Loss: 44.294193267822266 \n",
      "Epoch: 42050 | MAE Train Loss: 46.57548141479492 | MAE Test Loss: 44.293365478515625 \n",
      "Epoch: 42060 | MAE Train Loss: 46.57438659667969 | MAE Test Loss: 44.29251480102539 \n",
      "Epoch: 42070 | MAE Train Loss: 46.573307037353516 | MAE Test Loss: 44.29164123535156 \n",
      "Epoch: 42080 | MAE Train Loss: 46.57221984863281 | MAE Test Loss: 44.290794372558594 \n",
      "Epoch: 42090 | MAE Train Loss: 46.571144104003906 | MAE Test Loss: 44.289955139160156 \n",
      "Epoch: 42100 | MAE Train Loss: 46.5700569152832 | MAE Test Loss: 44.28907775878906 \n",
      "Epoch: 42110 | MAE Train Loss: 46.56897735595703 | MAE Test Loss: 44.28823471069336 \n",
      "Epoch: 42120 | MAE Train Loss: 46.567901611328125 | MAE Test Loss: 44.28736114501953 \n",
      "Epoch: 42130 | MAE Train Loss: 46.566810607910156 | MAE Test Loss: 44.28651809692383 \n",
      "Epoch: 42140 | MAE Train Loss: 46.565731048583984 | MAE Test Loss: 44.285640716552734 \n",
      "Epoch: 42150 | MAE Train Loss: 46.56465148925781 | MAE Test Loss: 44.2848014831543 \n",
      "Epoch: 42160 | MAE Train Loss: 46.563568115234375 | MAE Test Loss: 44.2839241027832 \n",
      "Epoch: 42170 | MAE Train Loss: 46.5624885559082 | MAE Test Loss: 44.2830810546875 \n",
      "Epoch: 42180 | MAE Train Loss: 46.561405181884766 | MAE Test Loss: 44.2822380065918 \n",
      "Epoch: 42190 | MAE Train Loss: 46.560325622558594 | MAE Test Loss: 44.28136444091797 \n",
      "Epoch: 42200 | MAE Train Loss: 46.559242248535156 | MAE Test Loss: 44.280517578125 \n",
      "Epoch: 42210 | MAE Train Loss: 46.55815505981445 | MAE Test Loss: 44.27964782714844 \n",
      "Epoch: 42220 | MAE Train Loss: 46.55707931518555 | MAE Test Loss: 44.27880096435547 \n",
      "Epoch: 42230 | MAE Train Loss: 46.555992126464844 | MAE Test Loss: 44.27792739868164 \n",
      "Epoch: 42240 | MAE Train Loss: 46.5549201965332 | MAE Test Loss: 44.27708435058594 \n",
      "Epoch: 42250 | MAE Train Loss: 46.553836822509766 | MAE Test Loss: 44.27621078491211 \n",
      "Epoch: 42260 | MAE Train Loss: 46.552757263183594 | MAE Test Loss: 44.275367736816406 \n",
      "Epoch: 42270 | MAE Train Loss: 46.551673889160156 | MAE Test Loss: 44.27449417114258 \n",
      "Epoch: 42280 | MAE Train Loss: 46.55058670043945 | MAE Test Loss: 44.27364730834961 \n",
      "Epoch: 42290 | MAE Train Loss: 46.549503326416016 | MAE Test Loss: 44.27280807495117 \n",
      "Epoch: 42300 | MAE Train Loss: 46.548423767089844 | MAE Test Loss: 44.27192687988281 \n",
      "Epoch: 42310 | MAE Train Loss: 46.54734420776367 | MAE Test Loss: 44.271087646484375 \n",
      "Epoch: 42320 | MAE Train Loss: 46.5462646484375 | MAE Test Loss: 44.27021026611328 \n",
      "Epoch: 42330 | MAE Train Loss: 46.54518127441406 | MAE Test Loss: 44.269371032714844 \n",
      "Epoch: 42340 | MAE Train Loss: 46.54410171508789 | MAE Test Loss: 44.268497467041016 \n",
      "Epoch: 42350 | MAE Train Loss: 46.54301834106445 | MAE Test Loss: 44.26765060424805 \n",
      "Epoch: 42360 | MAE Train Loss: 46.541934967041016 | MAE Test Loss: 44.26677703857422 \n",
      "Epoch: 42370 | MAE Train Loss: 46.540855407714844 | MAE Test Loss: 44.265933990478516 \n",
      "Epoch: 42380 | MAE Train Loss: 46.539772033691406 | MAE Test Loss: 44.26508712768555 \n",
      "Epoch: 42390 | MAE Train Loss: 46.538692474365234 | MAE Test Loss: 44.26421356201172 \n",
      "Epoch: 42400 | MAE Train Loss: 46.53761291503906 | MAE Test Loss: 44.263370513916016 \n",
      "Epoch: 42410 | MAE Train Loss: 46.536529541015625 | MAE Test Loss: 44.26249694824219 \n",
      "Epoch: 42420 | MAE Train Loss: 46.53544998168945 | MAE Test Loss: 44.261653900146484 \n",
      "Epoch: 42430 | MAE Train Loss: 46.534366607666016 | MAE Test Loss: 44.26077651977539 \n",
      "Epoch: 42440 | MAE Train Loss: 46.533287048339844 | MAE Test Loss: 44.25993728637695 \n",
      "Epoch: 42450 | MAE Train Loss: 46.53219985961914 | MAE Test Loss: 44.25905990600586 \n",
      "Epoch: 42460 | MAE Train Loss: 46.5311164855957 | MAE Test Loss: 44.258216857910156 \n",
      "Epoch: 42470 | MAE Train Loss: 46.53003692626953 | MAE Test Loss: 44.25736999511719 \n",
      "Epoch: 42480 | MAE Train Loss: 46.528961181640625 | MAE Test Loss: 44.256500244140625 \n",
      "Epoch: 42490 | MAE Train Loss: 46.52787399291992 | MAE Test Loss: 44.255653381347656 \n",
      "Epoch: 42500 | MAE Train Loss: 46.52679443359375 | MAE Test Loss: 44.254783630371094 \n",
      "Epoch: 42510 | MAE Train Loss: 46.52571105957031 | MAE Test Loss: 44.253936767578125 \n",
      "Epoch: 42520 | MAE Train Loss: 46.524627685546875 | MAE Test Loss: 44.2530632019043 \n",
      "Epoch: 42530 | MAE Train Loss: 46.5235481262207 | MAE Test Loss: 44.252220153808594 \n",
      "Epoch: 42540 | MAE Train Loss: 46.522464752197266 | MAE Test Loss: 44.25135040283203 \n",
      "Epoch: 42550 | MAE Train Loss: 46.521385192871094 | MAE Test Loss: 44.25050354003906 \n",
      "Epoch: 42560 | MAE Train Loss: 46.520301818847656 | MAE Test Loss: 44.249656677246094 \n",
      "Epoch: 42570 | MAE Train Loss: 46.519222259521484 | MAE Test Loss: 44.248783111572266 \n",
      "Epoch: 42580 | MAE Train Loss: 46.51813507080078 | MAE Test Loss: 44.24794387817383 \n",
      "Epoch: 42590 | MAE Train Loss: 46.51706314086914 | MAE Test Loss: 44.247066497802734 \n",
      "Epoch: 42600 | MAE Train Loss: 46.5159797668457 | MAE Test Loss: 44.246219635009766 \n",
      "Epoch: 42610 | MAE Train Loss: 46.514896392822266 | MAE Test Loss: 44.24534606933594 \n",
      "Epoch: 42620 | MAE Train Loss: 46.513816833496094 | MAE Test Loss: 44.2445068359375 \n",
      "Epoch: 42630 | MAE Train Loss: 46.51272964477539 | MAE Test Loss: 44.243629455566406 \n",
      "Epoch: 42640 | MAE Train Loss: 46.511653900146484 | MAE Test Loss: 44.2427864074707 \n",
      "Epoch: 42650 | MAE Train Loss: 46.51056671142578 | MAE Test Loss: 44.241912841796875 \n",
      "Epoch: 42660 | MAE Train Loss: 46.509483337402344 | MAE Test Loss: 44.24106979370117 \n",
      "Epoch: 42670 | MAE Train Loss: 46.50840377807617 | MAE Test Loss: 44.2402229309082 \n",
      "Epoch: 42680 | MAE Train Loss: 46.507320404052734 | MAE Test Loss: 44.23935317993164 \n",
      "Epoch: 42690 | MAE Train Loss: 46.50624084472656 | MAE Test Loss: 44.23850631713867 \n",
      "Epoch: 42700 | MAE Train Loss: 46.50516128540039 | MAE Test Loss: 44.237632751464844 \n",
      "Epoch: 42710 | MAE Train Loss: 46.50407791137695 | MAE Test Loss: 44.23678970336914 \n",
      "Epoch: 42720 | MAE Train Loss: 46.502994537353516 | MAE Test Loss: 44.23591232299805 \n",
      "Epoch: 42730 | MAE Train Loss: 46.50191879272461 | MAE Test Loss: 44.23507308959961 \n",
      "Epoch: 42740 | MAE Train Loss: 46.500831604003906 | MAE Test Loss: 44.234195709228516 \n",
      "Epoch: 42750 | MAE Train Loss: 46.499755859375 | MAE Test Loss: 44.23334884643555 \n",
      "Epoch: 42760 | MAE Train Loss: 46.49866485595703 | MAE Test Loss: 44.232505798339844 \n",
      "Epoch: 42770 | MAE Train Loss: 46.49759292602539 | MAE Test Loss: 44.231632232666016 \n",
      "Epoch: 42780 | MAE Train Loss: 46.49650955200195 | MAE Test Loss: 44.23078536987305 \n",
      "Epoch: 42790 | MAE Train Loss: 46.49542236328125 | MAE Test Loss: 44.229915618896484 \n",
      "Epoch: 42800 | MAE Train Loss: 46.494346618652344 | MAE Test Loss: 44.229068756103516 \n",
      "Epoch: 42810 | MAE Train Loss: 46.49325942993164 | MAE Test Loss: 44.22819900512695 \n",
      "Epoch: 42820 | MAE Train Loss: 46.492183685302734 | MAE Test Loss: 44.227359771728516 \n",
      "Epoch: 42830 | MAE Train Loss: 46.49109649658203 | MAE Test Loss: 44.22648239135742 \n",
      "Epoch: 42840 | MAE Train Loss: 46.49001693725586 | MAE Test Loss: 44.22563552856445 \n",
      "Epoch: 42850 | MAE Train Loss: 46.48893356323242 | MAE Test Loss: 44.224788665771484 \n",
      "Epoch: 42860 | MAE Train Loss: 46.48786163330078 | MAE Test Loss: 44.223915100097656 \n",
      "Epoch: 42870 | MAE Train Loss: 46.48677062988281 | MAE Test Loss: 44.22307586669922 \n",
      "Epoch: 42880 | MAE Train Loss: 46.48569107055664 | MAE Test Loss: 44.22220230102539 \n",
      "Epoch: 42890 | MAE Train Loss: 46.48461151123047 | MAE Test Loss: 44.22135543823242 \n",
      "Epoch: 42900 | MAE Train Loss: 46.48352813720703 | MAE Test Loss: 44.220481872558594 \n",
      "Epoch: 42910 | MAE Train Loss: 46.48244857788086 | MAE Test Loss: 44.21963882446289 \n",
      "Epoch: 42920 | MAE Train Loss: 46.48136520385742 | MAE Test Loss: 44.21876525878906 \n",
      "Epoch: 42930 | MAE Train Loss: 46.480281829833984 | MAE Test Loss: 44.21792221069336 \n",
      "Epoch: 42940 | MAE Train Loss: 46.47919464111328 | MAE Test Loss: 44.21707534790039 \n",
      "Epoch: 42950 | MAE Train Loss: 46.47812271118164 | MAE Test Loss: 44.21620178222656 \n",
      "Epoch: 42960 | MAE Train Loss: 46.47703170776367 | MAE Test Loss: 44.215362548828125 \n",
      "Epoch: 42970 | MAE Train Loss: 46.4759521484375 | MAE Test Loss: 44.21448516845703 \n",
      "Epoch: 42980 | MAE Train Loss: 46.474876403808594 | MAE Test Loss: 44.21364212036133 \n",
      "Epoch: 42990 | MAE Train Loss: 46.47378921508789 | MAE Test Loss: 44.2127685546875 \n",
      "Epoch: 43000 | MAE Train Loss: 46.472713470458984 | MAE Test Loss: 44.211917877197266 \n",
      "Epoch: 43010 | MAE Train Loss: 46.47162628173828 | MAE Test Loss: 44.2110481262207 \n",
      "Epoch: 43020 | MAE Train Loss: 46.47054672241211 | MAE Test Loss: 44.210205078125 \n",
      "Epoch: 43030 | MAE Train Loss: 46.46946334838867 | MAE Test Loss: 44.20933532714844 \n",
      "Epoch: 43040 | MAE Train Loss: 46.4683837890625 | MAE Test Loss: 44.208492279052734 \n",
      "Epoch: 43050 | MAE Train Loss: 46.46730041503906 | MAE Test Loss: 44.2076416015625 \n",
      "Epoch: 43060 | MAE Train Loss: 46.46622085571289 | MAE Test Loss: 44.20677185058594 \n",
      "Epoch: 43070 | MAE Train Loss: 46.46514129638672 | MAE Test Loss: 44.20592498779297 \n",
      "Epoch: 43080 | MAE Train Loss: 46.46405792236328 | MAE Test Loss: 44.205055236816406 \n",
      "Epoch: 43090 | MAE Train Loss: 46.462974548339844 | MAE Test Loss: 44.20420837402344 \n",
      "Epoch: 43100 | MAE Train Loss: 46.46189498901367 | MAE Test Loss: 44.20333480834961 \n",
      "Epoch: 43110 | MAE Train Loss: 46.4608154296875 | MAE Test Loss: 44.20248794555664 \n",
      "Epoch: 43120 | MAE Train Loss: 46.45973205566406 | MAE Test Loss: 44.20161819458008 \n",
      "Epoch: 43130 | MAE Train Loss: 46.45865249633789 | MAE Test Loss: 44.20077133178711 \n",
      "Epoch: 43140 | MAE Train Loss: 46.45756149291992 | MAE Test Loss: 44.199928283691406 \n",
      "Epoch: 43150 | MAE Train Loss: 46.45648193359375 | MAE Test Loss: 44.19905471801758 \n",
      "Epoch: 43160 | MAE Train Loss: 46.455406188964844 | MAE Test Loss: 44.198211669921875 \n",
      "Epoch: 43170 | MAE Train Loss: 46.45431900024414 | MAE Test Loss: 44.19733810424805 \n",
      "Epoch: 43180 | MAE Train Loss: 46.45323944091797 | MAE Test Loss: 44.19649124145508 \n",
      "Epoch: 43190 | MAE Train Loss: 46.45215606689453 | MAE Test Loss: 44.195621490478516 \n",
      "Epoch: 43200 | MAE Train Loss: 46.45107650756836 | MAE Test Loss: 44.19477462768555 \n",
      "Epoch: 43210 | MAE Train Loss: 46.44999313354492 | MAE Test Loss: 44.19390106201172 \n",
      "Epoch: 43220 | MAE Train Loss: 46.44891357421875 | MAE Test Loss: 44.193058013916016 \n",
      "Epoch: 43230 | MAE Train Loss: 46.44783020019531 | MAE Test Loss: 44.19221115112305 \n",
      "Epoch: 43240 | MAE Train Loss: 46.44675064086914 | MAE Test Loss: 44.191341400146484 \n",
      "Epoch: 43250 | MAE Train Loss: 46.44567108154297 | MAE Test Loss: 44.190494537353516 \n",
      "Epoch: 43260 | MAE Train Loss: 46.44458770751953 | MAE Test Loss: 44.18962097167969 \n",
      "Epoch: 43270 | MAE Train Loss: 46.44350814819336 | MAE Test Loss: 44.18877410888672 \n",
      "Epoch: 43280 | MAE Train Loss: 46.44242477416992 | MAE Test Loss: 44.187904357910156 \n",
      "Epoch: 43290 | MAE Train Loss: 46.441341400146484 | MAE Test Loss: 44.187042236328125 \n",
      "Epoch: 43300 | MAE Train Loss: 46.44026184082031 | MAE Test Loss: 44.18620300292969 \n",
      "Epoch: 43310 | MAE Train Loss: 46.43917465209961 | MAE Test Loss: 44.185325622558594 \n",
      "Epoch: 43320 | MAE Train Loss: 46.4380989074707 | MAE Test Loss: 44.184478759765625 \n",
      "Epoch: 43330 | MAE Train Loss: 46.43701171875 | MAE Test Loss: 44.183624267578125 \n",
      "Epoch: 43340 | MAE Train Loss: 46.435935974121094 | MAE Test Loss: 44.182777404785156 \n",
      "Epoch: 43350 | MAE Train Loss: 46.43485641479492 | MAE Test Loss: 44.181907653808594 \n",
      "Epoch: 43360 | MAE Train Loss: 46.43376922607422 | MAE Test Loss: 44.181060791015625 \n",
      "Epoch: 43370 | MAE Train Loss: 46.43268585205078 | MAE Test Loss: 44.180198669433594 \n",
      "Epoch: 43380 | MAE Train Loss: 46.431602478027344 | MAE Test Loss: 44.1793327331543 \n",
      "Epoch: 43390 | MAE Train Loss: 46.43052673339844 | MAE Test Loss: 44.17848205566406 \n",
      "Epoch: 43400 | MAE Train Loss: 46.429443359375 | MAE Test Loss: 44.177608489990234 \n",
      "Epoch: 43410 | MAE Train Loss: 46.42835998535156 | MAE Test Loss: 44.17675018310547 \n",
      "Epoch: 43420 | MAE Train Loss: 46.42728042602539 | MAE Test Loss: 44.17591094970703 \n",
      "Epoch: 43430 | MAE Train Loss: 46.42620086669922 | MAE Test Loss: 44.17506408691406 \n",
      "Epoch: 43440 | MAE Train Loss: 46.42511749267578 | MAE Test Loss: 44.174190521240234 \n",
      "Epoch: 43450 | MAE Train Loss: 46.424034118652344 | MAE Test Loss: 44.1733283996582 \n",
      "Epoch: 43460 | MAE Train Loss: 46.42295455932617 | MAE Test Loss: 44.1724853515625 \n",
      "Epoch: 43470 | MAE Train Loss: 46.421875 | MAE Test Loss: 44.17161178588867 \n",
      "Epoch: 43480 | MAE Train Loss: 46.42079162597656 | MAE Test Loss: 44.17075729370117 \n",
      "Epoch: 43490 | MAE Train Loss: 46.41971206665039 | MAE Test Loss: 44.1699104309082 \n",
      "Epoch: 43500 | MAE Train Loss: 46.41862869262695 | MAE Test Loss: 44.169036865234375 \n",
      "Epoch: 43510 | MAE Train Loss: 46.41754913330078 | MAE Test Loss: 44.16819381713867 \n",
      "Epoch: 43520 | MAE Train Loss: 46.41645812988281 | MAE Test Loss: 44.1673469543457 \n",
      "Epoch: 43530 | MAE Train Loss: 46.41537857055664 | MAE Test Loss: 44.16647720336914 \n",
      "Epoch: 43540 | MAE Train Loss: 46.41429901123047 | MAE Test Loss: 44.16563034057617 \n",
      "Epoch: 43550 | MAE Train Loss: 46.41322326660156 | MAE Test Loss: 44.164756774902344 \n",
      "Epoch: 43560 | MAE Train Loss: 46.412139892578125 | MAE Test Loss: 44.16391372680664 \n",
      "Epoch: 43570 | MAE Train Loss: 46.41105651855469 | MAE Test Loss: 44.16303634643555 \n",
      "Epoch: 43580 | MAE Train Loss: 46.40997314453125 | MAE Test Loss: 44.162193298339844 \n",
      "Epoch: 43590 | MAE Train Loss: 46.40888977050781 | MAE Test Loss: 44.161319732666016 \n",
      "Epoch: 43600 | MAE Train Loss: 46.407814025878906 | MAE Test Loss: 44.16048049926758 \n",
      "Epoch: 43610 | MAE Train Loss: 46.4067268371582 | MAE Test Loss: 44.15963363647461 \n",
      "Epoch: 43620 | MAE Train Loss: 46.40564727783203 | MAE Test Loss: 44.158756256103516 \n",
      "Epoch: 43630 | MAE Train Loss: 46.40456771850586 | MAE Test Loss: 44.15791320800781 \n",
      "Epoch: 43640 | MAE Train Loss: 46.40348434448242 | MAE Test Loss: 44.15704345703125 \n",
      "Epoch: 43650 | MAE Train Loss: 46.40240478515625 | MAE Test Loss: 44.15620040893555 \n",
      "Epoch: 43660 | MAE Train Loss: 46.40132141113281 | MAE Test Loss: 44.15531921386719 \n",
      "Epoch: 43670 | MAE Train Loss: 46.40024185180664 | MAE Test Loss: 44.154476165771484 \n",
      "Epoch: 43680 | MAE Train Loss: 46.3991584777832 | MAE Test Loss: 44.15361022949219 \n",
      "Epoch: 43690 | MAE Train Loss: 46.39807891845703 | MAE Test Loss: 44.15275955200195 \n",
      "Epoch: 43700 | MAE Train Loss: 46.39699172973633 | MAE Test Loss: 44.151912689208984 \n",
      "Epoch: 43710 | MAE Train Loss: 46.39591598510742 | MAE Test Loss: 44.15104293823242 \n",
      "Epoch: 43720 | MAE Train Loss: 46.39482879638672 | MAE Test Loss: 44.15019607543945 \n",
      "Epoch: 43730 | MAE Train Loss: 46.39374923706055 | MAE Test Loss: 44.14932632446289 \n",
      "Epoch: 43740 | MAE Train Loss: 46.392669677734375 | MAE Test Loss: 44.14848327636719 \n",
      "Epoch: 43750 | MAE Train Loss: 46.39158630371094 | MAE Test Loss: 44.147605895996094 \n",
      "Epoch: 43760 | MAE Train Loss: 46.3905029296875 | MAE Test Loss: 44.14676284790039 \n",
      "Epoch: 43770 | MAE Train Loss: 46.38941955566406 | MAE Test Loss: 44.14588928222656 \n",
      "Epoch: 43780 | MAE Train Loss: 46.388343811035156 | MAE Test Loss: 44.14504623413086 \n",
      "Epoch: 43790 | MAE Train Loss: 46.38725662231445 | MAE Test Loss: 44.14417266845703 \n",
      "Epoch: 43800 | MAE Train Loss: 46.38617706298828 | MAE Test Loss: 44.14332580566406 \n",
      "Epoch: 43810 | MAE Train Loss: 46.38509750366211 | MAE Test Loss: 44.14248275756836 \n",
      "Epoch: 43820 | MAE Train Loss: 46.38401412963867 | MAE Test Loss: 44.14160919189453 \n",
      "Epoch: 43830 | MAE Train Loss: 46.3829345703125 | MAE Test Loss: 44.14076232910156 \n",
      "Epoch: 43840 | MAE Train Loss: 46.3818473815918 | MAE Test Loss: 44.139888763427734 \n",
      "Epoch: 43850 | MAE Train Loss: 46.38077163696289 | MAE Test Loss: 44.13904571533203 \n",
      "Epoch: 43860 | MAE Train Loss: 46.37968826293945 | MAE Test Loss: 44.13817596435547 \n",
      "Epoch: 43870 | MAE Train Loss: 46.37860870361328 | MAE Test Loss: 44.1373291015625 \n",
      "Epoch: 43880 | MAE Train Loss: 46.37752151489258 | MAE Test Loss: 44.13645553588867 \n",
      "Epoch: 43890 | MAE Train Loss: 46.37644577026367 | MAE Test Loss: 44.1356086730957 \n",
      "Epoch: 43900 | MAE Train Loss: 46.37535858154297 | MAE Test Loss: 44.134769439697266 \n",
      "Epoch: 43910 | MAE Train Loss: 46.3742790222168 | MAE Test Loss: 44.13389587402344 \n",
      "Epoch: 43920 | MAE Train Loss: 46.37319564819336 | MAE Test Loss: 44.13304901123047 \n",
      "Epoch: 43930 | MAE Train Loss: 46.37211608886719 | MAE Test Loss: 44.13217544555664 \n",
      "Epoch: 43940 | MAE Train Loss: 46.371036529541016 | MAE Test Loss: 44.13133239746094 \n",
      "Epoch: 43950 | MAE Train Loss: 46.36994552612305 | MAE Test Loss: 44.13045883178711 \n",
      "Epoch: 43960 | MAE Train Loss: 46.36887741088867 | MAE Test Loss: 44.129615783691406 \n",
      "Epoch: 43970 | MAE Train Loss: 46.36779022216797 | MAE Test Loss: 44.12874221801758 \n",
      "Epoch: 43980 | MAE Train Loss: 46.36670684814453 | MAE Test Loss: 44.12789535522461 \n",
      "Epoch: 43990 | MAE Train Loss: 46.365623474121094 | MAE Test Loss: 44.12705612182617 \n",
      "Epoch: 44000 | MAE Train Loss: 46.36457824707031 | MAE Test Loss: 44.12626647949219 \n",
      "Epoch: 44010 | MAE Train Loss: 46.36354064941406 | MAE Test Loss: 44.12553405761719 \n",
      "Epoch: 44020 | MAE Train Loss: 46.36250305175781 | MAE Test Loss: 44.124778747558594 \n",
      "Epoch: 44030 | MAE Train Loss: 46.3614616394043 | MAE Test Loss: 44.124046325683594 \n",
      "Epoch: 44040 | MAE Train Loss: 46.360416412353516 | MAE Test Loss: 44.123294830322266 \n",
      "Epoch: 44050 | MAE Train Loss: 46.359378814697266 | MAE Test Loss: 44.1225471496582 \n",
      "Epoch: 44060 | MAE Train Loss: 46.358341217041016 | MAE Test Loss: 44.12179183959961 \n",
      "Epoch: 44070 | MAE Train Loss: 46.3572998046875 | MAE Test Loss: 44.12104034423828 \n",
      "Epoch: 44080 | MAE Train Loss: 46.356266021728516 | MAE Test Loss: 44.12029266357422 \n",
      "Epoch: 44090 | MAE Train Loss: 46.355220794677734 | MAE Test Loss: 44.11952209472656 \n",
      "Epoch: 44100 | MAE Train Loss: 46.35417556762695 | MAE Test Loss: 44.118770599365234 \n",
      "Epoch: 44110 | MAE Train Loss: 46.3531379699707 | MAE Test Loss: 44.1180534362793 \n",
      "Epoch: 44120 | MAE Train Loss: 46.35210037231445 | MAE Test Loss: 44.117305755615234 \n",
      "Epoch: 44130 | MAE Train Loss: 46.35105895996094 | MAE Test Loss: 44.11655044555664 \n",
      "Epoch: 44140 | MAE Train Loss: 46.35002517700195 | MAE Test Loss: 44.11580276489258 \n",
      "Epoch: 44150 | MAE Train Loss: 46.34897994995117 | MAE Test Loss: 44.11503219604492 \n",
      "Epoch: 44160 | MAE Train Loss: 46.347938537597656 | MAE Test Loss: 44.114280700683594 \n",
      "Epoch: 44170 | MAE Train Loss: 46.34690475463867 | MAE Test Loss: 44.113529205322266 \n",
      "Epoch: 44180 | MAE Train Loss: 46.345863342285156 | MAE Test Loss: 44.11277770996094 \n",
      "Epoch: 44190 | MAE Train Loss: 46.34482192993164 | MAE Test Loss: 44.11202621459961 \n",
      "Epoch: 44200 | MAE Train Loss: 46.34377670288086 | MAE Test Loss: 44.11127853393555 \n",
      "Epoch: 44210 | MAE Train Loss: 46.34273910522461 | MAE Test Loss: 44.11054229736328 \n",
      "Epoch: 44220 | MAE Train Loss: 46.34170150756836 | MAE Test Loss: 44.10979080200195 \n",
      "Epoch: 44230 | MAE Train Loss: 46.34066390991211 | MAE Test Loss: 44.10904312133789 \n",
      "Epoch: 44240 | MAE Train Loss: 46.33961868286133 | MAE Test Loss: 44.1082878112793 \n",
      "Epoch: 44250 | MAE Train Loss: 46.33858108520508 | MAE Test Loss: 44.10753631591797 \n",
      "Epoch: 44260 | MAE Train Loss: 46.33754348754883 | MAE Test Loss: 44.10678482055664 \n",
      "Epoch: 44270 | MAE Train Loss: 46.33649826049805 | MAE Test Loss: 44.10603713989258 \n",
      "Epoch: 44280 | MAE Train Loss: 46.3354606628418 | MAE Test Loss: 44.10528564453125 \n",
      "Epoch: 44290 | MAE Train Loss: 46.334415435791016 | MAE Test Loss: 44.104530334472656 \n",
      "Epoch: 44300 | MAE Train Loss: 46.3333740234375 | MAE Test Loss: 44.10377883911133 \n",
      "Epoch: 44310 | MAE Train Loss: 46.33233642578125 | MAE Test Loss: 44.103031158447266 \n",
      "Epoch: 44320 | MAE Train Loss: 46.331302642822266 | MAE Test Loss: 44.10231018066406 \n",
      "Epoch: 44330 | MAE Train Loss: 46.330265045166016 | MAE Test Loss: 44.101558685302734 \n",
      "Epoch: 44340 | MAE Train Loss: 46.329219818115234 | MAE Test Loss: 44.10081100463867 \n",
      "Epoch: 44350 | MAE Train Loss: 46.328182220458984 | MAE Test Loss: 44.10005569458008 \n",
      "Epoch: 44360 | MAE Train Loss: 46.32714080810547 | MAE Test Loss: 44.09928894042969 \n",
      "Epoch: 44370 | MAE Train Loss: 46.32609939575195 | MAE Test Loss: 44.098541259765625 \n",
      "Epoch: 44380 | MAE Train Loss: 46.32505798339844 | MAE Test Loss: 44.0977897644043 \n",
      "Epoch: 44390 | MAE Train Loss: 46.32401657104492 | MAE Test Loss: 44.0970344543457 \n",
      "Epoch: 44400 | MAE Train Loss: 46.322975158691406 | MAE Test Loss: 44.096282958984375 \n",
      "Epoch: 44410 | MAE Train Loss: 46.321937561035156 | MAE Test Loss: 44.09553527832031 \n",
      "Epoch: 44420 | MAE Train Loss: 46.320899963378906 | MAE Test Loss: 44.09479904174805 \n",
      "Epoch: 44430 | MAE Train Loss: 46.31985855102539 | MAE Test Loss: 44.09404754638672 \n",
      "Epoch: 44440 | MAE Train Loss: 46.31882095336914 | MAE Test Loss: 44.09329605102539 \n",
      "Epoch: 44450 | MAE Train Loss: 46.317779541015625 | MAE Test Loss: 44.09254837036133 \n",
      "Epoch: 44460 | MAE Train Loss: 46.31673812866211 | MAE Test Loss: 44.091793060302734 \n",
      "Epoch: 44470 | MAE Train Loss: 46.31570053100586 | MAE Test Loss: 44.091041564941406 \n",
      "Epoch: 44480 | MAE Train Loss: 46.314666748046875 | MAE Test Loss: 44.090293884277344 \n",
      "Epoch: 44490 | MAE Train Loss: 46.31361770629883 | MAE Test Loss: 44.08953857421875 \n",
      "Epoch: 44500 | MAE Train Loss: 46.31258010864258 | MAE Test Loss: 44.08879089355469 \n",
      "Epoch: 44510 | MAE Train Loss: 46.31153869628906 | MAE Test Loss: 44.08803939819336 \n",
      "Epoch: 44520 | MAE Train Loss: 46.31049728393555 | MAE Test Loss: 44.08732223510742 \n",
      "Epoch: 44530 | MAE Train Loss: 46.3094596862793 | MAE Test Loss: 44.08656692504883 \n",
      "Epoch: 44540 | MAE Train Loss: 46.30841827392578 | MAE Test Loss: 44.0858154296875 \n",
      "Epoch: 44550 | MAE Train Loss: 46.307376861572266 | MAE Test Loss: 44.08506393432617 \n",
      "Epoch: 44560 | MAE Train Loss: 46.30634307861328 | MAE Test Loss: 44.08430099487305 \n",
      "Epoch: 44570 | MAE Train Loss: 46.3052978515625 | MAE Test Loss: 44.08354568481445 \n",
      "Epoch: 44580 | MAE Train Loss: 46.30426025390625 | MAE Test Loss: 44.082794189453125 \n",
      "Epoch: 44590 | MAE Train Loss: 46.30322265625 | MAE Test Loss: 44.0820426940918 \n",
      "Epoch: 44600 | MAE Train Loss: 46.30217742919922 | MAE Test Loss: 44.081295013427734 \n",
      "Epoch: 44610 | MAE Train Loss: 46.3011360168457 | MAE Test Loss: 44.080543518066406 \n",
      "Epoch: 44620 | MAE Train Loss: 46.30009460449219 | MAE Test Loss: 44.079811096191406 \n",
      "Epoch: 44630 | MAE Train Loss: 46.2990608215332 | MAE Test Loss: 44.07905578613281 \n",
      "Epoch: 44640 | MAE Train Loss: 46.29801940917969 | MAE Test Loss: 44.078304290771484 \n",
      "Epoch: 44650 | MAE Train Loss: 46.29698181152344 | MAE Test Loss: 44.07755661010742 \n",
      "Epoch: 44660 | MAE Train Loss: 46.29594421386719 | MAE Test Loss: 44.076805114746094 \n",
      "Epoch: 44670 | MAE Train Loss: 46.294898986816406 | MAE Test Loss: 44.0760498046875 \n",
      "Epoch: 44680 | MAE Train Loss: 46.293861389160156 | MAE Test Loss: 44.07529830932617 \n",
      "Epoch: 44690 | MAE Train Loss: 46.292823791503906 | MAE Test Loss: 44.07456588745117 \n",
      "Epoch: 44700 | MAE Train Loss: 46.29178237915039 | MAE Test Loss: 44.073814392089844 \n",
      "Epoch: 44710 | MAE Train Loss: 46.29073715209961 | MAE Test Loss: 44.07305908203125 \n",
      "Epoch: 44720 | MAE Train Loss: 46.289703369140625 | MAE Test Loss: 44.07231140136719 \n",
      "Epoch: 44730 | MAE Train Loss: 46.28866195678711 | MAE Test Loss: 44.071556091308594 \n",
      "Epoch: 44740 | MAE Train Loss: 46.28761672973633 | MAE Test Loss: 44.070804595947266 \n",
      "Epoch: 44750 | MAE Train Loss: 46.28657913208008 | MAE Test Loss: 44.0700569152832 \n",
      "Epoch: 44760 | MAE Train Loss: 46.28554153442383 | MAE Test Loss: 44.06930923461914 \n",
      "Epoch: 44770 | MAE Train Loss: 46.28450393676758 | MAE Test Loss: 44.06855392456055 \n",
      "Epoch: 44780 | MAE Train Loss: 46.2834587097168 | MAE Test Loss: 44.067806243896484 \n",
      "Epoch: 44790 | MAE Train Loss: 46.28241729736328 | MAE Test Loss: 44.067054748535156 \n",
      "Epoch: 44800 | MAE Train Loss: 46.28137969970703 | MAE Test Loss: 44.06630325317383 \n",
      "Epoch: 44810 | MAE Train Loss: 46.280338287353516 | MAE Test Loss: 44.0655517578125 \n",
      "Epoch: 44820 | MAE Train Loss: 46.279296875 | MAE Test Loss: 44.06480026245117 \n",
      "Epoch: 44830 | MAE Train Loss: 46.27825927734375 | MAE Test Loss: 44.064064025878906 \n",
      "Epoch: 44840 | MAE Train Loss: 46.277217864990234 | MAE Test Loss: 44.06331253051758 \n",
      "Epoch: 44850 | MAE Train Loss: 46.276180267333984 | MAE Test Loss: 44.062564849853516 \n",
      "Epoch: 44860 | MAE Train Loss: 46.275142669677734 | MAE Test Loss: 44.06181335449219 \n",
      "Epoch: 44870 | MAE Train Loss: 46.27410125732422 | MAE Test Loss: 44.061058044433594 \n",
      "Epoch: 44880 | MAE Train Loss: 46.2730598449707 | MAE Test Loss: 44.06031036376953 \n",
      "Epoch: 44890 | MAE Train Loss: 46.27202224731445 | MAE Test Loss: 44.0595703125 \n",
      "Epoch: 44900 | MAE Train Loss: 46.27097702026367 | MAE Test Loss: 44.05882263183594 \n",
      "Epoch: 44910 | MAE Train Loss: 46.26993942260742 | MAE Test Loss: 44.05807113647461 \n",
      "Epoch: 44920 | MAE Train Loss: 46.26890182495117 | MAE Test Loss: 44.05731964111328 \n",
      "Epoch: 44930 | MAE Train Loss: 46.267860412597656 | MAE Test Loss: 44.05656814575195 \n",
      "Epoch: 44940 | MAE Train Loss: 46.26681900024414 | MAE Test Loss: 44.05582046508789 \n",
      "Epoch: 44950 | MAE Train Loss: 46.26577377319336 | MAE Test Loss: 44.055084228515625 \n",
      "Epoch: 44960 | MAE Train Loss: 46.26473617553711 | MAE Test Loss: 44.0543327331543 \n",
      "Epoch: 44970 | MAE Train Loss: 46.26369857788086 | MAE Test Loss: 44.053585052490234 \n",
      "Epoch: 44980 | MAE Train Loss: 46.26266098022461 | MAE Test Loss: 44.052833557128906 \n",
      "Epoch: 44990 | MAE Train Loss: 46.26161575317383 | MAE Test Loss: 44.05207824707031 \n",
      "Epoch: 45000 | MAE Train Loss: 46.26057815551758 | MAE Test Loss: 44.05132293701172 \n",
      "Epoch: 45010 | MAE Train Loss: 46.25954055786133 | MAE Test Loss: 44.050575256347656 \n",
      "Epoch: 45020 | MAE Train Loss: 46.25849914550781 | MAE Test Loss: 44.049827575683594 \n",
      "Epoch: 45030 | MAE Train Loss: 46.25746154785156 | MAE Test Loss: 44.049072265625 \n",
      "Epoch: 45040 | MAE Train Loss: 46.25642013549805 | MAE Test Loss: 44.04832458496094 \n",
      "Epoch: 45050 | MAE Train Loss: 46.2553825378418 | MAE Test Loss: 44.04757308959961 \n",
      "Epoch: 45060 | MAE Train Loss: 46.25434112548828 | MAE Test Loss: 44.04682159423828 \n",
      "Epoch: 45070 | MAE Train Loss: 46.253299713134766 | MAE Test Loss: 44.04607009887695 \n",
      "Epoch: 45080 | MAE Train Loss: 46.25225830078125 | MAE Test Loss: 44.04531478881836 \n",
      "Epoch: 45090 | MAE Train Loss: 46.251216888427734 | MAE Test Loss: 44.0445671081543 \n",
      "Epoch: 45100 | MAE Train Loss: 46.25017547607422 | MAE Test Loss: 44.043827056884766 \n",
      "Epoch: 45110 | MAE Train Loss: 46.24913787841797 | MAE Test Loss: 44.04308319091797 \n",
      "Epoch: 45120 | MAE Train Loss: 46.248104095458984 | MAE Test Loss: 44.042327880859375 \n",
      "Epoch: 45130 | MAE Train Loss: 46.24705505371094 | MAE Test Loss: 44.04158020019531 \n",
      "Epoch: 45140 | MAE Train Loss: 46.24601745605469 | MAE Test Loss: 44.04082489013672 \n",
      "Epoch: 45150 | MAE Train Loss: 46.24497985839844 | MAE Test Loss: 44.04007339477539 \n",
      "Epoch: 45160 | MAE Train Loss: 46.243934631347656 | MAE Test Loss: 44.039337158203125 \n",
      "Epoch: 45170 | MAE Train Loss: 46.242897033691406 | MAE Test Loss: 44.03858947753906 \n",
      "Epoch: 45180 | MAE Train Loss: 46.241859436035156 | MAE Test Loss: 44.037837982177734 \n",
      "Epoch: 45190 | MAE Train Loss: 46.24082565307617 | MAE Test Loss: 44.03705978393555 \n",
      "Epoch: 45200 | MAE Train Loss: 46.239810943603516 | MAE Test Loss: 44.036277770996094 \n",
      "Epoch: 45210 | MAE Train Loss: 46.23881530761719 | MAE Test Loss: 44.035484313964844 \n",
      "Epoch: 45220 | MAE Train Loss: 46.2378044128418 | MAE Test Loss: 44.03470230102539 \n",
      "Epoch: 45230 | MAE Train Loss: 46.2368049621582 | MAE Test Loss: 44.03391647338867 \n",
      "Epoch: 45240 | MAE Train Loss: 46.235801696777344 | MAE Test Loss: 44.03313064575195 \n",
      "Epoch: 45250 | MAE Train Loss: 46.23479461669922 | MAE Test Loss: 44.03234100341797 \n",
      "Epoch: 45260 | MAE Train Loss: 46.233795166015625 | MAE Test Loss: 44.03156280517578 \n",
      "Epoch: 45270 | MAE Train Loss: 46.2327880859375 | MAE Test Loss: 44.0307731628418 \n",
      "Epoch: 45280 | MAE Train Loss: 46.23178482055664 | MAE Test Loss: 44.02998733520508 \n",
      "Epoch: 45290 | MAE Train Loss: 46.2308235168457 | MAE Test Loss: 44.029296875 \n",
      "Epoch: 45300 | MAE Train Loss: 46.229862213134766 | MAE Test Loss: 44.028648376464844 \n",
      "Epoch: 45310 | MAE Train Loss: 46.22890853881836 | MAE Test Loss: 44.02796173095703 \n",
      "Epoch: 45320 | MAE Train Loss: 46.22795486450195 | MAE Test Loss: 44.02730941772461 \n",
      "Epoch: 45330 | MAE Train Loss: 46.22698974609375 | MAE Test Loss: 44.02665710449219 \n",
      "Epoch: 45340 | MAE Train Loss: 46.226036071777344 | MAE Test Loss: 44.02596664428711 \n",
      "Epoch: 45350 | MAE Train Loss: 46.22508239746094 | MAE Test Loss: 44.02531814575195 \n",
      "Epoch: 45360 | MAE Train Loss: 46.224124908447266 | MAE Test Loss: 44.0246467590332 \n",
      "Epoch: 45370 | MAE Train Loss: 46.223167419433594 | MAE Test Loss: 44.02399444580078 \n",
      "Epoch: 45380 | MAE Train Loss: 46.22220993041992 | MAE Test Loss: 44.02334213256836 \n",
      "Epoch: 45390 | MAE Train Loss: 46.22125244140625 | MAE Test Loss: 44.02265167236328 \n",
      "Epoch: 45400 | MAE Train Loss: 46.220298767089844 | MAE Test Loss: 44.02201843261719 \n",
      "Epoch: 45410 | MAE Train Loss: 46.219337463378906 | MAE Test Loss: 44.021331787109375 \n",
      "Epoch: 45420 | MAE Train Loss: 46.2183837890625 | MAE Test Loss: 44.02067947387695 \n",
      "Epoch: 45430 | MAE Train Loss: 46.21742630004883 | MAE Test Loss: 44.02002716064453 \n",
      "Epoch: 45440 | MAE Train Loss: 46.216468811035156 | MAE Test Loss: 44.01934051513672 \n",
      "Epoch: 45450 | MAE Train Loss: 46.21551513671875 | MAE Test Loss: 44.0186882019043 \n",
      "Epoch: 45460 | MAE Train Loss: 46.21455764770508 | MAE Test Loss: 44.01803207397461 \n",
      "Epoch: 45470 | MAE Train Loss: 46.213600158691406 | MAE Test Loss: 44.01737976074219 \n",
      "Epoch: 45480 | MAE Train Loss: 46.21265411376953 | MAE Test Loss: 44.01669692993164 \n",
      "Epoch: 45490 | MAE Train Loss: 46.21170425415039 | MAE Test Loss: 44.0159797668457 \n",
      "Epoch: 45500 | MAE Train Loss: 46.21076202392578 | MAE Test Loss: 44.015296936035156 \n",
      "Epoch: 45510 | MAE Train Loss: 46.209815979003906 | MAE Test Loss: 44.01460647583008 \n",
      "Epoch: 45520 | MAE Train Loss: 46.20886993408203 | MAE Test Loss: 44.01392364501953 \n",
      "Epoch: 45530 | MAE Train Loss: 46.207923889160156 | MAE Test Loss: 44.013240814208984 \n",
      "Epoch: 45540 | MAE Train Loss: 46.206974029541016 | MAE Test Loss: 44.012542724609375 \n",
      "Epoch: 45550 | MAE Train Loss: 46.20602798461914 | MAE Test Loss: 44.0118522644043 \n",
      "Epoch: 45560 | MAE Train Loss: 46.20508575439453 | MAE Test Loss: 44.01116943359375 \n",
      "Epoch: 45570 | MAE Train Loss: 46.204139709472656 | MAE Test Loss: 44.01045227050781 \n",
      "Epoch: 45580 | MAE Train Loss: 46.203189849853516 | MAE Test Loss: 44.009765625 \n",
      "Epoch: 45590 | MAE Train Loss: 46.202247619628906 | MAE Test Loss: 44.00907897949219 \n",
      "Epoch: 45600 | MAE Train Loss: 46.20130157470703 | MAE Test Loss: 44.008399963378906 \n",
      "Epoch: 45610 | MAE Train Loss: 46.200355529785156 | MAE Test Loss: 44.007713317871094 \n",
      "Epoch: 45620 | MAE Train Loss: 46.19941329956055 | MAE Test Loss: 44.00702667236328 \n",
      "Epoch: 45630 | MAE Train Loss: 46.19845962524414 | MAE Test Loss: 44.00631332397461 \n",
      "Epoch: 45640 | MAE Train Loss: 46.1975212097168 | MAE Test Loss: 44.005645751953125 \n",
      "Epoch: 45650 | MAE Train Loss: 46.196571350097656 | MAE Test Loss: 44.00495910644531 \n",
      "Epoch: 45660 | MAE Train Loss: 46.19562911987305 | MAE Test Loss: 44.004241943359375 \n",
      "Epoch: 45670 | MAE Train Loss: 46.19468307495117 | MAE Test Loss: 44.00355529785156 \n",
      "Epoch: 45680 | MAE Train Loss: 46.1937370300293 | MAE Test Loss: 44.00288009643555 \n",
      "Epoch: 45690 | MAE Train Loss: 46.19279098510742 | MAE Test Loss: 44.00218963623047 \n",
      "Epoch: 45700 | MAE Train Loss: 46.19184494018555 | MAE Test Loss: 44.001502990722656 \n",
      "Epoch: 45710 | MAE Train Loss: 46.19089889526367 | MAE Test Loss: 44.00082015991211 \n",
      "Epoch: 45720 | MAE Train Loss: 46.1899528503418 | MAE Test Loss: 44.00010299682617 \n",
      "Epoch: 45730 | MAE Train Loss: 46.18900680541992 | MAE Test Loss: 43.999420166015625 \n",
      "Epoch: 45740 | MAE Train Loss: 46.18806076049805 | MAE Test Loss: 43.99873352050781 \n",
      "Epoch: 45750 | MAE Train Loss: 46.18711471557617 | MAE Test Loss: 43.998050689697266 \n",
      "Epoch: 45760 | MAE Train Loss: 46.18617630004883 | MAE Test Loss: 43.99736785888672 \n",
      "Epoch: 45770 | MAE Train Loss: 46.18522644042969 | MAE Test Loss: 43.996646881103516 \n",
      "Epoch: 45780 | MAE Train Loss: 46.18428039550781 | MAE Test Loss: 43.99596405029297 \n",
      "Epoch: 45790 | MAE Train Loss: 46.1833381652832 | MAE Test Loss: 43.995277404785156 \n",
      "Epoch: 45800 | MAE Train Loss: 46.18239212036133 | MAE Test Loss: 43.99459457397461 \n",
      "Epoch: 45810 | MAE Train Loss: 46.18144607543945 | MAE Test Loss: 43.9939079284668 \n",
      "Epoch: 45820 | MAE Train Loss: 46.18048858642578 | MAE Test Loss: 43.993228912353516 \n",
      "Epoch: 45830 | MAE Train Loss: 46.17954635620117 | MAE Test Loss: 43.99250793457031 \n",
      "Epoch: 45840 | MAE Train Loss: 46.17860412597656 | MAE Test Loss: 43.99184036254883 \n",
      "Epoch: 45850 | MAE Train Loss: 46.17765426635742 | MAE Test Loss: 43.99115753173828 \n",
      "Epoch: 45860 | MAE Train Loss: 46.17671203613281 | MAE Test Loss: 43.990440368652344 \n",
      "Epoch: 45870 | MAE Train Loss: 46.17576599121094 | MAE Test Loss: 43.98975372314453 \n",
      "Epoch: 45880 | MAE Train Loss: 46.17481994628906 | MAE Test Loss: 43.98906707763672 \n",
      "Epoch: 45890 | MAE Train Loss: 46.17387390136719 | MAE Test Loss: 43.98838424682617 \n",
      "Epoch: 45900 | MAE Train Loss: 46.17293167114258 | MAE Test Loss: 43.987701416015625 \n",
      "Epoch: 45910 | MAE Train Loss: 46.17198181152344 | MAE Test Loss: 43.98701858520508 \n",
      "Epoch: 45920 | MAE Train Loss: 46.17103958129883 | MAE Test Loss: 43.98630142211914 \n",
      "Epoch: 45930 | MAE Train Loss: 46.17009353637695 | MAE Test Loss: 43.98561096191406 \n",
      "Epoch: 45940 | MAE Train Loss: 46.16913986206055 | MAE Test Loss: 43.98491287231445 \n",
      "Epoch: 45950 | MAE Train Loss: 46.1682014465332 | MAE Test Loss: 43.984230041503906 \n",
      "Epoch: 45960 | MAE Train Loss: 46.16725540161133 | MAE Test Loss: 43.983543395996094 \n",
      "Epoch: 45970 | MAE Train Loss: 46.16630935668945 | MAE Test Loss: 43.98286437988281 \n",
      "Epoch: 45980 | MAE Train Loss: 46.16536331176758 | MAE Test Loss: 43.982173919677734 \n",
      "Epoch: 45990 | MAE Train Loss: 46.16441345214844 | MAE Test Loss: 43.98149108886719 \n",
      "Epoch: 46000 | MAE Train Loss: 46.16346740722656 | MAE Test Loss: 43.980770111083984 \n",
      "Epoch: 46010 | MAE Train Loss: 46.16252136230469 | MAE Test Loss: 43.98008728027344 \n",
      "Epoch: 46020 | MAE Train Loss: 46.16157913208008 | MAE Test Loss: 43.97940444946289 \n",
      "Epoch: 46030 | MAE Train Loss: 46.1606330871582 | MAE Test Loss: 43.97871780395508 \n",
      "Epoch: 46040 | MAE Train Loss: 46.15968704223633 | MAE Test Loss: 43.97803497314453 \n",
      "Epoch: 46050 | MAE Train Loss: 46.15874481201172 | MAE Test Loss: 43.977352142333984 \n",
      "Epoch: 46060 | MAE Train Loss: 46.15779495239258 | MAE Test Loss: 43.97663497924805 \n",
      "Epoch: 46070 | MAE Train Loss: 46.15685272216797 | MAE Test Loss: 43.975948333740234 \n",
      "Epoch: 46080 | MAE Train Loss: 46.155906677246094 | MAE Test Loss: 43.97526931762695 \n",
      "Epoch: 46090 | MAE Train Loss: 46.15495681762695 | MAE Test Loss: 43.974586486816406 \n",
      "Epoch: 46100 | MAE Train Loss: 46.15401077270508 | MAE Test Loss: 43.973899841308594 \n",
      "Epoch: 46110 | MAE Train Loss: 46.1530647277832 | MAE Test Loss: 43.97321701049805 \n",
      "Epoch: 46120 | MAE Train Loss: 46.152122497558594 | MAE Test Loss: 43.972496032714844 \n",
      "Epoch: 46130 | MAE Train Loss: 46.15117645263672 | MAE Test Loss: 43.9718132019043 \n",
      "Epoch: 46140 | MAE Train Loss: 46.15022277832031 | MAE Test Loss: 43.971107482910156 \n",
      "Epoch: 46150 | MAE Train Loss: 46.149288177490234 | MAE Test Loss: 43.97042465209961 \n",
      "Epoch: 46160 | MAE Train Loss: 46.14834213256836 | MAE Test Loss: 43.96974182128906 \n",
      "Epoch: 46170 | MAE Train Loss: 46.14739227294922 | MAE Test Loss: 43.969058990478516 \n",
      "Epoch: 46180 | MAE Train Loss: 46.146446228027344 | MAE Test Loss: 43.9683723449707 \n",
      "Epoch: 46190 | MAE Train Loss: 46.145503997802734 | MAE Test Loss: 43.967689514160156 \n",
      "Epoch: 46200 | MAE Train Loss: 46.144554138183594 | MAE Test Loss: 43.96696853637695 \n",
      "Epoch: 46210 | MAE Train Loss: 46.143611907958984 | MAE Test Loss: 43.96628189086914 \n",
      "Epoch: 46220 | MAE Train Loss: 46.14266586303711 | MAE Test Loss: 43.965599060058594 \n",
      "Epoch: 46230 | MAE Train Loss: 46.14171600341797 | MAE Test Loss: 43.96491622924805 \n",
      "Epoch: 46240 | MAE Train Loss: 46.14077377319336 | MAE Test Loss: 43.96421432495117 \n",
      "Epoch: 46250 | MAE Train Loss: 46.13983154296875 | MAE Test Loss: 43.963531494140625 \n",
      "Epoch: 46260 | MAE Train Loss: 46.13888168334961 | MAE Test Loss: 43.96284866333008 \n",
      "Epoch: 46270 | MAE Train Loss: 46.137935638427734 | MAE Test Loss: 43.962162017822266 \n",
      "Epoch: 46280 | MAE Train Loss: 46.136985778808594 | MAE Test Loss: 43.96147918701172 \n",
      "Epoch: 46290 | MAE Train Loss: 46.13604736328125 | MAE Test Loss: 43.96076202392578 \n",
      "Epoch: 46300 | MAE Train Loss: 46.13509750366211 | MAE Test Loss: 43.9600715637207 \n",
      "Epoch: 46310 | MAE Train Loss: 46.1341552734375 | MAE Test Loss: 43.95939254760742 \n",
      "Epoch: 46320 | MAE Train Loss: 46.13320541381836 | MAE Test Loss: 43.95870590209961 \n",
      "Epoch: 46330 | MAE Train Loss: 46.13226318359375 | MAE Test Loss: 43.958003997802734 \n",
      "Epoch: 46340 | MAE Train Loss: 46.131317138671875 | MAE Test Loss: 43.95732116699219 \n",
      "Epoch: 46350 | MAE Train Loss: 46.13037109375 | MAE Test Loss: 43.956634521484375 \n",
      "Epoch: 46360 | MAE Train Loss: 46.129425048828125 | MAE Test Loss: 43.955955505371094 \n",
      "Epoch: 46370 | MAE Train Loss: 46.12847137451172 | MAE Test Loss: 43.95523452758789 \n",
      "Epoch: 46380 | MAE Train Loss: 46.12752914428711 | MAE Test Loss: 43.95454788208008 \n",
      "Epoch: 46390 | MAE Train Loss: 46.1265869140625 | MAE Test Loss: 43.95386505126953 \n",
      "Epoch: 46400 | MAE Train Loss: 46.12564468383789 | MAE Test Loss: 43.953182220458984 \n",
      "Epoch: 46410 | MAE Train Loss: 46.12469482421875 | MAE Test Loss: 43.95249557495117 \n",
      "Epoch: 46420 | MAE Train Loss: 46.123748779296875 | MAE Test Loss: 43.951812744140625 \n",
      "Epoch: 46430 | MAE Train Loss: 46.122802734375 | MAE Test Loss: 43.95109558105469 \n",
      "Epoch: 46440 | MAE Train Loss: 46.121864318847656 | MAE Test Loss: 43.95041275024414 \n",
      "Epoch: 46450 | MAE Train Loss: 46.120914459228516 | MAE Test Loss: 43.94972610473633 \n",
      "Epoch: 46460 | MAE Train Loss: 46.119964599609375 | MAE Test Loss: 43.949039459228516 \n",
      "Epoch: 46470 | MAE Train Loss: 46.1190185546875 | MAE Test Loss: 43.94835662841797 \n",
      "Epoch: 46480 | MAE Train Loss: 46.118072509765625 | MAE Test Loss: 43.94767761230469 \n",
      "Epoch: 46490 | MAE Train Loss: 46.11712646484375 | MAE Test Loss: 43.94695281982422 \n",
      "Epoch: 46500 | MAE Train Loss: 46.11618423461914 | MAE Test Loss: 43.94627380371094 \n",
      "Epoch: 46510 | MAE Train Loss: 46.115238189697266 | MAE Test Loss: 43.94558334350586 \n",
      "Epoch: 46520 | MAE Train Loss: 46.11429214477539 | MAE Test Loss: 43.94490051269531 \n",
      "Epoch: 46530 | MAE Train Loss: 46.113346099853516 | MAE Test Loss: 43.9442024230957 \n",
      "Epoch: 46540 | MAE Train Loss: 46.112403869628906 | MAE Test Loss: 43.943519592285156 \n",
      "Epoch: 46550 | MAE Train Loss: 46.111454010009766 | MAE Test Loss: 43.942832946777344 \n",
      "Epoch: 46560 | MAE Train Loss: 46.11050796508789 | MAE Test Loss: 43.9421501159668 \n",
      "Epoch: 46570 | MAE Train Loss: 46.109561920166016 | MAE Test Loss: 43.94143295288086 \n",
      "Epoch: 46580 | MAE Train Loss: 46.10861587524414 | MAE Test Loss: 43.94074249267578 \n",
      "Epoch: 46590 | MAE Train Loss: 46.107669830322266 | MAE Test Loss: 43.940059661865234 \n",
      "Epoch: 46600 | MAE Train Loss: 46.10672378540039 | MAE Test Loss: 43.93937683105469 \n",
      "Epoch: 46610 | MAE Train Loss: 46.105777740478516 | MAE Test Loss: 43.938697814941406 \n",
      "Epoch: 46620 | MAE Train Loss: 46.10483169555664 | MAE Test Loss: 43.93800735473633 \n",
      "Epoch: 46630 | MAE Train Loss: 46.103885650634766 | MAE Test Loss: 43.93729019165039 \n",
      "Epoch: 46640 | MAE Train Loss: 46.102943420410156 | MAE Test Loss: 43.936607360839844 \n",
      "Epoch: 46650 | MAE Train Loss: 46.10200119018555 | MAE Test Loss: 43.9359245300293 \n",
      "Epoch: 46660 | MAE Train Loss: 46.10105514526367 | MAE Test Loss: 43.935237884521484 \n",
      "Epoch: 46670 | MAE Train Loss: 46.100101470947266 | MAE Test Loss: 43.93455505371094 \n",
      "Epoch: 46680 | MAE Train Loss: 46.09915542602539 | MAE Test Loss: 43.933868408203125 \n",
      "Epoch: 46690 | MAE Train Loss: 46.09821319580078 | MAE Test Loss: 43.93315124511719 \n",
      "Epoch: 46700 | MAE Train Loss: 46.097267150878906 | MAE Test Loss: 43.932464599609375 \n",
      "Epoch: 46710 | MAE Train Loss: 46.09632110595703 | MAE Test Loss: 43.93178176879883 \n",
      "Epoch: 46720 | MAE Train Loss: 46.095375061035156 | MAE Test Loss: 43.93110275268555 \n",
      "Epoch: 46730 | MAE Train Loss: 46.09443283081055 | MAE Test Loss: 43.930397033691406 \n",
      "Epoch: 46740 | MAE Train Loss: 46.093482971191406 | MAE Test Loss: 43.929710388183594 \n",
      "Epoch: 46750 | MAE Train Loss: 46.09253692626953 | MAE Test Loss: 43.92902755737305 \n",
      "Epoch: 46760 | MAE Train Loss: 46.091590881347656 | MAE Test Loss: 43.928340911865234 \n",
      "Epoch: 46770 | MAE Train Loss: 46.09064865112305 | MAE Test Loss: 43.9276237487793 \n",
      "Epoch: 46780 | MAE Train Loss: 46.089698791503906 | MAE Test Loss: 43.926944732666016 \n",
      "Epoch: 46790 | MAE Train Loss: 46.08876037597656 | MAE Test Loss: 43.92625427246094 \n",
      "Epoch: 46800 | MAE Train Loss: 46.08781051635742 | MAE Test Loss: 43.92557144165039 \n",
      "Epoch: 46810 | MAE Train Loss: 46.08686065673828 | MAE Test Loss: 43.924888610839844 \n",
      "Epoch: 46820 | MAE Train Loss: 46.085914611816406 | MAE Test Loss: 43.9242057800293 \n",
      "Epoch: 46830 | MAE Train Loss: 46.08497619628906 | MAE Test Loss: 43.92350387573242 \n",
      "Epoch: 46840 | MAE Train Loss: 46.08403015136719 | MAE Test Loss: 43.92279815673828 \n",
      "Epoch: 46850 | MAE Train Loss: 46.08308410644531 | MAE Test Loss: 43.922119140625 \n",
      "Epoch: 46860 | MAE Train Loss: 46.08213424682617 | MAE Test Loss: 43.92143249511719 \n",
      "Epoch: 46870 | MAE Train Loss: 46.0811882019043 | MAE Test Loss: 43.92074966430664 \n",
      "Epoch: 46880 | MAE Train Loss: 46.08024215698242 | MAE Test Loss: 43.92006301879883 \n",
      "Epoch: 46890 | MAE Train Loss: 46.07929611206055 | MAE Test Loss: 43.91934585571289 \n",
      "Epoch: 46900 | MAE Train Loss: 46.07835006713867 | MAE Test Loss: 43.918663024902344 \n",
      "Epoch: 46910 | MAE Train Loss: 46.07740783691406 | MAE Test Loss: 43.9179801940918 \n",
      "Epoch: 46920 | MAE Train Loss: 46.07645797729492 | MAE Test Loss: 43.917293548583984 \n",
      "Epoch: 46930 | MAE Train Loss: 46.07551193237305 | MAE Test Loss: 43.916595458984375 \n",
      "Epoch: 46940 | MAE Train Loss: 46.0745735168457 | MAE Test Loss: 43.9159049987793 \n",
      "Epoch: 46950 | MAE Train Loss: 46.0736198425293 | MAE Test Loss: 43.915225982666016 \n",
      "Epoch: 46960 | MAE Train Loss: 46.07267761230469 | MAE Test Loss: 43.9145393371582 \n",
      "Epoch: 46970 | MAE Train Loss: 46.07172775268555 | MAE Test Loss: 43.913822174072266 \n",
      "Epoch: 46980 | MAE Train Loss: 46.07078552246094 | MAE Test Loss: 43.91313552856445 \n",
      "Epoch: 46990 | MAE Train Loss: 46.06984329223633 | MAE Test Loss: 43.912452697753906 \n",
      "Epoch: 47000 | MAE Train Loss: 46.06888961791992 | MAE Test Loss: 43.911766052246094 \n",
      "Epoch: 47010 | MAE Train Loss: 46.06794357299805 | MAE Test Loss: 43.91108322143555 \n",
      "Epoch: 47020 | MAE Train Loss: 46.06699752807617 | MAE Test Loss: 43.910400390625 \n",
      "Epoch: 47030 | MAE Train Loss: 46.06605911254883 | MAE Test Loss: 43.90970230102539 \n",
      "Epoch: 47040 | MAE Train Loss: 46.06511306762695 | MAE Test Loss: 43.90901184082031 \n",
      "Epoch: 47050 | MAE Train Loss: 46.06416320800781 | MAE Test Loss: 43.90833282470703 \n",
      "Epoch: 47060 | MAE Train Loss: 46.06321716308594 | MAE Test Loss: 43.90761184692383 \n",
      "Epoch: 47070 | MAE Train Loss: 46.06227493286133 | MAE Test Loss: 43.90692901611328 \n",
      "Epoch: 47080 | MAE Train Loss: 46.06132888793945 | MAE Test Loss: 43.906246185302734 \n",
      "Epoch: 47090 | MAE Train Loss: 46.06037902832031 | MAE Test Loss: 43.90555953979492 \n",
      "Epoch: 47100 | MAE Train Loss: 46.05943298339844 | MAE Test Loss: 43.90487289428711 \n",
      "Epoch: 47110 | MAE Train Loss: 46.05849075317383 | MAE Test Loss: 43.90419006347656 \n",
      "Epoch: 47120 | MAE Train Loss: 46.05754470825195 | MAE Test Loss: 43.903472900390625 \n",
      "Epoch: 47130 | MAE Train Loss: 46.05659866333008 | MAE Test Loss: 43.90280532836914 \n",
      "Epoch: 47140 | MAE Train Loss: 46.05564880371094 | MAE Test Loss: 43.90208435058594 \n",
      "Epoch: 47150 | MAE Train Loss: 46.054710388183594 | MAE Test Loss: 43.901405334472656 \n",
      "Epoch: 47160 | MAE Train Loss: 46.053768157958984 | MAE Test Loss: 43.900718688964844 \n",
      "Epoch: 47170 | MAE Train Loss: 46.052818298339844 | MAE Test Loss: 43.9000358581543 \n",
      "Epoch: 47180 | MAE Train Loss: 46.05186462402344 | MAE Test Loss: 43.89935302734375 \n",
      "Epoch: 47190 | MAE Train Loss: 46.05091857910156 | MAE Test Loss: 43.89866638183594 \n",
      "Epoch: 47200 | MAE Train Loss: 46.04997634887695 | MAE Test Loss: 43.897945404052734 \n",
      "Epoch: 47210 | MAE Train Loss: 46.049034118652344 | MAE Test Loss: 43.89726257324219 \n",
      "Epoch: 47220 | MAE Train Loss: 46.04808807373047 | MAE Test Loss: 43.89657974243164 \n",
      "Epoch: 47230 | MAE Train Loss: 46.047142028808594 | MAE Test Loss: 43.895896911621094 \n",
      "Epoch: 47240 | MAE Train Loss: 46.04619598388672 | MAE Test Loss: 43.89521408081055 \n",
      "Epoch: 47250 | MAE Train Loss: 46.045249938964844 | MAE Test Loss: 43.894527435302734 \n",
      "Epoch: 47260 | MAE Train Loss: 46.04430389404297 | MAE Test Loss: 43.89380645751953 \n",
      "Epoch: 47270 | MAE Train Loss: 46.043357849121094 | MAE Test Loss: 43.893123626708984 \n",
      "Epoch: 47280 | MAE Train Loss: 46.04241180419922 | MAE Test Loss: 43.89244079589844 \n",
      "Epoch: 47290 | MAE Train Loss: 46.041465759277344 | MAE Test Loss: 43.891754150390625 \n",
      "Epoch: 47300 | MAE Train Loss: 46.04051971435547 | MAE Test Loss: 43.89107131958008 \n",
      "Epoch: 47310 | MAE Train Loss: 46.03956985473633 | MAE Test Loss: 43.890384674072266 \n",
      "Epoch: 47320 | MAE Train Loss: 46.03862762451172 | MAE Test Loss: 43.889671325683594 \n",
      "Epoch: 47330 | MAE Train Loss: 46.03767776489258 | MAE Test Loss: 43.888999938964844 \n",
      "Epoch: 47340 | MAE Train Loss: 46.0367317199707 | MAE Test Loss: 43.88828659057617 \n",
      "Epoch: 47350 | MAE Train Loss: 46.03579330444336 | MAE Test Loss: 43.88759231567383 \n",
      "Epoch: 47360 | MAE Train Loss: 46.034847259521484 | MAE Test Loss: 43.88690948486328 \n",
      "Epoch: 47370 | MAE Train Loss: 46.03390121459961 | MAE Test Loss: 43.88623046875 \n",
      "Epoch: 47380 | MAE Train Loss: 46.032955169677734 | MAE Test Loss: 43.88554382324219 \n",
      "Epoch: 47390 | MAE Train Loss: 46.032005310058594 | MAE Test Loss: 43.884864807128906 \n",
      "Epoch: 47400 | MAE Train Loss: 46.031063079833984 | MAE Test Loss: 43.88414001464844 \n",
      "Epoch: 47410 | MAE Train Loss: 46.030113220214844 | MAE Test Loss: 43.88345718383789 \n",
      "Epoch: 47420 | MAE Train Loss: 46.029170989990234 | MAE Test Loss: 43.88279342651367 \n",
      "Epoch: 47430 | MAE Train Loss: 46.02822494506836 | MAE Test Loss: 43.88208770751953 \n",
      "Epoch: 47440 | MAE Train Loss: 46.02728271484375 | MAE Test Loss: 43.88140869140625 \n",
      "Epoch: 47450 | MAE Train Loss: 46.02633285522461 | MAE Test Loss: 43.88072204589844 \n",
      "Epoch: 47460 | MAE Train Loss: 46.025386810302734 | MAE Test Loss: 43.8800048828125 \n",
      "Epoch: 47470 | MAE Train Loss: 46.024444580078125 | MAE Test Loss: 43.87932205200195 \n",
      "Epoch: 47480 | MAE Train Loss: 46.02349853515625 | MAE Test Loss: 43.878639221191406 \n",
      "Epoch: 47490 | MAE Train Loss: 46.022552490234375 | MAE Test Loss: 43.877952575683594 \n",
      "Epoch: 47500 | MAE Train Loss: 46.021602630615234 | MAE Test Loss: 43.87726593017578 \n",
      "Epoch: 47510 | MAE Train Loss: 46.020660400390625 | MAE Test Loss: 43.876583099365234 \n",
      "Epoch: 47520 | MAE Train Loss: 46.01970672607422 | MAE Test Loss: 43.8758659362793 \n",
      "Epoch: 47530 | MAE Train Loss: 46.01876449584961 | MAE Test Loss: 43.87519454956055 \n",
      "Epoch: 47540 | MAE Train Loss: 46.017818450927734 | MAE Test Loss: 43.87447738647461 \n",
      "Epoch: 47550 | MAE Train Loss: 46.01687240600586 | MAE Test Loss: 43.87379455566406 \n",
      "Epoch: 47560 | MAE Train Loss: 46.01593017578125 | MAE Test Loss: 43.87310791015625 \n",
      "Epoch: 47570 | MAE Train Loss: 46.01498794555664 | MAE Test Loss: 43.87242889404297 \n",
      "Epoch: 47580 | MAE Train Loss: 46.0140380859375 | MAE Test Loss: 43.871742248535156 \n",
      "Epoch: 47590 | MAE Train Loss: 46.013092041015625 | MAE Test Loss: 43.87105941772461 \n",
      "Epoch: 47600 | MAE Train Loss: 46.012142181396484 | MAE Test Loss: 43.870338439941406 \n",
      "Epoch: 47610 | MAE Train Loss: 46.011199951171875 | MAE Test Loss: 43.869651794433594 \n",
      "Epoch: 47620 | MAE Train Loss: 46.01025390625 | MAE Test Loss: 43.868988037109375 \n",
      "Epoch: 47630 | MAE Train Loss: 46.009307861328125 | MAE Test Loss: 43.86827087402344 \n",
      "Epoch: 47640 | MAE Train Loss: 46.00836181640625 | MAE Test Loss: 43.867584228515625 \n",
      "Epoch: 47650 | MAE Train Loss: 46.00741958618164 | MAE Test Loss: 43.86690139770508 \n",
      "Epoch: 47660 | MAE Train Loss: 46.006473541259766 | MAE Test Loss: 43.866214752197266 \n",
      "Epoch: 47670 | MAE Train Loss: 46.005523681640625 | MAE Test Loss: 43.86553192138672 \n",
      "Epoch: 47680 | MAE Train Loss: 46.004581451416016 | MAE Test Loss: 43.86484909057617 \n",
      "Epoch: 47690 | MAE Train Loss: 46.00363540649414 | MAE Test Loss: 43.86412811279297 \n",
      "Epoch: 47700 | MAE Train Loss: 46.002689361572266 | MAE Test Loss: 43.86344528198242 \n",
      "Epoch: 47710 | MAE Train Loss: 46.00174331665039 | MAE Test Loss: 43.862762451171875 \n",
      "Epoch: 47720 | MAE Train Loss: 46.00079345703125 | MAE Test Loss: 43.862056732177734 \n",
      "Epoch: 47730 | MAE Train Loss: 45.999855041503906 | MAE Test Loss: 43.86137390136719 \n",
      "Epoch: 47740 | MAE Train Loss: 45.99890899658203 | MAE Test Loss: 43.860687255859375 \n",
      "Epoch: 47750 | MAE Train Loss: 45.997962951660156 | MAE Test Loss: 43.860008239746094 \n",
      "Epoch: 47760 | MAE Train Loss: 45.997013092041016 | MAE Test Loss: 43.85932159423828 \n",
      "Epoch: 47770 | MAE Train Loss: 45.99606704711914 | MAE Test Loss: 43.858604431152344 \n",
      "Epoch: 47780 | MAE Train Loss: 45.995121002197266 | MAE Test Loss: 43.8579216003418 \n",
      "Epoch: 47790 | MAE Train Loss: 45.994178771972656 | MAE Test Loss: 43.857234954833984 \n",
      "Epoch: 47800 | MAE Train Loss: 45.99323272705078 | MAE Test Loss: 43.85655212402344 \n",
      "Epoch: 47810 | MAE Train Loss: 45.992286682128906 | MAE Test Loss: 43.85586929321289 \n",
      "Epoch: 47820 | MAE Train Loss: 45.991336822509766 | MAE Test Loss: 43.85518264770508 \n",
      "Epoch: 47830 | MAE Train Loss: 45.99039077758789 | MAE Test Loss: 43.854461669921875 \n",
      "Epoch: 47840 | MAE Train Loss: 45.989444732666016 | MAE Test Loss: 43.853782653808594 \n",
      "Epoch: 47850 | MAE Train Loss: 45.98850631713867 | MAE Test Loss: 43.85309600830078 \n",
      "Epoch: 47860 | MAE Train Loss: 45.98755645751953 | MAE Test Loss: 43.852413177490234 \n",
      "Epoch: 47870 | MAE Train Loss: 45.986610412597656 | MAE Test Loss: 43.851722717285156 \n",
      "Epoch: 47880 | MAE Train Loss: 45.98566436767578 | MAE Test Loss: 43.851043701171875 \n",
      "Epoch: 47890 | MAE Train Loss: 45.98471450805664 | MAE Test Loss: 43.85032653808594 \n",
      "Epoch: 47900 | MAE Train Loss: 45.9837760925293 | MAE Test Loss: 43.84964370727539 \n",
      "Epoch: 47910 | MAE Train Loss: 45.98283004760742 | MAE Test Loss: 43.84895324707031 \n",
      "Epoch: 47920 | MAE Train Loss: 45.98188400268555 | MAE Test Loss: 43.84825134277344 \n",
      "Epoch: 47930 | MAE Train Loss: 45.98094177246094 | MAE Test Loss: 43.847572326660156 \n",
      "Epoch: 47940 | MAE Train Loss: 45.9799919128418 | MAE Test Loss: 43.846885681152344 \n",
      "Epoch: 47950 | MAE Train Loss: 45.979042053222656 | MAE Test Loss: 43.84619903564453 \n",
      "Epoch: 47960 | MAE Train Loss: 45.97809600830078 | MAE Test Loss: 43.84552001953125 \n",
      "Epoch: 47970 | MAE Train Loss: 45.977149963378906 | MAE Test Loss: 43.84480285644531 \n",
      "Epoch: 47980 | MAE Train Loss: 45.9762077331543 | MAE Test Loss: 43.8441162109375 \n",
      "Epoch: 47990 | MAE Train Loss: 45.97526550292969 | MAE Test Loss: 43.84343338012695 \n",
      "Epoch: 48000 | MAE Train Loss: 45.97431564331055 | MAE Test Loss: 43.84274673461914 \n",
      "Epoch: 48010 | MAE Train Loss: 45.97337341308594 | MAE Test Loss: 43.842063903808594 \n",
      "Epoch: 48020 | MAE Train Loss: 45.9724235534668 | MAE Test Loss: 43.84136199951172 \n",
      "Epoch: 48030 | MAE Train Loss: 45.971473693847656 | MAE Test Loss: 43.84068298339844 \n",
      "Epoch: 48040 | MAE Train Loss: 45.97053146362305 | MAE Test Loss: 43.83999252319336 \n",
      "Epoch: 48050 | MAE Train Loss: 45.969581604003906 | MAE Test Loss: 43.83930969238281 \n",
      "Epoch: 48060 | MAE Train Loss: 45.96863555908203 | MAE Test Loss: 43.83858871459961 \n",
      "Epoch: 48070 | MAE Train Loss: 45.96769714355469 | MAE Test Loss: 43.83790588378906 \n",
      "Epoch: 48080 | MAE Train Loss: 45.96674728393555 | MAE Test Loss: 43.837223052978516 \n",
      "Epoch: 48090 | MAE Train Loss: 45.96580505371094 | MAE Test Loss: 43.8365364074707 \n",
      "Epoch: 48100 | MAE Train Loss: 45.96485900878906 | MAE Test Loss: 43.835853576660156 \n",
      "Epoch: 48110 | MAE Train Loss: 45.96391296386719 | MAE Test Loss: 43.83515167236328 \n",
      "Epoch: 48120 | MAE Train Loss: 45.96296691894531 | MAE Test Loss: 43.83446502685547 \n",
      "Epoch: 48130 | MAE Train Loss: 45.96201705932617 | MAE Test Loss: 43.83378601074219 \n",
      "Epoch: 48140 | MAE Train Loss: 45.96107482910156 | MAE Test Loss: 43.83306121826172 \n",
      "Epoch: 48150 | MAE Train Loss: 45.96012878417969 | MAE Test Loss: 43.83238220214844 \n",
      "Epoch: 48160 | MAE Train Loss: 45.95918273925781 | MAE Test Loss: 43.831695556640625 \n",
      "Epoch: 48170 | MAE Train Loss: 45.95823287963867 | MAE Test Loss: 43.83100891113281 \n",
      "Epoch: 48180 | MAE Train Loss: 45.9572868347168 | MAE Test Loss: 43.83032989501953 \n",
      "Epoch: 48190 | MAE Train Loss: 45.95634460449219 | MAE Test Loss: 43.82964324951172 \n",
      "Epoch: 48200 | MAE Train Loss: 45.95539474487305 | MAE Test Loss: 43.82892990112305 \n",
      "Epoch: 48210 | MAE Train Loss: 45.9544563293457 | MAE Test Loss: 43.82823944091797 \n",
      "Epoch: 48220 | MAE Train Loss: 45.953514099121094 | MAE Test Loss: 43.82756042480469 \n",
      "Epoch: 48230 | MAE Train Loss: 45.95256423950195 | MAE Test Loss: 43.826873779296875 \n",
      "Epoch: 48240 | MAE Train Loss: 45.95161437988281 | MAE Test Loss: 43.82618713378906 \n",
      "Epoch: 48250 | MAE Train Loss: 45.9506721496582 | MAE Test Loss: 43.825504302978516 \n",
      "Epoch: 48260 | MAE Train Loss: 45.94972229003906 | MAE Test Loss: 43.824790954589844 \n",
      "Epoch: 48270 | MAE Train Loss: 45.94878005981445 | MAE Test Loss: 43.82410430908203 \n",
      "Epoch: 48280 | MAE Train Loss: 45.94783401489258 | MAE Test Loss: 43.823421478271484 \n",
      "Epoch: 48290 | MAE Train Loss: 45.9468879699707 | MAE Test Loss: 43.82273483276367 \n",
      "Epoch: 48300 | MAE Train Loss: 45.94594192504883 | MAE Test Loss: 43.82204818725586 \n",
      "Epoch: 48310 | MAE Train Loss: 45.94499588012695 | MAE Test Loss: 43.82135009765625 \n",
      "Epoch: 48320 | MAE Train Loss: 45.94404983520508 | MAE Test Loss: 43.82066345214844 \n",
      "Epoch: 48330 | MAE Train Loss: 45.9431037902832 | MAE Test Loss: 43.819976806640625 \n",
      "Epoch: 48340 | MAE Train Loss: 45.94215774536133 | MAE Test Loss: 43.81925964355469 \n",
      "Epoch: 48350 | MAE Train Loss: 45.94121551513672 | MAE Test Loss: 43.81857681274414 \n",
      "Epoch: 48360 | MAE Train Loss: 45.940269470214844 | MAE Test Loss: 43.817893981933594 \n",
      "Epoch: 48370 | MAE Train Loss: 45.93932342529297 | MAE Test Loss: 43.81721115112305 \n",
      "Epoch: 48380 | MAE Train Loss: 45.93837356567383 | MAE Test Loss: 43.81652069091797 \n",
      "Epoch: 48390 | MAE Train Loss: 45.93742752075195 | MAE Test Loss: 43.81584167480469 \n",
      "Epoch: 48400 | MAE Train Loss: 45.936485290527344 | MAE Test Loss: 43.815120697021484 \n",
      "Epoch: 48410 | MAE Train Loss: 45.9355354309082 | MAE Test Loss: 43.814453125 \n",
      "Epoch: 48420 | MAE Train Loss: 45.93458557128906 | MAE Test Loss: 43.81377029418945 \n",
      "Epoch: 48430 | MAE Train Loss: 45.933650970458984 | MAE Test Loss: 43.813053131103516 \n",
      "Epoch: 48440 | MAE Train Loss: 45.932701110839844 | MAE Test Loss: 43.8123664855957 \n",
      "Epoch: 48450 | MAE Train Loss: 45.931758880615234 | MAE Test Loss: 43.811683654785156 \n",
      "Epoch: 48460 | MAE Train Loss: 45.930809020996094 | MAE Test Loss: 43.810997009277344 \n",
      "Epoch: 48470 | MAE Train Loss: 45.92986297607422 | MAE Test Loss: 43.8103141784668 \n",
      "Epoch: 48480 | MAE Train Loss: 45.92891311645508 | MAE Test Loss: 43.809635162353516 \n",
      "Epoch: 48490 | MAE Train Loss: 45.92797088623047 | MAE Test Loss: 43.80891036987305 \n",
      "Epoch: 48500 | MAE Train Loss: 45.92702865600586 | MAE Test Loss: 43.8082275390625 \n",
      "Epoch: 48510 | MAE Train Loss: 45.92607879638672 | MAE Test Loss: 43.80754470825195 \n",
      "Epoch: 48520 | MAE Train Loss: 45.92513656616211 | MAE Test Loss: 43.80685806274414 \n",
      "Epoch: 48530 | MAE Train Loss: 45.92418670654297 | MAE Test Loss: 43.806175231933594 \n",
      "Epoch: 48540 | MAE Train Loss: 45.923240661621094 | MAE Test Loss: 43.80545425415039 \n",
      "Epoch: 48550 | MAE Train Loss: 45.922298431396484 | MAE Test Loss: 43.804771423339844 \n",
      "Epoch: 48560 | MAE Train Loss: 45.92135238647461 | MAE Test Loss: 43.8040885925293 \n",
      "Epoch: 48570 | MAE Train Loss: 45.92041015625 | MAE Test Loss: 43.803401947021484 \n",
      "Epoch: 48580 | MAE Train Loss: 45.91946029663086 | MAE Test Loss: 43.80271911621094 \n",
      "Epoch: 48590 | MAE Train Loss: 45.91851043701172 | MAE Test Loss: 43.80203628540039 \n",
      "Epoch: 48600 | MAE Train Loss: 45.917572021484375 | MAE Test Loss: 43.80131530761719 \n",
      "Epoch: 48610 | MAE Train Loss: 45.9166374206543 | MAE Test Loss: 43.800601959228516 \n",
      "Epoch: 48620 | MAE Train Loss: 45.91571044921875 | MAE Test Loss: 43.79991912841797 \n",
      "Epoch: 48630 | MAE Train Loss: 45.91481018066406 | MAE Test Loss: 43.799251556396484 \n",
      "Epoch: 48640 | MAE Train Loss: 45.913917541503906 | MAE Test Loss: 43.798580169677734 \n",
      "Epoch: 48650 | MAE Train Loss: 45.913021087646484 | MAE Test Loss: 43.797916412353516 \n",
      "Epoch: 48660 | MAE Train Loss: 45.91213607788086 | MAE Test Loss: 43.79724884033203 \n",
      "Epoch: 48670 | MAE Train Loss: 45.91124725341797 | MAE Test Loss: 43.796546936035156 \n",
      "Epoch: 48680 | MAE Train Loss: 45.91035461425781 | MAE Test Loss: 43.79588317871094 \n",
      "Epoch: 48690 | MAE Train Loss: 45.90946578979492 | MAE Test Loss: 43.79521179199219 \n",
      "Epoch: 48700 | MAE Train Loss: 45.908573150634766 | MAE Test Loss: 43.79451370239258 \n",
      "Epoch: 48710 | MAE Train Loss: 45.90768814086914 | MAE Test Loss: 43.79384231567383 \n",
      "Epoch: 48720 | MAE Train Loss: 45.90679931640625 | MAE Test Loss: 43.79317855834961 \n",
      "Epoch: 48730 | MAE Train Loss: 45.90590286254883 | MAE Test Loss: 43.79250717163086 \n",
      "Epoch: 48740 | MAE Train Loss: 45.90501403808594 | MAE Test Loss: 43.79180908203125 \n",
      "Epoch: 48750 | MAE Train Loss: 45.90412521362305 | MAE Test Loss: 43.791141510009766 \n",
      "Epoch: 48760 | MAE Train Loss: 45.903228759765625 | MAE Test Loss: 43.79047393798828 \n",
      "Epoch: 48770 | MAE Train Loss: 45.902339935302734 | MAE Test Loss: 43.789772033691406 \n",
      "Epoch: 48780 | MAE Train Loss: 45.90145492553711 | MAE Test Loss: 43.78910827636719 \n",
      "Epoch: 48790 | MAE Train Loss: 45.90056610107422 | MAE Test Loss: 43.78843307495117 \n",
      "Epoch: 48800 | MAE Train Loss: 45.8996696472168 | MAE Test Loss: 43.78776931762695 \n",
      "Epoch: 48810 | MAE Train Loss: 45.89878463745117 | MAE Test Loss: 43.787071228027344 \n",
      "Epoch: 48820 | MAE Train Loss: 45.89788818359375 | MAE Test Loss: 43.786399841308594 \n",
      "Epoch: 48830 | MAE Train Loss: 45.897003173828125 | MAE Test Loss: 43.785736083984375 \n",
      "Epoch: 48840 | MAE Train Loss: 45.8961067199707 | MAE Test Loss: 43.7850341796875 \n",
      "Epoch: 48850 | MAE Train Loss: 45.89522171020508 | MAE Test Loss: 43.784366607666016 \n",
      "Epoch: 48860 | MAE Train Loss: 45.89433288574219 | MAE Test Loss: 43.783695220947266 \n",
      "Epoch: 48870 | MAE Train Loss: 45.893470764160156 | MAE Test Loss: 43.78297424316406 \n",
      "Epoch: 48880 | MAE Train Loss: 45.89262008666992 | MAE Test Loss: 43.782230377197266 \n",
      "Epoch: 48890 | MAE Train Loss: 45.89176940917969 | MAE Test Loss: 43.781497955322266 \n",
      "Epoch: 48900 | MAE Train Loss: 45.89091873168945 | MAE Test Loss: 43.780757904052734 \n",
      "Epoch: 48910 | MAE Train Loss: 45.890071868896484 | MAE Test Loss: 43.78003692626953 \n",
      "Epoch: 48920 | MAE Train Loss: 45.88922119140625 | MAE Test Loss: 43.779293060302734 \n",
      "Epoch: 48930 | MAE Train Loss: 45.88837432861328 | MAE Test Loss: 43.77854919433594 \n",
      "Epoch: 48940 | MAE Train Loss: 45.88752746582031 | MAE Test Loss: 43.77783203125 \n",
      "Epoch: 48950 | MAE Train Loss: 45.88669204711914 | MAE Test Loss: 43.77712631225586 \n",
      "Epoch: 48960 | MAE Train Loss: 45.885868072509766 | MAE Test Loss: 43.77649688720703 \n",
      "Epoch: 48970 | MAE Train Loss: 45.885047912597656 | MAE Test Loss: 43.77582931518555 \n",
      "Epoch: 48980 | MAE Train Loss: 45.88422775268555 | MAE Test Loss: 43.77516555786133 \n",
      "Epoch: 48990 | MAE Train Loss: 45.88340377807617 | MAE Test Loss: 43.774497985839844 \n",
      "Epoch: 49000 | MAE Train Loss: 45.88257598876953 | MAE Test Loss: 43.77384567260742 \n",
      "Epoch: 49010 | MAE Train Loss: 45.881752014160156 | MAE Test Loss: 43.77317810058594 \n",
      "Epoch: 49020 | MAE Train Loss: 45.88093185424805 | MAE Test Loss: 43.77251434326172 \n",
      "Epoch: 49030 | MAE Train Loss: 45.88010787963867 | MAE Test Loss: 43.771846771240234 \n",
      "Epoch: 49040 | MAE Train Loss: 45.87928771972656 | MAE Test Loss: 43.771175384521484 \n",
      "Epoch: 49050 | MAE Train Loss: 45.87845993041992 | MAE Test Loss: 43.77051544189453 \n",
      "Epoch: 49060 | MAE Train Loss: 45.87763977050781 | MAE Test Loss: 43.76984786987305 \n",
      "Epoch: 49070 | MAE Train Loss: 45.87681579589844 | MAE Test Loss: 43.76921463012695 \n",
      "Epoch: 49080 | MAE Train Loss: 45.87599182128906 | MAE Test Loss: 43.768550872802734 \n",
      "Epoch: 49090 | MAE Train Loss: 45.87516784667969 | MAE Test Loss: 43.76788330078125 \n",
      "Epoch: 49100 | MAE Train Loss: 45.87434387207031 | MAE Test Loss: 43.767215728759766 \n",
      "Epoch: 49110 | MAE Train Loss: 45.87351989746094 | MAE Test Loss: 43.76654815673828 \n",
      "Epoch: 49120 | MAE Train Loss: 45.87269973754883 | MAE Test Loss: 43.76588439941406 \n",
      "Epoch: 49130 | MAE Train Loss: 45.87187576293945 | MAE Test Loss: 43.76521301269531 \n",
      "Epoch: 49140 | MAE Train Loss: 45.87104797363281 | MAE Test Loss: 43.764549255371094 \n",
      "Epoch: 49150 | MAE Train Loss: 45.8702278137207 | MAE Test Loss: 43.76390075683594 \n",
      "Epoch: 49160 | MAE Train Loss: 45.869407653808594 | MAE Test Loss: 43.76323318481445 \n",
      "Epoch: 49170 | MAE Train Loss: 45.86858367919922 | MAE Test Loss: 43.762569427490234 \n",
      "Epoch: 49180 | MAE Train Loss: 45.86775207519531 | MAE Test Loss: 43.761898040771484 \n",
      "Epoch: 49190 | MAE Train Loss: 45.86693572998047 | MAE Test Loss: 43.76124954223633 \n",
      "Epoch: 49200 | MAE Train Loss: 45.86610794067383 | MAE Test Loss: 43.760581970214844 \n",
      "Epoch: 49210 | MAE Train Loss: 45.865291595458984 | MAE Test Loss: 43.759918212890625 \n",
      "Epoch: 49220 | MAE Train Loss: 45.86445999145508 | MAE Test Loss: 43.759281158447266 \n",
      "Epoch: 49230 | MAE Train Loss: 45.86363983154297 | MAE Test Loss: 43.75861740112305 \n",
      "Epoch: 49240 | MAE Train Loss: 45.86281967163086 | MAE Test Loss: 43.75795364379883 \n",
      "Epoch: 49250 | MAE Train Loss: 45.86199951171875 | MAE Test Loss: 43.757286071777344 \n",
      "Epoch: 49260 | MAE Train Loss: 45.86117172241211 | MAE Test Loss: 43.75664520263672 \n",
      "Epoch: 49270 | MAE Train Loss: 45.860347747802734 | MAE Test Loss: 43.756126403808594 \n",
      "Epoch: 49280 | MAE Train Loss: 45.85952377319336 | MAE Test Loss: 43.75560760498047 \n",
      "Epoch: 49290 | MAE Train Loss: 45.858699798583984 | MAE Test Loss: 43.75509262084961 \n",
      "Epoch: 49300 | MAE Train Loss: 45.857879638671875 | MAE Test Loss: 43.754547119140625 \n",
      "Epoch: 49310 | MAE Train Loss: 45.8570556640625 | MAE Test Loss: 43.7540283203125 \n",
      "Epoch: 49320 | MAE Train Loss: 45.856231689453125 | MAE Test Loss: 43.753517150878906 \n",
      "Epoch: 49330 | MAE Train Loss: 45.855411529541016 | MAE Test Loss: 43.752994537353516 \n",
      "Epoch: 49340 | MAE Train Loss: 45.854583740234375 | MAE Test Loss: 43.752464294433594 \n",
      "Epoch: 49350 | MAE Train Loss: 45.853763580322266 | MAE Test Loss: 43.75194549560547 \n",
      "Epoch: 49360 | MAE Train Loss: 45.852935791015625 | MAE Test Loss: 43.75143051147461 \n",
      "Epoch: 49370 | MAE Train Loss: 45.852115631103516 | MAE Test Loss: 43.75091552734375 \n",
      "Epoch: 49380 | MAE Train Loss: 45.85129165649414 | MAE Test Loss: 43.7503776550293 \n",
      "Epoch: 49390 | MAE Train Loss: 45.85047149658203 | MAE Test Loss: 43.74986267089844 \n",
      "Epoch: 49400 | MAE Train Loss: 45.849647521972656 | MAE Test Loss: 43.74934005737305 \n",
      "Epoch: 49410 | MAE Train Loss: 45.848819732666016 | MAE Test Loss: 43.74881362915039 \n",
      "Epoch: 49420 | MAE Train Loss: 45.847999572753906 | MAE Test Loss: 43.748294830322266 \n",
      "Epoch: 49430 | MAE Train Loss: 45.84717559814453 | MAE Test Loss: 43.74777603149414 \n",
      "Epoch: 49440 | MAE Train Loss: 45.84635543823242 | MAE Test Loss: 43.747257232666016 \n",
      "Epoch: 49450 | MAE Train Loss: 45.84552764892578 | MAE Test Loss: 43.74674606323242 \n",
      "Epoch: 49460 | MAE Train Loss: 45.844703674316406 | MAE Test Loss: 43.74632263183594 \n",
      "Epoch: 49470 | MAE Train Loss: 45.8438835144043 | MAE Test Loss: 43.74591827392578 \n",
      "Epoch: 49480 | MAE Train Loss: 45.84305953979492 | MAE Test Loss: 43.74551773071289 \n",
      "Epoch: 49490 | MAE Train Loss: 45.84223556518555 | MAE Test Loss: 43.74515151977539 \n",
      "Epoch: 49500 | MAE Train Loss: 45.841407775878906 | MAE Test Loss: 43.744754791259766 \n",
      "Epoch: 49510 | MAE Train Loss: 45.84059143066406 | MAE Test Loss: 43.744354248046875 \n",
      "Epoch: 49520 | MAE Train Loss: 45.83976745605469 | MAE Test Loss: 43.743953704833984 \n",
      "Epoch: 49530 | MAE Train Loss: 45.83894729614258 | MAE Test Loss: 43.743553161621094 \n",
      "Epoch: 49540 | MAE Train Loss: 45.83811569213867 | MAE Test Loss: 43.74315643310547 \n",
      "Epoch: 49550 | MAE Train Loss: 45.83729934692383 | MAE Test Loss: 43.74276351928711 \n",
      "Epoch: 49560 | MAE Train Loss: 45.83647537231445 | MAE Test Loss: 43.74237823486328 \n",
      "Epoch: 49570 | MAE Train Loss: 45.83565139770508 | MAE Test Loss: 43.741973876953125 \n",
      "Epoch: 49580 | MAE Train Loss: 45.83482360839844 | MAE Test Loss: 43.7415771484375 \n",
      "Epoch: 49590 | MAE Train Loss: 45.83399963378906 | MAE Test Loss: 43.74117660522461 \n",
      "Epoch: 49600 | MAE Train Loss: 45.83318328857422 | MAE Test Loss: 43.74079513549805 \n",
      "Epoch: 49610 | MAE Train Loss: 45.832359313964844 | MAE Test Loss: 43.740394592285156 \n",
      "Epoch: 49620 | MAE Train Loss: 45.8315315246582 | MAE Test Loss: 43.739994049072266 \n",
      "Epoch: 49630 | MAE Train Loss: 45.83070755004883 | MAE Test Loss: 43.73959732055664 \n",
      "Epoch: 49640 | MAE Train Loss: 45.82988357543945 | MAE Test Loss: 43.73923110961914 \n",
      "Epoch: 49650 | MAE Train Loss: 45.829063415527344 | MAE Test Loss: 43.738834381103516 \n",
      "Epoch: 49660 | MAE Train Loss: 45.82823944091797 | MAE Test Loss: 43.738433837890625 \n",
      "Epoch: 49670 | MAE Train Loss: 45.827423095703125 | MAE Test Loss: 43.738033294677734 \n",
      "Epoch: 49680 | MAE Train Loss: 45.82659149169922 | MAE Test Loss: 43.737632751464844 \n",
      "Epoch: 49690 | MAE Train Loss: 45.825775146484375 | MAE Test Loss: 43.73723220825195 \n",
      "Epoch: 49700 | MAE Train Loss: 45.824947357177734 | MAE Test Loss: 43.73683547973633 \n",
      "Epoch: 49710 | MAE Train Loss: 45.82412338256836 | MAE Test Loss: 43.73643493652344 \n",
      "Epoch: 49720 | MAE Train Loss: 45.823299407958984 | MAE Test Loss: 43.73606872558594 \n",
      "Epoch: 49730 | MAE Train Loss: 45.822479248046875 | MAE Test Loss: 43.73566818237305 \n",
      "Epoch: 49740 | MAE Train Loss: 45.8216552734375 | MAE Test Loss: 43.735267639160156 \n",
      "Epoch: 49750 | MAE Train Loss: 45.820831298828125 | MAE Test Loss: 43.73488998413086 \n",
      "Epoch: 49760 | MAE Train Loss: 45.82000732421875 | MAE Test Loss: 43.73448944091797 \n",
      "Epoch: 49770 | MAE Train Loss: 45.81918716430664 | MAE Test Loss: 43.73408889770508 \n",
      "Epoch: 49780 | MAE Train Loss: 45.818363189697266 | MAE Test Loss: 43.73368835449219 \n",
      "Epoch: 49790 | MAE Train Loss: 45.81753921508789 | MAE Test Loss: 43.733306884765625 \n",
      "Epoch: 49800 | MAE Train Loss: 45.816715240478516 | MAE Test Loss: 43.732906341552734 \n",
      "Epoch: 49810 | MAE Train Loss: 45.815887451171875 | MAE Test Loss: 43.732505798339844 \n",
      "Epoch: 49820 | MAE Train Loss: 45.815067291259766 | MAE Test Loss: 43.73210906982422 \n",
      "Epoch: 49830 | MAE Train Loss: 45.814247131347656 | MAE Test Loss: 43.73172378540039 \n",
      "Epoch: 49840 | MAE Train Loss: 45.81342315673828 | MAE Test Loss: 43.731327056884766 \n",
      "Epoch: 49850 | MAE Train Loss: 45.81260299682617 | MAE Test Loss: 43.730926513671875 \n",
      "Epoch: 49860 | MAE Train Loss: 45.81177520751953 | MAE Test Loss: 43.73052978515625 \n",
      "Epoch: 49870 | MAE Train Loss: 45.81095504760742 | MAE Test Loss: 43.730125427246094 \n",
      "Epoch: 49880 | MAE Train Loss: 45.81013107299805 | MAE Test Loss: 43.72972869873047 \n",
      "Epoch: 49890 | MAE Train Loss: 45.809303283691406 | MAE Test Loss: 43.729331970214844 \n",
      "Epoch: 49900 | MAE Train Loss: 45.80847930908203 | MAE Test Loss: 43.72893142700195 \n",
      "Epoch: 49910 | MAE Train Loss: 45.80766296386719 | MAE Test Loss: 43.72856521606445 \n",
      "Epoch: 49920 | MAE Train Loss: 45.80683517456055 | MAE Test Loss: 43.72816467285156 \n",
      "Epoch: 49930 | MAE Train Loss: 45.80601501464844 | MAE Test Loss: 43.72776794433594 \n",
      "Epoch: 49940 | MAE Train Loss: 45.80519104003906 | MAE Test Loss: 43.72737121582031 \n",
      "Epoch: 49950 | MAE Train Loss: 45.80437088012695 | MAE Test Loss: 43.726966857910156 \n",
      "Epoch: 49960 | MAE Train Loss: 45.80354309082031 | MAE Test Loss: 43.726566314697266 \n",
      "Epoch: 49970 | MAE Train Loss: 45.80271911621094 | MAE Test Loss: 43.726165771484375 \n",
      "Epoch: 49980 | MAE Train Loss: 45.801902770996094 | MAE Test Loss: 43.72578430175781 \n",
      "Epoch: 49990 | MAE Train Loss: 45.80107498168945 | MAE Test Loss: 43.72538757324219 \n",
      "Epoch: 50000 | MAE Train Loss: 45.80025100708008 | MAE Test Loss: 43.72499084472656 \n",
      "Epoch: 50010 | MAE Train Loss: 45.7994270324707 | MAE Test Loss: 43.72459030151367 \n",
      "Epoch: 50020 | MAE Train Loss: 45.79860305786133 | MAE Test Loss: 43.724205017089844 \n",
      "Epoch: 50030 | MAE Train Loss: 45.79777526855469 | MAE Test Loss: 43.723812103271484 \n",
      "Epoch: 50040 | MAE Train Loss: 45.79695510864258 | MAE Test Loss: 43.72340774536133 \n",
      "Epoch: 50050 | MAE Train Loss: 45.7961311340332 | MAE Test Loss: 43.7230110168457 \n",
      "Epoch: 50060 | MAE Train Loss: 45.795310974121094 | MAE Test Loss: 43.7226448059082 \n",
      "Epoch: 50070 | MAE Train Loss: 45.79448318481445 | MAE Test Loss: 43.72224807739258 \n",
      "Epoch: 50080 | MAE Train Loss: 45.793663024902344 | MAE Test Loss: 43.72184371948242 \n",
      "Epoch: 50090 | MAE Train Loss: 45.792842864990234 | MAE Test Loss: 43.72144317626953 \n",
      "Epoch: 50100 | MAE Train Loss: 45.79201889038086 | MAE Test Loss: 43.72105026245117 \n",
      "Epoch: 50110 | MAE Train Loss: 45.79121017456055 | MAE Test Loss: 43.72062683105469 \n",
      "Epoch: 50120 | MAE Train Loss: 45.79043960571289 | MAE Test Loss: 43.72018814086914 \n",
      "Epoch: 50130 | MAE Train Loss: 45.7896614074707 | MAE Test Loss: 43.719730377197266 \n",
      "Epoch: 50140 | MAE Train Loss: 45.78888702392578 | MAE Test Loss: 43.71929168701172 \n",
      "Epoch: 50150 | MAE Train Loss: 45.788116455078125 | MAE Test Loss: 43.71885299682617 \n",
      "Epoch: 50160 | MAE Train Loss: 45.78733825683594 | MAE Test Loss: 43.718414306640625 \n",
      "Epoch: 50170 | MAE Train Loss: 45.78657150268555 | MAE Test Loss: 43.71796798706055 \n",
      "Epoch: 50180 | MAE Train Loss: 45.785797119140625 | MAE Test Loss: 43.717529296875 \n",
      "Epoch: 50190 | MAE Train Loss: 45.78501510620117 | MAE Test Loss: 43.71708679199219 \n",
      "Epoch: 50200 | MAE Train Loss: 45.784244537353516 | MAE Test Loss: 43.716617584228516 \n",
      "Epoch: 50210 | MAE Train Loss: 45.783470153808594 | MAE Test Loss: 43.716182708740234 \n",
      "Epoch: 50220 | MAE Train Loss: 45.78269958496094 | MAE Test Loss: 43.715736389160156 \n",
      "Epoch: 50230 | MAE Train Loss: 45.78192138671875 | MAE Test Loss: 43.715309143066406 \n",
      "Epoch: 50240 | MAE Train Loss: 45.781150817871094 | MAE Test Loss: 43.71484375 \n",
      "Epoch: 50250 | MAE Train Loss: 45.780372619628906 | MAE Test Loss: 43.71440505981445 \n",
      "Epoch: 50260 | MAE Train Loss: 45.77960205078125 | MAE Test Loss: 43.71396255493164 \n",
      "Epoch: 50270 | MAE Train Loss: 45.77882766723633 | MAE Test Loss: 43.713523864746094 \n",
      "Epoch: 50280 | MAE Train Loss: 45.778053283691406 | MAE Test Loss: 43.71308517456055 \n",
      "Epoch: 50290 | MAE Train Loss: 45.777278900146484 | MAE Test Loss: 43.712642669677734 \n",
      "Epoch: 50300 | MAE Train Loss: 45.77650451660156 | MAE Test Loss: 43.71220397949219 \n",
      "Epoch: 50310 | MAE Train Loss: 45.775726318359375 | MAE Test Loss: 43.71175003051758 \n",
      "Epoch: 50320 | MAE Train Loss: 45.77495574951172 | MAE Test Loss: 43.71131134033203 \n",
      "Epoch: 50330 | MAE Train Loss: 45.77418518066406 | MAE Test Loss: 43.71086502075195 \n",
      "Epoch: 50340 | MAE Train Loss: 45.773406982421875 | MAE Test Loss: 43.71043014526367 \n",
      "Epoch: 50350 | MAE Train Loss: 45.77262878417969 | MAE Test Loss: 43.7099609375 \n",
      "Epoch: 50360 | MAE Train Loss: 45.771854400634766 | MAE Test Loss: 43.70951843261719 \n",
      "Epoch: 50370 | MAE Train Loss: 45.771087646484375 | MAE Test Loss: 43.709075927734375 \n",
      "Epoch: 50380 | MAE Train Loss: 45.77031326293945 | MAE Test Loss: 43.70863723754883 \n",
      "Epoch: 50390 | MAE Train Loss: 45.76953887939453 | MAE Test Loss: 43.70819854736328 \n",
      "Epoch: 50400 | MAE Train Loss: 45.76876449584961 | MAE Test Loss: 43.707759857177734 \n",
      "Epoch: 50410 | MAE Train Loss: 45.76799011230469 | MAE Test Loss: 43.70730209350586 \n",
      "Epoch: 50420 | MAE Train Loss: 45.767215728759766 | MAE Test Loss: 43.70686340332031 \n",
      "Epoch: 50430 | MAE Train Loss: 45.766441345214844 | MAE Test Loss: 43.7064208984375 \n",
      "Epoch: 50440 | MAE Train Loss: 45.76567077636719 | MAE Test Loss: 43.70598220825195 \n",
      "Epoch: 50450 | MAE Train Loss: 45.764888763427734 | MAE Test Loss: 43.705543518066406 \n",
      "Epoch: 50460 | MAE Train Loss: 45.76411819458008 | MAE Test Loss: 43.705074310302734 \n",
      "Epoch: 50470 | MAE Train Loss: 45.76333999633789 | MAE Test Loss: 43.704627990722656 \n",
      "Epoch: 50480 | MAE Train Loss: 45.762569427490234 | MAE Test Loss: 43.704193115234375 \n",
      "Epoch: 50490 | MAE Train Loss: 45.76179885864258 | MAE Test Loss: 43.70375061035156 \n",
      "Epoch: 50500 | MAE Train Loss: 45.76102066040039 | MAE Test Loss: 43.70330810546875 \n",
      "Epoch: 50510 | MAE Train Loss: 45.76025390625 | MAE Test Loss: 43.70287322998047 \n",
      "Epoch: 50520 | MAE Train Loss: 45.75947570800781 | MAE Test Loss: 43.70243453979492 \n",
      "Epoch: 50530 | MAE Train Loss: 45.75870132446289 | MAE Test Loss: 43.701988220214844 \n",
      "Epoch: 50540 | MAE Train Loss: 45.75792694091797 | MAE Test Loss: 43.70151901245117 \n",
      "Epoch: 50550 | MAE Train Loss: 45.75714874267578 | MAE Test Loss: 43.70108413696289 \n",
      "Epoch: 50560 | MAE Train Loss: 45.756378173828125 | MAE Test Loss: 43.70064163208008 \n",
      "Epoch: 50570 | MAE Train Loss: 45.7556037902832 | MAE Test Loss: 43.700199127197266 \n",
      "Epoch: 50580 | MAE Train Loss: 45.754825592041016 | MAE Test Loss: 43.69976043701172 \n",
      "Epoch: 50590 | MAE Train Loss: 45.754051208496094 | MAE Test Loss: 43.69932174682617 \n",
      "Epoch: 50600 | MAE Train Loss: 45.7532844543457 | MAE Test Loss: 43.698883056640625 \n",
      "Epoch: 50610 | MAE Train Loss: 45.752506256103516 | MAE Test Loss: 43.69841003417969 \n",
      "Epoch: 50620 | MAE Train Loss: 45.751731872558594 | MAE Test Loss: 43.69797134399414 \n",
      "Epoch: 50630 | MAE Train Loss: 45.75096130371094 | MAE Test Loss: 43.69752883911133 \n",
      "Epoch: 50640 | MAE Train Loss: 45.750186920166016 | MAE Test Loss: 43.69709014892578 \n",
      "Epoch: 50650 | MAE Train Loss: 45.74940872192383 | MAE Test Loss: 43.6966552734375 \n",
      "Epoch: 50660 | MAE Train Loss: 45.74863815307617 | MAE Test Loss: 43.69620895385742 \n",
      "Epoch: 50670 | MAE Train Loss: 45.74786376953125 | MAE Test Loss: 43.69576644897461 \n",
      "Epoch: 50680 | MAE Train Loss: 45.74708938598633 | MAE Test Loss: 43.6953125 \n",
      "Epoch: 50690 | MAE Train Loss: 45.746315002441406 | MAE Test Loss: 43.69487762451172 \n",
      "Epoch: 50700 | MAE Train Loss: 45.745540618896484 | MAE Test Loss: 43.69443130493164 \n",
      "Epoch: 50710 | MAE Train Loss: 45.74476623535156 | MAE Test Loss: 43.69399642944336 \n",
      "Epoch: 50720 | MAE Train Loss: 45.74399185180664 | MAE Test Loss: 43.69352340698242 \n",
      "Epoch: 50730 | MAE Train Loss: 45.743221282958984 | MAE Test Loss: 43.69308090209961 \n",
      "Epoch: 50740 | MAE Train Loss: 45.7424430847168 | MAE Test Loss: 43.69264602661133 \n",
      "Epoch: 50750 | MAE Train Loss: 45.74167251586914 | MAE Test Loss: 43.692203521728516 \n",
      "Epoch: 50760 | MAE Train Loss: 45.74089813232422 | MAE Test Loss: 43.69176483154297 \n",
      "Epoch: 50770 | MAE Train Loss: 45.7401237487793 | MAE Test Loss: 43.691322326660156 \n",
      "Epoch: 50780 | MAE Train Loss: 45.73935317993164 | MAE Test Loss: 43.69088363647461 \n",
      "Epoch: 50790 | MAE Train Loss: 45.73857498168945 | MAE Test Loss: 43.69044494628906 \n",
      "Epoch: 50800 | MAE Train Loss: 45.73780059814453 | MAE Test Loss: 43.689971923828125 \n",
      "Epoch: 50810 | MAE Train Loss: 45.73702621459961 | MAE Test Loss: 43.68953323364258 \n",
      "Epoch: 50820 | MAE Train Loss: 45.73625183105469 | MAE Test Loss: 43.68909454345703 \n",
      "Epoch: 50830 | MAE Train Loss: 45.735477447509766 | MAE Test Loss: 43.688655853271484 \n",
      "Epoch: 50840 | MAE Train Loss: 45.73470687866211 | MAE Test Loss: 43.688209533691406 \n",
      "Epoch: 50850 | MAE Train Loss: 45.73392868041992 | MAE Test Loss: 43.687767028808594 \n",
      "Epoch: 50860 | MAE Train Loss: 45.733154296875 | MAE Test Loss: 43.68733215332031 \n",
      "Epoch: 50870 | MAE Train Loss: 45.73237609863281 | MAE Test Loss: 43.686859130859375 \n",
      "Epoch: 50880 | MAE Train Loss: 45.731605529785156 | MAE Test Loss: 43.68642044067383 \n",
      "Epoch: 50890 | MAE Train Loss: 45.7308349609375 | MAE Test Loss: 43.68598175048828 \n",
      "Epoch: 50900 | MAE Train Loss: 45.73006057739258 | MAE Test Loss: 43.685543060302734 \n",
      "Epoch: 50910 | MAE Train Loss: 45.729286193847656 | MAE Test Loss: 43.68510437011719 \n",
      "Epoch: 50920 | MAE Train Loss: 45.728511810302734 | MAE Test Loss: 43.68466567993164 \n",
      "Epoch: 50930 | MAE Train Loss: 45.72774124145508 | MAE Test Loss: 43.68422317504883 \n",
      "Epoch: 50940 | MAE Train Loss: 45.72696304321289 | MAE Test Loss: 43.683753967285156 \n",
      "Epoch: 50950 | MAE Train Loss: 45.7261848449707 | MAE Test Loss: 43.68331527709961 \n",
      "Epoch: 50960 | MAE Train Loss: 45.72541809082031 | MAE Test Loss: 43.6828727722168 \n",
      "Epoch: 50970 | MAE Train Loss: 45.72464370727539 | MAE Test Loss: 43.68243408203125 \n",
      "Epoch: 50980 | MAE Train Loss: 45.72386932373047 | MAE Test Loss: 43.68198776245117 \n",
      "Epoch: 50990 | MAE Train Loss: 45.72309875488281 | MAE Test Loss: 43.681549072265625 \n",
      "Epoch: 51000 | MAE Train Loss: 45.722320556640625 | MAE Test Loss: 43.681114196777344 \n",
      "Epoch: 51010 | MAE Train Loss: 45.72154998779297 | MAE Test Loss: 43.68067169189453 \n",
      "Epoch: 51020 | MAE Train Loss: 45.720767974853516 | MAE Test Loss: 43.680206298828125 \n",
      "Epoch: 51030 | MAE Train Loss: 45.720001220703125 | MAE Test Loss: 43.67976379394531 \n",
      "Epoch: 51040 | MAE Train Loss: 45.71922302246094 | MAE Test Loss: 43.6793212890625 \n",
      "Epoch: 51050 | MAE Train Loss: 45.718448638916016 | MAE Test Loss: 43.67888259887695 \n",
      "Epoch: 51060 | MAE Train Loss: 45.71767044067383 | MAE Test Loss: 43.67844009399414 \n",
      "Epoch: 51070 | MAE Train Loss: 45.71690368652344 | MAE Test Loss: 43.678001403808594 \n",
      "Epoch: 51080 | MAE Train Loss: 45.71612548828125 | MAE Test Loss: 43.67756271362305 \n",
      "Epoch: 51090 | MAE Train Loss: 45.71535110473633 | MAE Test Loss: 43.67708969116211 \n",
      "Epoch: 51100 | MAE Train Loss: 45.71460723876953 | MAE Test Loss: 43.6767578125 \n",
      "Epoch: 51110 | MAE Train Loss: 45.7138671875 | MAE Test Loss: 43.67641067504883 \n",
      "Epoch: 51120 | MAE Train Loss: 45.713134765625 | MAE Test Loss: 43.676082611083984 \n",
      "Epoch: 51130 | MAE Train Loss: 45.71239471435547 | MAE Test Loss: 43.675716400146484 \n",
      "Epoch: 51140 | MAE Train Loss: 45.7116584777832 | MAE Test Loss: 43.67538833618164 \n",
      "Epoch: 51150 | MAE Train Loss: 45.7109260559082 | MAE Test Loss: 43.675045013427734 \n",
      "Epoch: 51160 | MAE Train Loss: 45.71017837524414 | MAE Test Loss: 43.674713134765625 \n",
      "Epoch: 51170 | MAE Train Loss: 45.70944595336914 | MAE Test Loss: 43.67435073852539 \n",
      "Epoch: 51180 | MAE Train Loss: 45.70871353149414 | MAE Test Loss: 43.67401885986328 \n",
      "Epoch: 51190 | MAE Train Loss: 45.70797348022461 | MAE Test Loss: 43.67369079589844 \n",
      "Epoch: 51200 | MAE Train Loss: 45.70723342895508 | MAE Test Loss: 43.67332458496094 \n",
      "Epoch: 51210 | MAE Train Loss: 45.70650100708008 | MAE Test Loss: 43.67300033569336 \n",
      "Epoch: 51220 | MAE Train Loss: 45.70575714111328 | MAE Test Loss: 43.67266845703125 \n",
      "Epoch: 51230 | MAE Train Loss: 45.70502471923828 | MAE Test Loss: 43.67230224609375 \n",
      "Epoch: 51240 | MAE Train Loss: 45.704288482666016 | MAE Test Loss: 43.67197036743164 \n",
      "Epoch: 51250 | MAE Train Loss: 45.70354461669922 | MAE Test Loss: 43.67164611816406 \n",
      "Epoch: 51260 | MAE Train Loss: 45.70280838012695 | MAE Test Loss: 43.6712760925293 \n",
      "Epoch: 51270 | MAE Train Loss: 45.70206832885742 | MAE Test Loss: 43.67095184326172 \n",
      "Epoch: 51280 | MAE Train Loss: 45.701332092285156 | MAE Test Loss: 43.67060852050781 \n",
      "Epoch: 51290 | MAE Train Loss: 45.700592041015625 | MAE Test Loss: 43.67027282714844 \n",
      "Epoch: 51300 | MAE Train Loss: 45.699859619140625 | MAE Test Loss: 43.66991424560547 \n",
      "Epoch: 51310 | MAE Train Loss: 45.69912338256836 | MAE Test Loss: 43.6695671081543 \n",
      "Epoch: 51320 | MAE Train Loss: 45.698387145996094 | MAE Test Loss: 43.66923522949219 \n",
      "Epoch: 51330 | MAE Train Loss: 45.69765090942383 | MAE Test Loss: 43.668907165527344 \n",
      "Epoch: 51340 | MAE Train Loss: 45.6969108581543 | MAE Test Loss: 43.668540954589844 \n",
      "Epoch: 51350 | MAE Train Loss: 45.69617462158203 | MAE Test Loss: 43.668212890625 \n",
      "Epoch: 51360 | MAE Train Loss: 45.6954345703125 | MAE Test Loss: 43.66788101196289 \n",
      "Epoch: 51370 | MAE Train Loss: 45.694698333740234 | MAE Test Loss: 43.667518615722656 \n",
      "Epoch: 51380 | MAE Train Loss: 45.69396209716797 | MAE Test Loss: 43.66719055175781 \n",
      "Epoch: 51390 | MAE Train Loss: 45.69322204589844 | MAE Test Loss: 43.6668586730957 \n",
      "Epoch: 51400 | MAE Train Loss: 45.69248962402344 | MAE Test Loss: 43.666500091552734 \n",
      "Epoch: 51410 | MAE Train Loss: 45.691749572753906 | MAE Test Loss: 43.666168212890625 \n",
      "Epoch: 51420 | MAE Train Loss: 45.691009521484375 | MAE Test Loss: 43.665802001953125 \n",
      "Epoch: 51430 | MAE Train Loss: 45.69027328491211 | MAE Test Loss: 43.66547393798828 \n",
      "Epoch: 51440 | MAE Train Loss: 45.689537048339844 | MAE Test Loss: 43.66514587402344 \n",
      "Epoch: 51450 | MAE Train Loss: 45.68880081176758 | MAE Test Loss: 43.66477966308594 \n",
      "Epoch: 51460 | MAE Train Loss: 45.68806457519531 | MAE Test Loss: 43.66444778442383 \n",
      "Epoch: 51470 | MAE Train Loss: 45.68732833862305 | MAE Test Loss: 43.664119720458984 \n",
      "Epoch: 51480 | MAE Train Loss: 45.686588287353516 | MAE Test Loss: 43.663761138916016 \n",
      "Epoch: 51490 | MAE Train Loss: 45.68585205078125 | MAE Test Loss: 43.66342544555664 \n",
      "Epoch: 51500 | MAE Train Loss: 45.685115814208984 | MAE Test Loss: 43.6630859375 \n",
      "Epoch: 51510 | MAE Train Loss: 45.68437576293945 | MAE Test Loss: 43.662750244140625 \n",
      "Epoch: 51520 | MAE Train Loss: 45.68363952636719 | MAE Test Loss: 43.66238784790039 \n",
      "Epoch: 51530 | MAE Train Loss: 45.68290328979492 | MAE Test Loss: 43.66205596923828 \n",
      "Epoch: 51540 | MAE Train Loss: 45.682159423828125 | MAE Test Loss: 43.6617317199707 \n",
      "Epoch: 51550 | MAE Train Loss: 45.68142318725586 | MAE Test Loss: 43.66136169433594 \n",
      "Epoch: 51560 | MAE Train Loss: 45.68069076538086 | MAE Test Loss: 43.661033630371094 \n",
      "Epoch: 51570 | MAE Train Loss: 45.67994689941406 | MAE Test Loss: 43.66070556640625 \n",
      "Epoch: 51580 | MAE Train Loss: 45.6792106628418 | MAE Test Loss: 43.660343170166016 \n",
      "Epoch: 51590 | MAE Train Loss: 45.67847442626953 | MAE Test Loss: 43.66001510620117 \n",
      "Epoch: 51600 | MAE Train Loss: 45.677738189697266 | MAE Test Loss: 43.65968322753906 \n",
      "Epoch: 51610 | MAE Train Loss: 45.677001953125 | MAE Test Loss: 43.65932083129883 \n",
      "Epoch: 51620 | MAE Train Loss: 45.67626190185547 | MAE Test Loss: 43.65898895263672 \n",
      "Epoch: 51630 | MAE Train Loss: 45.67552185058594 | MAE Test Loss: 43.658660888671875 \n",
      "Epoch: 51640 | MAE Train Loss: 45.67478561401367 | MAE Test Loss: 43.658294677734375 \n",
      "Epoch: 51650 | MAE Train Loss: 45.67405319213867 | MAE Test Loss: 43.657962799072266 \n",
      "Epoch: 51660 | MAE Train Loss: 45.673309326171875 | MAE Test Loss: 43.6576042175293 \n",
      "Epoch: 51670 | MAE Train Loss: 45.67258071899414 | MAE Test Loss: 43.65727233886719 \n",
      "Epoch: 51680 | MAE Train Loss: 45.671836853027344 | MAE Test Loss: 43.65694046020508 \n",
      "Epoch: 51690 | MAE Train Loss: 45.67110061645508 | MAE Test Loss: 43.65658187866211 \n",
      "Epoch: 51700 | MAE Train Loss: 45.67036056518555 | MAE Test Loss: 43.65626525878906 \n",
      "Epoch: 51710 | MAE Train Loss: 45.66962432861328 | MAE Test Loss: 43.65590286254883 \n",
      "Epoch: 51720 | MAE Train Loss: 45.668888092041016 | MAE Test Loss: 43.655574798583984 \n",
      "Epoch: 51730 | MAE Train Loss: 45.66815185546875 | MAE Test Loss: 43.655208587646484 \n",
      "Epoch: 51740 | MAE Train Loss: 45.667415618896484 | MAE Test Loss: 43.654884338378906 \n",
      "Epoch: 51750 | MAE Train Loss: 45.66667556762695 | MAE Test Loss: 43.65454864501953 \n",
      "Epoch: 51760 | MAE Train Loss: 45.66593551635742 | MAE Test Loss: 43.6541862487793 \n",
      "Epoch: 51770 | MAE Train Loss: 45.66520690917969 | MAE Test Loss: 43.65385818481445 \n",
      "Epoch: 51780 | MAE Train Loss: 45.66446304321289 | MAE Test Loss: 43.65353012084961 \n",
      "Epoch: 51790 | MAE Train Loss: 45.663726806640625 | MAE Test Loss: 43.653167724609375 \n",
      "Epoch: 51800 | MAE Train Loss: 45.66299057006836 | MAE Test Loss: 43.652835845947266 \n",
      "Epoch: 51810 | MAE Train Loss: 45.66224670410156 | MAE Test Loss: 43.652503967285156 \n",
      "Epoch: 51820 | MAE Train Loss: 45.66151809692383 | MAE Test Loss: 43.65214157104492 \n",
      "Epoch: 51830 | MAE Train Loss: 45.66077423095703 | MAE Test Loss: 43.651798248291016 \n",
      "Epoch: 51840 | MAE Train Loss: 45.66004180908203 | MAE Test Loss: 43.65147018432617 \n",
      "Epoch: 51850 | MAE Train Loss: 45.6593017578125 | MAE Test Loss: 43.65113830566406 \n",
      "Epoch: 51860 | MAE Train Loss: 45.658565521240234 | MAE Test Loss: 43.650787353515625 \n",
      "Epoch: 51870 | MAE Train Loss: 45.6578254699707 | MAE Test Loss: 43.650428771972656 \n",
      "Epoch: 51880 | MAE Train Loss: 45.65708923339844 | MAE Test Loss: 43.65009689331055 \n",
      "Epoch: 51890 | MAE Train Loss: 45.65635299682617 | MAE Test Loss: 43.649749755859375 \n",
      "Epoch: 51900 | MAE Train Loss: 45.655616760253906 | MAE Test Loss: 43.649417877197266 \n",
      "Epoch: 51910 | MAE Train Loss: 45.654876708984375 | MAE Test Loss: 43.649085998535156 \n",
      "Epoch: 51920 | MAE Train Loss: 45.65414047241211 | MAE Test Loss: 43.64873123168945 \n",
      "Epoch: 51930 | MAE Train Loss: 45.653404235839844 | MAE Test Loss: 43.648399353027344 \n",
      "Epoch: 51940 | MAE Train Loss: 45.65266036987305 | MAE Test Loss: 43.648033142089844 \n",
      "Epoch: 51950 | MAE Train Loss: 45.65192794799805 | MAE Test Loss: 43.647705078125 \n",
      "Epoch: 51960 | MAE Train Loss: 45.65119171142578 | MAE Test Loss: 43.647377014160156 \n",
      "Epoch: 51970 | MAE Train Loss: 45.65045166015625 | MAE Test Loss: 43.64701461791992 \n",
      "Epoch: 51980 | MAE Train Loss: 45.649715423583984 | MAE Test Loss: 43.64667510986328 \n",
      "Epoch: 51990 | MAE Train Loss: 45.64897918701172 | MAE Test Loss: 43.6463508605957 \n",
      "Epoch: 52000 | MAE Train Loss: 45.64824295043945 | MAE Test Loss: 43.645992279052734 \n",
      "Epoch: 52010 | MAE Train Loss: 45.64750671386719 | MAE Test Loss: 43.645660400390625 \n",
      "Epoch: 52020 | MAE Train Loss: 45.646766662597656 | MAE Test Loss: 43.64531326293945 \n",
      "Epoch: 52030 | MAE Train Loss: 45.64603042602539 | MAE Test Loss: 43.64498519897461 \n",
      "Epoch: 52040 | MAE Train Loss: 45.64529037475586 | MAE Test Loss: 43.64461898803711 \n",
      "Epoch: 52050 | MAE Train Loss: 45.64455795288086 | MAE Test Loss: 43.64430618286133 \n",
      "Epoch: 52060 | MAE Train Loss: 45.64381790161133 | MAE Test Loss: 43.64393997192383 \n",
      "Epoch: 52070 | MAE Train Loss: 45.64308166503906 | MAE Test Loss: 43.64361572265625 \n",
      "Epoch: 52080 | MAE Train Loss: 45.642337799072266 | MAE Test Loss: 43.643245697021484 \n",
      "Epoch: 52090 | MAE Train Loss: 45.641605377197266 | MAE Test Loss: 43.64291763305664 \n",
      "Epoch: 52100 | MAE Train Loss: 45.640865325927734 | MAE Test Loss: 43.6425895690918 \n",
      "Epoch: 52110 | MAE Train Loss: 45.6401252746582 | MAE Test Loss: 43.64223098754883 \n",
      "Epoch: 52120 | MAE Train Loss: 45.63939666748047 | MAE Test Loss: 43.64189529418945 \n",
      "Epoch: 52130 | MAE Train Loss: 45.63865661621094 | MAE Test Loss: 43.64156723022461 \n",
      "Epoch: 52140 | MAE Train Loss: 45.637916564941406 | MAE Test Loss: 43.641204833984375 \n",
      "Epoch: 52150 | MAE Train Loss: 45.637184143066406 | MAE Test Loss: 43.640872955322266 \n",
      "Epoch: 52160 | MAE Train Loss: 45.63644027709961 | MAE Test Loss: 43.640541076660156 \n",
      "Epoch: 52170 | MAE Train Loss: 45.63570785522461 | MAE Test Loss: 43.64017868041992 \n",
      "Epoch: 52180 | MAE Train Loss: 45.634971618652344 | MAE Test Loss: 43.63984680175781 \n",
      "Epoch: 52190 | MAE Train Loss: 45.63423156738281 | MAE Test Loss: 43.639522552490234 \n",
      "Epoch: 52200 | MAE Train Loss: 45.63349151611328 | MAE Test Loss: 43.639156341552734 \n",
      "Epoch: 52210 | MAE Train Loss: 45.632755279541016 | MAE Test Loss: 43.638824462890625 \n",
      "Epoch: 52220 | MAE Train Loss: 45.63201904296875 | MAE Test Loss: 43.63849639892578 \n",
      "Epoch: 52230 | MAE Train Loss: 45.631282806396484 | MAE Test Loss: 43.63813400268555 \n",
      "Epoch: 52240 | MAE Train Loss: 45.63054275512695 | MAE Test Loss: 43.6378059387207 \n",
      "Epoch: 52250 | MAE Train Loss: 45.62980651855469 | MAE Test Loss: 43.63745880126953 \n",
      "Epoch: 52260 | MAE Train Loss: 45.62907028198242 | MAE Test Loss: 43.637123107910156 \n",
      "Epoch: 52270 | MAE Train Loss: 45.62833023071289 | MAE Test Loss: 43.63676452636719 \n",
      "Epoch: 52280 | MAE Train Loss: 45.627593994140625 | MAE Test Loss: 43.636436462402344 \n",
      "Epoch: 52290 | MAE Train Loss: 45.62685775756836 | MAE Test Loss: 43.6361083984375 \n",
      "Epoch: 52300 | MAE Train Loss: 45.626121520996094 | MAE Test Loss: 43.6357421875 \n",
      "Epoch: 52310 | MAE Train Loss: 45.62538146972656 | MAE Test Loss: 43.635414123535156 \n",
      "Epoch: 52320 | MAE Train Loss: 45.62464141845703 | MAE Test Loss: 43.63505172729492 \n",
      "Epoch: 52330 | MAE Train Loss: 45.62390899658203 | MAE Test Loss: 43.63471984863281 \n",
      "Epoch: 52340 | MAE Train Loss: 45.6231689453125 | MAE Test Loss: 43.6343879699707 \n",
      "Epoch: 52350 | MAE Train Loss: 45.622432708740234 | MAE Test Loss: 43.634029388427734 \n",
      "Epoch: 52360 | MAE Train Loss: 45.6216926574707 | MAE Test Loss: 43.633697509765625 \n",
      "Epoch: 52370 | MAE Train Loss: 45.62095642089844 | MAE Test Loss: 43.633365631103516 \n",
      "Epoch: 52380 | MAE Train Loss: 45.62022018432617 | MAE Test Loss: 43.633018493652344 \n",
      "Epoch: 52390 | MAE Train Loss: 45.619483947753906 | MAE Test Loss: 43.632659912109375 \n",
      "Epoch: 52400 | MAE Train Loss: 45.618743896484375 | MAE Test Loss: 43.63232421875 \n",
      "Epoch: 52410 | MAE Train Loss: 45.61800765991211 | MAE Test Loss: 43.63197708129883 \n",
      "Epoch: 52420 | MAE Train Loss: 45.617271423339844 | MAE Test Loss: 43.631649017333984 \n",
      "Epoch: 52430 | MAE Train Loss: 45.61653137207031 | MAE Test Loss: 43.63132095336914 \n",
      "Epoch: 52440 | MAE Train Loss: 45.61579132080078 | MAE Test Loss: 43.630958557128906 \n",
      "Epoch: 52450 | MAE Train Loss: 45.61505889892578 | MAE Test Loss: 43.63063049316406 \n",
      "Epoch: 52460 | MAE Train Loss: 45.61431884765625 | MAE Test Loss: 43.63026809692383 \n",
      "Epoch: 52470 | MAE Train Loss: 45.61358642578125 | MAE Test Loss: 43.62993621826172 \n",
      "Epoch: 52480 | MAE Train Loss: 45.61284255981445 | MAE Test Loss: 43.629608154296875 \n",
      "Epoch: 52490 | MAE Train Loss: 45.61210632324219 | MAE Test Loss: 43.629241943359375 \n",
      "Epoch: 52500 | MAE Train Loss: 45.61137390136719 | MAE Test Loss: 43.628910064697266 \n",
      "Epoch: 52510 | MAE Train Loss: 45.610633850097656 | MAE Test Loss: 43.628578186035156 \n",
      "Epoch: 52520 | MAE Train Loss: 45.60989761352539 | MAE Test Loss: 43.62821960449219 \n",
      "Epoch: 52530 | MAE Train Loss: 45.60915756225586 | MAE Test Loss: 43.627891540527344 \n",
      "Epoch: 52540 | MAE Train Loss: 45.60841751098633 | MAE Test Loss: 43.627559661865234 \n",
      "Epoch: 52550 | MAE Train Loss: 45.60768508911133 | MAE Test Loss: 43.627193450927734 \n",
      "Epoch: 52560 | MAE Train Loss: 45.60694885253906 | MAE Test Loss: 43.626869201660156 \n",
      "Epoch: 52570 | MAE Train Loss: 45.60620880126953 | MAE Test Loss: 43.62653732299805 \n",
      "Epoch: 52580 | MAE Train Loss: 45.605472564697266 | MAE Test Loss: 43.62617492675781 \n",
      "Epoch: 52590 | MAE Train Loss: 45.604732513427734 | MAE Test Loss: 43.6258430480957 \n",
      "Epoch: 52600 | MAE Train Loss: 45.6039924621582 | MAE Test Loss: 43.62549591064453 \n",
      "Epoch: 52610 | MAE Train Loss: 45.60325622558594 | MAE Test Loss: 43.62517166137695 \n",
      "Epoch: 52620 | MAE Train Loss: 45.60252380371094 | MAE Test Loss: 43.62480163574219 \n",
      "Epoch: 52630 | MAE Train Loss: 45.601783752441406 | MAE Test Loss: 43.62447738647461 \n",
      "Epoch: 52640 | MAE Train Loss: 45.601043701171875 | MAE Test Loss: 43.6241455078125 \n",
      "Epoch: 52650 | MAE Train Loss: 45.600311279296875 | MAE Test Loss: 43.623783111572266 \n",
      "Epoch: 52660 | MAE Train Loss: 45.59957504272461 | MAE Test Loss: 43.623451232910156 \n",
      "Epoch: 52670 | MAE Train Loss: 45.59883117675781 | MAE Test Loss: 43.62312316894531 \n",
      "Epoch: 52680 | MAE Train Loss: 45.59809875488281 | MAE Test Loss: 43.62276077270508 \n",
      "Epoch: 52690 | MAE Train Loss: 45.59735870361328 | MAE Test Loss: 43.6224250793457 \n",
      "Epoch: 52700 | MAE Train Loss: 45.596622467041016 | MAE Test Loss: 43.622066497802734 \n",
      "Epoch: 52710 | MAE Train Loss: 45.595882415771484 | MAE Test Loss: 43.621734619140625 \n",
      "Epoch: 52720 | MAE Train Loss: 45.59514617919922 | MAE Test Loss: 43.62140655517578 \n",
      "Epoch: 52730 | MAE Train Loss: 45.59440994262695 | MAE Test Loss: 43.62104415893555 \n",
      "Epoch: 52740 | MAE Train Loss: 45.59367370605469 | MAE Test Loss: 43.62070846557617 \n",
      "Epoch: 52750 | MAE Train Loss: 45.59292984008789 | MAE Test Loss: 43.62038040161133 \n",
      "Epoch: 52760 | MAE Train Loss: 45.592193603515625 | MAE Test Loss: 43.62002182006836 \n",
      "Epoch: 52770 | MAE Train Loss: 45.591461181640625 | MAE Test Loss: 43.61968994140625 \n",
      "Epoch: 52780 | MAE Train Loss: 45.59072494506836 | MAE Test Loss: 43.619361877441406 \n",
      "Epoch: 52790 | MAE Train Loss: 45.589988708496094 | MAE Test Loss: 43.618995666503906 \n",
      "Epoch: 52800 | MAE Train Loss: 45.5892448425293 | MAE Test Loss: 43.618648529052734 \n",
      "Epoch: 52810 | MAE Train Loss: 45.5885124206543 | MAE Test Loss: 43.61832046508789 \n",
      "Epoch: 52820 | MAE Train Loss: 45.58777618408203 | MAE Test Loss: 43.61799240112305 \n",
      "Epoch: 52830 | MAE Train Loss: 45.5870361328125 | MAE Test Loss: 43.61763000488281 \n",
      "Epoch: 52840 | MAE Train Loss: 45.5863037109375 | MAE Test Loss: 43.6172981262207 \n",
      "Epoch: 52850 | MAE Train Loss: 45.58555603027344 | MAE Test Loss: 43.616966247558594 \n",
      "Epoch: 52860 | MAE Train Loss: 45.58482360839844 | MAE Test Loss: 43.61660385131836 \n",
      "Epoch: 52870 | MAE Train Loss: 45.58409118652344 | MAE Test Loss: 43.616275787353516 \n",
      "Epoch: 52880 | MAE Train Loss: 45.58334732055664 | MAE Test Loss: 43.615943908691406 \n",
      "Epoch: 52890 | MAE Train Loss: 45.58261489868164 | MAE Test Loss: 43.61558151245117 \n",
      "Epoch: 52900 | MAE Train Loss: 45.58187484741211 | MAE Test Loss: 43.61524963378906 \n",
      "Epoch: 52910 | MAE Train Loss: 45.58113479614258 | MAE Test Loss: 43.61488723754883 \n",
      "Epoch: 52920 | MAE Train Loss: 45.58040237426758 | MAE Test Loss: 43.61455535888672 \n",
      "Epoch: 52930 | MAE Train Loss: 45.57966232299805 | MAE Test Loss: 43.61423110961914 \n",
      "Epoch: 52940 | MAE Train Loss: 45.57892608642578 | MAE Test Loss: 43.613861083984375 \n",
      "Epoch: 52950 | MAE Train Loss: 45.578189849853516 | MAE Test Loss: 43.613529205322266 \n",
      "Epoch: 52960 | MAE Train Loss: 45.577449798583984 | MAE Test Loss: 43.61320495605469 \n",
      "Epoch: 52970 | MAE Train Loss: 45.57671356201172 | MAE Test Loss: 43.61283874511719 \n",
      "Epoch: 52980 | MAE Train Loss: 45.57597732543945 | MAE Test Loss: 43.612510681152344 \n",
      "Epoch: 52990 | MAE Train Loss: 45.57524108886719 | MAE Test Loss: 43.61216735839844 \n",
      "Epoch: 53000 | MAE Train Loss: 45.57449722290039 | MAE Test Loss: 43.611839294433594 \n",
      "Epoch: 53010 | MAE Train Loss: 45.573760986328125 | MAE Test Loss: 43.611473083496094 \n",
      "Epoch: 53020 | MAE Train Loss: 45.573028564453125 | MAE Test Loss: 43.61114501953125 \n",
      "Epoch: 53030 | MAE Train Loss: 45.572288513183594 | MAE Test Loss: 43.610809326171875 \n",
      "Epoch: 53040 | MAE Train Loss: 45.57154846191406 | MAE Test Loss: 43.61045455932617 \n",
      "Epoch: 53050 | MAE Train Loss: 45.57081604003906 | MAE Test Loss: 43.61012268066406 \n",
      "Epoch: 53060 | MAE Train Loss: 45.57007598876953 | MAE Test Loss: 43.60979080200195 \n",
      "Epoch: 53070 | MAE Train Loss: 45.569339752197266 | MAE Test Loss: 43.60942840576172 \n",
      "Epoch: 53080 | MAE Train Loss: 45.568603515625 | MAE Test Loss: 43.60909652709961 \n",
      "Epoch: 53090 | MAE Train Loss: 45.5678596496582 | MAE Test Loss: 43.6087646484375 \n",
      "Epoch: 53100 | MAE Train Loss: 45.5671272277832 | MAE Test Loss: 43.608402252197266 \n",
      "Epoch: 53110 | MAE Train Loss: 45.56639099121094 | MAE Test Loss: 43.60807418823242 \n",
      "Epoch: 53120 | MAE Train Loss: 45.56565475463867 | MAE Test Loss: 43.60772705078125 \n",
      "Epoch: 53130 | MAE Train Loss: 45.564910888671875 | MAE Test Loss: 43.607398986816406 \n",
      "Epoch: 53140 | MAE Train Loss: 45.564178466796875 | MAE Test Loss: 43.60703659057617 \n",
      "Epoch: 53150 | MAE Train Loss: 45.56344223022461 | MAE Test Loss: 43.60670471191406 \n",
      "Epoch: 53160 | MAE Train Loss: 45.56270217895508 | MAE Test Loss: 43.60635757446289 \n",
      "Epoch: 53170 | MAE Train Loss: 45.56196212768555 | MAE Test Loss: 43.60602951049805 \n",
      "Epoch: 53180 | MAE Train Loss: 45.56122589111328 | MAE Test Loss: 43.60566711425781 \n",
      "Epoch: 53190 | MAE Train Loss: 45.560489654541016 | MAE Test Loss: 43.6053352355957 \n",
      "Epoch: 53200 | MAE Train Loss: 45.559749603271484 | MAE Test Loss: 43.60500717163086 \n",
      "Epoch: 53210 | MAE Train Loss: 45.55901336669922 | MAE Test Loss: 43.60464096069336 \n",
      "Epoch: 53220 | MAE Train Loss: 45.55828094482422 | MAE Test Loss: 43.60431671142578 \n",
      "Epoch: 53230 | MAE Train Loss: 45.55754089355469 | MAE Test Loss: 43.603981018066406 \n",
      "Epoch: 53240 | MAE Train Loss: 45.556800842285156 | MAE Test Loss: 43.60362243652344 \n",
      "Epoch: 53250 | MAE Train Loss: 45.556068420410156 | MAE Test Loss: 43.60329055786133 \n",
      "Epoch: 53260 | MAE Train Loss: 45.555328369140625 | MAE Test Loss: 43.60295867919922 \n",
      "Epoch: 53270 | MAE Train Loss: 45.55459976196289 | MAE Test Loss: 43.60257339477539 \n",
      "Epoch: 53280 | MAE Train Loss: 45.55387878417969 | MAE Test Loss: 43.602237701416016 \n",
      "Epoch: 53290 | MAE Train Loss: 45.55317306518555 | MAE Test Loss: 43.60187911987305 \n",
      "Epoch: 53300 | MAE Train Loss: 45.552459716796875 | MAE Test Loss: 43.60151672363281 \n",
      "Epoch: 53310 | MAE Train Loss: 45.55175018310547 | MAE Test Loss: 43.601165771484375 \n",
      "Epoch: 53320 | MAE Train Loss: 45.55104064941406 | MAE Test Loss: 43.600807189941406 \n",
      "Epoch: 53330 | MAE Train Loss: 45.55033493041992 | MAE Test Loss: 43.6004524230957 \n",
      "Epoch: 53340 | MAE Train Loss: 45.549625396728516 | MAE Test Loss: 43.600093841552734 \n",
      "Epoch: 53350 | MAE Train Loss: 45.548912048339844 | MAE Test Loss: 43.5997314453125 \n",
      "Epoch: 53360 | MAE Train Loss: 45.5482063293457 | MAE Test Loss: 43.59937286376953 \n",
      "Epoch: 53370 | MAE Train Loss: 45.54749298095703 | MAE Test Loss: 43.59901428222656 \n",
      "Epoch: 53380 | MAE Train Loss: 45.54677963256836 | MAE Test Loss: 43.598655700683594 \n",
      "Epoch: 53390 | MAE Train Loss: 45.546077728271484 | MAE Test Loss: 43.59830093383789 \n",
      "Epoch: 53400 | MAE Train Loss: 45.54536437988281 | MAE Test Loss: 43.59794616699219 \n",
      "Epoch: 53410 | MAE Train Loss: 45.544654846191406 | MAE Test Loss: 43.59760665893555 \n",
      "Epoch: 53420 | MAE Train Loss: 45.543949127197266 | MAE Test Loss: 43.59725570678711 \n",
      "Epoch: 53430 | MAE Train Loss: 45.543235778808594 | MAE Test Loss: 43.59688949584961 \n",
      "Epoch: 53440 | MAE Train Loss: 45.54253005981445 | MAE Test Loss: 43.59653854370117 \n",
      "Epoch: 53450 | MAE Train Loss: 45.54182052612305 | MAE Test Loss: 43.59617614746094 \n",
      "Epoch: 53460 | MAE Train Loss: 45.54111099243164 | MAE Test Loss: 43.59581756591797 \n",
      "Epoch: 53470 | MAE Train Loss: 45.5404052734375 | MAE Test Loss: 43.59546661376953 \n",
      "Epoch: 53480 | MAE Train Loss: 45.53969192504883 | MAE Test Loss: 43.5951042175293 \n",
      "Epoch: 53490 | MAE Train Loss: 45.53898620605469 | MAE Test Loss: 43.59474563598633 \n",
      "Epoch: 53500 | MAE Train Loss: 45.53827667236328 | MAE Test Loss: 43.594390869140625 \n",
      "Epoch: 53510 | MAE Train Loss: 45.537567138671875 | MAE Test Loss: 43.59402847290039 \n",
      "Epoch: 53520 | MAE Train Loss: 45.53685760498047 | MAE Test Loss: 43.59366989135742 \n",
      "Epoch: 53530 | MAE Train Loss: 45.53614807128906 | MAE Test Loss: 43.59331512451172 \n",
      "Epoch: 53540 | MAE Train Loss: 45.535438537597656 | MAE Test Loss: 43.592952728271484 \n",
      "Epoch: 53550 | MAE Train Loss: 45.53472900390625 | MAE Test Loss: 43.59259796142578 \n",
      "Epoch: 53560 | MAE Train Loss: 45.534019470214844 | MAE Test Loss: 43.59223937988281 \n",
      "Epoch: 53570 | MAE Train Loss: 45.53331756591797 | MAE Test Loss: 43.591880798339844 \n",
      "Epoch: 53580 | MAE Train Loss: 45.53260040283203 | MAE Test Loss: 43.591522216796875 \n",
      "Epoch: 53590 | MAE Train Loss: 45.531890869140625 | MAE Test Loss: 43.59116744995117 \n",
      "Epoch: 53600 | MAE Train Loss: 45.531185150146484 | MAE Test Loss: 43.5908088684082 \n",
      "Epoch: 53610 | MAE Train Loss: 45.53047180175781 | MAE Test Loss: 43.59044647216797 \n",
      "Epoch: 53620 | MAE Train Loss: 45.52976608276367 | MAE Test Loss: 43.590091705322266 \n",
      "Epoch: 53630 | MAE Train Loss: 45.529052734375 | MAE Test Loss: 43.5897331237793 \n",
      "Epoch: 53640 | MAE Train Loss: 45.52834701538086 | MAE Test Loss: 43.58937454223633 \n",
      "Epoch: 53650 | MAE Train Loss: 45.52763366699219 | MAE Test Loss: 43.589019775390625 \n",
      "Epoch: 53660 | MAE Train Loss: 45.52693176269531 | MAE Test Loss: 43.588661193847656 \n",
      "Epoch: 53670 | MAE Train Loss: 45.52621841430664 | MAE Test Loss: 43.58830261230469 \n",
      "Epoch: 53680 | MAE Train Loss: 45.52550506591797 | MAE Test Loss: 43.58794403076172 \n",
      "Epoch: 53690 | MAE Train Loss: 45.524803161621094 | MAE Test Loss: 43.587581634521484 \n",
      "Epoch: 53700 | MAE Train Loss: 45.524085998535156 | MAE Test Loss: 43.58722686767578 \n",
      "Epoch: 53710 | MAE Train Loss: 45.523380279541016 | MAE Test Loss: 43.58686828613281 \n",
      "Epoch: 53720 | MAE Train Loss: 45.522666931152344 | MAE Test Loss: 43.586509704589844 \n",
      "Epoch: 53730 | MAE Train Loss: 45.5219612121582 | MAE Test Loss: 43.58614730834961 \n",
      "Epoch: 53740 | MAE Train Loss: 45.52124786376953 | MAE Test Loss: 43.58579635620117 \n",
      "Epoch: 53750 | MAE Train Loss: 45.52054214477539 | MAE Test Loss: 43.58546447753906 \n",
      "Epoch: 53760 | MAE Train Loss: 45.519832611083984 | MAE Test Loss: 43.585105895996094 \n",
      "Epoch: 53770 | MAE Train Loss: 45.51912307739258 | MAE Test Loss: 43.584747314453125 \n",
      "Epoch: 53780 | MAE Train Loss: 45.51841735839844 | MAE Test Loss: 43.584388732910156 \n",
      "Epoch: 53790 | MAE Train Loss: 45.517704010009766 | MAE Test Loss: 43.58403396606445 \n",
      "Epoch: 53800 | MAE Train Loss: 45.51699447631836 | MAE Test Loss: 43.58367156982422 \n",
      "Epoch: 53810 | MAE Train Loss: 45.51628494262695 | MAE Test Loss: 43.583316802978516 \n",
      "Epoch: 53820 | MAE Train Loss: 45.51557922363281 | MAE Test Loss: 43.58295822143555 \n",
      "Epoch: 53830 | MAE Train Loss: 45.514869689941406 | MAE Test Loss: 43.582603454589844 \n",
      "Epoch: 53840 | MAE Train Loss: 45.51416015625 | MAE Test Loss: 43.58224105834961 \n",
      "Epoch: 53850 | MAE Train Loss: 45.513450622558594 | MAE Test Loss: 43.58188247680664 \n",
      "Epoch: 53860 | MAE Train Loss: 45.51274490356445 | MAE Test Loss: 43.58152389526367 \n",
      "Epoch: 53870 | MAE Train Loss: 45.51203155517578 | MAE Test Loss: 43.5811653137207 \n",
      "Epoch: 53880 | MAE Train Loss: 45.511322021484375 | MAE Test Loss: 43.580810546875 \n",
      "Epoch: 53890 | MAE Train Loss: 45.510616302490234 | MAE Test Loss: 43.5804557800293 \n",
      "Epoch: 53900 | MAE Train Loss: 45.50990676879883 | MAE Test Loss: 43.5800895690918 \n",
      "Epoch: 53910 | MAE Train Loss: 45.50919723510742 | MAE Test Loss: 43.57973098754883 \n",
      "Epoch: 53920 | MAE Train Loss: 45.508487701416016 | MAE Test Loss: 43.57937240600586 \n",
      "Epoch: 53930 | MAE Train Loss: 45.50777816772461 | MAE Test Loss: 43.579017639160156 \n",
      "Epoch: 53940 | MAE Train Loss: 45.5070686340332 | MAE Test Loss: 43.57865905761719 \n",
      "Epoch: 53950 | MAE Train Loss: 45.5063591003418 | MAE Test Loss: 43.57830047607422 \n",
      "Epoch: 53960 | MAE Train Loss: 45.505653381347656 | MAE Test Loss: 43.577938079833984 \n",
      "Epoch: 53970 | MAE Train Loss: 45.504940032958984 | MAE Test Loss: 43.57758331298828 \n",
      "Epoch: 53980 | MAE Train Loss: 45.504234313964844 | MAE Test Loss: 43.57722473144531 \n",
      "Epoch: 53990 | MAE Train Loss: 45.50352478027344 | MAE Test Loss: 43.57686996459961 \n",
      "Epoch: 54000 | MAE Train Loss: 45.50281524658203 | MAE Test Loss: 43.576507568359375 \n",
      "Epoch: 54010 | MAE Train Loss: 45.502098083496094 | MAE Test Loss: 43.57615280151367 \n",
      "Epoch: 54020 | MAE Train Loss: 45.50139617919922 | MAE Test Loss: 43.5757942199707 \n",
      "Epoch: 54030 | MAE Train Loss: 45.50068283081055 | MAE Test Loss: 43.575435638427734 \n",
      "Epoch: 54040 | MAE Train Loss: 45.49997329711914 | MAE Test Loss: 43.575077056884766 \n",
      "Epoch: 54050 | MAE Train Loss: 45.499263763427734 | MAE Test Loss: 43.57472229003906 \n",
      "Epoch: 54060 | MAE Train Loss: 45.49855422973633 | MAE Test Loss: 43.57435989379883 \n",
      "Epoch: 54070 | MAE Train Loss: 45.49784851074219 | MAE Test Loss: 43.57400131225586 \n",
      "Epoch: 54080 | MAE Train Loss: 45.497135162353516 | MAE Test Loss: 43.57366943359375 \n",
      "Epoch: 54090 | MAE Train Loss: 45.49642562866211 | MAE Test Loss: 43.57331848144531 \n",
      "Epoch: 54100 | MAE Train Loss: 45.4957160949707 | MAE Test Loss: 43.57295608520508 \n",
      "Epoch: 54110 | MAE Train Loss: 45.4950065612793 | MAE Test Loss: 43.572601318359375 \n",
      "Epoch: 54120 | MAE Train Loss: 45.494300842285156 | MAE Test Loss: 43.57223892211914 \n",
      "Epoch: 54130 | MAE Train Loss: 45.49359130859375 | MAE Test Loss: 43.5718879699707 \n",
      "Epoch: 54140 | MAE Train Loss: 45.492881774902344 | MAE Test Loss: 43.571529388427734 \n",
      "Epoch: 54150 | MAE Train Loss: 45.49217224121094 | MAE Test Loss: 43.5711669921875 \n",
      "Epoch: 54160 | MAE Train Loss: 45.4914665222168 | MAE Test Loss: 43.570804595947266 \n",
      "Epoch: 54170 | MAE Train Loss: 45.490753173828125 | MAE Test Loss: 43.57045364379883 \n",
      "Epoch: 54180 | MAE Train Loss: 45.490047454833984 | MAE Test Loss: 43.57009506225586 \n",
      "Epoch: 54190 | MAE Train Loss: 45.48933792114258 | MAE Test Loss: 43.569732666015625 \n",
      "Epoch: 54200 | MAE Train Loss: 45.48862838745117 | MAE Test Loss: 43.569374084472656 \n",
      "Epoch: 54210 | MAE Train Loss: 45.4879150390625 | MAE Test Loss: 43.56901550292969 \n",
      "Epoch: 54220 | MAE Train Loss: 45.48720932006836 | MAE Test Loss: 43.56865692138672 \n",
      "Epoch: 54230 | MAE Train Loss: 45.48649978637695 | MAE Test Loss: 43.568302154541016 \n",
      "Epoch: 54240 | MAE Train Loss: 45.48579025268555 | MAE Test Loss: 43.56794357299805 \n",
      "Epoch: 54250 | MAE Train Loss: 45.48508071899414 | MAE Test Loss: 43.56758499145508 \n",
      "Epoch: 54260 | MAE Train Loss: 45.484371185302734 | MAE Test Loss: 43.56722640991211 \n",
      "Epoch: 54270 | MAE Train Loss: 45.48366165161133 | MAE Test Loss: 43.566871643066406 \n",
      "Epoch: 54280 | MAE Train Loss: 45.48295593261719 | MAE Test Loss: 43.56650924682617 \n",
      "Epoch: 54290 | MAE Train Loss: 45.48224639892578 | MAE Test Loss: 43.56615447998047 \n",
      "Epoch: 54300 | MAE Train Loss: 45.481536865234375 | MAE Test Loss: 43.5657958984375 \n",
      "Epoch: 54310 | MAE Train Loss: 45.48082733154297 | MAE Test Loss: 43.5654411315918 \n",
      "Epoch: 54320 | MAE Train Loss: 45.48011779785156 | MAE Test Loss: 43.56508255004883 \n",
      "Epoch: 54330 | MAE Train Loss: 45.47940444946289 | MAE Test Loss: 43.564720153808594 \n",
      "Epoch: 54340 | MAE Train Loss: 45.478694915771484 | MAE Test Loss: 43.56436538696289 \n",
      "Epoch: 54350 | MAE Train Loss: 45.47798538208008 | MAE Test Loss: 43.564002990722656 \n",
      "Epoch: 54360 | MAE Train Loss: 45.47727966308594 | MAE Test Loss: 43.56364822387695 \n",
      "Epoch: 54370 | MAE Train Loss: 45.476566314697266 | MAE Test Loss: 43.563297271728516 \n",
      "Epoch: 54380 | MAE Train Loss: 45.475860595703125 | MAE Test Loss: 43.562931060791016 \n",
      "Epoch: 54390 | MAE Train Loss: 45.47515106201172 | MAE Test Loss: 43.56257247924805 \n",
      "Epoch: 54400 | MAE Train Loss: 45.47444152832031 | MAE Test Loss: 43.56221389770508 \n",
      "Epoch: 54410 | MAE Train Loss: 45.47373580932617 | MAE Test Loss: 43.561859130859375 \n",
      "Epoch: 54420 | MAE Train Loss: 45.4730224609375 | MAE Test Loss: 43.561527252197266 \n",
      "Epoch: 54430 | MAE Train Loss: 45.472312927246094 | MAE Test Loss: 43.5611686706543 \n",
      "Epoch: 54440 | MAE Train Loss: 45.47160339355469 | MAE Test Loss: 43.56080627441406 \n",
      "Epoch: 54450 | MAE Train Loss: 45.47089385986328 | MAE Test Loss: 43.56045150756836 \n",
      "Epoch: 54460 | MAE Train Loss: 45.47018814086914 | MAE Test Loss: 43.56009292602539 \n",
      "Epoch: 54470 | MAE Train Loss: 45.469478607177734 | MAE Test Loss: 43.55973434448242 \n",
      "Epoch: 54480 | MAE Train Loss: 45.46876907348633 | MAE Test Loss: 43.55937957763672 \n",
      "Epoch: 54490 | MAE Train Loss: 45.46805953979492 | MAE Test Loss: 43.55902099609375 \n",
      "Epoch: 54500 | MAE Train Loss: 45.467350006103516 | MAE Test Loss: 43.55866241455078 \n",
      "Epoch: 54510 | MAE Train Loss: 45.46664047241211 | MAE Test Loss: 43.55830383300781 \n",
      "Epoch: 54520 | MAE Train Loss: 45.46592712402344 | MAE Test Loss: 43.557945251464844 \n",
      "Epoch: 54530 | MAE Train Loss: 45.4652214050293 | MAE Test Loss: 43.55758285522461 \n",
      "Epoch: 54540 | MAE Train Loss: 45.464515686035156 | MAE Test Loss: 43.55723190307617 \n",
      "Epoch: 54550 | MAE Train Loss: 45.463802337646484 | MAE Test Loss: 43.55686950683594 \n",
      "Epoch: 54560 | MAE Train Loss: 45.463096618652344 | MAE Test Loss: 43.556514739990234 \n",
      "Epoch: 54570 | MAE Train Loss: 45.46238327026367 | MAE Test Loss: 43.556156158447266 \n",
      "Epoch: 54580 | MAE Train Loss: 45.46167755126953 | MAE Test Loss: 43.5557975769043 \n",
      "Epoch: 54590 | MAE Train Loss: 45.46096420288086 | MAE Test Loss: 43.55543899536133 \n",
      "Epoch: 54600 | MAE Train Loss: 45.46025848388672 | MAE Test Loss: 43.555076599121094 \n",
      "Epoch: 54610 | MAE Train Loss: 45.45954513549805 | MAE Test Loss: 43.554718017578125 \n",
      "Epoch: 54620 | MAE Train Loss: 45.458839416503906 | MAE Test Loss: 43.55437088012695 \n",
      "Epoch: 54630 | MAE Train Loss: 45.458126068115234 | MAE Test Loss: 43.55400085449219 \n",
      "Epoch: 54640 | MAE Train Loss: 45.457420349121094 | MAE Test Loss: 43.553646087646484 \n",
      "Epoch: 54650 | MAE Train Loss: 45.45670700073242 | MAE Test Loss: 43.553287506103516 \n",
      "Epoch: 54660 | MAE Train Loss: 45.455997467041016 | MAE Test Loss: 43.55293273925781 \n",
      "Epoch: 54670 | MAE Train Loss: 45.455291748046875 | MAE Test Loss: 43.55257797241211 \n",
      "Epoch: 54680 | MAE Train Loss: 45.4545783996582 | MAE Test Loss: 43.552215576171875 \n",
      "Epoch: 54690 | MAE Train Loss: 45.4538688659668 | MAE Test Loss: 43.551856994628906 \n",
      "Epoch: 54700 | MAE Train Loss: 45.453163146972656 | MAE Test Loss: 43.55149841308594 \n",
      "Epoch: 54710 | MAE Train Loss: 45.45245361328125 | MAE Test Loss: 43.551143646240234 \n",
      "Epoch: 54720 | MAE Train Loss: 45.45174026489258 | MAE Test Loss: 43.55078125 \n",
      "Epoch: 54730 | MAE Train Loss: 45.45103454589844 | MAE Test Loss: 43.5504264831543 \n",
      "Epoch: 54740 | MAE Train Loss: 45.450321197509766 | MAE Test Loss: 43.55006790161133 \n",
      "Epoch: 54750 | MAE Train Loss: 45.449615478515625 | MAE Test Loss: 43.54973220825195 \n",
      "Epoch: 54760 | MAE Train Loss: 45.44890213012695 | MAE Test Loss: 43.549381256103516 \n",
      "Epoch: 54770 | MAE Train Loss: 45.44819641113281 | MAE Test Loss: 43.549015045166016 \n",
      "Epoch: 54780 | MAE Train Loss: 45.447486877441406 | MAE Test Loss: 43.54866409301758 \n",
      "Epoch: 54790 | MAE Train Loss: 45.44677734375 | MAE Test Loss: 43.548301696777344 \n",
      "Epoch: 54800 | MAE Train Loss: 45.44607162475586 | MAE Test Loss: 43.547943115234375 \n",
      "Epoch: 54810 | MAE Train Loss: 45.44536209106445 | MAE Test Loss: 43.547584533691406 \n",
      "Epoch: 54820 | MAE Train Loss: 45.44465255737305 | MAE Test Loss: 43.5472297668457 \n",
      "Epoch: 54830 | MAE Train Loss: 45.443939208984375 | MAE Test Loss: 43.546871185302734 \n",
      "Epoch: 54840 | MAE Train Loss: 45.443233489990234 | MAE Test Loss: 43.546512603759766 \n",
      "Epoch: 54850 | MAE Train Loss: 45.44252395629883 | MAE Test Loss: 43.54615783691406 \n",
      "Epoch: 54860 | MAE Train Loss: 45.44181823730469 | MAE Test Loss: 43.54579544067383 \n",
      "Epoch: 54870 | MAE Train Loss: 45.44110870361328 | MAE Test Loss: 43.545440673828125 \n",
      "Epoch: 54880 | MAE Train Loss: 45.44039535522461 | MAE Test Loss: 43.54507827758789 \n",
      "Epoch: 54890 | MAE Train Loss: 45.43968963623047 | MAE Test Loss: 43.54472351074219 \n",
      "Epoch: 54900 | MAE Train Loss: 45.43898010253906 | MAE Test Loss: 43.54436111450195 \n",
      "Epoch: 54910 | MAE Train Loss: 45.438270568847656 | MAE Test Loss: 43.544010162353516 \n",
      "Epoch: 54920 | MAE Train Loss: 45.43756103515625 | MAE Test Loss: 43.54364776611328 \n",
      "Epoch: 54930 | MAE Train Loss: 45.436851501464844 | MAE Test Loss: 43.54329299926758 \n",
      "Epoch: 54940 | MAE Train Loss: 45.43614196777344 | MAE Test Loss: 43.54293441772461 \n",
      "Epoch: 54950 | MAE Train Loss: 45.43543243408203 | MAE Test Loss: 43.542572021484375 \n",
      "Epoch: 54960 | MAE Train Loss: 45.434722900390625 | MAE Test Loss: 43.54221725463867 \n",
      "Epoch: 54970 | MAE Train Loss: 45.43401336669922 | MAE Test Loss: 43.5418586730957 \n",
      "Epoch: 54980 | MAE Train Loss: 45.43330383300781 | MAE Test Loss: 43.54150390625 \n",
      "Epoch: 54990 | MAE Train Loss: 45.43259048461914 | MAE Test Loss: 43.541141510009766 \n",
      "Epoch: 55000 | MAE Train Loss: 45.431884765625 | MAE Test Loss: 43.54078674316406 \n",
      "Epoch: 55010 | MAE Train Loss: 45.431175231933594 | MAE Test Loss: 43.540428161621094 \n",
      "Epoch: 55020 | MAE Train Loss: 45.43046951293945 | MAE Test Loss: 43.540069580078125 \n",
      "Epoch: 55030 | MAE Train Loss: 45.429752349853516 | MAE Test Loss: 43.539710998535156 \n",
      "Epoch: 55040 | MAE Train Loss: 45.429046630859375 | MAE Test Loss: 43.53935241699219 \n",
      "Epoch: 55050 | MAE Train Loss: 45.4283332824707 | MAE Test Loss: 43.53899002075195 \n",
      "Epoch: 55060 | MAE Train Loss: 45.42762756347656 | MAE Test Loss: 43.53863525390625 \n",
      "Epoch: 55070 | MAE Train Loss: 45.426918029785156 | MAE Test Loss: 43.53827667236328 \n",
      "Epoch: 55080 | MAE Train Loss: 45.42620849609375 | MAE Test Loss: 43.53792190551758 \n",
      "Epoch: 55090 | MAE Train Loss: 45.42550277709961 | MAE Test Loss: 43.53759002685547 \n",
      "Epoch: 55100 | MAE Train Loss: 45.42478942871094 | MAE Test Loss: 43.5372314453125 \n",
      "Epoch: 55110 | MAE Train Loss: 45.42407989501953 | MAE Test Loss: 43.53687286376953 \n",
      "Epoch: 55120 | MAE Train Loss: 45.423370361328125 | MAE Test Loss: 43.5365104675293 \n",
      "Epoch: 55130 | MAE Train Loss: 45.422664642333984 | MAE Test Loss: 43.536155700683594 \n",
      "Epoch: 55140 | MAE Train Loss: 45.42195129394531 | MAE Test Loss: 43.535797119140625 \n",
      "Epoch: 55150 | MAE Train Loss: 45.42124557495117 | MAE Test Loss: 43.53544235229492 \n",
      "Epoch: 55160 | MAE Train Loss: 45.420536041259766 | MAE Test Loss: 43.53507995605469 \n",
      "Epoch: 55170 | MAE Train Loss: 45.41982650756836 | MAE Test Loss: 43.53472900390625 \n",
      "Epoch: 55180 | MAE Train Loss: 45.41912078857422 | MAE Test Loss: 43.53436279296875 \n",
      "Epoch: 55190 | MAE Train Loss: 45.41841125488281 | MAE Test Loss: 43.53400802612305 \n",
      "Epoch: 55200 | MAE Train Loss: 45.417701721191406 | MAE Test Loss: 43.53364944458008 \n",
      "Epoch: 55210 | MAE Train Loss: 45.4169921875 | MAE Test Loss: 43.53329086303711 \n",
      "Epoch: 55220 | MAE Train Loss: 45.41628646850586 | MAE Test Loss: 43.532936096191406 \n",
      "Epoch: 55230 | MAE Train Loss: 45.41557312011719 | MAE Test Loss: 43.53257369995117 \n",
      "Epoch: 55240 | MAE Train Loss: 45.41486740112305 | MAE Test Loss: 43.5322151184082 \n",
      "Epoch: 55250 | MAE Train Loss: 45.414154052734375 | MAE Test Loss: 43.5318603515625 \n",
      "Epoch: 55260 | MAE Train Loss: 45.41344451904297 | MAE Test Loss: 43.531497955322266 \n",
      "Epoch: 55270 | MAE Train Loss: 45.4127311706543 | MAE Test Loss: 43.5311393737793 \n",
      "Epoch: 55280 | MAE Train Loss: 45.412025451660156 | MAE Test Loss: 43.530784606933594 \n",
      "Epoch: 55290 | MAE Train Loss: 45.41131591796875 | MAE Test Loss: 43.530426025390625 \n",
      "Epoch: 55300 | MAE Train Loss: 45.410606384277344 | MAE Test Loss: 43.53006362915039 \n",
      "Epoch: 55310 | MAE Train Loss: 45.4099006652832 | MAE Test Loss: 43.52971267700195 \n",
      "Epoch: 55320 | MAE Train Loss: 45.409183502197266 | MAE Test Loss: 43.52935028076172 \n",
      "Epoch: 55330 | MAE Train Loss: 45.40848159790039 | MAE Test Loss: 43.52899169921875 \n",
      "Epoch: 55340 | MAE Train Loss: 45.40776443481445 | MAE Test Loss: 43.52863693237305 \n",
      "Epoch: 55350 | MAE Train Loss: 45.40706253051758 | MAE Test Loss: 43.52827835083008 \n",
      "Epoch: 55360 | MAE Train Loss: 45.406349182128906 | MAE Test Loss: 43.52791976928711 \n",
      "Epoch: 55370 | MAE Train Loss: 45.4056396484375 | MAE Test Loss: 43.52756118774414 \n",
      "Epoch: 55380 | MAE Train Loss: 45.40493392944336 | MAE Test Loss: 43.52720260620117 \n",
      "Epoch: 55390 | MAE Train Loss: 45.40422058105469 | MAE Test Loss: 43.52684783935547 \n",
      "Epoch: 55400 | MAE Train Loss: 45.40351104736328 | MAE Test Loss: 43.5264892578125 \n",
      "Epoch: 55410 | MAE Train Loss: 45.402801513671875 | MAE Test Loss: 43.526126861572266 \n",
      "Epoch: 55420 | MAE Train Loss: 45.402095794677734 | MAE Test Loss: 43.52579879760742 \n",
      "Epoch: 55430 | MAE Train Loss: 45.40138626098633 | MAE Test Loss: 43.52544021606445 \n",
      "Epoch: 55440 | MAE Train Loss: 45.40067672729492 | MAE Test Loss: 43.525081634521484 \n",
      "Epoch: 55450 | MAE Train Loss: 45.399967193603516 | MAE Test Loss: 43.52472686767578 \n",
      "Epoch: 55460 | MAE Train Loss: 45.39925765991211 | MAE Test Loss: 43.52436447143555 \n",
      "Epoch: 55470 | MAE Train Loss: 45.3985481262207 | MAE Test Loss: 43.524009704589844 \n",
      "Epoch: 55480 | MAE Train Loss: 45.39784240722656 | MAE Test Loss: 43.52364730834961 \n",
      "Epoch: 55490 | MAE Train Loss: 45.39712905883789 | MAE Test Loss: 43.523292541503906 \n",
      "Epoch: 55500 | MAE Train Loss: 45.39642333984375 | MAE Test Loss: 43.52293395996094 \n",
      "Epoch: 55510 | MAE Train Loss: 45.39571762084961 | MAE Test Loss: 43.52257537841797 \n",
      "Epoch: 55520 | MAE Train Loss: 45.39500045776367 | MAE Test Loss: 43.522216796875 \n",
      "Epoch: 55530 | MAE Train Loss: 45.3942985534668 | MAE Test Loss: 43.5218620300293 \n",
      "Epoch: 55540 | MAE Train Loss: 45.393585205078125 | MAE Test Loss: 43.52150344848633 \n",
      "Epoch: 55550 | MAE Train Loss: 45.39288330078125 | MAE Test Loss: 43.52114486694336 \n",
      "Epoch: 55560 | MAE Train Loss: 45.39216613769531 | MAE Test Loss: 43.52078628540039 \n",
      "Epoch: 55570 | MAE Train Loss: 45.391456604003906 | MAE Test Loss: 43.52042770385742 \n",
      "Epoch: 55580 | MAE Train Loss: 45.390750885009766 | MAE Test Loss: 43.52007293701172 \n",
      "Epoch: 55590 | MAE Train Loss: 45.390037536621094 | MAE Test Loss: 43.519710540771484 \n",
      "Epoch: 55600 | MAE Train Loss: 45.38933181762695 | MAE Test Loss: 43.519351959228516 \n",
      "Epoch: 55610 | MAE Train Loss: 45.38862228393555 | MAE Test Loss: 43.51899719238281 \n",
      "Epoch: 55620 | MAE Train Loss: 45.38791275024414 | MAE Test Loss: 43.518638610839844 \n",
      "Epoch: 55630 | MAE Train Loss: 45.3871955871582 | MAE Test Loss: 43.518280029296875 \n",
      "Epoch: 55640 | MAE Train Loss: 45.38649368286133 | MAE Test Loss: 43.517921447753906 \n",
      "Epoch: 55650 | MAE Train Loss: 45.385780334472656 | MAE Test Loss: 43.51756286621094 \n",
      "Epoch: 55660 | MAE Train Loss: 45.38507080078125 | MAE Test Loss: 43.51720428466797 \n",
      "Epoch: 55670 | MAE Train Loss: 45.38436508178711 | MAE Test Loss: 43.516845703125 \n",
      "Epoch: 55680 | MAE Train Loss: 45.38365173339844 | MAE Test Loss: 43.5164909362793 \n",
      "Epoch: 55690 | MAE Train Loss: 45.3829460144043 | MAE Test Loss: 43.51613235473633 \n",
      "Epoch: 55700 | MAE Train Loss: 45.382232666015625 | MAE Test Loss: 43.515777587890625 \n",
      "Epoch: 55710 | MAE Train Loss: 45.381526947021484 | MAE Test Loss: 43.515419006347656 \n",
      "Epoch: 55720 | MAE Train Loss: 45.38081359863281 | MAE Test Loss: 43.515052795410156 \n",
      "Epoch: 55730 | MAE Train Loss: 45.38010787963867 | MAE Test Loss: 43.51469802856445 \n",
      "Epoch: 55740 | MAE Train Loss: 45.379398345947266 | MAE Test Loss: 43.514339447021484 \n",
      "Epoch: 55750 | MAE Train Loss: 45.37868881225586 | MAE Test Loss: 43.51398468017578 \n",
      "Epoch: 55760 | MAE Train Loss: 45.37798309326172 | MAE Test Loss: 43.51365280151367 \n",
      "Epoch: 55770 | MAE Train Loss: 45.37726974487305 | MAE Test Loss: 43.5132942199707 \n",
      "Epoch: 55780 | MAE Train Loss: 45.376556396484375 | MAE Test Loss: 43.512935638427734 \n",
      "Epoch: 55790 | MAE Train Loss: 45.375850677490234 | MAE Test Loss: 43.51258087158203 \n",
      "Epoch: 55800 | MAE Train Loss: 45.37513732910156 | MAE Test Loss: 43.5122184753418 \n",
      "Epoch: 55810 | MAE Train Loss: 45.37443542480469 | MAE Test Loss: 43.51185989379883 \n",
      "Epoch: 55820 | MAE Train Loss: 45.37372589111328 | MAE Test Loss: 43.511497497558594 \n",
      "Epoch: 55830 | MAE Train Loss: 45.373016357421875 | MAE Test Loss: 43.511146545410156 \n",
      "Epoch: 55840 | MAE Train Loss: 45.37230682373047 | MAE Test Loss: 43.51079177856445 \n",
      "Epoch: 55850 | MAE Train Loss: 45.37159729003906 | MAE Test Loss: 43.51042556762695 \n",
      "Epoch: 55860 | MAE Train Loss: 45.370887756347656 | MAE Test Loss: 43.510074615478516 \n",
      "Epoch: 55870 | MAE Train Loss: 45.370182037353516 | MAE Test Loss: 43.50971221923828 \n",
      "Epoch: 55880 | MAE Train Loss: 45.369468688964844 | MAE Test Loss: 43.50935363769531 \n",
      "Epoch: 55890 | MAE Train Loss: 45.3687629699707 | MAE Test Loss: 43.50899887084961 \n",
      "Epoch: 55900 | MAE Train Loss: 45.36804962158203 | MAE Test Loss: 43.508636474609375 \n",
      "Epoch: 55910 | MAE Train Loss: 45.36734390258789 | MAE Test Loss: 43.50828170776367 \n",
      "Epoch: 55920 | MAE Train Loss: 45.36663055419922 | MAE Test Loss: 43.50791931152344 \n",
      "Epoch: 55930 | MAE Train Loss: 45.36592483520508 | MAE Test Loss: 43.50756072998047 \n",
      "Epoch: 55940 | MAE Train Loss: 45.36521530151367 | MAE Test Loss: 43.507205963134766 \n",
      "Epoch: 55950 | MAE Train Loss: 45.364505767822266 | MAE Test Loss: 43.5068473815918 \n",
      "Epoch: 55960 | MAE Train Loss: 45.36379623413086 | MAE Test Loss: 43.506492614746094 \n",
      "Epoch: 55970 | MAE Train Loss: 45.36308670043945 | MAE Test Loss: 43.506134033203125 \n",
      "Epoch: 55980 | MAE Train Loss: 45.36237716674805 | MAE Test Loss: 43.505775451660156 \n",
      "Epoch: 55990 | MAE Train Loss: 45.361671447753906 | MAE Test Loss: 43.50541687011719 \n",
      "Epoch: 56000 | MAE Train Loss: 45.360958099365234 | MAE Test Loss: 43.50505828857422 \n",
      "Epoch: 56010 | MAE Train Loss: 45.36024856567383 | MAE Test Loss: 43.50469970703125 \n",
      "Epoch: 56020 | MAE Train Loss: 45.35954284667969 | MAE Test Loss: 43.50434112548828 \n",
      "Epoch: 56030 | MAE Train Loss: 45.358829498291016 | MAE Test Loss: 43.50398254394531 \n",
      "Epoch: 56040 | MAE Train Loss: 45.35811996459961 | MAE Test Loss: 43.50362777709961 \n",
      "Epoch: 56050 | MAE Train Loss: 45.35740661621094 | MAE Test Loss: 43.503265380859375 \n",
      "Epoch: 56060 | MAE Train Loss: 45.3567008972168 | MAE Test Loss: 43.502906799316406 \n",
      "Epoch: 56070 | MAE Train Loss: 45.35599136352539 | MAE Test Loss: 43.5025520324707 \n",
      "Epoch: 56080 | MAE Train Loss: 45.355281829833984 | MAE Test Loss: 43.502193450927734 \n",
      "Epoch: 56090 | MAE Train Loss: 45.354610443115234 | MAE Test Loss: 43.50192642211914 \n",
      "Epoch: 56100 | MAE Train Loss: 45.353973388671875 | MAE Test Loss: 43.50175476074219 \n",
      "Epoch: 56110 | MAE Train Loss: 45.353328704833984 | MAE Test Loss: 43.5015754699707 \n",
      "Epoch: 56120 | MAE Train Loss: 45.35269546508789 | MAE Test Loss: 43.501365661621094 \n",
      "Epoch: 56130 | MAE Train Loss: 45.3520622253418 | MAE Test Loss: 43.501197814941406 \n",
      "Epoch: 56140 | MAE Train Loss: 45.35142517089844 | MAE Test Loss: 43.50102233886719 \n",
      "Epoch: 56150 | MAE Train Loss: 45.35078048706055 | MAE Test Loss: 43.50081253051758 \n",
      "Epoch: 56160 | MAE Train Loss: 45.35014343261719 | MAE Test Loss: 43.50065994262695 \n",
      "Epoch: 56170 | MAE Train Loss: 45.34951400756836 | MAE Test Loss: 43.500450134277344 \n",
      "Epoch: 56180 | MAE Train Loss: 45.34886932373047 | MAE Test Loss: 43.50025939941406 \n",
      "Epoch: 56190 | MAE Train Loss: 45.3482780456543 | MAE Test Loss: 43.49997329711914 \n",
      "Epoch: 56200 | MAE Train Loss: 45.34770202636719 | MAE Test Loss: 43.499691009521484 \n",
      "Epoch: 56210 | MAE Train Loss: 45.34711837768555 | MAE Test Loss: 43.49940872192383 \n",
      "Epoch: 56220 | MAE Train Loss: 45.346534729003906 | MAE Test Loss: 43.49909210205078 \n",
      "Epoch: 56230 | MAE Train Loss: 45.3459587097168 | MAE Test Loss: 43.498809814453125 \n",
      "Epoch: 56240 | MAE Train Loss: 45.345375061035156 | MAE Test Loss: 43.49852752685547 \n",
      "Epoch: 56250 | MAE Train Loss: 45.34479522705078 | MAE Test Loss: 43.49821472167969 \n",
      "Epoch: 56260 | MAE Train Loss: 45.344215393066406 | MAE Test Loss: 43.49793243408203 \n",
      "Epoch: 56270 | MAE Train Loss: 45.343631744384766 | MAE Test Loss: 43.497650146484375 \n",
      "Epoch: 56280 | MAE Train Loss: 45.34305953979492 | MAE Test Loss: 43.497337341308594 \n",
      "Epoch: 56290 | MAE Train Loss: 45.34247589111328 | MAE Test Loss: 43.49705505371094 \n",
      "Epoch: 56300 | MAE Train Loss: 45.341888427734375 | MAE Test Loss: 43.496734619140625 \n",
      "Epoch: 56310 | MAE Train Loss: 45.34130859375 | MAE Test Loss: 43.496456146240234 \n",
      "Epoch: 56320 | MAE Train Loss: 45.340728759765625 | MAE Test Loss: 43.49617004394531 \n",
      "Epoch: 56330 | MAE Train Loss: 45.34014892578125 | MAE Test Loss: 43.4958610534668 \n",
      "Epoch: 56340 | MAE Train Loss: 45.339576721191406 | MAE Test Loss: 43.49557876586914 \n",
      "Epoch: 56350 | MAE Train Loss: 45.3389892578125 | MAE Test Loss: 43.495296478271484 \n",
      "Epoch: 56360 | MAE Train Loss: 45.338409423828125 | MAE Test Loss: 43.4949836730957 \n",
      "Epoch: 56370 | MAE Train Loss: 45.33782958984375 | MAE Test Loss: 43.49469757080078 \n",
      "Epoch: 56380 | MAE Train Loss: 45.337242126464844 | MAE Test Loss: 43.494380950927734 \n",
      "Epoch: 56390 | MAE Train Loss: 45.336666107177734 | MAE Test Loss: 43.494102478027344 \n",
      "Epoch: 56400 | MAE Train Loss: 45.336082458496094 | MAE Test Loss: 43.49381637573242 \n",
      "Epoch: 56410 | MAE Train Loss: 45.335506439208984 | MAE Test Loss: 43.49350357055664 \n",
      "Epoch: 56420 | MAE Train Loss: 45.33492660522461 | MAE Test Loss: 43.493221282958984 \n",
      "Epoch: 56430 | MAE Train Loss: 45.334346771240234 | MAE Test Loss: 43.49293899536133 \n",
      "Epoch: 56440 | MAE Train Loss: 45.33376693725586 | MAE Test Loss: 43.49262619018555 \n",
      "Epoch: 56450 | MAE Train Loss: 45.33318328857422 | MAE Test Loss: 43.49234390258789 \n",
      "Epoch: 56460 | MAE Train Loss: 45.332603454589844 | MAE Test Loss: 43.492061614990234 \n",
      "Epoch: 56470 | MAE Train Loss: 45.332027435302734 | MAE Test Loss: 43.49174880981445 \n",
      "Epoch: 56480 | MAE Train Loss: 45.331443786621094 | MAE Test Loss: 43.49146270751953 \n",
      "Epoch: 56490 | MAE Train Loss: 45.33086013793945 | MAE Test Loss: 43.49114990234375 \n",
      "Epoch: 56500 | MAE Train Loss: 45.330284118652344 | MAE Test Loss: 43.490867614746094 \n",
      "Epoch: 56510 | MAE Train Loss: 45.3297004699707 | MAE Test Loss: 43.49058151245117 \n",
      "Epoch: 56520 | MAE Train Loss: 45.32912063598633 | MAE Test Loss: 43.49026870727539 \n",
      "Epoch: 56530 | MAE Train Loss: 45.32854461669922 | MAE Test Loss: 43.489986419677734 \n",
      "Epoch: 56540 | MAE Train Loss: 45.32795715332031 | MAE Test Loss: 43.489707946777344 \n",
      "Epoch: 56550 | MAE Train Loss: 45.32737731933594 | MAE Test Loss: 43.4893913269043 \n",
      "Epoch: 56560 | MAE Train Loss: 45.32680130004883 | MAE Test Loss: 43.48909378051758 \n",
      "Epoch: 56570 | MAE Train Loss: 45.32621765136719 | MAE Test Loss: 43.48881149291992 \n",
      "Epoch: 56580 | MAE Train Loss: 45.32563400268555 | MAE Test Loss: 43.488529205322266 \n",
      "Epoch: 56590 | MAE Train Loss: 45.32505798339844 | MAE Test Loss: 43.488216400146484 \n",
      "Epoch: 56600 | MAE Train Loss: 45.32448196411133 | MAE Test Loss: 43.48793411254883 \n",
      "Epoch: 56610 | MAE Train Loss: 45.32389831542969 | MAE Test Loss: 43.48765182495117 \n",
      "Epoch: 56620 | MAE Train Loss: 45.32331466674805 | MAE Test Loss: 43.48733139038086 \n",
      "Epoch: 56630 | MAE Train Loss: 45.32273483276367 | MAE Test Loss: 43.48705291748047 \n",
      "Epoch: 56640 | MAE Train Loss: 45.3221549987793 | MAE Test Loss: 43.48674011230469 \n",
      "Epoch: 56650 | MAE Train Loss: 45.321571350097656 | MAE Test Loss: 43.486454010009766 \n",
      "Epoch: 56660 | MAE Train Loss: 45.32099914550781 | MAE Test Loss: 43.48616409301758 \n",
      "Epoch: 56670 | MAE Train Loss: 45.3204231262207 | MAE Test Loss: 43.48586654663086 \n",
      "Epoch: 56680 | MAE Train Loss: 45.319847106933594 | MAE Test Loss: 43.485572814941406 \n",
      "Epoch: 56690 | MAE Train Loss: 45.31927490234375 | MAE Test Loss: 43.48530197143555 \n",
      "Epoch: 56700 | MAE Train Loss: 45.31870651245117 | MAE Test Loss: 43.48500442504883 \n",
      "Epoch: 56710 | MAE Train Loss: 45.31813430786133 | MAE Test Loss: 43.484710693359375 \n",
      "Epoch: 56720 | MAE Train Loss: 45.31755447387695 | MAE Test Loss: 43.48440933227539 \n",
      "Epoch: 56730 | MAE Train Loss: 45.31698226928711 | MAE Test Loss: 43.4841423034668 \n",
      "Epoch: 56740 | MAE Train Loss: 45.316410064697266 | MAE Test Loss: 43.48384094238281 \n",
      "Epoch: 56750 | MAE Train Loss: 45.31583786010742 | MAE Test Loss: 43.48354721069336 \n",
      "Epoch: 56760 | MAE Train Loss: 45.31526184082031 | MAE Test Loss: 43.483253479003906 \n",
      "Epoch: 56770 | MAE Train Loss: 45.31468963623047 | MAE Test Loss: 43.48295211791992 \n",
      "Epoch: 56780 | MAE Train Loss: 45.31411361694336 | MAE Test Loss: 43.48268127441406 \n",
      "Epoch: 56790 | MAE Train Loss: 45.313541412353516 | MAE Test Loss: 43.48236846923828 \n",
      "Epoch: 56800 | MAE Train Loss: 45.31296920776367 | MAE Test Loss: 43.48210144042969 \n",
      "Epoch: 56810 | MAE Train Loss: 45.31239318847656 | MAE Test Loss: 43.48180389404297 \n",
      "Epoch: 56820 | MAE Train Loss: 45.31182098388672 | MAE Test Loss: 43.48150634765625 \n",
      "Epoch: 56830 | MAE Train Loss: 45.31125259399414 | MAE Test Loss: 43.481204986572266 \n",
      "Epoch: 56840 | MAE Train Loss: 45.310672760009766 | MAE Test Loss: 43.48091506958008 \n",
      "Epoch: 56850 | MAE Train Loss: 45.31010055541992 | MAE Test Loss: 43.48064422607422 \n",
      "Epoch: 56860 | MAE Train Loss: 45.30952835083008 | MAE Test Loss: 43.4803466796875 \n",
      "Epoch: 56870 | MAE Train Loss: 45.30895233154297 | MAE Test Loss: 43.480045318603516 \n",
      "Epoch: 56880 | MAE Train Loss: 45.308380126953125 | MAE Test Loss: 43.47975158691406 \n",
      "Epoch: 56890 | MAE Train Loss: 45.30780792236328 | MAE Test Loss: 43.4794807434082 \n",
      "Epoch: 56900 | MAE Train Loss: 45.3072395324707 | MAE Test Loss: 43.479183197021484 \n",
      "Epoch: 56910 | MAE Train Loss: 45.306663513183594 | MAE Test Loss: 43.47888946533203 \n",
      "Epoch: 56920 | MAE Train Loss: 45.306087493896484 | MAE Test Loss: 43.47858810424805 \n",
      "Epoch: 56930 | MAE Train Loss: 45.305511474609375 | MAE Test Loss: 43.47829055786133 \n",
      "Epoch: 56940 | MAE Train Loss: 45.304935455322266 | MAE Test Loss: 43.478023529052734 \n",
      "Epoch: 56950 | MAE Train Loss: 45.30436706542969 | MAE Test Loss: 43.47772979736328 \n",
      "Epoch: 56960 | MAE Train Loss: 45.303794860839844 | MAE Test Loss: 43.4774284362793 \n",
      "Epoch: 56970 | MAE Train Loss: 45.303218841552734 | MAE Test Loss: 43.47713088989258 \n",
      "Epoch: 56980 | MAE Train Loss: 45.30264663696289 | MAE Test Loss: 43.47683334350586 \n",
      "Epoch: 56990 | MAE Train Loss: 45.30207061767578 | MAE Test Loss: 43.476558685302734 \n",
      "Epoch: 57000 | MAE Train Loss: 45.30149841308594 | MAE Test Loss: 43.47626495361328 \n",
      "Epoch: 57010 | MAE Train Loss: 45.300926208496094 | MAE Test Loss: 43.47597122192383 \n",
      "Epoch: 57020 | MAE Train Loss: 45.30034637451172 | MAE Test Loss: 43.47567367553711 \n",
      "Epoch: 57030 | MAE Train Loss: 45.299774169921875 | MAE Test Loss: 43.475399017333984 \n",
      "Epoch: 57040 | MAE Train Loss: 45.2992057800293 | MAE Test Loss: 43.47510528564453 \n",
      "Epoch: 57050 | MAE Train Loss: 45.29862594604492 | MAE Test Loss: 43.47480773925781 \n",
      "Epoch: 57060 | MAE Train Loss: 45.298057556152344 | MAE Test Loss: 43.474510192871094 \n",
      "Epoch: 57070 | MAE Train Loss: 45.2974853515625 | MAE Test Loss: 43.474212646484375 \n",
      "Epoch: 57080 | MAE Train Loss: 45.29690933227539 | MAE Test Loss: 43.473941802978516 \n",
      "Epoch: 57090 | MAE Train Loss: 45.29633331298828 | MAE Test Loss: 43.4736442565918 \n",
      "Epoch: 57100 | MAE Train Loss: 45.29576110839844 | MAE Test Loss: 43.47334671020508 \n",
      "Epoch: 57110 | MAE Train Loss: 45.295188903808594 | MAE Test Loss: 43.47304916381836 \n",
      "Epoch: 57120 | MAE Train Loss: 45.29461669921875 | MAE Test Loss: 43.472782135009766 \n",
      "Epoch: 57130 | MAE Train Loss: 45.29404067993164 | MAE Test Loss: 43.47248458862305 \n",
      "Epoch: 57140 | MAE Train Loss: 45.2934684753418 | MAE Test Loss: 43.47218322753906 \n",
      "Epoch: 57150 | MAE Train Loss: 45.29289627075195 | MAE Test Loss: 43.47188949584961 \n",
      "Epoch: 57160 | MAE Train Loss: 45.292320251464844 | MAE Test Loss: 43.47159194946289 \n",
      "Epoch: 57170 | MAE Train Loss: 45.291744232177734 | MAE Test Loss: 43.47132110595703 \n",
      "Epoch: 57180 | MAE Train Loss: 45.29117202758789 | MAE Test Loss: 43.47102355957031 \n",
      "Epoch: 57190 | MAE Train Loss: 45.29059982299805 | MAE Test Loss: 43.470726013183594 \n",
      "Epoch: 57200 | MAE Train Loss: 45.29002380371094 | MAE Test Loss: 43.470428466796875 \n",
      "Epoch: 57210 | MAE Train Loss: 45.289451599121094 | MAE Test Loss: 43.470130920410156 \n",
      "Epoch: 57220 | MAE Train Loss: 45.288875579833984 | MAE Test Loss: 43.46986389160156 \n",
      "Epoch: 57230 | MAE Train Loss: 45.28830337524414 | MAE Test Loss: 43.469566345214844 \n",
      "Epoch: 57240 | MAE Train Loss: 45.28772735595703 | MAE Test Loss: 43.46926498413086 \n",
      "Epoch: 57250 | MAE Train Loss: 45.28715896606445 | MAE Test Loss: 43.468971252441406 \n",
      "Epoch: 57260 | MAE Train Loss: 45.28657913208008 | MAE Test Loss: 43.46870040893555 \n",
      "Epoch: 57270 | MAE Train Loss: 45.2860107421875 | MAE Test Loss: 43.46840286254883 \n",
      "Epoch: 57280 | MAE Train Loss: 45.285438537597656 | MAE Test Loss: 43.46810531616211 \n",
      "Epoch: 57290 | MAE Train Loss: 45.28485870361328 | MAE Test Loss: 43.467811584472656 \n",
      "Epoch: 57300 | MAE Train Loss: 45.28428649902344 | MAE Test Loss: 43.46751403808594 \n",
      "Epoch: 57310 | MAE Train Loss: 45.28371810913086 | MAE Test Loss: 43.46723937988281 \n",
      "Epoch: 57320 | MAE Train Loss: 45.283145904541016 | MAE Test Loss: 43.46694564819336 \n",
      "Epoch: 57330 | MAE Train Loss: 45.28256607055664 | MAE Test Loss: 43.46664810180664 \n",
      "Epoch: 57340 | MAE Train Loss: 45.28199005126953 | MAE Test Loss: 43.46635055541992 \n",
      "Epoch: 57350 | MAE Train Loss: 45.28141784667969 | MAE Test Loss: 43.46607971191406 \n",
      "Epoch: 57360 | MAE Train Loss: 45.280845642089844 | MAE Test Loss: 43.46578598022461 \n",
      "Epoch: 57370 | MAE Train Loss: 45.280277252197266 | MAE Test Loss: 43.46548843383789 \n",
      "Epoch: 57380 | MAE Train Loss: 45.279701232910156 | MAE Test Loss: 43.465187072753906 \n",
      "Epoch: 57390 | MAE Train Loss: 45.27912521362305 | MAE Test Loss: 43.46489715576172 \n",
      "Epoch: 57400 | MAE Train Loss: 45.2785530090332 | MAE Test Loss: 43.464622497558594 \n",
      "Epoch: 57410 | MAE Train Loss: 45.27798080444336 | MAE Test Loss: 43.46432113647461 \n",
      "Epoch: 57420 | MAE Train Loss: 45.27740478515625 | MAE Test Loss: 43.464027404785156 \n",
      "Epoch: 57430 | MAE Train Loss: 45.27682876586914 | MAE Test Loss: 43.46372985839844 \n",
      "Epoch: 57440 | MAE Train Loss: 45.2762565612793 | MAE Test Loss: 43.46343231201172 \n",
      "Epoch: 57450 | MAE Train Loss: 45.27568435668945 | MAE Test Loss: 43.463157653808594 \n",
      "Epoch: 57460 | MAE Train Loss: 45.27511215209961 | MAE Test Loss: 43.46286392211914 \n",
      "Epoch: 57470 | MAE Train Loss: 45.274539947509766 | MAE Test Loss: 43.46256637573242 \n",
      "Epoch: 57480 | MAE Train Loss: 45.27396774291992 | MAE Test Loss: 43.4622688293457 \n",
      "Epoch: 57490 | MAE Train Loss: 45.27338790893555 | MAE Test Loss: 43.462005615234375 \n",
      "Epoch: 57500 | MAE Train Loss: 45.2728157043457 | MAE Test Loss: 43.46170425415039 \n",
      "Epoch: 57510 | MAE Train Loss: 45.272247314453125 | MAE Test Loss: 43.46141052246094 \n",
      "Epoch: 57520 | MAE Train Loss: 45.271671295166016 | MAE Test Loss: 43.46110534667969 \n",
      "Epoch: 57530 | MAE Train Loss: 45.271095275878906 | MAE Test Loss: 43.4608154296875 \n",
      "Epoch: 57540 | MAE Train Loss: 45.27052307128906 | MAE Test Loss: 43.460540771484375 \n",
      "Epoch: 57550 | MAE Train Loss: 45.26995086669922 | MAE Test Loss: 43.46024703979492 \n",
      "Epoch: 57560 | MAE Train Loss: 45.26937484741211 | MAE Test Loss: 43.45994567871094 \n",
      "Epoch: 57570 | MAE Train Loss: 45.268802642822266 | MAE Test Loss: 43.459651947021484 \n",
      "Epoch: 57580 | MAE Train Loss: 45.26822280883789 | MAE Test Loss: 43.45937728881836 \n",
      "Epoch: 57590 | MAE Train Loss: 45.26765441894531 | MAE Test Loss: 43.459083557128906 \n",
      "Epoch: 57600 | MAE Train Loss: 45.26708221435547 | MAE Test Loss: 43.45878982543945 \n",
      "Epoch: 57610 | MAE Train Loss: 45.26650619506836 | MAE Test Loss: 43.45848846435547 \n",
      "Epoch: 57620 | MAE Train Loss: 45.26593017578125 | MAE Test Loss: 43.45819091796875 \n",
      "Epoch: 57630 | MAE Train Loss: 45.265357971191406 | MAE Test Loss: 43.45792007446289 \n",
      "Epoch: 57640 | MAE Train Loss: 45.26478958129883 | MAE Test Loss: 43.45762634277344 \n",
      "Epoch: 57650 | MAE Train Loss: 45.26420974731445 | MAE Test Loss: 43.45732879638672 \n",
      "Epoch: 57660 | MAE Train Loss: 45.26363754272461 | MAE Test Loss: 43.457027435302734 \n",
      "Epoch: 57670 | MAE Train Loss: 45.2630615234375 | MAE Test Loss: 43.45673370361328 \n",
      "Epoch: 57680 | MAE Train Loss: 45.26249694824219 | MAE Test Loss: 43.45646286010742 \n",
      "Epoch: 57690 | MAE Train Loss: 45.261924743652344 | MAE Test Loss: 43.4561653137207 \n",
      "Epoch: 57700 | MAE Train Loss: 45.26134490966797 | MAE Test Loss: 43.45587158203125 \n",
      "Epoch: 57710 | MAE Train Loss: 45.26076889038086 | MAE Test Loss: 43.455570220947266 \n",
      "Epoch: 57720 | MAE Train Loss: 45.260196685791016 | MAE Test Loss: 43.45530319213867 \n",
      "Epoch: 57730 | MAE Train Loss: 45.25962448120117 | MAE Test Loss: 43.45500564575195 \n",
      "Epoch: 57740 | MAE Train Loss: 45.25904846191406 | MAE Test Loss: 43.454708099365234 \n",
      "Epoch: 57750 | MAE Train Loss: 45.25847625732422 | MAE Test Loss: 43.454410552978516 \n",
      "Epoch: 57760 | MAE Train Loss: 45.25790023803711 | MAE Test Loss: 43.4541130065918 \n",
      "Epoch: 57770 | MAE Train Loss: 45.25733184814453 | MAE Test Loss: 43.4538459777832 \n",
      "Epoch: 57780 | MAE Train Loss: 45.256752014160156 | MAE Test Loss: 43.45354461669922 \n",
      "Epoch: 57790 | MAE Train Loss: 45.25617980957031 | MAE Test Loss: 43.4532470703125 \n",
      "Epoch: 57800 | MAE Train Loss: 45.2556037902832 | MAE Test Loss: 43.45295333862305 \n",
      "Epoch: 57810 | MAE Train Loss: 45.255035400390625 | MAE Test Loss: 43.45265579223633 \n",
      "Epoch: 57820 | MAE Train Loss: 45.254459381103516 | MAE Test Loss: 43.45238494873047 \n",
      "Epoch: 57830 | MAE Train Loss: 45.25389099121094 | MAE Test Loss: 43.45208740234375 \n",
      "Epoch: 57840 | MAE Train Loss: 45.253318786621094 | MAE Test Loss: 43.451786041259766 \n",
      "Epoch: 57850 | MAE Train Loss: 45.25273513793945 | MAE Test Loss: 43.45148849487305 \n",
      "Epoch: 57860 | MAE Train Loss: 45.252166748046875 | MAE Test Loss: 43.45122528076172 \n",
      "Epoch: 57870 | MAE Train Loss: 45.25159454345703 | MAE Test Loss: 43.450923919677734 \n",
      "Epoch: 57880 | MAE Train Loss: 45.25102233886719 | MAE Test Loss: 43.45063018798828 \n",
      "Epoch: 57890 | MAE Train Loss: 45.25044631958008 | MAE Test Loss: 43.4503288269043 \n",
      "Epoch: 57900 | MAE Train Loss: 45.249874114990234 | MAE Test Loss: 43.45003128051758 \n",
      "Epoch: 57910 | MAE Train Loss: 45.249298095703125 | MAE Test Loss: 43.44976043701172 \n",
      "Epoch: 57920 | MAE Train Loss: 45.24872589111328 | MAE Test Loss: 43.449466705322266 \n",
      "Epoch: 57930 | MAE Train Loss: 45.24815368652344 | MAE Test Loss: 43.44916534423828 \n",
      "Epoch: 57940 | MAE Train Loss: 45.24757766723633 | MAE Test Loss: 43.44887161254883 \n",
      "Epoch: 57950 | MAE Train Loss: 45.24700164794922 | MAE Test Loss: 43.4485969543457 \n",
      "Epoch: 57960 | MAE Train Loss: 45.246429443359375 | MAE Test Loss: 43.44830322265625 \n",
      "Epoch: 57970 | MAE Train Loss: 45.24585723876953 | MAE Test Loss: 43.44800567626953 \n",
      "Epoch: 57980 | MAE Train Loss: 45.24528503417969 | MAE Test Loss: 43.44770812988281 \n",
      "Epoch: 57990 | MAE Train Loss: 45.24470520019531 | MAE Test Loss: 43.44740676879883 \n",
      "Epoch: 58000 | MAE Train Loss: 45.244136810302734 | MAE Test Loss: 43.4471435546875 \n",
      "Epoch: 58010 | MAE Train Loss: 45.24356460571289 | MAE Test Loss: 43.446842193603516 \n",
      "Epoch: 58020 | MAE Train Loss: 45.24298858642578 | MAE Test Loss: 43.44654846191406 \n",
      "Epoch: 58030 | MAE Train Loss: 45.24241256713867 | MAE Test Loss: 43.44625473022461 \n",
      "Epoch: 58040 | MAE Train Loss: 45.24184036254883 | MAE Test Loss: 43.44595718383789 \n",
      "Epoch: 58050 | MAE Train Loss: 45.241268157958984 | MAE Test Loss: 43.44568634033203 \n",
      "Epoch: 58060 | MAE Train Loss: 45.24070358276367 | MAE Test Loss: 43.44538497924805 \n",
      "Epoch: 58070 | MAE Train Loss: 45.2401237487793 | MAE Test Loss: 43.44508743286133 \n",
      "Epoch: 58080 | MAE Train Loss: 45.23954772949219 | MAE Test Loss: 43.44478988647461 \n",
      "Epoch: 58090 | MAE Train Loss: 45.23897171020508 | MAE Test Loss: 43.44451904296875 \n",
      "Epoch: 58100 | MAE Train Loss: 45.238399505615234 | MAE Test Loss: 43.4442253112793 \n",
      "Epoch: 58110 | MAE Train Loss: 45.237831115722656 | MAE Test Loss: 43.443931579589844 \n",
      "Epoch: 58120 | MAE Train Loss: 45.23725891113281 | MAE Test Loss: 43.44363021850586 \n",
      "Epoch: 58130 | MAE Train Loss: 45.2366828918457 | MAE Test Loss: 43.443336486816406 \n",
      "Epoch: 58140 | MAE Train Loss: 45.236106872558594 | MAE Test Loss: 43.44306182861328 \n",
      "Epoch: 58150 | MAE Train Loss: 45.23553466796875 | MAE Test Loss: 43.44276809692383 \n",
      "Epoch: 58160 | MAE Train Loss: 45.234962463378906 | MAE Test Loss: 43.442466735839844 \n",
      "Epoch: 58170 | MAE Train Loss: 45.2343864440918 | MAE Test Loss: 43.44217300415039 \n",
      "Epoch: 58180 | MAE Train Loss: 45.23381042480469 | MAE Test Loss: 43.4419059753418 \n",
      "Epoch: 58190 | MAE Train Loss: 45.23324203491211 | MAE Test Loss: 43.44160461425781 \n",
      "Epoch: 58200 | MAE Train Loss: 45.232666015625 | MAE Test Loss: 43.44130325317383 \n",
      "Epoch: 58210 | MAE Train Loss: 45.23208999633789 | MAE Test Loss: 43.441009521484375 \n",
      "Epoch: 58220 | MAE Train Loss: 45.23151397705078 | MAE Test Loss: 43.44070816040039 \n",
      "Epoch: 58230 | MAE Train Loss: 45.23093795776367 | MAE Test Loss: 43.44044494628906 \n",
      "Epoch: 58240 | MAE Train Loss: 45.230369567871094 | MAE Test Loss: 43.44015121459961 \n",
      "Epoch: 58250 | MAE Train Loss: 45.22979736328125 | MAE Test Loss: 43.439849853515625 \n",
      "Epoch: 58260 | MAE Train Loss: 45.22922134399414 | MAE Test Loss: 43.439552307128906 \n",
      "Epoch: 58270 | MAE Train Loss: 45.22865295410156 | MAE Test Loss: 43.43925476074219 \n",
      "Epoch: 58280 | MAE Train Loss: 45.22807693481445 | MAE Test Loss: 43.43898010253906 \n",
      "Epoch: 58290 | MAE Train Loss: 45.227508544921875 | MAE Test Loss: 43.43868637084961 \n",
      "Epoch: 58300 | MAE Train Loss: 45.2269287109375 | MAE Test Loss: 43.43838882446289 \n",
      "Epoch: 58310 | MAE Train Loss: 45.226356506347656 | MAE Test Loss: 43.4380989074707 \n",
      "Epoch: 58320 | MAE Train Loss: 45.22578048706055 | MAE Test Loss: 43.43782424926758 \n",
      "Epoch: 58330 | MAE Train Loss: 45.2252082824707 | MAE Test Loss: 43.437522888183594 \n",
      "Epoch: 58340 | MAE Train Loss: 45.22463607788086 | MAE Test Loss: 43.437225341796875 \n",
      "Epoch: 58350 | MAE Train Loss: 45.224063873291016 | MAE Test Loss: 43.436927795410156 \n",
      "Epoch: 58360 | MAE Train Loss: 45.22348403930664 | MAE Test Loss: 43.43663024902344 \n",
      "Epoch: 58370 | MAE Train Loss: 45.2229118347168 | MAE Test Loss: 43.436363220214844 \n",
      "Epoch: 58380 | MAE Train Loss: 45.22233963012695 | MAE Test Loss: 43.436065673828125 \n",
      "Epoch: 58390 | MAE Train Loss: 45.22176742553711 | MAE Test Loss: 43.43577194213867 \n",
      "Epoch: 58400 | MAE Train Loss: 45.221195220947266 | MAE Test Loss: 43.43547058105469 \n",
      "Epoch: 58410 | MAE Train Loss: 45.220619201660156 | MAE Test Loss: 43.43519973754883 \n",
      "Epoch: 58420 | MAE Train Loss: 45.22004318237305 | MAE Test Loss: 43.434906005859375 \n",
      "Epoch: 58430 | MAE Train Loss: 45.2194709777832 | MAE Test Loss: 43.434608459472656 \n",
      "Epoch: 58440 | MAE Train Loss: 45.21889877319336 | MAE Test Loss: 43.43431091308594 \n",
      "Epoch: 58450 | MAE Train Loss: 45.218326568603516 | MAE Test Loss: 43.43401336669922 \n",
      "Epoch: 58460 | MAE Train Loss: 45.21774673461914 | MAE Test Loss: 43.433746337890625 \n",
      "Epoch: 58470 | MAE Train Loss: 45.2171745300293 | MAE Test Loss: 43.433441162109375 \n",
      "Epoch: 58480 | MAE Train Loss: 45.21660614013672 | MAE Test Loss: 43.43314743041992 \n",
      "Epoch: 58490 | MAE Train Loss: 45.21603012084961 | MAE Test Loss: 43.43285369873047 \n",
      "Epoch: 58500 | MAE Train Loss: 45.215457916259766 | MAE Test Loss: 43.432552337646484 \n",
      "Epoch: 58510 | MAE Train Loss: 45.21488571166992 | MAE Test Loss: 43.432281494140625 \n",
      "Epoch: 58520 | MAE Train Loss: 45.21430969238281 | MAE Test Loss: 43.43198776245117 \n",
      "Epoch: 58530 | MAE Train Loss: 45.21373748779297 | MAE Test Loss: 43.43169021606445 \n",
      "Epoch: 58540 | MAE Train Loss: 45.21316146850586 | MAE Test Loss: 43.431392669677734 \n",
      "Epoch: 58550 | MAE Train Loss: 45.21258544921875 | MAE Test Loss: 43.431121826171875 \n",
      "Epoch: 58560 | MAE Train Loss: 45.21201705932617 | MAE Test Loss: 43.430824279785156 \n",
      "Epoch: 58570 | MAE Train Loss: 45.21144485473633 | MAE Test Loss: 43.43052673339844 \n",
      "Epoch: 58580 | MAE Train Loss: 45.21086883544922 | MAE Test Loss: 43.43022918701172 \n",
      "Epoch: 58590 | MAE Train Loss: 45.210289001464844 | MAE Test Loss: 43.429935455322266 \n",
      "Epoch: 58600 | MAE Train Loss: 45.209720611572266 | MAE Test Loss: 43.429664611816406 \n",
      "Epoch: 58610 | MAE Train Loss: 45.209144592285156 | MAE Test Loss: 43.42937088012695 \n",
      "Epoch: 58620 | MAE Train Loss: 45.20857620239258 | MAE Test Loss: 43.42906951904297 \n",
      "Epoch: 58630 | MAE Train Loss: 45.20800018310547 | MAE Test Loss: 43.42877197265625 \n",
      "Epoch: 58640 | MAE Train Loss: 45.207427978515625 | MAE Test Loss: 43.42847442626953 \n",
      "Epoch: 58650 | MAE Train Loss: 45.20684814453125 | MAE Test Loss: 43.42820358276367 \n",
      "Epoch: 58660 | MAE Train Loss: 45.20627975463867 | MAE Test Loss: 43.42790985107422 \n",
      "Epoch: 58670 | MAE Train Loss: 45.20570755004883 | MAE Test Loss: 43.427608489990234 \n",
      "Epoch: 58680 | MAE Train Loss: 45.20513153076172 | MAE Test Loss: 43.427310943603516 \n",
      "Epoch: 58690 | MAE Train Loss: 45.204551696777344 | MAE Test Loss: 43.42703628540039 \n",
      "Epoch: 58700 | MAE Train Loss: 45.203983306884766 | MAE Test Loss: 43.4267463684082 \n",
      "Epoch: 58710 | MAE Train Loss: 45.20341110229492 | MAE Test Loss: 43.426448822021484 \n",
      "Epoch: 58720 | MAE Train Loss: 45.20283126831055 | MAE Test Loss: 43.4261474609375 \n",
      "Epoch: 58730 | MAE Train Loss: 45.20226287841797 | MAE Test Loss: 43.42585372924805 \n",
      "Epoch: 58740 | MAE Train Loss: 45.201690673828125 | MAE Test Loss: 43.42558288574219 \n",
      "Epoch: 58750 | MAE Train Loss: 45.201114654541016 | MAE Test Loss: 43.4252815246582 \n",
      "Epoch: 58760 | MAE Train Loss: 45.20054244995117 | MAE Test Loss: 43.42498779296875 \n",
      "Epoch: 58770 | MAE Train Loss: 45.19997024536133 | MAE Test Loss: 43.4246940612793 \n",
      "Epoch: 58780 | MAE Train Loss: 45.19939422607422 | MAE Test Loss: 43.42441940307617 \n",
      "Epoch: 58790 | MAE Train Loss: 45.198822021484375 | MAE Test Loss: 43.42412185668945 \n",
      "Epoch: 58800 | MAE Train Loss: 45.198246002197266 | MAE Test Loss: 43.423824310302734 \n",
      "Epoch: 58810 | MAE Train Loss: 45.19767379760742 | MAE Test Loss: 43.42353057861328 \n",
      "Epoch: 58820 | MAE Train Loss: 45.19709777832031 | MAE Test Loss: 43.42323303222656 \n",
      "Epoch: 58830 | MAE Train Loss: 45.19652557373047 | MAE Test Loss: 43.4229621887207 \n",
      "Epoch: 58840 | MAE Train Loss: 45.195953369140625 | MAE Test Loss: 43.422664642333984 \n",
      "Epoch: 58850 | MAE Train Loss: 45.195377349853516 | MAE Test Loss: 43.422367095947266 \n",
      "Epoch: 58860 | MAE Train Loss: 45.19480514526367 | MAE Test Loss: 43.42206954956055 \n",
      "Epoch: 58870 | MAE Train Loss: 45.19422912597656 | MAE Test Loss: 43.421775817871094 \n",
      "Epoch: 58880 | MAE Train Loss: 45.19365692138672 | MAE Test Loss: 43.421504974365234 \n",
      "Epoch: 58890 | MAE Train Loss: 45.19308853149414 | MAE Test Loss: 43.421207427978516 \n",
      "Epoch: 58900 | MAE Train Loss: 45.1925163269043 | MAE Test Loss: 43.4209098815918 \n",
      "Epoch: 58910 | MAE Train Loss: 45.19194412231445 | MAE Test Loss: 43.42061233520508 \n",
      "Epoch: 58920 | MAE Train Loss: 45.191368103027344 | MAE Test Loss: 43.42034149169922 \n",
      "Epoch: 58930 | MAE Train Loss: 45.19078826904297 | MAE Test Loss: 43.420047760009766 \n",
      "Epoch: 58940 | MAE Train Loss: 45.190223693847656 | MAE Test Loss: 43.41974639892578 \n",
      "Epoch: 58950 | MAE Train Loss: 45.18964767456055 | MAE Test Loss: 43.41944885253906 \n",
      "Epoch: 58960 | MAE Train Loss: 45.18906784057617 | MAE Test Loss: 43.41915512084961 \n",
      "Epoch: 58970 | MAE Train Loss: 45.18849563598633 | MAE Test Loss: 43.41888427734375 \n",
      "Epoch: 58980 | MAE Train Loss: 45.18792724609375 | MAE Test Loss: 43.41858673095703 \n",
      "Epoch: 58990 | MAE Train Loss: 45.187355041503906 | MAE Test Loss: 43.41828536987305 \n",
      "Epoch: 59000 | MAE Train Loss: 45.1867790222168 | MAE Test Loss: 43.417991638183594 \n",
      "Epoch: 59010 | MAE Train Loss: 45.18619918823242 | MAE Test Loss: 43.417720794677734 \n",
      "Epoch: 59020 | MAE Train Loss: 45.18562698364258 | MAE Test Loss: 43.41742706298828 \n",
      "Epoch: 59030 | MAE Train Loss: 45.18505859375 | MAE Test Loss: 43.41712951660156 \n",
      "Epoch: 59040 | MAE Train Loss: 45.18448257446289 | MAE Test Loss: 43.416831970214844 \n",
      "Epoch: 59050 | MAE Train Loss: 45.18391036987305 | MAE Test Loss: 43.41653060913086 \n",
      "Epoch: 59060 | MAE Train Loss: 45.18333435058594 | MAE Test Loss: 43.416259765625 \n",
      "Epoch: 59070 | MAE Train Loss: 45.18276596069336 | MAE Test Loss: 43.41596603393555 \n",
      "Epoch: 59080 | MAE Train Loss: 45.182186126708984 | MAE Test Loss: 43.41566848754883 \n",
      "Epoch: 59090 | MAE Train Loss: 45.181610107421875 | MAE Test Loss: 43.415367126464844 \n",
      "Epoch: 59100 | MAE Train Loss: 45.1810417175293 | MAE Test Loss: 43.415069580078125 \n",
      "Epoch: 59110 | MAE Train Loss: 45.18046951293945 | MAE Test Loss: 43.41480255126953 \n",
      "Epoch: 59120 | MAE Train Loss: 45.179893493652344 | MAE Test Loss: 43.41450500488281 \n",
      "Epoch: 59130 | MAE Train Loss: 45.1793212890625 | MAE Test Loss: 43.414207458496094 \n",
      "Epoch: 59140 | MAE Train Loss: 45.17874526977539 | MAE Test Loss: 43.413909912109375 \n",
      "Epoch: 59150 | MAE Train Loss: 45.17817306518555 | MAE Test Loss: 43.413639068603516 \n",
      "Epoch: 59160 | MAE Train Loss: 45.17759704589844 | MAE Test Loss: 43.4133415222168 \n",
      "Epoch: 59170 | MAE Train Loss: 45.177024841308594 | MAE Test Loss: 43.413047790527344 \n",
      "Epoch: 59180 | MAE Train Loss: 45.17645263671875 | MAE Test Loss: 43.412750244140625 \n",
      "Epoch: 59190 | MAE Train Loss: 45.17587661743164 | MAE Test Loss: 43.412452697753906 \n",
      "Epoch: 59200 | MAE Train Loss: 45.1753044128418 | MAE Test Loss: 43.41218185424805 \n",
      "Epoch: 59210 | MAE Train Loss: 45.17473220825195 | MAE Test Loss: 43.41188049316406 \n",
      "Epoch: 59220 | MAE Train Loss: 45.174156188964844 | MAE Test Loss: 43.41158676147461 \n",
      "Epoch: 59230 | MAE Train Loss: 45.173587799072266 | MAE Test Loss: 43.411293029785156 \n",
      "Epoch: 59240 | MAE Train Loss: 45.17300796508789 | MAE Test Loss: 43.4110221862793 \n",
      "Epoch: 59250 | MAE Train Loss: 45.17243194580078 | MAE Test Loss: 43.41072463989258 \n",
      "Epoch: 59260 | MAE Train Loss: 45.1718635559082 | MAE Test Loss: 43.410423278808594 \n",
      "Epoch: 59270 | MAE Train Loss: 45.171287536621094 | MAE Test Loss: 43.410125732421875 \n",
      "Epoch: 59280 | MAE Train Loss: 45.17071533203125 | MAE Test Loss: 43.40983581542969 \n",
      "Epoch: 59290 | MAE Train Loss: 45.170143127441406 | MAE Test Loss: 43.40956115722656 \n",
      "Epoch: 59300 | MAE Train Loss: 45.16957092285156 | MAE Test Loss: 43.409263610839844 \n",
      "Epoch: 59310 | MAE Train Loss: 45.16899490356445 | MAE Test Loss: 43.40896987915039 \n",
      "Epoch: 59320 | MAE Train Loss: 45.16842269897461 | MAE Test Loss: 43.40867233276367 \n",
      "Epoch: 59330 | MAE Train Loss: 45.167842864990234 | MAE Test Loss: 43.40837478637695 \n",
      "Epoch: 59340 | MAE Train Loss: 45.16727066040039 | MAE Test Loss: 43.40810012817383 \n",
      "Epoch: 59350 | MAE Train Loss: 45.16670608520508 | MAE Test Loss: 43.407806396484375 \n",
      "Epoch: 59360 | MAE Train Loss: 45.16613006591797 | MAE Test Loss: 43.407508850097656 \n",
      "Epoch: 59370 | MAE Train Loss: 45.165550231933594 | MAE Test Loss: 43.40721130371094 \n",
      "Epoch: 59380 | MAE Train Loss: 45.16497802734375 | MAE Test Loss: 43.406944274902344 \n",
      "Epoch: 59390 | MAE Train Loss: 45.16440963745117 | MAE Test Loss: 43.40664291381836 \n",
      "Epoch: 59400 | MAE Train Loss: 45.16383743286133 | MAE Test Loss: 43.406341552734375 \n",
      "Epoch: 59410 | MAE Train Loss: 45.16325759887695 | MAE Test Loss: 43.40604782104492 \n",
      "Epoch: 59420 | MAE Train Loss: 45.16268539428711 | MAE Test Loss: 43.4057502746582 \n",
      "Epoch: 59430 | MAE Train Loss: 45.162113189697266 | MAE Test Loss: 43.405479431152344 \n",
      "Epoch: 59440 | MAE Train Loss: 45.16154098510742 | MAE Test Loss: 43.40518569946289 \n",
      "Epoch: 59450 | MAE Train Loss: 45.16096496582031 | MAE Test Loss: 43.404884338378906 \n",
      "Epoch: 59460 | MAE Train Loss: 45.1603889465332 | MAE Test Loss: 43.40459060668945 \n",
      "Epoch: 59470 | MAE Train Loss: 45.159820556640625 | MAE Test Loss: 43.404293060302734 \n",
      "Epoch: 59480 | MAE Train Loss: 45.159244537353516 | MAE Test Loss: 43.40401840209961 \n",
      "Epoch: 59490 | MAE Train Loss: 45.15867233276367 | MAE Test Loss: 43.403724670410156 \n",
      "Epoch: 59500 | MAE Train Loss: 45.1580924987793 | MAE Test Loss: 43.4034309387207 \n",
      "Epoch: 59510 | MAE Train Loss: 45.157527923583984 | MAE Test Loss: 43.40312957763672 \n",
      "Epoch: 59520 | MAE Train Loss: 45.15694808959961 | MAE Test Loss: 43.40285873413086 \n",
      "Epoch: 59530 | MAE Train Loss: 45.156375885009766 | MAE Test Loss: 43.402565002441406 \n",
      "Epoch: 59540 | MAE Train Loss: 45.15580368041992 | MAE Test Loss: 43.40226364135742 \n",
      "Epoch: 59550 | MAE Train Loss: 45.15522766113281 | MAE Test Loss: 43.4019660949707 \n",
      "Epoch: 59560 | MAE Train Loss: 45.15465545654297 | MAE Test Loss: 43.40167236328125 \n",
      "Epoch: 59570 | MAE Train Loss: 45.15407943725586 | MAE Test Loss: 43.40140151977539 \n",
      "Epoch: 59580 | MAE Train Loss: 45.15351104736328 | MAE Test Loss: 43.40110397338867 \n",
      "Epoch: 59590 | MAE Train Loss: 45.152931213378906 | MAE Test Loss: 43.40080642700195 \n",
      "Epoch: 59600 | MAE Train Loss: 45.15235900878906 | MAE Test Loss: 43.400508880615234 \n",
      "Epoch: 59610 | MAE Train Loss: 45.15178680419922 | MAE Test Loss: 43.400238037109375 \n",
      "Epoch: 59620 | MAE Train Loss: 45.15121078491211 | MAE Test Loss: 43.39994430541992 \n",
      "Epoch: 59630 | MAE Train Loss: 45.15064239501953 | MAE Test Loss: 43.39964294433594 \n",
      "Epoch: 59640 | MAE Train Loss: 45.15006637573242 | MAE Test Loss: 43.399349212646484 \n",
      "Epoch: 59650 | MAE Train Loss: 45.14949035644531 | MAE Test Loss: 43.399051666259766 \n",
      "Epoch: 59660 | MAE Train Loss: 45.1489143371582 | MAE Test Loss: 43.39878463745117 \n",
      "Epoch: 59670 | MAE Train Loss: 45.14834976196289 | MAE Test Loss: 43.39848327636719 \n",
      "Epoch: 59680 | MAE Train Loss: 45.147769927978516 | MAE Test Loss: 43.398189544677734 \n",
      "Epoch: 59690 | MAE Train Loss: 45.147193908691406 | MAE Test Loss: 43.397891998291016 \n",
      "Epoch: 59700 | MAE Train Loss: 45.14662170410156 | MAE Test Loss: 43.3975944519043 \n",
      "Epoch: 59710 | MAE Train Loss: 45.146053314208984 | MAE Test Loss: 43.39732360839844 \n",
      "Epoch: 59720 | MAE Train Loss: 45.14548110961914 | MAE Test Loss: 43.39702606201172 \n",
      "Epoch: 59730 | MAE Train Loss: 45.14490509033203 | MAE Test Loss: 43.396728515625 \n",
      "Epoch: 59740 | MAE Train Loss: 45.14433288574219 | MAE Test Loss: 43.39643096923828 \n",
      "Epoch: 59750 | MAE Train Loss: 45.14375686645508 | MAE Test Loss: 43.39616012573242 \n",
      "Epoch: 59760 | MAE Train Loss: 45.143184661865234 | MAE Test Loss: 43.3958625793457 \n",
      "Epoch: 59770 | MAE Train Loss: 45.142608642578125 | MAE Test Loss: 43.395565032958984 \n",
      "Epoch: 59780 | MAE Train Loss: 45.142032623291016 | MAE Test Loss: 43.395267486572266 \n",
      "Epoch: 59790 | MAE Train Loss: 45.14146423339844 | MAE Test Loss: 43.39496994018555 \n",
      "Epoch: 59800 | MAE Train Loss: 45.14088821411133 | MAE Test Loss: 43.39470291137695 \n",
      "Epoch: 59810 | MAE Train Loss: 45.14031982421875 | MAE Test Loss: 43.394405364990234 \n",
      "Epoch: 59820 | MAE Train Loss: 45.13974380493164 | MAE Test Loss: 43.394107818603516 \n",
      "Epoch: 59830 | MAE Train Loss: 45.1391716003418 | MAE Test Loss: 43.3938102722168 \n",
      "Epoch: 59840 | MAE Train Loss: 45.13859558105469 | MAE Test Loss: 43.39353942871094 \n",
      "Epoch: 59850 | MAE Train Loss: 45.13801956176758 | MAE Test Loss: 43.39324188232422 \n",
      "Epoch: 59860 | MAE Train Loss: 45.13744354248047 | MAE Test Loss: 43.3929443359375 \n",
      "Epoch: 59870 | MAE Train Loss: 45.136871337890625 | MAE Test Loss: 43.39265060424805 \n",
      "Epoch: 59880 | MAE Train Loss: 45.13629913330078 | MAE Test Loss: 43.39234924316406 \n",
      "Epoch: 59890 | MAE Train Loss: 45.13572692871094 | MAE Test Loss: 43.3920783996582 \n",
      "Epoch: 59900 | MAE Train Loss: 45.135154724121094 | MAE Test Loss: 43.391780853271484 \n",
      "Epoch: 59910 | MAE Train Loss: 45.134578704833984 | MAE Test Loss: 43.391483306884766 \n",
      "Epoch: 59920 | MAE Train Loss: 45.13400650024414 | MAE Test Loss: 43.39118576049805 \n",
      "Epoch: 59930 | MAE Train Loss: 45.13343048095703 | MAE Test Loss: 43.390892028808594 \n",
      "Epoch: 59940 | MAE Train Loss: 45.13285827636719 | MAE Test Loss: 43.390621185302734 \n",
      "Epoch: 59950 | MAE Train Loss: 45.132286071777344 | MAE Test Loss: 43.390323638916016 \n",
      "Epoch: 59960 | MAE Train Loss: 45.131710052490234 | MAE Test Loss: 43.3900260925293 \n",
      "Epoch: 59970 | MAE Train Loss: 45.13113784790039 | MAE Test Loss: 43.389732360839844 \n",
      "Epoch: 59980 | MAE Train Loss: 45.13056182861328 | MAE Test Loss: 43.38945770263672 \n",
      "Epoch: 59990 | MAE Train Loss: 45.12998962402344 | MAE Test Loss: 43.389163970947266 \n",
      "Epoch: 60000 | MAE Train Loss: 45.129417419433594 | MAE Test Loss: 43.38886642456055 \n",
      "Epoch: 60010 | MAE Train Loss: 45.12884521484375 | MAE Test Loss: 43.38856887817383 \n",
      "Epoch: 60020 | MAE Train Loss: 45.128265380859375 | MAE Test Loss: 43.388267517089844 \n",
      "Epoch: 60030 | MAE Train Loss: 45.12769317626953 | MAE Test Loss: 43.38800048828125 \n",
      "Epoch: 60040 | MAE Train Loss: 45.12712097167969 | MAE Test Loss: 43.3877067565918 \n",
      "Epoch: 60050 | MAE Train Loss: 45.126548767089844 | MAE Test Loss: 43.38740539550781 \n",
      "Epoch: 60060 | MAE Train Loss: 45.125972747802734 | MAE Test Loss: 43.38711166381836 \n",
      "Epoch: 60070 | MAE Train Loss: 45.125396728515625 | MAE Test Loss: 43.3868408203125 \n",
      "Epoch: 60080 | MAE Train Loss: 45.12483215332031 | MAE Test Loss: 43.38654327392578 \n",
      "Epoch: 60090 | MAE Train Loss: 45.12425231933594 | MAE Test Loss: 43.38624572753906 \n",
      "Epoch: 60100 | MAE Train Loss: 45.123680114746094 | MAE Test Loss: 43.38594436645508 \n",
      "Epoch: 60110 | MAE Train Loss: 45.123104095458984 | MAE Test Loss: 43.385650634765625 \n",
      "Epoch: 60120 | MAE Train Loss: 45.12253189086914 | MAE Test Loss: 43.385379791259766 \n",
      "Epoch: 60130 | MAE Train Loss: 45.1219596862793 | MAE Test Loss: 43.38507843017578 \n",
      "Epoch: 60140 | MAE Train Loss: 45.12139129638672 | MAE Test Loss: 43.384788513183594 \n",
      "Epoch: 60150 | MAE Train Loss: 45.12081527709961 | MAE Test Loss: 43.38448715209961 \n",
      "Epoch: 60160 | MAE Train Loss: 45.120243072509766 | MAE Test Loss: 43.38418960571289 \n",
      "Epoch: 60170 | MAE Train Loss: 45.119667053222656 | MAE Test Loss: 43.3839225769043 \n",
      "Epoch: 60180 | MAE Train Loss: 45.11909484863281 | MAE Test Loss: 43.38362503051758 \n",
      "Epoch: 60190 | MAE Train Loss: 45.11852264404297 | MAE Test Loss: 43.38332748413086 \n",
      "Epoch: 60200 | MAE Train Loss: 45.11794662475586 | MAE Test Loss: 43.383026123046875 \n",
      "Epoch: 60210 | MAE Train Loss: 45.11737060546875 | MAE Test Loss: 43.38275909423828 \n",
      "Epoch: 60220 | MAE Train Loss: 45.116798400878906 | MAE Test Loss: 43.38246154785156 \n",
      "Epoch: 60230 | MAE Train Loss: 45.11622619628906 | MAE Test Loss: 43.382164001464844 \n",
      "Epoch: 60240 | MAE Train Loss: 45.11565017700195 | MAE Test Loss: 43.381866455078125 \n",
      "Epoch: 60250 | MAE Train Loss: 45.115074157714844 | MAE Test Loss: 43.381568908691406 \n",
      "Epoch: 60260 | MAE Train Loss: 45.114501953125 | MAE Test Loss: 43.38130187988281 \n",
      "Epoch: 60270 | MAE Train Loss: 45.113929748535156 | MAE Test Loss: 43.38100051879883 \n",
      "Epoch: 60280 | MAE Train Loss: 45.11335754394531 | MAE Test Loss: 43.380706787109375 \n",
      "Epoch: 60290 | MAE Train Loss: 45.1127815246582 | MAE Test Loss: 43.38040542602539 \n",
      "Epoch: 60300 | MAE Train Loss: 45.11220932006836 | MAE Test Loss: 43.38010787963867 \n",
      "Epoch: 60310 | MAE Train Loss: 45.111637115478516 | MAE Test Loss: 43.37984085083008 \n",
      "Epoch: 60320 | MAE Train Loss: 45.11106491088867 | MAE Test Loss: 43.37954330444336 \n",
      "Epoch: 60330 | MAE Train Loss: 45.11048889160156 | MAE Test Loss: 43.37924575805664 \n",
      "Epoch: 60340 | MAE Train Loss: 45.10991287231445 | MAE Test Loss: 43.37895202636719 \n",
      "Epoch: 60350 | MAE Train Loss: 45.10934066772461 | MAE Test Loss: 43.37868118286133 \n",
      "Epoch: 60360 | MAE Train Loss: 45.1087646484375 | MAE Test Loss: 43.378379821777344 \n",
      "Epoch: 60370 | MAE Train Loss: 45.10819625854492 | MAE Test Loss: 43.37808609008789 \n",
      "Epoch: 60380 | MAE Train Loss: 45.10761642456055 | MAE Test Loss: 43.37778854370117 \n",
      "Epoch: 60390 | MAE Train Loss: 45.1070442199707 | MAE Test Loss: 43.37749099731445 \n",
      "Epoch: 60400 | MAE Train Loss: 45.10647201538086 | MAE Test Loss: 43.377220153808594 \n",
      "Epoch: 60410 | MAE Train Loss: 45.105899810791016 | MAE Test Loss: 43.376930236816406 \n",
      "Epoch: 60420 | MAE Train Loss: 45.10532760620117 | MAE Test Loss: 43.376625061035156 \n",
      "Epoch: 60430 | MAE Train Loss: 45.1047477722168 | MAE Test Loss: 43.37632751464844 \n",
      "Epoch: 60440 | MAE Train Loss: 45.10417556762695 | MAE Test Loss: 43.376060485839844 \n",
      "Epoch: 60450 | MAE Train Loss: 45.103607177734375 | MAE Test Loss: 43.37576675415039 \n",
      "Epoch: 60460 | MAE Train Loss: 45.103031158447266 | MAE Test Loss: 43.375465393066406 \n",
      "Epoch: 60470 | MAE Train Loss: 45.102455139160156 | MAE Test Loss: 43.37516784667969 \n",
      "Epoch: 60480 | MAE Train Loss: 45.10188293457031 | MAE Test Loss: 43.374874114990234 \n",
      "Epoch: 60490 | MAE Train Loss: 45.1013069152832 | MAE Test Loss: 43.37459945678711 \n",
      "Epoch: 60500 | MAE Train Loss: 45.100738525390625 | MAE Test Loss: 43.374305725097656 \n",
      "Epoch: 60510 | MAE Train Loss: 45.100162506103516 | MAE Test Loss: 43.37400817871094 \n",
      "Epoch: 60520 | MAE Train Loss: 45.09959411621094 | MAE Test Loss: 43.37370681762695 \n",
      "Epoch: 60530 | MAE Train Loss: 45.09901428222656 | MAE Test Loss: 43.373409271240234 \n",
      "Epoch: 60540 | MAE Train Loss: 45.098445892333984 | MAE Test Loss: 43.373146057128906 \n",
      "Epoch: 60550 | MAE Train Loss: 45.09786605834961 | MAE Test Loss: 43.37284469604492 \n",
      "Epoch: 60560 | MAE Train Loss: 45.09729766845703 | MAE Test Loss: 43.3725471496582 \n",
      "Epoch: 60570 | MAE Train Loss: 45.09672164916992 | MAE Test Loss: 43.372249603271484 \n",
      "Epoch: 60580 | MAE Train Loss: 45.09614562988281 | MAE Test Loss: 43.371978759765625 \n",
      "Epoch: 60590 | MAE Train Loss: 45.095577239990234 | MAE Test Loss: 43.371681213378906 \n",
      "Epoch: 60600 | MAE Train Loss: 45.09500503540039 | MAE Test Loss: 43.37138366699219 \n",
      "Epoch: 60610 | MAE Train Loss: 45.094425201416016 | MAE Test Loss: 43.37108612060547 \n",
      "Epoch: 60620 | MAE Train Loss: 45.093849182128906 | MAE Test Loss: 43.37078857421875 \n",
      "Epoch: 60630 | MAE Train Loss: 45.0932731628418 | MAE Test Loss: 43.37051773071289 \n",
      "Epoch: 60640 | MAE Train Loss: 45.092708587646484 | MAE Test Loss: 43.37022399902344 \n",
      "Epoch: 60650 | MAE Train Loss: 45.092132568359375 | MAE Test Loss: 43.36992645263672 \n",
      "Epoch: 60660 | MAE Train Loss: 45.09156036376953 | MAE Test Loss: 43.369625091552734 \n",
      "Epoch: 60670 | MAE Train Loss: 45.09098434448242 | MAE Test Loss: 43.36935806274414 \n",
      "Epoch: 60680 | MAE Train Loss: 45.09041213989258 | MAE Test Loss: 43.36906433105469 \n",
      "Epoch: 60690 | MAE Train Loss: 45.089839935302734 | MAE Test Loss: 43.3687629699707 \n",
      "Epoch: 60700 | MAE Train Loss: 45.089263916015625 | MAE Test Loss: 43.36846923828125 \n",
      "Epoch: 60710 | MAE Train Loss: 45.088687896728516 | MAE Test Loss: 43.368167877197266 \n",
      "Epoch: 60720 | MAE Train Loss: 45.08811569213867 | MAE Test Loss: 43.36790084838867 \n",
      "Epoch: 60730 | MAE Train Loss: 45.08754348754883 | MAE Test Loss: 43.36760330200195 \n",
      "Epoch: 60740 | MAE Train Loss: 45.08696746826172 | MAE Test Loss: 43.36730194091797 \n",
      "Epoch: 60750 | MAE Train Loss: 45.086395263671875 | MAE Test Loss: 43.367008209228516 \n",
      "Epoch: 60760 | MAE Train Loss: 45.08582305908203 | MAE Test Loss: 43.3667106628418 \n",
      "Epoch: 60770 | MAE Train Loss: 45.08524703979492 | MAE Test Loss: 43.36643981933594 \n",
      "Epoch: 60780 | MAE Train Loss: 45.08467483520508 | MAE Test Loss: 43.366146087646484 \n",
      "Epoch: 60790 | MAE Train Loss: 45.0841064453125 | MAE Test Loss: 43.365848541259766 \n",
      "Epoch: 60800 | MAE Train Loss: 45.08353042602539 | MAE Test Loss: 43.36554718017578 \n",
      "Epoch: 60810 | MAE Train Loss: 45.08295440673828 | MAE Test Loss: 43.36528015136719 \n",
      "Epoch: 60820 | MAE Train Loss: 45.08237838745117 | MAE Test Loss: 43.364986419677734 \n",
      "Epoch: 60830 | MAE Train Loss: 45.08180618286133 | MAE Test Loss: 43.364688873291016 \n",
      "Epoch: 60840 | MAE Train Loss: 45.081233978271484 | MAE Test Loss: 43.36438751220703 \n",
      "Epoch: 60850 | MAE Train Loss: 45.080657958984375 | MAE Test Loss: 43.364097595214844 \n",
      "Epoch: 60860 | MAE Train Loss: 45.08008575439453 | MAE Test Loss: 43.36382293701172 \n",
      "Epoch: 60870 | MAE Train Loss: 45.07951354980469 | MAE Test Loss: 43.363521575927734 \n",
      "Epoch: 60880 | MAE Train Loss: 45.07893753051758 | MAE Test Loss: 43.36323165893555 \n",
      "Epoch: 60890 | MAE Train Loss: 45.07836151123047 | MAE Test Loss: 43.36293029785156 \n",
      "Epoch: 60900 | MAE Train Loss: 45.077789306640625 | MAE Test Loss: 43.3626594543457 \n",
      "Epoch: 60910 | MAE Train Loss: 45.07721710205078 | MAE Test Loss: 43.36235809326172 \n",
      "Epoch: 60920 | MAE Train Loss: 45.0766487121582 | MAE Test Loss: 43.362064361572266 \n",
      "Epoch: 60930 | MAE Train Loss: 45.076072692871094 | MAE Test Loss: 43.36176300048828 \n",
      "Epoch: 60940 | MAE Train Loss: 45.07549285888672 | MAE Test Loss: 43.36146545410156 \n",
      "Epoch: 60950 | MAE Train Loss: 45.074920654296875 | MAE Test Loss: 43.36119842529297 \n",
      "Epoch: 60960 | MAE Train Loss: 45.0743522644043 | MAE Test Loss: 43.360904693603516 \n",
      "Epoch: 60970 | MAE Train Loss: 45.07377624511719 | MAE Test Loss: 43.36061096191406 \n",
      "Epoch: 60980 | MAE Train Loss: 45.07320022583008 | MAE Test Loss: 43.36030578613281 \n",
      "Epoch: 60990 | MAE Train Loss: 45.072628021240234 | MAE Test Loss: 43.360015869140625 \n",
      "Epoch: 61000 | MAE Train Loss: 45.072059631347656 | MAE Test Loss: 43.3597412109375 \n",
      "Epoch: 61010 | MAE Train Loss: 45.07148361206055 | MAE Test Loss: 43.35944747924805 \n",
      "Epoch: 61020 | MAE Train Loss: 45.07090759277344 | MAE Test Loss: 43.35914611816406 \n",
      "Epoch: 61030 | MAE Train Loss: 45.07033920288086 | MAE Test Loss: 43.358848571777344 \n",
      "Epoch: 61040 | MAE Train Loss: 45.06976318359375 | MAE Test Loss: 43.358577728271484 \n",
      "Epoch: 61050 | MAE Train Loss: 45.06918716430664 | MAE Test Loss: 43.358280181884766 \n",
      "Epoch: 61060 | MAE Train Loss: 45.0686149597168 | MAE Test Loss: 43.35798263549805 \n",
      "Epoch: 61070 | MAE Train Loss: 45.06804275512695 | MAE Test Loss: 43.35768508911133 \n",
      "Epoch: 61080 | MAE Train Loss: 45.067466735839844 | MAE Test Loss: 43.357391357421875 \n",
      "Epoch: 61090 | MAE Train Loss: 45.06689453125 | MAE Test Loss: 43.357120513916016 \n",
      "Epoch: 61100 | MAE Train Loss: 45.066322326660156 | MAE Test Loss: 43.3568229675293 \n",
      "Epoch: 61110 | MAE Train Loss: 45.06574630737305 | MAE Test Loss: 43.356529235839844 \n",
      "Epoch: 61120 | MAE Train Loss: 45.0651741027832 | MAE Test Loss: 43.356231689453125 \n",
      "Epoch: 61130 | MAE Train Loss: 45.064598083496094 | MAE Test Loss: 43.355934143066406 \n",
      "Epoch: 61140 | MAE Train Loss: 45.06402587890625 | MAE Test Loss: 43.35566329956055 \n",
      "Epoch: 61150 | MAE Train Loss: 45.063453674316406 | MAE Test Loss: 43.35536575317383 \n",
      "Epoch: 61160 | MAE Train Loss: 45.0628776550293 | MAE Test Loss: 43.355072021484375 \n",
      "Epoch: 61170 | MAE Train Loss: 45.06230545043945 | MAE Test Loss: 43.35477066040039 \n",
      "Epoch: 61180 | MAE Train Loss: 45.06173324584961 | MAE Test Loss: 43.35449981689453 \n",
      "Epoch: 61190 | MAE Train Loss: 45.0611572265625 | MAE Test Loss: 43.35420227050781 \n",
      "Epoch: 61200 | MAE Train Loss: 45.06058883666992 | MAE Test Loss: 43.353904724121094 \n",
      "Epoch: 61210 | MAE Train Loss: 45.06001281738281 | MAE Test Loss: 43.353607177734375 \n",
      "Epoch: 61220 | MAE Train Loss: 45.05943298339844 | MAE Test Loss: 43.35331344604492 \n",
      "Epoch: 61230 | MAE Train Loss: 45.05886459350586 | MAE Test Loss: 43.3530387878418 \n",
      "Epoch: 61240 | MAE Train Loss: 45.058292388916016 | MAE Test Loss: 43.35274887084961 \n",
      "Epoch: 61250 | MAE Train Loss: 45.057716369628906 | MAE Test Loss: 43.352447509765625 \n",
      "Epoch: 61260 | MAE Train Loss: 45.0571403503418 | MAE Test Loss: 43.352149963378906 \n",
      "Epoch: 61270 | MAE Train Loss: 45.05656814575195 | MAE Test Loss: 43.35187911987305 \n",
      "Epoch: 61280 | MAE Train Loss: 45.055992126464844 | MAE Test Loss: 43.351585388183594 \n",
      "Epoch: 61290 | MAE Train Loss: 45.05542755126953 | MAE Test Loss: 43.35129165649414 \n",
      "Epoch: 61300 | MAE Train Loss: 45.05485153198242 | MAE Test Loss: 43.350990295410156 \n",
      "Epoch: 61310 | MAE Train Loss: 45.05427551269531 | MAE Test Loss: 43.35068893432617 \n",
      "Epoch: 61320 | MAE Train Loss: 45.05369567871094 | MAE Test Loss: 43.35042190551758 \n",
      "Epoch: 61330 | MAE Train Loss: 45.053131103515625 | MAE Test Loss: 43.35012435913086 \n",
      "Epoch: 61340 | MAE Train Loss: 45.05255126953125 | MAE Test Loss: 43.349830627441406 \n",
      "Epoch: 61350 | MAE Train Loss: 45.051979064941406 | MAE Test Loss: 43.349525451660156 \n",
      "Epoch: 61360 | MAE Train Loss: 45.05139923095703 | MAE Test Loss: 43.34922790527344 \n",
      "Epoch: 61370 | MAE Train Loss: 45.050838470458984 | MAE Test Loss: 43.348960876464844 \n",
      "Epoch: 61380 | MAE Train Loss: 45.050262451171875 | MAE Test Loss: 43.34866714477539 \n",
      "Epoch: 61390 | MAE Train Loss: 45.04969024658203 | MAE Test Loss: 43.348365783691406 \n",
      "Epoch: 61400 | MAE Train Loss: 45.049110412597656 | MAE Test Loss: 43.34807205200195 \n",
      "Epoch: 61410 | MAE Train Loss: 45.04853820800781 | MAE Test Loss: 43.347801208496094 \n",
      "Epoch: 61420 | MAE Train Loss: 45.04796600341797 | MAE Test Loss: 43.347503662109375 \n",
      "Epoch: 61430 | MAE Train Loss: 45.047393798828125 | MAE Test Loss: 43.347206115722656 \n",
      "Epoch: 61440 | MAE Train Loss: 45.046817779541016 | MAE Test Loss: 43.34690475463867 \n",
      "Epoch: 61450 | MAE Train Loss: 45.04624557495117 | MAE Test Loss: 43.34661102294922 \n",
      "Epoch: 61460 | MAE Train Loss: 45.04567337036133 | MAE Test Loss: 43.34634017944336 \n",
      "Epoch: 61470 | MAE Train Loss: 45.04509735107422 | MAE Test Loss: 43.34604263305664 \n",
      "Epoch: 61480 | MAE Train Loss: 45.044525146484375 | MAE Test Loss: 43.34574890136719 \n",
      "Epoch: 61490 | MAE Train Loss: 45.043949127197266 | MAE Test Loss: 43.3454475402832 \n",
      "Epoch: 61500 | MAE Train Loss: 45.043373107910156 | MAE Test Loss: 43.34518051147461 \n",
      "Epoch: 61510 | MAE Train Loss: 45.04280090332031 | MAE Test Loss: 43.344886779785156 \n",
      "Epoch: 61520 | MAE Train Loss: 45.04222869873047 | MAE Test Loss: 43.34458541870117 \n",
      "Epoch: 61530 | MAE Train Loss: 45.041656494140625 | MAE Test Loss: 43.34428787231445 \n",
      "Epoch: 61540 | MAE Train Loss: 45.041080474853516 | MAE Test Loss: 43.343990325927734 \n",
      "Epoch: 61550 | MAE Train Loss: 45.04051208496094 | MAE Test Loss: 43.343727111816406 \n",
      "Epoch: 61560 | MAE Train Loss: 45.03993225097656 | MAE Test Loss: 43.343421936035156 \n",
      "Epoch: 61570 | MAE Train Loss: 45.039363861083984 | MAE Test Loss: 43.3431282043457 \n",
      "Epoch: 61580 | MAE Train Loss: 45.03879165649414 | MAE Test Loss: 43.34282684326172 \n",
      "Epoch: 61590 | MAE Train Loss: 45.038211822509766 | MAE Test Loss: 43.342533111572266 \n",
      "Epoch: 61600 | MAE Train Loss: 45.03763961791992 | MAE Test Loss: 43.342262268066406 \n",
      "Epoch: 61610 | MAE Train Loss: 45.037071228027344 | MAE Test Loss: 43.34196853637695 \n",
      "Epoch: 61620 | MAE Train Loss: 45.03649139404297 | MAE Test Loss: 43.3416633605957 \n",
      "Epoch: 61630 | MAE Train Loss: 45.03591537475586 | MAE Test Loss: 43.341373443603516 \n",
      "Epoch: 61640 | MAE Train Loss: 45.035343170166016 | MAE Test Loss: 43.34110641479492 \n",
      "Epoch: 61650 | MAE Train Loss: 45.03477478027344 | MAE Test Loss: 43.34080505371094 \n",
      "Epoch: 61660 | MAE Train Loss: 45.034202575683594 | MAE Test Loss: 43.34050369262695 \n",
      "Epoch: 61670 | MAE Train Loss: 45.033626556396484 | MAE Test Loss: 43.3402099609375 \n",
      "Epoch: 61680 | MAE Train Loss: 45.033050537109375 | MAE Test Loss: 43.33991241455078 \n",
      "Epoch: 61690 | MAE Train Loss: 45.03247833251953 | MAE Test Loss: 43.33964157104492 \n",
      "Epoch: 61700 | MAE Train Loss: 45.03190612792969 | MAE Test Loss: 43.3393440246582 \n",
      "Epoch: 61710 | MAE Train Loss: 45.03133010864258 | MAE Test Loss: 43.339046478271484 \n",
      "Epoch: 61720 | MAE Train Loss: 45.030757904052734 | MAE Test Loss: 43.33875274658203 \n",
      "Epoch: 61730 | MAE Train Loss: 45.030181884765625 | MAE Test Loss: 43.33848190307617 \n",
      "Epoch: 61740 | MAE Train Loss: 45.02960968017578 | MAE Test Loss: 43.33818054199219 \n",
      "Epoch: 61750 | MAE Train Loss: 45.0290412902832 | MAE Test Loss: 43.33788299560547 \n",
      "Epoch: 61760 | MAE Train Loss: 45.028465270996094 | MAE Test Loss: 43.337589263916016 \n",
      "Epoch: 61770 | MAE Train Loss: 45.02788543701172 | MAE Test Loss: 43.3372917175293 \n",
      "Epoch: 61780 | MAE Train Loss: 45.02731704711914 | MAE Test Loss: 43.33701705932617 \n",
      "Epoch: 61790 | MAE Train Loss: 45.0267448425293 | MAE Test Loss: 43.33672332763672 \n",
      "Epoch: 61800 | MAE Train Loss: 45.02616882324219 | MAE Test Loss: 43.33642578125 \n",
      "Epoch: 61810 | MAE Train Loss: 45.025596618652344 | MAE Test Loss: 43.33612823486328 \n",
      "Epoch: 61820 | MAE Train Loss: 45.0250244140625 | MAE Test Loss: 43.33583068847656 \n",
      "Epoch: 61830 | MAE Train Loss: 45.02444839477539 | MAE Test Loss: 43.33556365966797 \n",
      "Epoch: 61840 | MAE Train Loss: 45.02387619018555 | MAE Test Loss: 43.335262298583984 \n",
      "Epoch: 61850 | MAE Train Loss: 45.02330017089844 | MAE Test Loss: 43.33496856689453 \n",
      "Epoch: 61860 | MAE Train Loss: 45.022727966308594 | MAE Test Loss: 43.33467102050781 \n",
      "Epoch: 61870 | MAE Train Loss: 45.022151947021484 | MAE Test Loss: 43.33440017700195 \n",
      "Epoch: 61880 | MAE Train Loss: 45.02157974243164 | MAE Test Loss: 43.3341064453125 \n",
      "Epoch: 61890 | MAE Train Loss: 45.0210075378418 | MAE Test Loss: 43.333805084228516 \n",
      "Epoch: 61900 | MAE Train Loss: 45.02043533325195 | MAE Test Loss: 43.33351135253906 \n",
      "Epoch: 61910 | MAE Train Loss: 45.01985549926758 | MAE Test Loss: 43.33320617675781 \n",
      "Epoch: 61920 | MAE Train Loss: 45.019283294677734 | MAE Test Loss: 43.332942962646484 \n",
      "Epoch: 61930 | MAE Train Loss: 45.01871109008789 | MAE Test Loss: 43.3326416015625 \n",
      "Epoch: 61940 | MAE Train Loss: 45.01814270019531 | MAE Test Loss: 43.33234786987305 \n",
      "Epoch: 61950 | MAE Train Loss: 45.01756286621094 | MAE Test Loss: 43.332054138183594 \n",
      "Epoch: 61960 | MAE Train Loss: 45.016990661621094 | MAE Test Loss: 43.33175277709961 \n",
      "Epoch: 61970 | MAE Train Loss: 45.016414642333984 | MAE Test Loss: 43.33148193359375 \n",
      "Epoch: 61980 | MAE Train Loss: 45.01584243774414 | MAE Test Loss: 43.33118438720703 \n",
      "Epoch: 61990 | MAE Train Loss: 45.0152702331543 | MAE Test Loss: 43.33089065551758 \n",
      "Epoch: 62000 | MAE Train Loss: 45.01469421386719 | MAE Test Loss: 43.33059310913086 \n",
      "Epoch: 62010 | MAE Train Loss: 45.01411819458008 | MAE Test Loss: 43.330318450927734 \n",
      "Epoch: 62020 | MAE Train Loss: 45.013553619384766 | MAE Test Loss: 43.330020904541016 \n",
      "Epoch: 62030 | MAE Train Loss: 45.01298141479492 | MAE Test Loss: 43.32972717285156 \n",
      "Epoch: 62040 | MAE Train Loss: 45.01240158081055 | MAE Test Loss: 43.32943344116211 \n",
      "Epoch: 62050 | MAE Train Loss: 45.01182556152344 | MAE Test Loss: 43.32912826538086 \n",
      "Epoch: 62060 | MAE Train Loss: 45.01125717163086 | MAE Test Loss: 43.328861236572266 \n",
      "Epoch: 62070 | MAE Train Loss: 45.01068115234375 | MAE Test Loss: 43.32856750488281 \n",
      "Epoch: 62080 | MAE Train Loss: 45.010108947753906 | MAE Test Loss: 43.32826614379883 \n",
      "Epoch: 62090 | MAE Train Loss: 45.0095329284668 | MAE Test Loss: 43.327972412109375 \n",
      "Epoch: 62100 | MAE Train Loss: 45.00895690917969 | MAE Test Loss: 43.327701568603516 \n",
      "Epoch: 62110 | MAE Train Loss: 45.00838851928711 | MAE Test Loss: 43.32740020751953 \n",
      "Epoch: 62120 | MAE Train Loss: 45.007816314697266 | MAE Test Loss: 43.32710266113281 \n",
      "Epoch: 62130 | MAE Train Loss: 45.00724411010742 | MAE Test Loss: 43.326805114746094 \n",
      "Epoch: 62140 | MAE Train Loss: 45.00666427612305 | MAE Test Loss: 43.32651138305664 \n",
      "Epoch: 62150 | MAE Train Loss: 45.00609588623047 | MAE Test Loss: 43.32624053955078 \n",
      "Epoch: 62160 | MAE Train Loss: 45.005516052246094 | MAE Test Loss: 43.32594299316406 \n",
      "Epoch: 62170 | MAE Train Loss: 45.004947662353516 | MAE Test Loss: 43.325645446777344 \n",
      "Epoch: 62180 | MAE Train Loss: 45.00437545776367 | MAE Test Loss: 43.325347900390625 \n",
      "Epoch: 62190 | MAE Train Loss: 45.00379943847656 | MAE Test Loss: 43.32505416870117 \n",
      "Epoch: 62200 | MAE Train Loss: 45.00322723388672 | MAE Test Loss: 43.32478332519531 \n",
      "Epoch: 62210 | MAE Train Loss: 45.00265121459961 | MAE Test Loss: 43.32448196411133 \n",
      "Epoch: 62220 | MAE Train Loss: 45.002079010009766 | MAE Test Loss: 43.32418441772461 \n",
      "Epoch: 62230 | MAE Train Loss: 45.00150680541992 | MAE Test Loss: 43.323890686035156 \n",
      "Epoch: 62240 | MAE Train Loss: 45.00093078613281 | MAE Test Loss: 43.3236198425293 \n",
      "Epoch: 62250 | MAE Train Loss: 45.00035858154297 | MAE Test Loss: 43.32332229614258 \n",
      "Epoch: 62260 | MAE Train Loss: 44.99978256225586 | MAE Test Loss: 43.32302474975586 \n",
      "Epoch: 62270 | MAE Train Loss: 44.999210357666016 | MAE Test Loss: 43.32272720336914 \n",
      "Epoch: 62280 | MAE Train Loss: 44.998634338378906 | MAE Test Loss: 43.32242965698242 \n",
      "Epoch: 62290 | MAE Train Loss: 44.99806213378906 | MAE Test Loss: 43.32216262817383 \n",
      "Epoch: 62300 | MAE Train Loss: 44.99748992919922 | MAE Test Loss: 43.32186508178711 \n",
      "Epoch: 62310 | MAE Train Loss: 44.99691390991211 | MAE Test Loss: 43.32156753540039 \n",
      "Epoch: 62320 | MAE Train Loss: 44.996341705322266 | MAE Test Loss: 43.32127380371094 \n",
      "Epoch: 62330 | MAE Train Loss: 44.995765686035156 | MAE Test Loss: 43.32099914550781 \n",
      "Epoch: 62340 | MAE Train Loss: 44.99519729614258 | MAE Test Loss: 43.32070541381836 \n",
      "Epoch: 62350 | MAE Train Loss: 44.99462127685547 | MAE Test Loss: 43.320404052734375 \n",
      "Epoch: 62360 | MAE Train Loss: 44.994049072265625 | MAE Test Loss: 43.32011032104492 \n",
      "Epoch: 62370 | MAE Train Loss: 44.99346923828125 | MAE Test Loss: 43.3198127746582 \n",
      "Epoch: 62380 | MAE Train Loss: 44.99290084838867 | MAE Test Loss: 43.31953811645508 \n",
      "Epoch: 62390 | MAE Train Loss: 44.99232864379883 | MAE Test Loss: 43.31924057006836 \n",
      "Epoch: 62400 | MAE Train Loss: 44.99175262451172 | MAE Test Loss: 43.318946838378906 \n",
      "Epoch: 62410 | MAE Train Loss: 44.99117660522461 | MAE Test Loss: 43.31864929199219 \n",
      "Epoch: 62420 | MAE Train Loss: 44.9906005859375 | MAE Test Loss: 43.3183479309082 \n",
      "Epoch: 62430 | MAE Train Loss: 44.99003219604492 | MAE Test Loss: 43.31808090209961 \n",
      "Epoch: 62440 | MAE Train Loss: 44.98945999145508 | MAE Test Loss: 43.31778335571289 \n",
      "Epoch: 62450 | MAE Train Loss: 44.9888801574707 | MAE Test Loss: 43.31748580932617 \n",
      "Epoch: 62460 | MAE Train Loss: 44.988319396972656 | MAE Test Loss: 43.31721878051758 \n",
      "Epoch: 62470 | MAE Train Loss: 44.987762451171875 | MAE Test Loss: 43.31696701049805 \n",
      "Epoch: 62480 | MAE Train Loss: 44.98720932006836 | MAE Test Loss: 43.316741943359375 \n",
      "Epoch: 62490 | MAE Train Loss: 44.98666000366211 | MAE Test Loss: 43.31650161743164 \n",
      "Epoch: 62500 | MAE Train Loss: 44.98611831665039 | MAE Test Loss: 43.316280364990234 \n",
      "Epoch: 62510 | MAE Train Loss: 44.985572814941406 | MAE Test Loss: 43.316062927246094 \n",
      "Epoch: 62520 | MAE Train Loss: 44.985023498535156 | MAE Test Loss: 43.31584548950195 \n",
      "Epoch: 62530 | MAE Train Loss: 44.98447036743164 | MAE Test Loss: 43.315608978271484 \n",
      "Epoch: 62540 | MAE Train Loss: 44.98392105102539 | MAE Test Loss: 43.315391540527344 \n",
      "Epoch: 62550 | MAE Train Loss: 44.983375549316406 | MAE Test Loss: 43.3151741027832 \n",
      "Epoch: 62560 | MAE Train Loss: 44.98283004760742 | MAE Test Loss: 43.31492614746094 \n",
      "Epoch: 62570 | MAE Train Loss: 44.9822883605957 | MAE Test Loss: 43.31470489501953 \n",
      "Epoch: 62580 | MAE Train Loss: 44.98173141479492 | MAE Test Loss: 43.31447219848633 \n",
      "Epoch: 62590 | MAE Train Loss: 44.9811897277832 | MAE Test Loss: 43.31425476074219 \n",
      "Epoch: 62600 | MAE Train Loss: 44.98064422607422 | MAE Test Loss: 43.31403732299805 \n",
      "Epoch: 62610 | MAE Train Loss: 44.9800910949707 | MAE Test Loss: 43.31381607055664 \n",
      "Epoch: 62620 | MAE Train Loss: 44.979549407958984 | MAE Test Loss: 43.313568115234375 \n",
      "Epoch: 62630 | MAE Train Loss: 44.97899627685547 | MAE Test Loss: 43.3133659362793 \n",
      "Epoch: 62640 | MAE Train Loss: 44.978450775146484 | MAE Test Loss: 43.313114166259766 \n",
      "Epoch: 62650 | MAE Train Loss: 44.977901458740234 | MAE Test Loss: 43.31290054321289 \n",
      "Epoch: 62660 | MAE Train Loss: 44.977352142333984 | MAE Test Loss: 43.312679290771484 \n",
      "Epoch: 62670 | MAE Train Loss: 44.976806640625 | MAE Test Loss: 43.31244659423828 \n",
      "Epoch: 62680 | MAE Train Loss: 44.976261138916016 | MAE Test Loss: 43.312232971191406 \n",
      "Epoch: 62690 | MAE Train Loss: 44.9757080078125 | MAE Test Loss: 43.31201171875 \n",
      "Epoch: 62700 | MAE Train Loss: 44.975162506103516 | MAE Test Loss: 43.31175994873047 \n",
      "Epoch: 62710 | MAE Train Loss: 44.974613189697266 | MAE Test Loss: 43.31153869628906 \n",
      "Epoch: 62720 | MAE Train Loss: 44.97406768798828 | MAE Test Loss: 43.311309814453125 \n",
      "Epoch: 62730 | MAE Train Loss: 44.9735221862793 | MAE Test Loss: 43.31108856201172 \n",
      "Epoch: 62740 | MAE Train Loss: 44.97297668457031 | MAE Test Loss: 43.31087112426758 \n",
      "Epoch: 62750 | MAE Train Loss: 44.9724235534668 | MAE Test Loss: 43.31064987182617 \n",
      "Epoch: 62760 | MAE Train Loss: 44.97187805175781 | MAE Test Loss: 43.310420989990234 \n",
      "Epoch: 62770 | MAE Train Loss: 44.9713249206543 | MAE Test Loss: 43.31019973754883 \n",
      "Epoch: 62780 | MAE Train Loss: 44.97077941894531 | MAE Test Loss: 43.30998229980469 \n",
      "Epoch: 62790 | MAE Train Loss: 44.97023391723633 | MAE Test Loss: 43.30973815917969 \n",
      "Epoch: 62800 | MAE Train Loss: 44.96969223022461 | MAE Test Loss: 43.309513092041016 \n",
      "Epoch: 62810 | MAE Train Loss: 44.969139099121094 | MAE Test Loss: 43.30928039550781 \n",
      "Epoch: 62820 | MAE Train Loss: 44.96859359741211 | MAE Test Loss: 43.309059143066406 \n",
      "Epoch: 62830 | MAE Train Loss: 44.968048095703125 | MAE Test Loss: 43.308841705322266 \n",
      "Epoch: 62840 | MAE Train Loss: 44.96749496459961 | MAE Test Loss: 43.30862808227539 \n",
      "Epoch: 62850 | MAE Train Loss: 44.966949462890625 | MAE Test Loss: 43.30837631225586 \n",
      "Epoch: 62860 | MAE Train Loss: 44.966400146484375 | MAE Test Loss: 43.30817794799805 \n",
      "Epoch: 62870 | MAE Train Loss: 44.96585464477539 | MAE Test Loss: 43.30792999267578 \n",
      "Epoch: 62880 | MAE Train Loss: 44.965309143066406 | MAE Test Loss: 43.30770492553711 \n",
      "Epoch: 62890 | MAE Train Loss: 44.96476364135742 | MAE Test Loss: 43.3074836730957 \n",
      "Epoch: 62900 | MAE Train Loss: 44.964210510253906 | MAE Test Loss: 43.307254791259766 \n",
      "Epoch: 62910 | MAE Train Loss: 44.96366500854492 | MAE Test Loss: 43.307037353515625 \n",
      "Epoch: 62920 | MAE Train Loss: 44.96311569213867 | MAE Test Loss: 43.30681610107422 \n",
      "Epoch: 62930 | MAE Train Loss: 44.96257019042969 | MAE Test Loss: 43.30656814575195 \n",
      "Epoch: 62940 | MAE Train Loss: 44.9620246887207 | MAE Test Loss: 43.30635070800781 \n",
      "Epoch: 62950 | MAE Train Loss: 44.96147537231445 | MAE Test Loss: 43.30613708496094 \n",
      "Epoch: 62960 | MAE Train Loss: 44.96092224121094 | MAE Test Loss: 43.30591583251953 \n",
      "Epoch: 62970 | MAE Train Loss: 44.96037673950195 | MAE Test Loss: 43.3056640625 \n",
      "Epoch: 62980 | MAE Train Loss: 44.959835052490234 | MAE Test Loss: 43.30544662475586 \n",
      "Epoch: 62990 | MAE Train Loss: 44.95928192138672 | MAE Test Loss: 43.30522918701172 \n",
      "Epoch: 63000 | MAE Train Loss: 44.958736419677734 | MAE Test Loss: 43.305015563964844 \n",
      "Epoch: 63010 | MAE Train Loss: 44.95818328857422 | MAE Test Loss: 43.30479431152344 \n",
      "Epoch: 63020 | MAE Train Loss: 44.9576416015625 | MAE Test Loss: 43.30454635620117 \n",
      "Epoch: 63030 | MAE Train Loss: 44.957096099853516 | MAE Test Loss: 43.304325103759766 \n",
      "Epoch: 63040 | MAE Train Loss: 44.95655059814453 | MAE Test Loss: 43.304107666015625 \n",
      "Epoch: 63050 | MAE Train Loss: 44.955997467041016 | MAE Test Loss: 43.303890228271484 \n",
      "Epoch: 63060 | MAE Train Loss: 44.955448150634766 | MAE Test Loss: 43.30363845825195 \n",
      "Epoch: 63070 | MAE Train Loss: 44.95490264892578 | MAE Test Loss: 43.30342102050781 \n",
      "Epoch: 63080 | MAE Train Loss: 44.9543571472168 | MAE Test Loss: 43.30320358276367 \n",
      "Epoch: 63090 | MAE Train Loss: 44.95380401611328 | MAE Test Loss: 43.30298614501953 \n",
      "Epoch: 63100 | MAE Train Loss: 44.95326232910156 | MAE Test Loss: 43.302738189697266 \n",
      "Epoch: 63110 | MAE Train Loss: 44.95271301269531 | MAE Test Loss: 43.30251693725586 \n",
      "Epoch: 63120 | MAE Train Loss: 44.95216369628906 | MAE Test Loss: 43.30229949951172 \n",
      "Epoch: 63130 | MAE Train Loss: 44.95161819458008 | MAE Test Loss: 43.30208206176758 \n",
      "Epoch: 63140 | MAE Train Loss: 44.95106887817383 | MAE Test Loss: 43.30183029174805 \n",
      "Epoch: 63150 | MAE Train Loss: 44.950523376464844 | MAE Test Loss: 43.30161666870117 \n",
      "Epoch: 63160 | MAE Train Loss: 44.949974060058594 | MAE Test Loss: 43.301395416259766 \n",
      "Epoch: 63170 | MAE Train Loss: 44.94942855834961 | MAE Test Loss: 43.301177978515625 \n",
      "Epoch: 63180 | MAE Train Loss: 44.948883056640625 | MAE Test Loss: 43.30092239379883 \n",
      "Epoch: 63190 | MAE Train Loss: 44.948333740234375 | MAE Test Loss: 43.30070877075195 \n",
      "Epoch: 63200 | MAE Train Loss: 44.947784423828125 | MAE Test Loss: 43.30049133300781 \n",
      "Epoch: 63210 | MAE Train Loss: 44.947235107421875 | MAE Test Loss: 43.30027770996094 \n",
      "Epoch: 63220 | MAE Train Loss: 44.946685791015625 | MAE Test Loss: 43.300052642822266 \n",
      "Epoch: 63230 | MAE Train Loss: 44.946144104003906 | MAE Test Loss: 43.2998046875 \n",
      "Epoch: 63240 | MAE Train Loss: 44.94559860229492 | MAE Test Loss: 43.299583435058594 \n",
      "Epoch: 63250 | MAE Train Loss: 44.945045471191406 | MAE Test Loss: 43.29936981201172 \n",
      "Epoch: 63260 | MAE Train Loss: 44.944496154785156 | MAE Test Loss: 43.29915237426758 \n",
      "Epoch: 63270 | MAE Train Loss: 44.9439582824707 | MAE Test Loss: 43.29890060424805 \n",
      "Epoch: 63280 | MAE Train Loss: 44.94340515136719 | MAE Test Loss: 43.29868698120117 \n",
      "Epoch: 63290 | MAE Train Loss: 44.94285583496094 | MAE Test Loss: 43.298465728759766 \n",
      "Epoch: 63300 | MAE Train Loss: 44.94230651855469 | MAE Test Loss: 43.298248291015625 \n",
      "Epoch: 63310 | MAE Train Loss: 44.94175720214844 | MAE Test Loss: 43.297996520996094 \n",
      "Epoch: 63320 | MAE Train Loss: 44.94121551513672 | MAE Test Loss: 43.29777908325195 \n",
      "Epoch: 63330 | MAE Train Loss: 44.94066619873047 | MAE Test Loss: 43.29756164550781 \n",
      "Epoch: 63340 | MAE Train Loss: 44.94011688232422 | MAE Test Loss: 43.29734802246094 \n",
      "Epoch: 63350 | MAE Train Loss: 44.93956756591797 | MAE Test Loss: 43.29709243774414 \n",
      "Epoch: 63360 | MAE Train Loss: 44.93902587890625 | MAE Test Loss: 43.296871185302734 \n",
      "Epoch: 63370 | MAE Train Loss: 44.9384765625 | MAE Test Loss: 43.296653747558594 \n",
      "Epoch: 63380 | MAE Train Loss: 44.93792724609375 | MAE Test Loss: 43.29644012451172 \n",
      "Epoch: 63390 | MAE Train Loss: 44.9373779296875 | MAE Test Loss: 43.29618835449219 \n",
      "Epoch: 63400 | MAE Train Loss: 44.936832427978516 | MAE Test Loss: 43.29597091674805 \n",
      "Epoch: 63410 | MAE Train Loss: 44.93628692626953 | MAE Test Loss: 43.29574966430664 \n",
      "Epoch: 63420 | MAE Train Loss: 44.935733795166016 | MAE Test Loss: 43.295536041259766 \n",
      "Epoch: 63430 | MAE Train Loss: 44.93518829345703 | MAE Test Loss: 43.2952880859375 \n",
      "Epoch: 63440 | MAE Train Loss: 44.93464279174805 | MAE Test Loss: 43.29507064819336 \n",
      "Epoch: 63450 | MAE Train Loss: 44.93409729003906 | MAE Test Loss: 43.29484939575195 \n",
      "Epoch: 63460 | MAE Train Loss: 44.93354797363281 | MAE Test Loss: 43.29462814331055 \n",
      "Epoch: 63470 | MAE Train Loss: 44.9329948425293 | MAE Test Loss: 43.29441452026367 \n",
      "Epoch: 63480 | MAE Train Loss: 44.93245315551758 | MAE Test Loss: 43.294166564941406 \n",
      "Epoch: 63490 | MAE Train Loss: 44.931907653808594 | MAE Test Loss: 43.293949127197266 \n",
      "Epoch: 63500 | MAE Train Loss: 44.93135452270508 | MAE Test Loss: 43.293724060058594 \n",
      "Epoch: 63510 | MAE Train Loss: 44.930809020996094 | MAE Test Loss: 43.29351043701172 \n",
      "Epoch: 63520 | MAE Train Loss: 44.93026351928711 | MAE Test Loss: 43.29325866699219 \n",
      "Epoch: 63530 | MAE Train Loss: 44.92971420288086 | MAE Test Loss: 43.29304122924805 \n",
      "Epoch: 63540 | MAE Train Loss: 44.929168701171875 | MAE Test Loss: 43.29281997680664 \n",
      "Epoch: 63550 | MAE Train Loss: 44.928619384765625 | MAE Test Loss: 43.292606353759766 \n",
      "Epoch: 63560 | MAE Train Loss: 44.928070068359375 | MAE Test Loss: 43.292354583740234 \n",
      "Epoch: 63570 | MAE Train Loss: 44.92752456665039 | MAE Test Loss: 43.29213333129883 \n",
      "Epoch: 63580 | MAE Train Loss: 44.926979064941406 | MAE Test Loss: 43.29191970825195 \n",
      "Epoch: 63590 | MAE Train Loss: 44.926429748535156 | MAE Test Loss: 43.29170227050781 \n",
      "Epoch: 63600 | MAE Train Loss: 44.92587661743164 | MAE Test Loss: 43.29145050048828 \n",
      "Epoch: 63610 | MAE Train Loss: 44.925331115722656 | MAE Test Loss: 43.291229248046875 \n",
      "Epoch: 63620 | MAE Train Loss: 44.92478561401367 | MAE Test Loss: 43.291015625 \n",
      "Epoch: 63630 | MAE Train Loss: 44.92424011230469 | MAE Test Loss: 43.29079818725586 \n",
      "Epoch: 63640 | MAE Train Loss: 44.923683166503906 | MAE Test Loss: 43.29054641723633 \n",
      "Epoch: 63650 | MAE Train Loss: 44.92314529418945 | MAE Test Loss: 43.29032897949219 \n",
      "Epoch: 63660 | MAE Train Loss: 44.9225959777832 | MAE Test Loss: 43.29011154174805 \n",
      "Epoch: 63670 | MAE Train Loss: 44.92204284667969 | MAE Test Loss: 43.28989028930664 \n",
      "Epoch: 63680 | MAE Train Loss: 44.9214973449707 | MAE Test Loss: 43.2896728515625 \n",
      "Epoch: 63690 | MAE Train Loss: 44.920955657958984 | MAE Test Loss: 43.289424896240234 \n",
      "Epoch: 63700 | MAE Train Loss: 44.92041015625 | MAE Test Loss: 43.28920364379883 \n",
      "Epoch: 63710 | MAE Train Loss: 44.919857025146484 | MAE Test Loss: 43.28898620605469 \n",
      "Epoch: 63720 | MAE Train Loss: 44.919307708740234 | MAE Test Loss: 43.28877258300781 \n",
      "Epoch: 63730 | MAE Train Loss: 44.918758392333984 | MAE Test Loss: 43.28852081298828 \n",
      "Epoch: 63740 | MAE Train Loss: 44.918216705322266 | MAE Test Loss: 43.28830337524414 \n",
      "Epoch: 63750 | MAE Train Loss: 44.91767120361328 | MAE Test Loss: 43.2880859375 \n",
      "Epoch: 63760 | MAE Train Loss: 44.917118072509766 | MAE Test Loss: 43.287864685058594 \n",
      "Epoch: 63770 | MAE Train Loss: 44.91657257080078 | MAE Test Loss: 43.28761672973633 \n",
      "Epoch: 63780 | MAE Train Loss: 44.91603088378906 | MAE Test Loss: 43.28739929199219 \n",
      "Epoch: 63790 | MAE Train Loss: 44.91547775268555 | MAE Test Loss: 43.28718185424805 \n",
      "Epoch: 63800 | MAE Train Loss: 44.91492462158203 | MAE Test Loss: 43.286964416503906 \n",
      "Epoch: 63810 | MAE Train Loss: 44.91437911987305 | MAE Test Loss: 43.28671646118164 \n",
      "Epoch: 63820 | MAE Train Loss: 44.91383743286133 | MAE Test Loss: 43.286495208740234 \n",
      "Epoch: 63830 | MAE Train Loss: 44.913291931152344 | MAE Test Loss: 43.286277770996094 \n",
      "Epoch: 63840 | MAE Train Loss: 44.91273880004883 | MAE Test Loss: 43.28605651855469 \n",
      "Epoch: 63850 | MAE Train Loss: 44.91218948364258 | MAE Test Loss: 43.28580856323242 \n",
      "Epoch: 63860 | MAE Train Loss: 44.911643981933594 | MAE Test Loss: 43.28559112548828 \n",
      "Epoch: 63870 | MAE Train Loss: 44.91109848022461 | MAE Test Loss: 43.285369873046875 \n",
      "Epoch: 63880 | MAE Train Loss: 44.91054916381836 | MAE Test Loss: 43.285152435302734 \n",
      "Epoch: 63890 | MAE Train Loss: 44.90999984741211 | MAE Test Loss: 43.284908294677734 \n",
      "Epoch: 63900 | MAE Train Loss: 44.909454345703125 | MAE Test Loss: 43.28468704223633 \n",
      "Epoch: 63910 | MAE Train Loss: 44.908905029296875 | MAE Test Loss: 43.28446578979492 \n",
      "Epoch: 63920 | MAE Train Loss: 44.90835952758789 | MAE Test Loss: 43.28425216674805 \n",
      "Epoch: 63930 | MAE Train Loss: 44.907806396484375 | MAE Test Loss: 43.28403091430664 \n",
      "Epoch: 63940 | MAE Train Loss: 44.907264709472656 | MAE Test Loss: 43.283782958984375 \n",
      "Epoch: 63950 | MAE Train Loss: 44.90671920776367 | MAE Test Loss: 43.28356170654297 \n",
      "Epoch: 63960 | MAE Train Loss: 44.906166076660156 | MAE Test Loss: 43.283348083496094 \n",
      "Epoch: 63970 | MAE Train Loss: 44.90562057495117 | MAE Test Loss: 43.28312683105469 \n",
      "Epoch: 63980 | MAE Train Loss: 44.90507125854492 | MAE Test Loss: 43.28287887573242 \n",
      "Epoch: 63990 | MAE Train Loss: 44.9045295715332 | MAE Test Loss: 43.28266143798828 \n",
      "Epoch: 64000 | MAE Train Loss: 44.90397644042969 | MAE Test Loss: 43.28244400024414 \n",
      "Epoch: 64010 | MAE Train Loss: 44.9034309387207 | MAE Test Loss: 43.282222747802734 \n",
      "Epoch: 64020 | MAE Train Loss: 44.90288162231445 | MAE Test Loss: 43.28197479248047 \n",
      "Epoch: 64030 | MAE Train Loss: 44.90233612060547 | MAE Test Loss: 43.28175735473633 \n",
      "Epoch: 64040 | MAE Train Loss: 44.901790618896484 | MAE Test Loss: 43.28153610229492 \n",
      "Epoch: 64050 | MAE Train Loss: 44.901241302490234 | MAE Test Loss: 43.28131866455078 \n",
      "Epoch: 64060 | MAE Train Loss: 44.90068817138672 | MAE Test Loss: 43.281070709228516 \n",
      "Epoch: 64070 | MAE Train Loss: 44.900146484375 | MAE Test Loss: 43.280853271484375 \n",
      "Epoch: 64080 | MAE Train Loss: 44.899600982666016 | MAE Test Loss: 43.280635833740234 \n",
      "Epoch: 64090 | MAE Train Loss: 44.8990478515625 | MAE Test Loss: 43.280418395996094 \n",
      "Epoch: 64100 | MAE Train Loss: 44.898502349853516 | MAE Test Loss: 43.2801628112793 \n",
      "Epoch: 64110 | MAE Train Loss: 44.89794921875 | MAE Test Loss: 43.27994918823242 \n",
      "Epoch: 64120 | MAE Train Loss: 44.89740753173828 | MAE Test Loss: 43.27973175048828 \n",
      "Epoch: 64130 | MAE Train Loss: 44.8968620300293 | MAE Test Loss: 43.27951431274414 \n",
      "Epoch: 64140 | MAE Train Loss: 44.89630889892578 | MAE Test Loss: 43.279293060302734 \n",
      "Epoch: 64150 | MAE Train Loss: 44.8957633972168 | MAE Test Loss: 43.2790412902832 \n",
      "Epoch: 64160 | MAE Train Loss: 44.89521789550781 | MAE Test Loss: 43.27882385253906 \n",
      "Epoch: 64170 | MAE Train Loss: 44.89466857910156 | MAE Test Loss: 43.278602600097656 \n",
      "Epoch: 64180 | MAE Train Loss: 44.89412307739258 | MAE Test Loss: 43.27838897705078 \n",
      "Epoch: 64190 | MAE Train Loss: 44.89357376098633 | MAE Test Loss: 43.278141021728516 \n",
      "Epoch: 64200 | MAE Train Loss: 44.89303207397461 | MAE Test Loss: 43.27791976928711 \n",
      "Epoch: 64210 | MAE Train Loss: 44.89247512817383 | MAE Test Loss: 43.277706146240234 \n",
      "Epoch: 64220 | MAE Train Loss: 44.891929626464844 | MAE Test Loss: 43.277488708496094 \n",
      "Epoch: 64230 | MAE Train Loss: 44.89138412475586 | MAE Test Loss: 43.2772331237793 \n",
      "Epoch: 64240 | MAE Train Loss: 44.89083480834961 | MAE Test Loss: 43.27701950073242 \n",
      "Epoch: 64250 | MAE Train Loss: 44.890289306640625 | MAE Test Loss: 43.276798248291016 \n",
      "Epoch: 64260 | MAE Train Loss: 44.889739990234375 | MAE Test Loss: 43.276588439941406 \n",
      "Epoch: 64270 | MAE Train Loss: 44.889190673828125 | MAE Test Loss: 43.27633285522461 \n",
      "Epoch: 64280 | MAE Train Loss: 44.88864517211914 | MAE Test Loss: 43.276119232177734 \n",
      "Epoch: 64290 | MAE Train Loss: 44.888099670410156 | MAE Test Loss: 43.27589797973633 \n",
      "Epoch: 64300 | MAE Train Loss: 44.88755416870117 | MAE Test Loss: 43.27568054199219 \n",
      "Epoch: 64310 | MAE Train Loss: 44.887001037597656 | MAE Test Loss: 43.27543258666992 \n",
      "Epoch: 64320 | MAE Train Loss: 44.88645935058594 | MAE Test Loss: 43.275211334228516 \n",
      "Epoch: 64330 | MAE Train Loss: 44.88590621948242 | MAE Test Loss: 43.274993896484375 \n",
      "Epoch: 64340 | MAE Train Loss: 44.8853645324707 | MAE Test Loss: 43.2747688293457 \n",
      "Epoch: 64350 | MAE Train Loss: 44.88481140136719 | MAE Test Loss: 43.2745246887207 \n",
      "Epoch: 64360 | MAE Train Loss: 44.8842658996582 | MAE Test Loss: 43.2743034362793 \n",
      "Epoch: 64370 | MAE Train Loss: 44.88372039794922 | MAE Test Loss: 43.274085998535156 \n",
      "Epoch: 64380 | MAE Train Loss: 44.8831672668457 | MAE Test Loss: 43.27387237548828 \n",
      "Epoch: 64390 | MAE Train Loss: 44.88262176513672 | MAE Test Loss: 43.27365493774414 \n",
      "Epoch: 64400 | MAE Train Loss: 44.882076263427734 | MAE Test Loss: 43.27340316772461 \n",
      "Epoch: 64410 | MAE Train Loss: 44.88153076171875 | MAE Test Loss: 43.27317810058594 \n",
      "Epoch: 64420 | MAE Train Loss: 44.88097381591797 | MAE Test Loss: 43.27296447753906 \n",
      "Epoch: 64430 | MAE Train Loss: 44.880428314208984 | MAE Test Loss: 43.27275085449219 \n",
      "Epoch: 64440 | MAE Train Loss: 44.879886627197266 | MAE Test Loss: 43.272499084472656 \n",
      "Epoch: 64450 | MAE Train Loss: 44.879337310791016 | MAE Test Loss: 43.272274017333984 \n",
      "Epoch: 64460 | MAE Train Loss: 44.878787994384766 | MAE Test Loss: 43.272064208984375 \n",
      "Epoch: 64470 | MAE Train Loss: 44.87824249267578 | MAE Test Loss: 43.2718391418457 \n",
      "Epoch: 64480 | MAE Train Loss: 44.877689361572266 | MAE Test Loss: 43.2715950012207 \n",
      "Epoch: 64490 | MAE Train Loss: 44.87714767456055 | MAE Test Loss: 43.27137756347656 \n",
      "Epoch: 64500 | MAE Train Loss: 44.8765983581543 | MAE Test Loss: 43.271156311035156 \n",
      "Epoch: 64510 | MAE Train Loss: 44.87605285644531 | MAE Test Loss: 43.27094268798828 \n",
      "Epoch: 64520 | MAE Train Loss: 44.87550354003906 | MAE Test Loss: 43.27069091796875 \n",
      "Epoch: 64530 | MAE Train Loss: 44.87495422363281 | MAE Test Loss: 43.27047348022461 \n",
      "Epoch: 64540 | MAE Train Loss: 44.874412536621094 | MAE Test Loss: 43.27025604248047 \n",
      "Epoch: 64550 | MAE Train Loss: 44.87385940551758 | MAE Test Loss: 43.2700309753418 \n",
      "Epoch: 64560 | MAE Train Loss: 44.87331008911133 | MAE Test Loss: 43.2697868347168 \n",
      "Epoch: 64570 | MAE Train Loss: 44.87276840209961 | MAE Test Loss: 43.26956558227539 \n",
      "Epoch: 64580 | MAE Train Loss: 44.87221908569336 | MAE Test Loss: 43.269351959228516 \n",
      "Epoch: 64590 | MAE Train Loss: 44.87166976928711 | MAE Test Loss: 43.269134521484375 \n",
      "Epoch: 64600 | MAE Train Loss: 44.87112045288086 | MAE Test Loss: 43.2689094543457 \n",
      "Epoch: 64610 | MAE Train Loss: 44.870574951171875 | MAE Test Loss: 43.2686653137207 \n",
      "Epoch: 64620 | MAE Train Loss: 44.870033264160156 | MAE Test Loss: 43.2684440612793 \n",
      "Epoch: 64630 | MAE Train Loss: 44.86948013305664 | MAE Test Loss: 43.268226623535156 \n",
      "Epoch: 64640 | MAE Train Loss: 44.86893081665039 | MAE Test Loss: 43.268009185791016 \n",
      "Epoch: 64650 | MAE Train Loss: 44.86838912963867 | MAE Test Loss: 43.267757415771484 \n",
      "Epoch: 64660 | MAE Train Loss: 44.867835998535156 | MAE Test Loss: 43.26753616333008 \n",
      "Epoch: 64670 | MAE Train Loss: 44.867286682128906 | MAE Test Loss: 43.2673225402832 \n",
      "Epoch: 64680 | MAE Train Loss: 44.86674118041992 | MAE Test Loss: 43.26710510253906 \n",
      "Epoch: 64690 | MAE Train Loss: 44.86619567871094 | MAE Test Loss: 43.2668571472168 \n",
      "Epoch: 64700 | MAE Train Loss: 44.86565399169922 | MAE Test Loss: 43.26663589477539 \n",
      "Epoch: 64710 | MAE Train Loss: 44.86510467529297 | MAE Test Loss: 43.266422271728516 \n",
      "Epoch: 64720 | MAE Train Loss: 44.86455154418945 | MAE Test Loss: 43.26620101928711 \n",
      "Epoch: 64730 | MAE Train Loss: 44.8640022277832 | MAE Test Loss: 43.265953063964844 \n",
      "Epoch: 64740 | MAE Train Loss: 44.86345672607422 | MAE Test Loss: 43.2657356262207 \n",
      "Epoch: 64750 | MAE Train Loss: 44.862911224365234 | MAE Test Loss: 43.2655143737793 \n",
      "Epoch: 64760 | MAE Train Loss: 44.862361907958984 | MAE Test Loss: 43.265281677246094 \n",
      "Epoch: 64770 | MAE Train Loss: 44.86181640625 | MAE Test Loss: 43.26506423950195 \n",
      "Epoch: 64780 | MAE Train Loss: 44.86126708984375 | MAE Test Loss: 43.26483917236328 \n",
      "Epoch: 64790 | MAE Train Loss: 44.860713958740234 | MAE Test Loss: 43.26459503173828 \n",
      "Epoch: 64800 | MAE Train Loss: 44.860172271728516 | MAE Test Loss: 43.2643928527832 \n",
      "Epoch: 64810 | MAE Train Loss: 44.859622955322266 | MAE Test Loss: 43.26414489746094 \n",
      "Epoch: 64820 | MAE Train Loss: 44.859073638916016 | MAE Test Loss: 43.2639274597168 \n",
      "Epoch: 64830 | MAE Train Loss: 44.85852813720703 | MAE Test Loss: 43.26370620727539 \n",
      "Epoch: 64840 | MAE Train Loss: 44.85797882080078 | MAE Test Loss: 43.263492584228516 \n",
      "Epoch: 64850 | MAE Train Loss: 44.8574333190918 | MAE Test Loss: 43.26325607299805 \n",
      "Epoch: 64860 | MAE Train Loss: 44.85688400268555 | MAE Test Loss: 43.26304244995117 \n",
      "Epoch: 64870 | MAE Train Loss: 44.85633850097656 | MAE Test Loss: 43.262821197509766 \n",
      "Epoch: 64880 | MAE Train Loss: 44.85578918457031 | MAE Test Loss: 43.262569427490234 \n",
      "Epoch: 64890 | MAE Train Loss: 44.85524368286133 | MAE Test Loss: 43.26237106323242 \n",
      "Epoch: 64900 | MAE Train Loss: 44.85469436645508 | MAE Test Loss: 43.262115478515625 \n",
      "Epoch: 64910 | MAE Train Loss: 44.85415267944336 | MAE Test Loss: 43.261898040771484 \n",
      "Epoch: 64920 | MAE Train Loss: 44.853599548339844 | MAE Test Loss: 43.261680603027344 \n",
      "Epoch: 64930 | MAE Train Loss: 44.853050231933594 | MAE Test Loss: 43.2614631652832 \n",
      "Epoch: 64940 | MAE Train Loss: 44.85250473022461 | MAE Test Loss: 43.261226654052734 \n",
      "Epoch: 64950 | MAE Train Loss: 44.85195541381836 | MAE Test Loss: 43.261009216308594 \n",
      "Epoch: 64960 | MAE Train Loss: 44.85140609741211 | MAE Test Loss: 43.26076126098633 \n",
      "Epoch: 64970 | MAE Train Loss: 44.85086441040039 | MAE Test Loss: 43.26054382324219 \n",
      "Epoch: 64980 | MAE Train Loss: 44.85031509399414 | MAE Test Loss: 43.26032638549805 \n",
      "Epoch: 64990 | MAE Train Loss: 44.84976577758789 | MAE Test Loss: 43.260093688964844 \n",
      "Epoch: 65000 | MAE Train Loss: 44.849220275878906 | MAE Test Loss: 43.25987243652344 \n",
      "Epoch: 65010 | MAE Train Loss: 44.84867477416992 | MAE Test Loss: 43.25965118408203 \n",
      "Epoch: 65020 | MAE Train Loss: 44.84812545776367 | MAE Test Loss: 43.2594108581543 \n",
      "Epoch: 65030 | MAE Train Loss: 44.84757614135742 | MAE Test Loss: 43.25920486450195 \n",
      "Epoch: 65040 | MAE Train Loss: 44.84702682495117 | MAE Test Loss: 43.25895309448242 \n",
      "Epoch: 65050 | MAE Train Loss: 44.846473693847656 | MAE Test Loss: 43.25873565673828 \n",
      "Epoch: 65060 | MAE Train Loss: 44.8459358215332 | MAE Test Loss: 43.25851821899414 \n",
      "Epoch: 65070 | MAE Train Loss: 44.84538650512695 | MAE Test Loss: 43.25830078125 \n",
      "Epoch: 65080 | MAE Train Loss: 44.84484100341797 | MAE Test Loss: 43.25806427001953 \n",
      "Epoch: 65090 | MAE Train Loss: 44.84429168701172 | MAE Test Loss: 43.25784683227539 \n",
      "Epoch: 65100 | MAE Train Loss: 44.84374237060547 | MAE Test Loss: 43.25762939453125 \n",
      "Epoch: 65110 | MAE Train Loss: 44.843196868896484 | MAE Test Loss: 43.25737762451172 \n",
      "Epoch: 65120 | MAE Train Loss: 44.842647552490234 | MAE Test Loss: 43.25717544555664 \n",
      "Epoch: 65130 | MAE Train Loss: 44.84210205078125 | MAE Test Loss: 43.25692367553711 \n",
      "Epoch: 65140 | MAE Train Loss: 44.841552734375 | MAE Test Loss: 43.25670623779297 \n",
      "Epoch: 65150 | MAE Train Loss: 44.841007232666016 | MAE Test Loss: 43.25648880004883 \n",
      "Epoch: 65160 | MAE Train Loss: 44.8404541015625 | MAE Test Loss: 43.25627136230469 \n",
      "Epoch: 65170 | MAE Train Loss: 44.839908599853516 | MAE Test Loss: 43.256038665771484 \n",
      "Epoch: 65180 | MAE Train Loss: 44.839359283447266 | MAE Test Loss: 43.255821228027344 \n",
      "Epoch: 65190 | MAE Train Loss: 44.83881378173828 | MAE Test Loss: 43.25556945800781 \n",
      "Epoch: 65200 | MAE Train Loss: 44.8382682800293 | MAE Test Loss: 43.25535202026367 \n",
      "Epoch: 65210 | MAE Train Loss: 44.83772277832031 | MAE Test Loss: 43.255130767822266 \n",
      "Epoch: 65220 | MAE Train Loss: 44.83717346191406 | MAE Test Loss: 43.25489807128906 \n",
      "Epoch: 65230 | MAE Train Loss: 44.83662796020508 | MAE Test Loss: 43.25468063354492 \n",
      "Epoch: 65240 | MAE Train Loss: 44.83607482910156 | MAE Test Loss: 43.25446319580078 \n",
      "Epoch: 65250 | MAE Train Loss: 44.83552932739258 | MAE Test Loss: 43.254215240478516 \n",
      "Epoch: 65260 | MAE Train Loss: 44.83498001098633 | MAE Test Loss: 43.25400924682617 \n",
      "Epoch: 65270 | MAE Train Loss: 44.83443069458008 | MAE Test Loss: 43.25375747680664 \n",
      "Epoch: 65280 | MAE Train Loss: 44.83388900756836 | MAE Test Loss: 43.2535400390625 \n",
      "Epoch: 65290 | MAE Train Loss: 44.83333969116211 | MAE Test Loss: 43.253326416015625 \n",
      "Epoch: 65300 | MAE Train Loss: 44.83279037475586 | MAE Test Loss: 43.25310516357422 \n",
      "Epoch: 65310 | MAE Train Loss: 44.832244873046875 | MAE Test Loss: 43.25286865234375 \n",
      "Epoch: 65320 | MAE Train Loss: 44.831695556640625 | MAE Test Loss: 43.252655029296875 \n",
      "Epoch: 65330 | MAE Train Loss: 44.831146240234375 | MAE Test Loss: 43.252437591552734 \n",
      "Epoch: 65340 | MAE Train Loss: 44.830604553222656 | MAE Test Loss: 43.25218963623047 \n",
      "Epoch: 65350 | MAE Train Loss: 44.83005142211914 | MAE Test Loss: 43.25197982788086 \n",
      "Epoch: 65360 | MAE Train Loss: 44.82950973510742 | MAE Test Loss: 43.251739501953125 \n",
      "Epoch: 65370 | MAE Train Loss: 44.828956604003906 | MAE Test Loss: 43.25151824951172 \n",
      "Epoch: 65380 | MAE Train Loss: 44.828407287597656 | MAE Test Loss: 43.25129699707031 \n",
      "Epoch: 65390 | MAE Train Loss: 44.82786560058594 | MAE Test Loss: 43.25107955932617 \n",
      "Epoch: 65400 | MAE Train Loss: 44.82731246948242 | MAE Test Loss: 43.25084686279297 \n",
      "Epoch: 65410 | MAE Train Loss: 44.82676696777344 | MAE Test Loss: 43.250633239746094 \n",
      "Epoch: 65420 | MAE Train Loss: 44.82621765136719 | MAE Test Loss: 43.25038146972656 \n",
      "Epoch: 65430 | MAE Train Loss: 44.8256721496582 | MAE Test Loss: 43.250160217285156 \n",
      "Epoch: 65440 | MAE Train Loss: 44.82512664794922 | MAE Test Loss: 43.24994659423828 \n",
      "Epoch: 65450 | MAE Train Loss: 44.8245849609375 | MAE Test Loss: 43.249691009521484 \n",
      "Epoch: 65460 | MAE Train Loss: 44.824058532714844 | MAE Test Loss: 43.24943923950195 \n",
      "Epoch: 65470 | MAE Train Loss: 44.82353973388672 | MAE Test Loss: 43.249149322509766 \n",
      "Epoch: 65480 | MAE Train Loss: 44.82301712036133 | MAE Test Loss: 43.24885559082031 \n",
      "Epoch: 65490 | MAE Train Loss: 44.82250213623047 | MAE Test Loss: 43.24856948852539 \n",
      "Epoch: 65500 | MAE Train Loss: 44.82197952270508 | MAE Test Loss: 43.24827575683594 \n",
      "Epoch: 65510 | MAE Train Loss: 44.82145690917969 | MAE Test Loss: 43.24799346923828 \n",
      "Epoch: 65520 | MAE Train Loss: 44.82094192504883 | MAE Test Loss: 43.247703552246094 \n",
      "Epoch: 65530 | MAE Train Loss: 44.82041931152344 | MAE Test Loss: 43.24741744995117 \n",
      "Epoch: 65540 | MAE Train Loss: 44.81989669799805 | MAE Test Loss: 43.24712371826172 \n",
      "Epoch: 65550 | MAE Train Loss: 44.819374084472656 | MAE Test Loss: 43.24684143066406 \n",
      "Epoch: 65560 | MAE Train Loss: 44.8188591003418 | MAE Test Loss: 43.246578216552734 \n",
      "Epoch: 65570 | MAE Train Loss: 44.818336486816406 | MAE Test Loss: 43.24629211425781 \n",
      "Epoch: 65580 | MAE Train Loss: 44.817813873291016 | MAE Test Loss: 43.246002197265625 \n",
      "Epoch: 65590 | MAE Train Loss: 44.817298889160156 | MAE Test Loss: 43.2457160949707 \n",
      "Epoch: 65600 | MAE Train Loss: 44.81678009033203 | MAE Test Loss: 43.24542999267578 \n",
      "Epoch: 65610 | MAE Train Loss: 44.81625747680664 | MAE Test Loss: 43.245140075683594 \n",
      "Epoch: 65620 | MAE Train Loss: 44.81573486328125 | MAE Test Loss: 43.244850158691406 \n",
      "Epoch: 65630 | MAE Train Loss: 44.815216064453125 | MAE Test Loss: 43.24457550048828 \n",
      "Epoch: 65640 | MAE Train Loss: 44.814697265625 | MAE Test Loss: 43.244285583496094 \n",
      "Epoch: 65650 | MAE Train Loss: 44.81417465209961 | MAE Test Loss: 43.24400329589844 \n",
      "Epoch: 65660 | MAE Train Loss: 44.81365966796875 | MAE Test Loss: 43.243709564208984 \n",
      "Epoch: 65670 | MAE Train Loss: 44.81313705444336 | MAE Test Loss: 43.24342346191406 \n",
      "Epoch: 65680 | MAE Train Loss: 44.81261444091797 | MAE Test Loss: 43.24313735961914 \n",
      "Epoch: 65690 | MAE Train Loss: 44.81209182739258 | MAE Test Loss: 43.24284744262695 \n",
      "Epoch: 65700 | MAE Train Loss: 44.81156921386719 | MAE Test Loss: 43.2425537109375 \n",
      "Epoch: 65710 | MAE Train Loss: 44.81105041503906 | MAE Test Loss: 43.242271423339844 \n",
      "Epoch: 65720 | MAE Train Loss: 44.81053161621094 | MAE Test Loss: 43.24201202392578 \n",
      "Epoch: 65730 | MAE Train Loss: 44.81001281738281 | MAE Test Loss: 43.241722106933594 \n",
      "Epoch: 65740 | MAE Train Loss: 44.80949401855469 | MAE Test Loss: 43.24142074584961 \n",
      "Epoch: 65750 | MAE Train Loss: 44.8089714050293 | MAE Test Loss: 43.241127014160156 \n",
      "Epoch: 65760 | MAE Train Loss: 44.808448791503906 | MAE Test Loss: 43.240840911865234 \n",
      "Epoch: 65770 | MAE Train Loss: 44.80792999267578 | MAE Test Loss: 43.24058151245117 \n",
      "Epoch: 65780 | MAE Train Loss: 44.807411193847656 | MAE Test Loss: 43.24029541015625 \n",
      "Epoch: 65790 | MAE Train Loss: 44.8068962097168 | MAE Test Loss: 43.24000549316406 \n",
      "Epoch: 65800 | MAE Train Loss: 44.80636978149414 | MAE Test Loss: 43.239723205566406 \n",
      "Epoch: 65810 | MAE Train Loss: 44.80585479736328 | MAE Test Loss: 43.23943328857422 \n",
      "Epoch: 65820 | MAE Train Loss: 44.80533218383789 | MAE Test Loss: 43.23914337158203 \n",
      "Epoch: 65830 | MAE Train Loss: 44.804813385009766 | MAE Test Loss: 43.238853454589844 \n",
      "Epoch: 65840 | MAE Train Loss: 44.804290771484375 | MAE Test Loss: 43.23855972290039 \n",
      "Epoch: 65850 | MAE Train Loss: 44.803775787353516 | MAE Test Loss: 43.238277435302734 \n",
      "Epoch: 65860 | MAE Train Loss: 44.803253173828125 | MAE Test Loss: 43.23800277709961 \n",
      "Epoch: 65870 | MAE Train Loss: 44.802734375 | MAE Test Loss: 43.23771286010742 \n",
      "Epoch: 65880 | MAE Train Loss: 44.802215576171875 | MAE Test Loss: 43.2374267578125 \n",
      "Epoch: 65890 | MAE Train Loss: 44.80168914794922 | MAE Test Loss: 43.23713302612305 \n",
      "Epoch: 65900 | MAE Train Loss: 44.80117416381836 | MAE Test Loss: 43.23685073852539 \n",
      "Epoch: 65910 | MAE Train Loss: 44.80065155029297 | MAE Test Loss: 43.23655700683594 \n",
      "Epoch: 65920 | MAE Train Loss: 44.80012893676758 | MAE Test Loss: 43.236270904541016 \n",
      "Epoch: 65930 | MAE Train Loss: 44.79961013793945 | MAE Test Loss: 43.23601150512695 \n",
      "Epoch: 65940 | MAE Train Loss: 44.79908752441406 | MAE Test Loss: 43.23572540283203 \n",
      "Epoch: 65950 | MAE Train Loss: 44.79856872558594 | MAE Test Loss: 43.23543930053711 \n",
      "Epoch: 65960 | MAE Train Loss: 44.79804992675781 | MAE Test Loss: 43.23514938354492 \n",
      "Epoch: 65970 | MAE Train Loss: 44.79752731323242 | MAE Test Loss: 43.23484420776367 \n",
      "Epoch: 65980 | MAE Train Loss: 44.7970085144043 | MAE Test Loss: 43.234588623046875 \n",
      "Epoch: 65990 | MAE Train Loss: 44.796485900878906 | MAE Test Loss: 43.23429489135742 \n",
      "Epoch: 66000 | MAE Train Loss: 44.79596710205078 | MAE Test Loss: 43.2340087890625 \n",
      "Epoch: 66010 | MAE Train Loss: 44.79545211791992 | MAE Test Loss: 43.233726501464844 \n",
      "Epoch: 66020 | MAE Train Loss: 44.79492950439453 | MAE Test Loss: 43.233428955078125 \n",
      "Epoch: 66030 | MAE Train Loss: 44.79441452026367 | MAE Test Loss: 43.23314666748047 \n",
      "Epoch: 66040 | MAE Train Loss: 44.79389190673828 | MAE Test Loss: 43.23285675048828 \n",
      "Epoch: 66050 | MAE Train Loss: 44.793373107910156 | MAE Test Loss: 43.232566833496094 \n",
      "Epoch: 66060 | MAE Train Loss: 44.792850494384766 | MAE Test Loss: 43.23228073120117 \n",
      "Epoch: 66070 | MAE Train Loss: 44.79232406616211 | MAE Test Loss: 43.23198699951172 \n",
      "Epoch: 66080 | MAE Train Loss: 44.791805267333984 | MAE Test Loss: 43.2317008972168 \n",
      "Epoch: 66090 | MAE Train Loss: 44.79128646850586 | MAE Test Loss: 43.23143005371094 \n",
      "Epoch: 66100 | MAE Train Loss: 44.790767669677734 | MAE Test Loss: 43.23114013671875 \n",
      "Epoch: 66110 | MAE Train Loss: 44.79024887084961 | MAE Test Loss: 43.2308464050293 \n",
      "Epoch: 66120 | MAE Train Loss: 44.78972625732422 | MAE Test Loss: 43.230560302734375 \n",
      "Epoch: 66130 | MAE Train Loss: 44.789207458496094 | MAE Test Loss: 43.23027420043945 \n",
      "Epoch: 66140 | MAE Train Loss: 44.7886848449707 | MAE Test Loss: 43.23002243041992 \n",
      "Epoch: 66150 | MAE Train Loss: 44.78816604614258 | MAE Test Loss: 43.229732513427734 \n",
      "Epoch: 66160 | MAE Train Loss: 44.78764724731445 | MAE Test Loss: 43.22943878173828 \n",
      "Epoch: 66170 | MAE Train Loss: 44.78712463378906 | MAE Test Loss: 43.229156494140625 \n",
      "Epoch: 66180 | MAE Train Loss: 44.7866096496582 | MAE Test Loss: 43.22886276245117 \n",
      "Epoch: 66190 | MAE Train Loss: 44.78608703613281 | MAE Test Loss: 43.228580474853516 \n",
      "Epoch: 66200 | MAE Train Loss: 44.78556442260742 | MAE Test Loss: 43.22829055786133 \n",
      "Epoch: 66210 | MAE Train Loss: 44.7850456237793 | MAE Test Loss: 43.2280158996582 \n",
      "Epoch: 66220 | MAE Train Loss: 44.78452682495117 | MAE Test Loss: 43.22771072387695 \n",
      "Epoch: 66230 | MAE Train Loss: 44.78400421142578 | MAE Test Loss: 43.2274169921875 \n",
      "Epoch: 66240 | MAE Train Loss: 44.783485412597656 | MAE Test Loss: 43.22713088989258 \n",
      "Epoch: 66250 | MAE Train Loss: 44.782962799072266 | MAE Test Loss: 43.22687530517578 \n",
      "Epoch: 66260 | MAE Train Loss: 44.78244400024414 | MAE Test Loss: 43.226585388183594 \n",
      "Epoch: 66270 | MAE Train Loss: 44.78192901611328 | MAE Test Loss: 43.22629928588867 \n",
      "Epoch: 66280 | MAE Train Loss: 44.78140640258789 | MAE Test Loss: 43.226009368896484 \n",
      "Epoch: 66290 | MAE Train Loss: 44.780887603759766 | MAE Test Loss: 43.22581100463867 \n",
      "Epoch: 66300 | MAE Train Loss: 44.780364990234375 | MAE Test Loss: 43.225669860839844 \n",
      "Epoch: 66310 | MAE Train Loss: 44.77984619140625 | MAE Test Loss: 43.225521087646484 \n",
      "Epoch: 66320 | MAE Train Loss: 44.77932357788086 | MAE Test Loss: 43.22537612915039 \n",
      "Epoch: 66330 | MAE Train Loss: 44.77880859375 | MAE Test Loss: 43.2252197265625 \n",
      "Epoch: 66340 | MAE Train Loss: 44.778282165527344 | MAE Test Loss: 43.225074768066406 \n",
      "Epoch: 66350 | MAE Train Loss: 44.77776336669922 | MAE Test Loss: 43.22492980957031 \n",
      "Epoch: 66360 | MAE Train Loss: 44.777244567871094 | MAE Test Loss: 43.22478485107422 \n",
      "Epoch: 66370 | MAE Train Loss: 44.77671813964844 | MAE Test Loss: 43.224639892578125 \n",
      "Epoch: 66380 | MAE Train Loss: 44.77620315551758 | MAE Test Loss: 43.224491119384766 \n",
      "Epoch: 66390 | MAE Train Loss: 44.77568435668945 | MAE Test Loss: 43.22434616088867 \n",
      "Epoch: 66400 | MAE Train Loss: 44.77516174316406 | MAE Test Loss: 43.224205017089844 \n",
      "Epoch: 66410 | MAE Train Loss: 44.77463912963867 | MAE Test Loss: 43.224029541015625 \n",
      "Epoch: 66420 | MAE Train Loss: 44.77412414550781 | MAE Test Loss: 43.22388458251953 \n",
      "Epoch: 66430 | MAE Train Loss: 44.77360534667969 | MAE Test Loss: 43.22373580932617 \n",
      "Epoch: 66440 | MAE Train Loss: 44.7730827331543 | MAE Test Loss: 43.22359848022461 \n",
      "Epoch: 66450 | MAE Train Loss: 44.772560119628906 | MAE Test Loss: 43.22346496582031 \n",
      "Epoch: 66460 | MAE Train Loss: 44.77204132080078 | MAE Test Loss: 43.22329330444336 \n",
      "Epoch: 66470 | MAE Train Loss: 44.77151870727539 | MAE Test Loss: 43.223140716552734 \n",
      "Epoch: 66480 | MAE Train Loss: 44.77100372314453 | MAE Test Loss: 43.22300338745117 \n",
      "Epoch: 66490 | MAE Train Loss: 44.770484924316406 | MAE Test Loss: 43.22285461425781 \n",
      "Epoch: 66500 | MAE Train Loss: 44.76996612548828 | MAE Test Loss: 43.22270965576172 \n",
      "Epoch: 66510 | MAE Train Loss: 44.76944351196289 | MAE Test Loss: 43.222564697265625 \n",
      "Epoch: 66520 | MAE Train Loss: 44.7689208984375 | MAE Test Loss: 43.22241973876953 \n",
      "Epoch: 66530 | MAE Train Loss: 44.76839828491211 | MAE Test Loss: 43.22227478027344 \n",
      "Epoch: 66540 | MAE Train Loss: 44.76787567138672 | MAE Test Loss: 43.222129821777344 \n",
      "Epoch: 66550 | MAE Train Loss: 44.76736068725586 | MAE Test Loss: 43.221988677978516 \n",
      "Epoch: 66560 | MAE Train Loss: 44.76683807373047 | MAE Test Loss: 43.22182083129883 \n",
      "Epoch: 66570 | MAE Train Loss: 44.76632308959961 | MAE Test Loss: 43.221683502197266 \n",
      "Epoch: 66580 | MAE Train Loss: 44.76580047607422 | MAE Test Loss: 43.221534729003906 \n",
      "Epoch: 66590 | MAE Train Loss: 44.76527786254883 | MAE Test Loss: 43.22138977050781 \n",
      "Epoch: 66600 | MAE Train Loss: 44.76475524902344 | MAE Test Loss: 43.221248626708984 \n",
      "Epoch: 66610 | MAE Train Loss: 44.76423645019531 | MAE Test Loss: 43.221099853515625 \n",
      "Epoch: 66620 | MAE Train Loss: 44.76371765136719 | MAE Test Loss: 43.220924377441406 \n",
      "Epoch: 66630 | MAE Train Loss: 44.76320266723633 | MAE Test Loss: 43.22078323364258 \n",
      "Epoch: 66640 | MAE Train Loss: 44.76268005371094 | MAE Test Loss: 43.22064208984375 \n",
      "Epoch: 66650 | MAE Train Loss: 44.76215744018555 | MAE Test Loss: 43.22049331665039 \n",
      "Epoch: 66660 | MAE Train Loss: 44.76164245605469 | MAE Test Loss: 43.2203483581543 \n",
      "Epoch: 66670 | MAE Train Loss: 44.7611198425293 | MAE Test Loss: 43.2202033996582 \n",
      "Epoch: 66680 | MAE Train Loss: 44.76060104370117 | MAE Test Loss: 43.22004318237305 \n",
      "Epoch: 66690 | MAE Train Loss: 44.760074615478516 | MAE Test Loss: 43.21989822387695 \n",
      "Epoch: 66700 | MAE Train Loss: 44.759559631347656 | MAE Test Loss: 43.21975326538086 \n",
      "Epoch: 66710 | MAE Train Loss: 44.75904083251953 | MAE Test Loss: 43.219608306884766 \n",
      "Epoch: 66720 | MAE Train Loss: 44.75851821899414 | MAE Test Loss: 43.219459533691406 \n",
      "Epoch: 66730 | MAE Train Loss: 44.75799560546875 | MAE Test Loss: 43.21931838989258 \n",
      "Epoch: 66740 | MAE Train Loss: 44.757476806640625 | MAE Test Loss: 43.219173431396484 \n",
      "Epoch: 66750 | MAE Train Loss: 44.756954193115234 | MAE Test Loss: 43.21902847290039 \n",
      "Epoch: 66760 | MAE Train Loss: 44.75643539428711 | MAE Test Loss: 43.21888732910156 \n",
      "Epoch: 66770 | MAE Train Loss: 44.755916595458984 | MAE Test Loss: 43.2187385559082 \n",
      "Epoch: 66780 | MAE Train Loss: 44.755393981933594 | MAE Test Loss: 43.21856689453125 \n",
      "Epoch: 66790 | MAE Train Loss: 44.75487518310547 | MAE Test Loss: 43.21841812133789 \n",
      "Epoch: 66800 | MAE Train Loss: 44.754356384277344 | MAE Test Loss: 43.21828842163086 \n",
      "Epoch: 66810 | MAE Train Loss: 44.75383377075195 | MAE Test Loss: 43.21814727783203 \n",
      "Epoch: 66820 | MAE Train Loss: 44.75331497192383 | MAE Test Loss: 43.21800231933594 \n",
      "Epoch: 66830 | MAE Train Loss: 44.75279235839844 | MAE Test Loss: 43.21782302856445 \n",
      "Epoch: 66840 | MAE Train Loss: 44.75227355957031 | MAE Test Loss: 43.21767807006836 \n",
      "Epoch: 66850 | MAE Train Loss: 44.75175857543945 | MAE Test Loss: 43.21753692626953 \n",
      "Epoch: 66860 | MAE Train Loss: 44.7512321472168 | MAE Test Loss: 43.21738815307617 \n",
      "Epoch: 66870 | MAE Train Loss: 44.75071334838867 | MAE Test Loss: 43.21724319458008 \n",
      "Epoch: 66880 | MAE Train Loss: 44.75019454956055 | MAE Test Loss: 43.21710205078125 \n",
      "Epoch: 66890 | MAE Train Loss: 44.749671936035156 | MAE Test Loss: 43.216957092285156 \n",
      "Epoch: 66900 | MAE Train Loss: 44.7491569519043 | MAE Test Loss: 43.21681213378906 \n",
      "Epoch: 66910 | MAE Train Loss: 44.748634338378906 | MAE Test Loss: 43.21664810180664 \n",
      "Epoch: 66920 | MAE Train Loss: 44.74811935424805 | MAE Test Loss: 43.21650695800781 \n",
      "Epoch: 66930 | MAE Train Loss: 44.74759292602539 | MAE Test Loss: 43.21636199951172 \n",
      "Epoch: 66940 | MAE Train Loss: 44.747074127197266 | MAE Test Loss: 43.216217041015625 \n",
      "Epoch: 66950 | MAE Train Loss: 44.746559143066406 | MAE Test Loss: 43.21607208251953 \n",
      "Epoch: 66960 | MAE Train Loss: 44.746028900146484 | MAE Test Loss: 43.2159309387207 \n",
      "Epoch: 66970 | MAE Train Loss: 44.745513916015625 | MAE Test Loss: 43.21578598022461 \n",
      "Epoch: 66980 | MAE Train Loss: 44.744991302490234 | MAE Test Loss: 43.215641021728516 \n",
      "Epoch: 66990 | MAE Train Loss: 44.74447250366211 | MAE Test Loss: 43.2154655456543 \n",
      "Epoch: 67000 | MAE Train Loss: 44.743953704833984 | MAE Test Loss: 43.21531677246094 \n",
      "Epoch: 67010 | MAE Train Loss: 44.743431091308594 | MAE Test Loss: 43.215171813964844 \n",
      "Epoch: 67020 | MAE Train Loss: 44.74291229248047 | MAE Test Loss: 43.215030670166016 \n",
      "Epoch: 67030 | MAE Train Loss: 44.742393493652344 | MAE Test Loss: 43.21489715576172 \n",
      "Epoch: 67040 | MAE Train Loss: 44.74187469482422 | MAE Test Loss: 43.21474075317383 \n",
      "Epoch: 67050 | MAE Train Loss: 44.741355895996094 | MAE Test Loss: 43.214595794677734 \n",
      "Epoch: 67060 | MAE Train Loss: 44.74082946777344 | MAE Test Loss: 43.214447021484375 \n",
      "Epoch: 67070 | MAE Train Loss: 44.74031066894531 | MAE Test Loss: 43.21430206298828 \n",
      "Epoch: 67080 | MAE Train Loss: 44.73979187011719 | MAE Test Loss: 43.21415710449219 \n",
      "Epoch: 67090 | MAE Train Loss: 44.73926544189453 | MAE Test Loss: 43.21398162841797 \n",
      "Epoch: 67100 | MAE Train Loss: 44.73875045776367 | MAE Test Loss: 43.21384048461914 \n",
      "Epoch: 67110 | MAE Train Loss: 44.73822784423828 | MAE Test Loss: 43.21369552612305 \n",
      "Epoch: 67120 | MAE Train Loss: 44.73771286010742 | MAE Test Loss: 43.21355056762695 \n",
      "Epoch: 67130 | MAE Train Loss: 44.73719024658203 | MAE Test Loss: 43.213401794433594 \n",
      "Epoch: 67140 | MAE Train Loss: 44.736671447753906 | MAE Test Loss: 43.213260650634766 \n",
      "Epoch: 67150 | MAE Train Loss: 44.73615264892578 | MAE Test Loss: 43.21311569213867 \n",
      "Epoch: 67160 | MAE Train Loss: 44.73563003540039 | MAE Test Loss: 43.212955474853516 \n",
      "Epoch: 67170 | MAE Train Loss: 44.735111236572266 | MAE Test Loss: 43.212806701660156 \n",
      "Epoch: 67180 | MAE Train Loss: 44.734588623046875 | MAE Test Loss: 43.21266555786133 \n",
      "Epoch: 67190 | MAE Train Loss: 44.73406982421875 | MAE Test Loss: 43.2125244140625 \n",
      "Epoch: 67200 | MAE Train Loss: 44.733551025390625 | MAE Test Loss: 43.21237564086914 \n",
      "Epoch: 67210 | MAE Train Loss: 44.7330322265625 | MAE Test Loss: 43.21223068237305 \n",
      "Epoch: 67220 | MAE Train Loss: 44.732505798339844 | MAE Test Loss: 43.21208572387695 \n",
      "Epoch: 67230 | MAE Train Loss: 44.73198699951172 | MAE Test Loss: 43.21194076538086 \n",
      "Epoch: 67240 | MAE Train Loss: 44.73147201538086 | MAE Test Loss: 43.211795806884766 \n",
      "Epoch: 67250 | MAE Train Loss: 44.7309455871582 | MAE Test Loss: 43.21162414550781 \n",
      "Epoch: 67260 | MAE Train Loss: 44.73042678833008 | MAE Test Loss: 43.21147537231445 \n",
      "Epoch: 67270 | MAE Train Loss: 44.72991180419922 | MAE Test Loss: 43.211341857910156 \n",
      "Epoch: 67280 | MAE Train Loss: 44.72938537597656 | MAE Test Loss: 43.21120071411133 \n",
      "Epoch: 67290 | MAE Train Loss: 44.72886276245117 | MAE Test Loss: 43.2110595703125 \n",
      "Epoch: 67300 | MAE Train Loss: 44.72834777832031 | MAE Test Loss: 43.21088409423828 \n",
      "Epoch: 67310 | MAE Train Loss: 44.72782897949219 | MAE Test Loss: 43.21073913574219 \n",
      "Epoch: 67320 | MAE Train Loss: 44.72731018066406 | MAE Test Loss: 43.21059036254883 \n",
      "Epoch: 67330 | MAE Train Loss: 44.72679138183594 | MAE Test Loss: 43.210445404052734 \n",
      "Epoch: 67340 | MAE Train Loss: 44.72626876831055 | MAE Test Loss: 43.21030044555664 \n",
      "Epoch: 67350 | MAE Train Loss: 44.725746154785156 | MAE Test Loss: 43.21015930175781 \n",
      "Epoch: 67360 | MAE Train Loss: 44.72522735595703 | MAE Test Loss: 43.21001052856445 \n",
      "Epoch: 67370 | MAE Train Loss: 44.72470474243164 | MAE Test Loss: 43.209869384765625 \n",
      "Epoch: 67380 | MAE Train Loss: 44.72418212890625 | MAE Test Loss: 43.20972442626953 \n",
      "Epoch: 67390 | MAE Train Loss: 44.72366714477539 | MAE Test Loss: 43.209564208984375 \n",
      "Epoch: 67400 | MAE Train Loss: 44.723148345947266 | MAE Test Loss: 43.20941925048828 \n",
      "Epoch: 67410 | MAE Train Loss: 44.722625732421875 | MAE Test Loss: 43.20927047729492 \n",
      "Epoch: 67420 | MAE Train Loss: 44.72210693359375 | MAE Test Loss: 43.209129333496094 \n",
      "Epoch: 67430 | MAE Train Loss: 44.721588134765625 | MAE Test Loss: 43.208984375 \n",
      "Epoch: 67440 | MAE Train Loss: 44.721065521240234 | MAE Test Loss: 43.208839416503906 \n",
      "Epoch: 67450 | MAE Train Loss: 44.72054672241211 | MAE Test Loss: 43.20869445800781 \n",
      "Epoch: 67460 | MAE Train Loss: 44.72002410888672 | MAE Test Loss: 43.208518981933594 \n",
      "Epoch: 67470 | MAE Train Loss: 44.719505310058594 | MAE Test Loss: 43.2083740234375 \n",
      "Epoch: 67480 | MAE Train Loss: 44.71898651123047 | MAE Test Loss: 43.208229064941406 \n",
      "Epoch: 67490 | MAE Train Loss: 44.718467712402344 | MAE Test Loss: 43.20808410644531 \n",
      "Epoch: 67500 | MAE Train Loss: 44.71794128417969 | MAE Test Loss: 43.20795440673828 \n",
      "Epoch: 67510 | MAE Train Loss: 44.71742630004883 | MAE Test Loss: 43.20777893066406 \n",
      "Epoch: 67520 | MAE Train Loss: 44.71690368652344 | MAE Test Loss: 43.20763397216797 \n",
      "Epoch: 67530 | MAE Train Loss: 44.71638488769531 | MAE Test Loss: 43.20748519897461 \n",
      "Epoch: 67540 | MAE Train Loss: 44.71586608886719 | MAE Test Loss: 43.20734405517578 \n",
      "Epoch: 67550 | MAE Train Loss: 44.71534729003906 | MAE Test Loss: 43.20720291137695 \n",
      "Epoch: 67560 | MAE Train Loss: 44.71483612060547 | MAE Test Loss: 43.207027435302734 \n",
      "Epoch: 67570 | MAE Train Loss: 44.714351654052734 | MAE Test Loss: 43.20682144165039 \n",
      "Epoch: 67580 | MAE Train Loss: 44.713863372802734 | MAE Test Loss: 43.206626892089844 \n",
      "Epoch: 67590 | MAE Train Loss: 44.713382720947266 | MAE Test Loss: 43.20643615722656 \n",
      "Epoch: 67600 | MAE Train Loss: 44.71290588378906 | MAE Test Loss: 43.20623779296875 \n",
      "Epoch: 67610 | MAE Train Loss: 44.71242141723633 | MAE Test Loss: 43.2060432434082 \n",
      "Epoch: 67620 | MAE Train Loss: 44.71192932128906 | MAE Test Loss: 43.20582580566406 \n",
      "Epoch: 67630 | MAE Train Loss: 44.711448669433594 | MAE Test Loss: 43.20562744140625 \n",
      "Epoch: 67640 | MAE Train Loss: 44.71096420288086 | MAE Test Loss: 43.2054328918457 \n",
      "Epoch: 67650 | MAE Train Loss: 44.710479736328125 | MAE Test Loss: 43.205223083496094 \n",
      "Epoch: 67660 | MAE Train Loss: 44.709999084472656 | MAE Test Loss: 43.20503234863281 \n",
      "Epoch: 67670 | MAE Train Loss: 44.70952224731445 | MAE Test Loss: 43.204837799072266 \n",
      "Epoch: 67680 | MAE Train Loss: 44.70903778076172 | MAE Test Loss: 43.20464324951172 \n",
      "Epoch: 67690 | MAE Train Loss: 44.708553314208984 | MAE Test Loss: 43.20444869995117 \n",
      "Epoch: 67700 | MAE Train Loss: 44.708065032958984 | MAE Test Loss: 43.20423126220703 \n",
      "Epoch: 67710 | MAE Train Loss: 44.707584381103516 | MAE Test Loss: 43.20402908325195 \n",
      "Epoch: 67720 | MAE Train Loss: 44.707096099853516 | MAE Test Loss: 43.203853607177734 \n",
      "Epoch: 67730 | MAE Train Loss: 44.70661544799805 | MAE Test Loss: 43.203636169433594 \n",
      "Epoch: 67740 | MAE Train Loss: 44.70613098144531 | MAE Test Loss: 43.20343780517578 \n",
      "Epoch: 67750 | MAE Train Loss: 44.70564651489258 | MAE Test Loss: 43.203243255615234 \n",
      "Epoch: 67760 | MAE Train Loss: 44.70516586303711 | MAE Test Loss: 43.20305252075195 \n",
      "Epoch: 67770 | MAE Train Loss: 44.704681396484375 | MAE Test Loss: 43.202857971191406 \n",
      "Epoch: 67780 | MAE Train Loss: 44.70419692993164 | MAE Test Loss: 43.20263671875 \n",
      "Epoch: 67790 | MAE Train Loss: 44.70371627807617 | MAE Test Loss: 43.202457427978516 \n",
      "Epoch: 67800 | MAE Train Loss: 44.70323181152344 | MAE Test Loss: 43.202232360839844 \n",
      "Epoch: 67810 | MAE Train Loss: 44.70275115966797 | MAE Test Loss: 43.2020378112793 \n",
      "Epoch: 67820 | MAE Train Loss: 44.702274322509766 | MAE Test Loss: 43.201847076416016 \n",
      "Epoch: 67830 | MAE Train Loss: 44.701786041259766 | MAE Test Loss: 43.20165252685547 \n",
      "Epoch: 67840 | MAE Train Loss: 44.701297760009766 | MAE Test Loss: 43.20145797729492 \n",
      "Epoch: 67850 | MAE Train Loss: 44.7008171081543 | MAE Test Loss: 43.201263427734375 \n",
      "Epoch: 67860 | MAE Train Loss: 44.70033264160156 | MAE Test Loss: 43.20104217529297 \n",
      "Epoch: 67870 | MAE Train Loss: 44.699851989746094 | MAE Test Loss: 43.20084762573242 \n",
      "Epoch: 67880 | MAE Train Loss: 44.699363708496094 | MAE Test Loss: 43.20063781738281 \n",
      "Epoch: 67890 | MAE Train Loss: 44.698883056640625 | MAE Test Loss: 43.200443267822266 \n",
      "Epoch: 67900 | MAE Train Loss: 44.69839859008789 | MAE Test Loss: 43.20024871826172 \n",
      "Epoch: 67910 | MAE Train Loss: 44.69792175292969 | MAE Test Loss: 43.20005416870117 \n",
      "Epoch: 67920 | MAE Train Loss: 44.69743347167969 | MAE Test Loss: 43.19986343383789 \n",
      "Epoch: 67930 | MAE Train Loss: 44.69694900512695 | MAE Test Loss: 43.19963455200195 \n",
      "Epoch: 67940 | MAE Train Loss: 44.696468353271484 | MAE Test Loss: 43.199459075927734 \n",
      "Epoch: 67950 | MAE Train Loss: 44.69598388671875 | MAE Test Loss: 43.19926834106445 \n",
      "Epoch: 67960 | MAE Train Loss: 44.695499420166016 | MAE Test Loss: 43.19904708862305 \n",
      "Epoch: 67970 | MAE Train Loss: 44.69501495361328 | MAE Test Loss: 43.1988525390625 \n",
      "Epoch: 67980 | MAE Train Loss: 44.69453430175781 | MAE Test Loss: 43.19865798950195 \n",
      "Epoch: 67990 | MAE Train Loss: 44.694053649902344 | MAE Test Loss: 43.198463439941406 \n",
      "Epoch: 68000 | MAE Train Loss: 44.693565368652344 | MAE Test Loss: 43.198265075683594 \n",
      "Epoch: 68010 | MAE Train Loss: 44.69308090209961 | MAE Test Loss: 43.19804382324219 \n",
      "Epoch: 68020 | MAE Train Loss: 44.69260025024414 | MAE Test Loss: 43.197853088378906 \n",
      "Epoch: 68030 | MAE Train Loss: 44.692115783691406 | MAE Test Loss: 43.197669982910156 \n",
      "Epoch: 68040 | MAE Train Loss: 44.691627502441406 | MAE Test Loss: 43.19744873046875 \n",
      "Epoch: 68050 | MAE Train Loss: 44.6911506652832 | MAE Test Loss: 43.1972541809082 \n",
      "Epoch: 68060 | MAE Train Loss: 44.690670013427734 | MAE Test Loss: 43.19706344604492 \n",
      "Epoch: 68070 | MAE Train Loss: 44.690181732177734 | MAE Test Loss: 43.196868896484375 \n",
      "Epoch: 68080 | MAE Train Loss: 44.689701080322266 | MAE Test Loss: 43.19667434692383 \n",
      "Epoch: 68090 | MAE Train Loss: 44.68921661376953 | MAE Test Loss: 43.196449279785156 \n",
      "Epoch: 68100 | MAE Train Loss: 44.68873596191406 | MAE Test Loss: 43.19626998901367 \n",
      "Epoch: 68110 | MAE Train Loss: 44.68824768066406 | MAE Test Loss: 43.196048736572266 \n",
      "Epoch: 68120 | MAE Train Loss: 44.687767028808594 | MAE Test Loss: 43.19585418701172 \n",
      "Epoch: 68130 | MAE Train Loss: 44.68728256225586 | MAE Test Loss: 43.19566345214844 \n",
      "Epoch: 68140 | MAE Train Loss: 44.68680191040039 | MAE Test Loss: 43.195472717285156 \n",
      "Epoch: 68150 | MAE Train Loss: 44.686317443847656 | MAE Test Loss: 43.19527053833008 \n",
      "Epoch: 68160 | MAE Train Loss: 44.68583297729492 | MAE Test Loss: 43.19507598876953 \n",
      "Epoch: 68170 | MAE Train Loss: 44.68535232543945 | MAE Test Loss: 43.19485855102539 \n",
      "Epoch: 68180 | MAE Train Loss: 44.68486785888672 | MAE Test Loss: 43.194664001464844 \n",
      "Epoch: 68190 | MAE Train Loss: 44.684383392333984 | MAE Test Loss: 43.19445037841797 \n",
      "Epoch: 68200 | MAE Train Loss: 44.68389892578125 | MAE Test Loss: 43.19426345825195 \n",
      "Epoch: 68210 | MAE Train Loss: 44.68341827392578 | MAE Test Loss: 43.194068908691406 \n",
      "Epoch: 68220 | MAE Train Loss: 44.68293380737305 | MAE Test Loss: 43.193870544433594 \n",
      "Epoch: 68230 | MAE Train Loss: 44.68244934082031 | MAE Test Loss: 43.19367599487305 \n",
      "Epoch: 68240 | MAE Train Loss: 44.681968688964844 | MAE Test Loss: 43.193458557128906 \n",
      "Epoch: 68250 | MAE Train Loss: 44.68148422241211 | MAE Test Loss: 43.19327926635742 \n",
      "Epoch: 68260 | MAE Train Loss: 44.68099594116211 | MAE Test Loss: 43.19308090209961 \n",
      "Epoch: 68270 | MAE Train Loss: 44.680511474609375 | MAE Test Loss: 43.1928596496582 \n",
      "Epoch: 68280 | MAE Train Loss: 44.680030822753906 | MAE Test Loss: 43.19266891479492 \n",
      "Epoch: 68290 | MAE Train Loss: 44.67955017089844 | MAE Test Loss: 43.192474365234375 \n",
      "Epoch: 68300 | MAE Train Loss: 44.67906951904297 | MAE Test Loss: 43.19227981567383 \n",
      "Epoch: 68310 | MAE Train Loss: 44.67858123779297 | MAE Test Loss: 43.192081451416016 \n",
      "Epoch: 68320 | MAE Train Loss: 44.6781005859375 | MAE Test Loss: 43.19186019897461 \n",
      "Epoch: 68330 | MAE Train Loss: 44.677616119384766 | MAE Test Loss: 43.19166946411133 \n",
      "Epoch: 68340 | MAE Train Loss: 44.6771354675293 | MAE Test Loss: 43.191490173339844 \n",
      "Epoch: 68350 | MAE Train Loss: 44.67665100097656 | MAE Test Loss: 43.19126510620117 \n",
      "Epoch: 68360 | MAE Train Loss: 44.67616653442383 | MAE Test Loss: 43.191070556640625 \n",
      "Epoch: 68370 | MAE Train Loss: 44.67568588256836 | MAE Test Loss: 43.190879821777344 \n",
      "Epoch: 68380 | MAE Train Loss: 44.675201416015625 | MAE Test Loss: 43.19068908691406 \n",
      "Epoch: 68390 | MAE Train Loss: 44.674713134765625 | MAE Test Loss: 43.190494537353516 \n",
      "Epoch: 68400 | MAE Train Loss: 44.674232482910156 | MAE Test Loss: 43.190269470214844 \n",
      "Epoch: 68410 | MAE Train Loss: 44.67375183105469 | MAE Test Loss: 43.190086364746094 \n",
      "Epoch: 68420 | MAE Train Loss: 44.67326354980469 | MAE Test Loss: 43.18986892700195 \n",
      "Epoch: 68430 | MAE Train Loss: 44.67278289794922 | MAE Test Loss: 43.18967819213867 \n",
      "Epoch: 68440 | MAE Train Loss: 44.67230224609375 | MAE Test Loss: 43.189476013183594 \n",
      "Epoch: 68450 | MAE Train Loss: 44.671817779541016 | MAE Test Loss: 43.18928146362305 \n",
      "Epoch: 68460 | MAE Train Loss: 44.671329498291016 | MAE Test Loss: 43.189090728759766 \n",
      "Epoch: 68470 | MAE Train Loss: 44.67084884643555 | MAE Test Loss: 43.188934326171875 \n",
      "Epoch: 68480 | MAE Train Loss: 44.670387268066406 | MAE Test Loss: 43.18876266479492 \n",
      "Epoch: 68490 | MAE Train Loss: 44.669925689697266 | MAE Test Loss: 43.18862533569336 \n",
      "Epoch: 68500 | MAE Train Loss: 44.669464111328125 | MAE Test Loss: 43.18852615356445 \n",
      "Epoch: 68510 | MAE Train Loss: 44.66900634765625 | MAE Test Loss: 43.188385009765625 \n",
      "Epoch: 68520 | MAE Train Loss: 44.66853713989258 | MAE Test Loss: 43.18824768066406 \n",
      "Epoch: 68530 | MAE Train Loss: 44.66808319091797 | MAE Test Loss: 43.188148498535156 \n",
      "Epoch: 68540 | MAE Train Loss: 44.66761779785156 | MAE Test Loss: 43.18800354003906 \n",
      "Epoch: 68550 | MAE Train Loss: 44.66716003417969 | MAE Test Loss: 43.18787384033203 \n",
      "Epoch: 68560 | MAE Train Loss: 44.66669464111328 | MAE Test Loss: 43.187767028808594 \n",
      "Epoch: 68570 | MAE Train Loss: 44.666236877441406 | MAE Test Loss: 43.1876335144043 \n",
      "Epoch: 68580 | MAE Train Loss: 44.665775299072266 | MAE Test Loss: 43.187496185302734 \n",
      "Epoch: 68590 | MAE Train Loss: 44.665306091308594 | MAE Test Loss: 43.18739318847656 \n",
      "Epoch: 68600 | MAE Train Loss: 44.664852142333984 | MAE Test Loss: 43.187252044677734 \n",
      "Epoch: 68610 | MAE Train Loss: 44.664390563964844 | MAE Test Loss: 43.18711853027344 \n",
      "Epoch: 68620 | MAE Train Loss: 44.66392517089844 | MAE Test Loss: 43.187015533447266 \n",
      "Epoch: 68630 | MAE Train Loss: 44.66346740722656 | MAE Test Loss: 43.1868782043457 \n",
      "Epoch: 68640 | MAE Train Loss: 44.66300964355469 | MAE Test Loss: 43.18674087524414 \n",
      "Epoch: 68650 | MAE Train Loss: 44.662540435791016 | MAE Test Loss: 43.186607360839844 \n",
      "Epoch: 68660 | MAE Train Loss: 44.66208267211914 | MAE Test Loss: 43.186500549316406 \n",
      "Epoch: 68670 | MAE Train Loss: 44.661624908447266 | MAE Test Loss: 43.186370849609375 \n",
      "Epoch: 68680 | MAE Train Loss: 44.66115951538086 | MAE Test Loss: 43.18622970581055 \n",
      "Epoch: 68690 | MAE Train Loss: 44.660701751708984 | MAE Test Loss: 43.186126708984375 \n",
      "Epoch: 68700 | MAE Train Loss: 44.660240173339844 | MAE Test Loss: 43.18598937988281 \n",
      "Epoch: 68710 | MAE Train Loss: 44.65977478027344 | MAE Test Loss: 43.18585205078125 \n",
      "Epoch: 68720 | MAE Train Loss: 44.6593132019043 | MAE Test Loss: 43.185752868652344 \n",
      "Epoch: 68730 | MAE Train Loss: 44.65885543823242 | MAE Test Loss: 43.185611724853516 \n",
      "Epoch: 68740 | MAE Train Loss: 44.658390045166016 | MAE Test Loss: 43.18547821044922 \n",
      "Epoch: 68750 | MAE Train Loss: 44.65793228149414 | MAE Test Loss: 43.18537902832031 \n",
      "Epoch: 68760 | MAE Train Loss: 44.657474517822266 | MAE Test Loss: 43.185237884521484 \n",
      "Epoch: 68770 | MAE Train Loss: 44.65700912475586 | MAE Test Loss: 43.185096740722656 \n",
      "Epoch: 68780 | MAE Train Loss: 44.65654754638672 | MAE Test Loss: 43.185001373291016 \n",
      "Epoch: 68790 | MAE Train Loss: 44.65608596801758 | MAE Test Loss: 43.184879302978516 \n",
      "Epoch: 68800 | MAE Train Loss: 44.6556282043457 | MAE Test Loss: 43.18474197387695 \n",
      "Epoch: 68810 | MAE Train Loss: 44.6551628112793 | MAE Test Loss: 43.184608459472656 \n",
      "Epoch: 68820 | MAE Train Loss: 44.654693603515625 | MAE Test Loss: 43.18450164794922 \n",
      "Epoch: 68830 | MAE Train Loss: 44.65423583984375 | MAE Test Loss: 43.18436813354492 \n",
      "Epoch: 68840 | MAE Train Loss: 44.653778076171875 | MAE Test Loss: 43.184226989746094 \n",
      "Epoch: 68850 | MAE Train Loss: 44.653316497802734 | MAE Test Loss: 43.18408966064453 \n",
      "Epoch: 68860 | MAE Train Loss: 44.65285873413086 | MAE Test Loss: 43.183990478515625 \n",
      "Epoch: 68870 | MAE Train Loss: 44.652400970458984 | MAE Test Loss: 43.18385314941406 \n",
      "Epoch: 68880 | MAE Train Loss: 44.65193557739258 | MAE Test Loss: 43.1837158203125 \n",
      "Epoch: 68890 | MAE Train Loss: 44.65147399902344 | MAE Test Loss: 43.18360900878906 \n",
      "Epoch: 68900 | MAE Train Loss: 44.6510124206543 | MAE Test Loss: 43.18347930908203 \n",
      "Epoch: 68910 | MAE Train Loss: 44.65054702758789 | MAE Test Loss: 43.1833381652832 \n",
      "Epoch: 68920 | MAE Train Loss: 44.650089263916016 | MAE Test Loss: 43.18324279785156 \n",
      "Epoch: 68930 | MAE Train Loss: 44.649627685546875 | MAE Test Loss: 43.18309783935547 \n",
      "Epoch: 68940 | MAE Train Loss: 44.64916229248047 | MAE Test Loss: 43.18296432495117 \n",
      "Epoch: 68950 | MAE Train Loss: 44.648704528808594 | MAE Test Loss: 43.182857513427734 \n",
      "Epoch: 68960 | MAE Train Loss: 44.64824295043945 | MAE Test Loss: 43.1827278137207 \n",
      "Epoch: 68970 | MAE Train Loss: 44.64777755737305 | MAE Test Loss: 43.18259048461914 \n",
      "Epoch: 68980 | MAE Train Loss: 44.64731979370117 | MAE Test Loss: 43.18248748779297 \n",
      "Epoch: 68990 | MAE Train Loss: 44.6468620300293 | MAE Test Loss: 43.182350158691406 \n",
      "Epoch: 69000 | MAE Train Loss: 44.646392822265625 | MAE Test Loss: 43.182212829589844 \n",
      "Epoch: 69010 | MAE Train Loss: 44.64593505859375 | MAE Test Loss: 43.18210983276367 \n",
      "Epoch: 69020 | MAE Train Loss: 44.64548110961914 | MAE Test Loss: 43.181976318359375 \n",
      "Epoch: 69030 | MAE Train Loss: 44.645015716552734 | MAE Test Loss: 43.18183898925781 \n",
      "Epoch: 69040 | MAE Train Loss: 44.644554138183594 | MAE Test Loss: 43.181732177734375 \n",
      "Epoch: 69050 | MAE Train Loss: 44.64409255981445 | MAE Test Loss: 43.18159484863281 \n",
      "Epoch: 69060 | MAE Train Loss: 44.64363098144531 | MAE Test Loss: 43.18147277832031 \n",
      "Epoch: 69070 | MAE Train Loss: 44.643165588378906 | MAE Test Loss: 43.181339263916016 \n",
      "Epoch: 69080 | MAE Train Loss: 44.642704010009766 | MAE Test Loss: 43.18120574951172 \n",
      "Epoch: 69090 | MAE Train Loss: 44.64224624633789 | MAE Test Loss: 43.18110275268555 \n",
      "Epoch: 69100 | MAE Train Loss: 44.641788482666016 | MAE Test Loss: 43.18096160888672 \n",
      "Epoch: 69110 | MAE Train Loss: 44.641319274902344 | MAE Test Loss: 43.18083190917969 \n",
      "Epoch: 69120 | MAE Train Loss: 44.64086151123047 | MAE Test Loss: 43.18072509765625 \n",
      "Epoch: 69130 | MAE Train Loss: 44.64039993286133 | MAE Test Loss: 43.18058776855469 \n",
      "Epoch: 69140 | MAE Train Loss: 44.63993835449219 | MAE Test Loss: 43.180450439453125 \n",
      "Epoch: 69150 | MAE Train Loss: 44.63948059082031 | MAE Test Loss: 43.18034744262695 \n",
      "Epoch: 69160 | MAE Train Loss: 44.63901901245117 | MAE Test Loss: 43.18021011352539 \n",
      "Epoch: 69170 | MAE Train Loss: 44.638553619384766 | MAE Test Loss: 43.180076599121094 \n",
      "Epoch: 69180 | MAE Train Loss: 44.638092041015625 | MAE Test Loss: 43.17997360229492 \n",
      "Epoch: 69190 | MAE Train Loss: 44.63763427734375 | MAE Test Loss: 43.17983627319336 \n",
      "Epoch: 69200 | MAE Train Loss: 44.637168884277344 | MAE Test Loss: 43.1796989440918 \n",
      "Epoch: 69210 | MAE Train Loss: 44.63671112060547 | MAE Test Loss: 43.179595947265625 \n",
      "Epoch: 69220 | MAE Train Loss: 44.63624954223633 | MAE Test Loss: 43.17945861816406 \n",
      "Epoch: 69230 | MAE Train Loss: 44.63578414916992 | MAE Test Loss: 43.1793212890625 \n",
      "Epoch: 69240 | MAE Train Loss: 44.63532257080078 | MAE Test Loss: 43.179222106933594 \n",
      "Epoch: 69250 | MAE Train Loss: 44.63486862182617 | MAE Test Loss: 43.17908477783203 \n",
      "Epoch: 69260 | MAE Train Loss: 44.634403228759766 | MAE Test Loss: 43.1789436340332 \n",
      "Epoch: 69270 | MAE Train Loss: 44.633941650390625 | MAE Test Loss: 43.1788444519043 \n",
      "Epoch: 69280 | MAE Train Loss: 44.633487701416016 | MAE Test Loss: 43.178707122802734 \n",
      "Epoch: 69290 | MAE Train Loss: 44.633018493652344 | MAE Test Loss: 43.17856979370117 \n",
      "Epoch: 69300 | MAE Train Loss: 44.6325569152832 | MAE Test Loss: 43.178462982177734 \n",
      "Epoch: 69310 | MAE Train Loss: 44.63209533691406 | MAE Test Loss: 43.1783332824707 \n",
      "Epoch: 69320 | MAE Train Loss: 44.63163757324219 | MAE Test Loss: 43.1782112121582 \n",
      "Epoch: 69330 | MAE Train Loss: 44.63117599487305 | MAE Test Loss: 43.17807388305664 \n",
      "Epoch: 69340 | MAE Train Loss: 44.630714416503906 | MAE Test Loss: 43.17793655395508 \n",
      "Epoch: 69350 | MAE Train Loss: 44.6302490234375 | MAE Test Loss: 43.177833557128906 \n",
      "Epoch: 69360 | MAE Train Loss: 44.629791259765625 | MAE Test Loss: 43.177696228027344 \n",
      "Epoch: 69370 | MAE Train Loss: 44.62932586669922 | MAE Test Loss: 43.17756271362305 \n",
      "Epoch: 69380 | MAE Train Loss: 44.628868103027344 | MAE Test Loss: 43.177459716796875 \n",
      "Epoch: 69390 | MAE Train Loss: 44.6284065246582 | MAE Test Loss: 43.17731857299805 \n",
      "Epoch: 69400 | MAE Train Loss: 44.62794494628906 | MAE Test Loss: 43.177181243896484 \n",
      "Epoch: 69410 | MAE Train Loss: 44.62748336791992 | MAE Test Loss: 43.177085876464844 \n",
      "Epoch: 69420 | MAE Train Loss: 44.62702178955078 | MAE Test Loss: 43.176944732666016 \n",
      "Epoch: 69430 | MAE Train Loss: 44.626564025878906 | MAE Test Loss: 43.17680740356445 \n",
      "Epoch: 69440 | MAE Train Loss: 44.626102447509766 | MAE Test Loss: 43.17670440673828 \n",
      "Epoch: 69450 | MAE Train Loss: 44.62563705444336 | MAE Test Loss: 43.17656707763672 \n",
      "Epoch: 69460 | MAE Train Loss: 44.62517547607422 | MAE Test Loss: 43.176429748535156 \n",
      "Epoch: 69470 | MAE Train Loss: 44.62471389770508 | MAE Test Loss: 43.17633056640625 \n",
      "Epoch: 69480 | MAE Train Loss: 44.6242561340332 | MAE Test Loss: 43.17619323730469 \n",
      "Epoch: 69490 | MAE Train Loss: 44.62379837036133 | MAE Test Loss: 43.176055908203125 \n",
      "Epoch: 69500 | MAE Train Loss: 44.623329162597656 | MAE Test Loss: 43.17595672607422 \n",
      "Epoch: 69510 | MAE Train Loss: 44.62287139892578 | MAE Test Loss: 43.175819396972656 \n",
      "Epoch: 69520 | MAE Train Loss: 44.622406005859375 | MAE Test Loss: 43.17567825317383 \n",
      "Epoch: 69530 | MAE Train Loss: 44.621944427490234 | MAE Test Loss: 43.17558288574219 \n",
      "Epoch: 69540 | MAE Train Loss: 44.62148666381836 | MAE Test Loss: 43.175437927246094 \n",
      "Epoch: 69550 | MAE Train Loss: 44.62102508544922 | MAE Test Loss: 43.1753044128418 \n",
      "Epoch: 69560 | MAE Train Loss: 44.62056350708008 | MAE Test Loss: 43.175201416015625 \n",
      "Epoch: 69570 | MAE Train Loss: 44.62010192871094 | MAE Test Loss: 43.17506408691406 \n",
      "Epoch: 69580 | MAE Train Loss: 44.6196403503418 | MAE Test Loss: 43.17494583129883 \n",
      "Epoch: 69590 | MAE Train Loss: 44.619178771972656 | MAE Test Loss: 43.174808502197266 \n",
      "Epoch: 69600 | MAE Train Loss: 44.61872100830078 | MAE Test Loss: 43.17467498779297 \n",
      "Epoch: 69610 | MAE Train Loss: 44.618255615234375 | MAE Test Loss: 43.174564361572266 \n",
      "Epoch: 69620 | MAE Train Loss: 44.6177978515625 | MAE Test Loss: 43.1744270324707 \n",
      "Epoch: 69630 | MAE Train Loss: 44.61733627319336 | MAE Test Loss: 43.174293518066406 \n",
      "Epoch: 69640 | MAE Train Loss: 44.61687088012695 | MAE Test Loss: 43.1741943359375 \n",
      "Epoch: 69650 | MAE Train Loss: 44.61640930175781 | MAE Test Loss: 43.17405700683594 \n",
      "Epoch: 69660 | MAE Train Loss: 44.61595153808594 | MAE Test Loss: 43.173919677734375 \n",
      "Epoch: 69670 | MAE Train Loss: 44.61548614501953 | MAE Test Loss: 43.17382049560547 \n",
      "Epoch: 69680 | MAE Train Loss: 44.615028381347656 | MAE Test Loss: 43.17367935180664 \n",
      "Epoch: 69690 | MAE Train Loss: 44.61456298828125 | MAE Test Loss: 43.173545837402344 \n",
      "Epoch: 69700 | MAE Train Loss: 44.61410140991211 | MAE Test Loss: 43.173439025878906 \n",
      "Epoch: 69710 | MAE Train Loss: 44.6136474609375 | MAE Test Loss: 43.17330551147461 \n",
      "Epoch: 69720 | MAE Train Loss: 44.613182067871094 | MAE Test Loss: 43.17316818237305 \n",
      "Epoch: 69730 | MAE Train Loss: 44.61271667480469 | MAE Test Loss: 43.173065185546875 \n",
      "Epoch: 69740 | MAE Train Loss: 44.61225509643555 | MAE Test Loss: 43.17292404174805 \n",
      "Epoch: 69750 | MAE Train Loss: 44.61180114746094 | MAE Test Loss: 43.17279052734375 \n",
      "Epoch: 69760 | MAE Train Loss: 44.61133575439453 | MAE Test Loss: 43.17268753051758 \n",
      "Epoch: 69770 | MAE Train Loss: 44.610877990722656 | MAE Test Loss: 43.172550201416016 \n",
      "Epoch: 69780 | MAE Train Loss: 44.610416412353516 | MAE Test Loss: 43.17241668701172 \n",
      "Epoch: 69790 | MAE Train Loss: 44.60995101928711 | MAE Test Loss: 43.17229461669922 \n",
      "Epoch: 69800 | MAE Train Loss: 44.60948944091797 | MAE Test Loss: 43.172176361083984 \n",
      "Epoch: 69810 | MAE Train Loss: 44.60903549194336 | MAE Test Loss: 43.17205810546875 \n",
      "Epoch: 69820 | MAE Train Loss: 44.60856628417969 | MAE Test Loss: 43.17195510864258 \n",
      "Epoch: 69830 | MAE Train Loss: 44.60810852050781 | MAE Test Loss: 43.17181396484375 \n",
      "Epoch: 69840 | MAE Train Loss: 44.607643127441406 | MAE Test Loss: 43.171695709228516 \n",
      "Epoch: 69850 | MAE Train Loss: 44.60718536376953 | MAE Test Loss: 43.17158889770508 \n",
      "Epoch: 69860 | MAE Train Loss: 44.60672378540039 | MAE Test Loss: 43.17148971557617 \n",
      "Epoch: 69870 | MAE Train Loss: 44.606258392333984 | MAE Test Loss: 43.17135238647461 \n",
      "Epoch: 69880 | MAE Train Loss: 44.60580062866211 | MAE Test Loss: 43.17124557495117 \n",
      "Epoch: 69890 | MAE Train Loss: 44.60533905029297 | MAE Test Loss: 43.171142578125 \n",
      "Epoch: 69900 | MAE Train Loss: 44.604881286621094 | MAE Test Loss: 43.1710090637207 \n",
      "Epoch: 69910 | MAE Train Loss: 44.60441207885742 | MAE Test Loss: 43.170902252197266 \n",
      "Epoch: 69920 | MAE Train Loss: 44.60395431518555 | MAE Test Loss: 43.170799255371094 \n",
      "Epoch: 69930 | MAE Train Loss: 44.60348892211914 | MAE Test Loss: 43.17066955566406 \n",
      "Epoch: 69940 | MAE Train Loss: 44.603031158447266 | MAE Test Loss: 43.170562744140625 \n",
      "Epoch: 69950 | MAE Train Loss: 44.60257339477539 | MAE Test Loss: 43.17045593261719 \n",
      "Epoch: 69960 | MAE Train Loss: 44.602108001708984 | MAE Test Loss: 43.170352935791016 \n",
      "Epoch: 69970 | MAE Train Loss: 44.601646423339844 | MAE Test Loss: 43.17021179199219 \n",
      "Epoch: 69980 | MAE Train Loss: 44.6011848449707 | MAE Test Loss: 43.17011260986328 \n",
      "Epoch: 69990 | MAE Train Loss: 44.60072326660156 | MAE Test Loss: 43.170005798339844 \n",
      "Epoch: 70000 | MAE Train Loss: 44.60026550292969 | MAE Test Loss: 43.16987228393555 \n",
      "Epoch: 70010 | MAE Train Loss: 44.59980392456055 | MAE Test Loss: 43.16976547241211 \n",
      "Epoch: 70020 | MAE Train Loss: 44.599342346191406 | MAE Test Loss: 43.16966247558594 \n",
      "Epoch: 70030 | MAE Train Loss: 44.598876953125 | MAE Test Loss: 43.169525146484375 \n",
      "Epoch: 70040 | MAE Train Loss: 44.598419189453125 | MAE Test Loss: 43.16942596435547 \n",
      "Epoch: 70050 | MAE Train Loss: 44.59795379638672 | MAE Test Loss: 43.16931915283203 \n",
      "Epoch: 70060 | MAE Train Loss: 44.597496032714844 | MAE Test Loss: 43.16918182373047 \n",
      "Epoch: 70070 | MAE Train Loss: 44.59703826904297 | MAE Test Loss: 43.1690788269043 \n",
      "Epoch: 70080 | MAE Train Loss: 44.59657287597656 | MAE Test Loss: 43.168975830078125 \n",
      "Epoch: 70090 | MAE Train Loss: 44.59611129760742 | MAE Test Loss: 43.16884231567383 \n",
      "Epoch: 70100 | MAE Train Loss: 44.595645904541016 | MAE Test Loss: 43.16871643066406 \n",
      "Epoch: 70110 | MAE Train Loss: 44.595191955566406 | MAE Test Loss: 43.168617248535156 \n",
      "Epoch: 70120 | MAE Train Loss: 44.594730377197266 | MAE Test Loss: 43.168514251708984 \n",
      "Epoch: 70130 | MAE Train Loss: 44.59426498413086 | MAE Test Loss: 43.168373107910156 \n",
      "Epoch: 70140 | MAE Train Loss: 44.593807220458984 | MAE Test Loss: 43.16827392578125 \n",
      "Epoch: 70150 | MAE Train Loss: 44.593345642089844 | MAE Test Loss: 43.16816711425781 \n",
      "Epoch: 70160 | MAE Train Loss: 44.59288024902344 | MAE Test Loss: 43.168060302734375 \n",
      "Epoch: 70170 | MAE Train Loss: 44.59242630004883 | MAE Test Loss: 43.16792678833008 \n",
      "Epoch: 70180 | MAE Train Loss: 44.59196472167969 | MAE Test Loss: 43.167823791503906 \n",
      "Epoch: 70190 | MAE Train Loss: 44.59149932861328 | MAE Test Loss: 43.16771697998047 \n",
      "Epoch: 70200 | MAE Train Loss: 44.59103775024414 | MAE Test Loss: 43.16758346557617 \n",
      "Epoch: 70210 | MAE Train Loss: 44.590576171875 | MAE Test Loss: 43.167476654052734 \n",
      "Epoch: 70220 | MAE Train Loss: 44.590110778808594 | MAE Test Loss: 43.16737747192383 \n",
      "Epoch: 70230 | MAE Train Loss: 44.58965301513672 | MAE Test Loss: 43.167236328125 \n",
      "Epoch: 70240 | MAE Train Loss: 44.589195251464844 | MAE Test Loss: 43.16713333129883 \n",
      "Epoch: 70250 | MAE Train Loss: 44.58872604370117 | MAE Test Loss: 43.167030334472656 \n",
      "Epoch: 70260 | MAE Train Loss: 44.5882682800293 | MAE Test Loss: 43.16689682006836 \n",
      "Epoch: 70270 | MAE Train Loss: 44.58781051635742 | MAE Test Loss: 43.16679000854492 \n",
      "Epoch: 70280 | MAE Train Loss: 44.587345123291016 | MAE Test Loss: 43.16668701171875 \n",
      "Epoch: 70290 | MAE Train Loss: 44.586883544921875 | MAE Test Loss: 43.16655349731445 \n",
      "Epoch: 70300 | MAE Train Loss: 44.58642578125 | MAE Test Loss: 43.16644287109375 \n",
      "Epoch: 70310 | MAE Train Loss: 44.58596420288086 | MAE Test Loss: 43.16633987426758 \n",
      "Epoch: 70320 | MAE Train Loss: 44.58550262451172 | MAE Test Loss: 43.166202545166016 \n",
      "Epoch: 70330 | MAE Train Loss: 44.58504104614258 | MAE Test Loss: 43.166099548339844 \n",
      "Epoch: 70340 | MAE Train Loss: 44.58457946777344 | MAE Test Loss: 43.16599655151367 \n",
      "Epoch: 70350 | MAE Train Loss: 44.58412170410156 | MAE Test Loss: 43.165863037109375 \n",
      "Epoch: 70360 | MAE Train Loss: 44.583656311035156 | MAE Test Loss: 43.16575622558594 \n",
      "Epoch: 70370 | MAE Train Loss: 44.58319854736328 | MAE Test Loss: 43.1656379699707 \n",
      "Epoch: 70380 | MAE Train Loss: 44.582733154296875 | MAE Test Loss: 43.16553497314453 \n",
      "Epoch: 70390 | MAE Train Loss: 44.58226776123047 | MAE Test Loss: 43.165428161621094 \n",
      "Epoch: 70400 | MAE Train Loss: 44.58181381225586 | MAE Test Loss: 43.16529846191406 \n",
      "Epoch: 70410 | MAE Train Loss: 44.58135223388672 | MAE Test Loss: 43.165191650390625 \n",
      "Epoch: 70420 | MAE Train Loss: 44.58088684082031 | MAE Test Loss: 43.16508483886719 \n",
      "Epoch: 70430 | MAE Train Loss: 44.58042526245117 | MAE Test Loss: 43.164947509765625 \n",
      "Epoch: 70440 | MAE Train Loss: 44.57996368408203 | MAE Test Loss: 43.16484451293945 \n",
      "Epoch: 70450 | MAE Train Loss: 44.579505920410156 | MAE Test Loss: 43.164737701416016 \n",
      "Epoch: 70460 | MAE Train Loss: 44.579044342041016 | MAE Test Loss: 43.164608001708984 \n",
      "Epoch: 70470 | MAE Train Loss: 44.578582763671875 | MAE Test Loss: 43.16450119018555 \n",
      "Epoch: 70480 | MAE Train Loss: 44.578121185302734 | MAE Test Loss: 43.16439437866211 \n",
      "Epoch: 70490 | MAE Train Loss: 44.57765579223633 | MAE Test Loss: 43.16426086425781 \n",
      "Epoch: 70500 | MAE Train Loss: 44.57720184326172 | MAE Test Loss: 43.16415786743164 \n",
      "Epoch: 70510 | MAE Train Loss: 44.57673263549805 | MAE Test Loss: 43.164058685302734 \n",
      "Epoch: 70520 | MAE Train Loss: 44.57627487182617 | MAE Test Loss: 43.16392135620117 \n",
      "Epoch: 70530 | MAE Train Loss: 44.5758171081543 | MAE Test Loss: 43.163814544677734 \n",
      "Epoch: 70540 | MAE Train Loss: 44.57535171508789 | MAE Test Loss: 43.1637077331543 \n",
      "Epoch: 70550 | MAE Train Loss: 44.57489013671875 | MAE Test Loss: 43.16357421875 \n",
      "Epoch: 70560 | MAE Train Loss: 44.574432373046875 | MAE Test Loss: 43.16347122192383 \n",
      "Epoch: 70570 | MAE Train Loss: 44.573970794677734 | MAE Test Loss: 43.163368225097656 \n",
      "Epoch: 70580 | MAE Train Loss: 44.573509216308594 | MAE Test Loss: 43.16322708129883 \n",
      "Epoch: 70590 | MAE Train Loss: 44.57304763793945 | MAE Test Loss: 43.16312789916992 \n",
      "Epoch: 70600 | MAE Train Loss: 44.57258224487305 | MAE Test Loss: 43.163021087646484 \n",
      "Epoch: 70610 | MAE Train Loss: 44.57212448120117 | MAE Test Loss: 43.16288757324219 \n",
      "Epoch: 70620 | MAE Train Loss: 44.57166290283203 | MAE Test Loss: 43.162776947021484 \n",
      "Epoch: 70630 | MAE Train Loss: 44.57120132446289 | MAE Test Loss: 43.162662506103516 \n",
      "Epoch: 70640 | MAE Train Loss: 44.57073974609375 | MAE Test Loss: 43.162559509277344 \n",
      "Epoch: 70650 | MAE Train Loss: 44.57027816772461 | MAE Test Loss: 43.16245651245117 \n",
      "Epoch: 70660 | MAE Train Loss: 44.5698127746582 | MAE Test Loss: 43.162315368652344 \n",
      "Epoch: 70670 | MAE Train Loss: 44.56935501098633 | MAE Test Loss: 43.16221237182617 \n",
      "Epoch: 70680 | MAE Train Loss: 44.56889343261719 | MAE Test Loss: 43.162109375 \n",
      "Epoch: 70690 | MAE Train Loss: 44.56843185424805 | MAE Test Loss: 43.1619758605957 \n",
      "Epoch: 70700 | MAE Train Loss: 44.567970275878906 | MAE Test Loss: 43.161869049072266 \n",
      "Epoch: 70710 | MAE Train Loss: 44.567508697509766 | MAE Test Loss: 43.16176223754883 \n",
      "Epoch: 70720 | MAE Train Loss: 44.567047119140625 | MAE Test Loss: 43.161624908447266 \n",
      "Epoch: 70730 | MAE Train Loss: 44.566593170166016 | MAE Test Loss: 43.161529541015625 \n",
      "Epoch: 70740 | MAE Train Loss: 44.56612777709961 | MAE Test Loss: 43.16142272949219 \n",
      "Epoch: 70750 | MAE Train Loss: 44.5656623840332 | MAE Test Loss: 43.161285400390625 \n",
      "Epoch: 70760 | MAE Train Loss: 44.56520462036133 | MAE Test Loss: 43.16118240356445 \n",
      "Epoch: 70770 | MAE Train Loss: 44.56474685668945 | MAE Test Loss: 43.16107940673828 \n",
      "Epoch: 70780 | MAE Train Loss: 44.56428146362305 | MAE Test Loss: 43.16094207763672 \n",
      "Epoch: 70790 | MAE Train Loss: 44.56381607055664 | MAE Test Loss: 43.16083908081055 \n",
      "Epoch: 70800 | MAE Train Loss: 44.5633544921875 | MAE Test Loss: 43.16073226928711 \n",
      "Epoch: 70810 | MAE Train Loss: 44.56289291381836 | MAE Test Loss: 43.16059875488281 \n",
      "Epoch: 70820 | MAE Train Loss: 44.562435150146484 | MAE Test Loss: 43.160491943359375 \n",
      "Epoch: 70830 | MAE Train Loss: 44.561973571777344 | MAE Test Loss: 43.16038513183594 \n",
      "Epoch: 70840 | MAE Train Loss: 44.5615119934082 | MAE Test Loss: 43.16025161743164 \n",
      "Epoch: 70850 | MAE Train Loss: 44.5610466003418 | MAE Test Loss: 43.1601448059082 \n",
      "Epoch: 70860 | MAE Train Loss: 44.56059265136719 | MAE Test Loss: 43.1600456237793 \n",
      "Epoch: 70870 | MAE Train Loss: 44.56012725830078 | MAE Test Loss: 43.159908294677734 \n",
      "Epoch: 70880 | MAE Train Loss: 44.559669494628906 | MAE Test Loss: 43.15980529785156 \n",
      "Epoch: 70890 | MAE Train Loss: 44.559207916259766 | MAE Test Loss: 43.15968704223633 \n",
      "Epoch: 70900 | MAE Train Loss: 44.55874252319336 | MAE Test Loss: 43.15958023071289 \n",
      "Epoch: 70910 | MAE Train Loss: 44.558284759521484 | MAE Test Loss: 43.15947723388672 \n",
      "Epoch: 70920 | MAE Train Loss: 44.557823181152344 | MAE Test Loss: 43.159339904785156 \n",
      "Epoch: 70930 | MAE Train Loss: 44.5573616027832 | MAE Test Loss: 43.15924072265625 \n",
      "Epoch: 70940 | MAE Train Loss: 44.55690002441406 | MAE Test Loss: 43.15913391113281 \n",
      "Epoch: 70950 | MAE Train Loss: 44.556434631347656 | MAE Test Loss: 43.158992767333984 \n",
      "Epoch: 70960 | MAE Train Loss: 44.55597686767578 | MAE Test Loss: 43.15889358520508 \n",
      "Epoch: 70970 | MAE Train Loss: 44.55551528930664 | MAE Test Loss: 43.158790588378906 \n",
      "Epoch: 70980 | MAE Train Loss: 44.555049896240234 | MAE Test Loss: 43.158653259277344 \n",
      "Epoch: 70990 | MAE Train Loss: 44.554595947265625 | MAE Test Loss: 43.15855026245117 \n",
      "Epoch: 71000 | MAE Train Loss: 44.554134368896484 | MAE Test Loss: 43.158443450927734 \n",
      "Epoch: 71010 | MAE Train Loss: 44.55366516113281 | MAE Test Loss: 43.15830612182617 \n",
      "Epoch: 71020 | MAE Train Loss: 44.55320739746094 | MAE Test Loss: 43.158203125 \n",
      "Epoch: 71030 | MAE Train Loss: 44.5527458190918 | MAE Test Loss: 43.15809631347656 \n",
      "Epoch: 71040 | MAE Train Loss: 44.552284240722656 | MAE Test Loss: 43.157962799072266 \n",
      "Epoch: 71050 | MAE Train Loss: 44.551822662353516 | MAE Test Loss: 43.15785598754883 \n",
      "Epoch: 71060 | MAE Train Loss: 44.551361083984375 | MAE Test Loss: 43.15775680541992 \n",
      "Epoch: 71070 | MAE Train Loss: 44.55089569091797 | MAE Test Loss: 43.157615661621094 \n",
      "Epoch: 71080 | MAE Train Loss: 44.550437927246094 | MAE Test Loss: 43.15751647949219 \n",
      "Epoch: 71090 | MAE Train Loss: 44.54998016357422 | MAE Test Loss: 43.157413482666016 \n",
      "Epoch: 71100 | MAE Train Loss: 44.54951858520508 | MAE Test Loss: 43.15730285644531 \n",
      "Epoch: 71110 | MAE Train Loss: 44.54905319213867 | MAE Test Loss: 43.157169342041016 \n",
      "Epoch: 71120 | MAE Train Loss: 44.5485954284668 | MAE Test Loss: 43.15707015991211 \n",
      "Epoch: 71130 | MAE Train Loss: 44.548133850097656 | MAE Test Loss: 43.15696334838867 \n",
      "Epoch: 71140 | MAE Train Loss: 44.547672271728516 | MAE Test Loss: 43.156829833984375 \n",
      "Epoch: 71150 | MAE Train Loss: 44.547210693359375 | MAE Test Loss: 43.15670394897461 \n",
      "Epoch: 71160 | MAE Train Loss: 44.546749114990234 | MAE Test Loss: 43.15660095214844 \n",
      "Epoch: 71170 | MAE Train Loss: 44.546287536621094 | MAE Test Loss: 43.156497955322266 \n",
      "Epoch: 71180 | MAE Train Loss: 44.54582214355469 | MAE Test Loss: 43.1563606262207 \n",
      "Epoch: 71190 | MAE Train Loss: 44.54536437988281 | MAE Test Loss: 43.156253814697266 \n",
      "Epoch: 71200 | MAE Train Loss: 44.54490280151367 | MAE Test Loss: 43.15615463256836 \n",
      "Epoch: 71210 | MAE Train Loss: 44.5444450378418 | MAE Test Loss: 43.15602111816406 \n",
      "Epoch: 71220 | MAE Train Loss: 44.543983459472656 | MAE Test Loss: 43.155914306640625 \n",
      "Epoch: 71230 | MAE Train Loss: 44.54351806640625 | MAE Test Loss: 43.15581130981445 \n",
      "Epoch: 71240 | MAE Train Loss: 44.543052673339844 | MAE Test Loss: 43.155677795410156 \n",
      "Epoch: 71250 | MAE Train Loss: 44.542598724365234 | MAE Test Loss: 43.15557098388672 \n",
      "Epoch: 71260 | MAE Train Loss: 44.542137145996094 | MAE Test Loss: 43.15546798706055 \n",
      "Epoch: 71270 | MAE Train Loss: 44.54167556762695 | MAE Test Loss: 43.15536117553711 \n",
      "Epoch: 71280 | MAE Train Loss: 44.54121398925781 | MAE Test Loss: 43.15522384643555 \n",
      "Epoch: 71290 | MAE Train Loss: 44.54075241088867 | MAE Test Loss: 43.15512466430664 \n",
      "Epoch: 71300 | MAE Train Loss: 44.540287017822266 | MAE Test Loss: 43.1550178527832 \n",
      "Epoch: 71310 | MAE Train Loss: 44.539825439453125 | MAE Test Loss: 43.154884338378906 \n",
      "Epoch: 71320 | MAE Train Loss: 44.539371490478516 | MAE Test Loss: 43.154781341552734 \n",
      "Epoch: 71330 | MAE Train Loss: 44.53890609741211 | MAE Test Loss: 43.1546745300293 \n",
      "Epoch: 71340 | MAE Train Loss: 44.53844451904297 | MAE Test Loss: 43.154537200927734 \n",
      "Epoch: 71350 | MAE Train Loss: 44.537986755371094 | MAE Test Loss: 43.15443420410156 \n",
      "Epoch: 71360 | MAE Train Loss: 44.53752136230469 | MAE Test Loss: 43.15433120727539 \n",
      "Epoch: 71370 | MAE Train Loss: 44.53706359863281 | MAE Test Loss: 43.15419387817383 \n",
      "Epoch: 71380 | MAE Train Loss: 44.53660202026367 | MAE Test Loss: 43.15408706665039 \n",
      "Epoch: 71390 | MAE Train Loss: 44.536136627197266 | MAE Test Loss: 43.15398406982422 \n",
      "Epoch: 71400 | MAE Train Loss: 44.535675048828125 | MAE Test Loss: 43.15385055541992 \n",
      "Epoch: 71410 | MAE Train Loss: 44.535213470458984 | MAE Test Loss: 43.15373229980469 \n",
      "Epoch: 71420 | MAE Train Loss: 44.53475570678711 | MAE Test Loss: 43.153629302978516 \n",
      "Epoch: 71430 | MAE Train Loss: 44.53429412841797 | MAE Test Loss: 43.15355682373047 \n",
      "Epoch: 71440 | MAE Train Loss: 44.533836364746094 | MAE Test Loss: 43.1534309387207 \n",
      "Epoch: 71450 | MAE Train Loss: 44.53337860107422 | MAE Test Loss: 43.15334701538086 \n",
      "Epoch: 71460 | MAE Train Loss: 44.53291702270508 | MAE Test Loss: 43.15327453613281 \n",
      "Epoch: 71470 | MAE Train Loss: 44.53246307373047 | MAE Test Loss: 43.153194427490234 \n",
      "Epoch: 71480 | MAE Train Loss: 44.53200912475586 | MAE Test Loss: 43.15309524536133 \n",
      "Epoch: 71490 | MAE Train Loss: 44.53154754638672 | MAE Test Loss: 43.15303039550781 \n",
      "Epoch: 71500 | MAE Train Loss: 44.53109359741211 | MAE Test Loss: 43.152923583984375 \n",
      "Epoch: 71510 | MAE Train Loss: 44.530635833740234 | MAE Test Loss: 43.1528434753418 \n",
      "Epoch: 71520 | MAE Train Loss: 44.53017807006836 | MAE Test Loss: 43.152767181396484 \n",
      "Epoch: 71530 | MAE Train Loss: 44.52972412109375 | MAE Test Loss: 43.15269088745117 \n",
      "Epoch: 71540 | MAE Train Loss: 44.52927017211914 | MAE Test Loss: 43.152618408203125 \n",
      "Epoch: 71550 | MAE Train Loss: 44.52880859375 | MAE Test Loss: 43.15253829956055 \n",
      "Epoch: 71560 | MAE Train Loss: 44.52835464477539 | MAE Test Loss: 43.152469635009766 \n",
      "Epoch: 71570 | MAE Train Loss: 44.52790069580078 | MAE Test Loss: 43.15238952636719 \n",
      "Epoch: 71580 | MAE Train Loss: 44.52743911743164 | MAE Test Loss: 43.152313232421875 \n",
      "Epoch: 71590 | MAE Train Loss: 44.52698516845703 | MAE Test Loss: 43.1522331237793 \n",
      "Epoch: 71600 | MAE Train Loss: 44.52652359008789 | MAE Test Loss: 43.152164459228516 \n",
      "Epoch: 71610 | MAE Train Loss: 44.52606964111328 | MAE Test Loss: 43.15208435058594 \n",
      "Epoch: 71620 | MAE Train Loss: 44.525611877441406 | MAE Test Loss: 43.152008056640625 \n",
      "Epoch: 71630 | MAE Train Loss: 44.52515411376953 | MAE Test Loss: 43.15193176269531 \n",
      "Epoch: 71640 | MAE Train Loss: 44.52469253540039 | MAE Test Loss: 43.151859283447266 \n",
      "Epoch: 71650 | MAE Train Loss: 44.52424621582031 | MAE Test Loss: 43.151763916015625 \n",
      "Epoch: 71660 | MAE Train Loss: 44.52378463745117 | MAE Test Loss: 43.15167999267578 \n",
      "Epoch: 71670 | MAE Train Loss: 44.52333068847656 | MAE Test Loss: 43.151611328125 \n",
      "Epoch: 71680 | MAE Train Loss: 44.52287292480469 | MAE Test Loss: 43.15153503417969 \n",
      "Epoch: 71690 | MAE Train Loss: 44.52241516113281 | MAE Test Loss: 43.151458740234375 \n",
      "Epoch: 71700 | MAE Train Loss: 44.5219612121582 | MAE Test Loss: 43.15138244628906 \n",
      "Epoch: 71710 | MAE Train Loss: 44.52149963378906 | MAE Test Loss: 43.15130615234375 \n",
      "Epoch: 71720 | MAE Train Loss: 44.52103805541992 | MAE Test Loss: 43.15119171142578 \n",
      "Epoch: 71730 | MAE Train Loss: 44.52058792114258 | MAE Test Loss: 43.151119232177734 \n",
      "Epoch: 71740 | MAE Train Loss: 44.5201301574707 | MAE Test Loss: 43.15104293823242 \n",
      "Epoch: 71750 | MAE Train Loss: 44.519676208496094 | MAE Test Loss: 43.15096664428711 \n",
      "Epoch: 71760 | MAE Train Loss: 44.51921844482422 | MAE Test Loss: 43.1508903503418 \n",
      "Epoch: 71770 | MAE Train Loss: 44.518760681152344 | MAE Test Loss: 43.150814056396484 \n",
      "Epoch: 71780 | MAE Train Loss: 44.518306732177734 | MAE Test Loss: 43.15073776245117 \n",
      "Epoch: 71790 | MAE Train Loss: 44.51784896850586 | MAE Test Loss: 43.150657653808594 \n",
      "Epoch: 71800 | MAE Train Loss: 44.517391204833984 | MAE Test Loss: 43.15056610107422 \n",
      "Epoch: 71810 | MAE Train Loss: 44.516937255859375 | MAE Test Loss: 43.15049362182617 \n",
      "Epoch: 71820 | MAE Train Loss: 44.516475677490234 | MAE Test Loss: 43.150413513183594 \n",
      "Epoch: 71830 | MAE Train Loss: 44.51601791381836 | MAE Test Loss: 43.15033721923828 \n",
      "Epoch: 71840 | MAE Train Loss: 44.51556396484375 | MAE Test Loss: 43.150264739990234 \n",
      "Epoch: 71850 | MAE Train Loss: 44.51511001586914 | MAE Test Loss: 43.15018844604492 \n",
      "Epoch: 71860 | MAE Train Loss: 44.514652252197266 | MAE Test Loss: 43.15011215209961 \n",
      "Epoch: 71870 | MAE Train Loss: 44.514198303222656 | MAE Test Loss: 43.1500358581543 \n",
      "Epoch: 71880 | MAE Train Loss: 44.51374053955078 | MAE Test Loss: 43.14995574951172 \n",
      "Epoch: 71890 | MAE Train Loss: 44.513282775878906 | MAE Test Loss: 43.14988327026367 \n",
      "Epoch: 71900 | MAE Train Loss: 44.51282501220703 | MAE Test Loss: 43.14980697631836 \n",
      "Epoch: 71910 | MAE Train Loss: 44.512367248535156 | MAE Test Loss: 43.14973068237305 \n",
      "Epoch: 71920 | MAE Train Loss: 44.511905670166016 | MAE Test Loss: 43.149654388427734 \n",
      "Epoch: 71930 | MAE Train Loss: 44.511451721191406 | MAE Test Loss: 43.149574279785156 \n",
      "Epoch: 71940 | MAE Train Loss: 44.51099395751953 | MAE Test Loss: 43.149505615234375 \n",
      "Epoch: 71950 | MAE Train Loss: 44.51054000854492 | MAE Test Loss: 43.149410247802734 \n",
      "Epoch: 71960 | MAE Train Loss: 44.51008224487305 | MAE Test Loss: 43.149330139160156 \n",
      "Epoch: 71970 | MAE Train Loss: 44.50962829589844 | MAE Test Loss: 43.14925765991211 \n",
      "Epoch: 71980 | MAE Train Loss: 44.50917053222656 | MAE Test Loss: 43.14918518066406 \n",
      "Epoch: 71990 | MAE Train Loss: 44.50871276855469 | MAE Test Loss: 43.149105072021484 \n",
      "Epoch: 72000 | MAE Train Loss: 44.50825500488281 | MAE Test Loss: 43.149024963378906 \n",
      "Epoch: 72010 | MAE Train Loss: 44.50779724121094 | MAE Test Loss: 43.148948669433594 \n",
      "Epoch: 72020 | MAE Train Loss: 44.50734329223633 | MAE Test Loss: 43.148841857910156 \n",
      "Epoch: 72030 | MAE Train Loss: 44.50688552856445 | MAE Test Loss: 43.148765563964844 \n",
      "Epoch: 72040 | MAE Train Loss: 44.50642776489258 | MAE Test Loss: 43.148685455322266 \n",
      "Epoch: 72050 | MAE Train Loss: 44.50597381591797 | MAE Test Loss: 43.14860916137695 \n",
      "Epoch: 72060 | MAE Train Loss: 44.505516052246094 | MAE Test Loss: 43.148536682128906 \n",
      "Epoch: 72070 | MAE Train Loss: 44.50505828857422 | MAE Test Loss: 43.14845657348633 \n",
      "Epoch: 72080 | MAE Train Loss: 44.504608154296875 | MAE Test Loss: 43.14838409423828 \n",
      "Epoch: 72090 | MAE Train Loss: 44.50414276123047 | MAE Test Loss: 43.148311614990234 \n",
      "Epoch: 72100 | MAE Train Loss: 44.50368881225586 | MAE Test Loss: 43.14821243286133 \n",
      "Epoch: 72110 | MAE Train Loss: 44.503231048583984 | MAE Test Loss: 43.148136138916016 \n",
      "Epoch: 72120 | MAE Train Loss: 44.50277328491211 | MAE Test Loss: 43.1480598449707 \n",
      "Epoch: 72130 | MAE Train Loss: 44.5023193359375 | MAE Test Loss: 43.14798355102539 \n",
      "Epoch: 72140 | MAE Train Loss: 44.50185775756836 | MAE Test Loss: 43.14790725708008 \n",
      "Epoch: 72150 | MAE Train Loss: 44.501407623291016 | MAE Test Loss: 43.1478385925293 \n",
      "Epoch: 72160 | MAE Train Loss: 44.50094985961914 | MAE Test Loss: 43.14775848388672 \n",
      "Epoch: 72170 | MAE Train Loss: 44.50049591064453 | MAE Test Loss: 43.147682189941406 \n",
      "Epoch: 72180 | MAE Train Loss: 44.500038146972656 | MAE Test Loss: 43.14760208129883 \n",
      "Epoch: 72190 | MAE Train Loss: 44.49958038330078 | MAE Test Loss: 43.14752960205078 \n",
      "Epoch: 72200 | MAE Train Loss: 44.499122619628906 | MAE Test Loss: 43.1474494934082 \n",
      "Epoch: 72210 | MAE Train Loss: 44.49866485595703 | MAE Test Loss: 43.147377014160156 \n",
      "Epoch: 72220 | MAE Train Loss: 44.498207092285156 | MAE Test Loss: 43.147300720214844 \n",
      "Epoch: 72230 | MAE Train Loss: 44.49774932861328 | MAE Test Loss: 43.1472282409668 \n",
      "Epoch: 72240 | MAE Train Loss: 44.49729537963867 | MAE Test Loss: 43.14714813232422 \n",
      "Epoch: 72250 | MAE Train Loss: 44.49684524536133 | MAE Test Loss: 43.147056579589844 \n",
      "Epoch: 72260 | MAE Train Loss: 44.49638366699219 | MAE Test Loss: 43.146976470947266 \n",
      "Epoch: 72270 | MAE Train Loss: 44.49592590332031 | MAE Test Loss: 43.14690017700195 \n",
      "Epoch: 72280 | MAE Train Loss: 44.4954719543457 | MAE Test Loss: 43.14682388305664 \n",
      "Epoch: 72290 | MAE Train Loss: 44.49501419067383 | MAE Test Loss: 43.146751403808594 \n",
      "Epoch: 72300 | MAE Train Loss: 44.49455261230469 | MAE Test Loss: 43.146671295166016 \n",
      "Epoch: 72310 | MAE Train Loss: 44.49409484863281 | MAE Test Loss: 43.1465950012207 \n",
      "Epoch: 72320 | MAE Train Loss: 44.4936408996582 | MAE Test Loss: 43.14651870727539 \n",
      "Epoch: 72330 | MAE Train Loss: 44.49318313598633 | MAE Test Loss: 43.14640808105469 \n",
      "Epoch: 72340 | MAE Train Loss: 44.49272537231445 | MAE Test Loss: 43.146331787109375 \n",
      "Epoch: 72350 | MAE Train Loss: 44.492271423339844 | MAE Test Loss: 43.14625549316406 \n",
      "Epoch: 72360 | MAE Train Loss: 44.49181365966797 | MAE Test Loss: 43.146175384521484 \n",
      "Epoch: 72370 | MAE Train Loss: 44.49135971069336 | MAE Test Loss: 43.1461067199707 \n",
      "Epoch: 72380 | MAE Train Loss: 44.49090576171875 | MAE Test Loss: 43.14603042602539 \n",
      "Epoch: 72390 | MAE Train Loss: 44.490447998046875 | MAE Test Loss: 43.14595031738281 \n",
      "Epoch: 72400 | MAE Train Loss: 44.489986419677734 | MAE Test Loss: 43.1458740234375 \n",
      "Epoch: 72410 | MAE Train Loss: 44.48953628540039 | MAE Test Loss: 43.14579772949219 \n",
      "Epoch: 72420 | MAE Train Loss: 44.48907470703125 | MAE Test Loss: 43.14572525024414 \n",
      "Epoch: 72430 | MAE Train Loss: 44.488616943359375 | MAE Test Loss: 43.145652770996094 \n",
      "Epoch: 72440 | MAE Train Loss: 44.488162994384766 | MAE Test Loss: 43.14557647705078 \n",
      "Epoch: 72450 | MAE Train Loss: 44.487701416015625 | MAE Test Loss: 43.1454963684082 \n",
      "Epoch: 72460 | MAE Train Loss: 44.487247467041016 | MAE Test Loss: 43.14542007446289 \n",
      "Epoch: 72470 | MAE Train Loss: 44.48678970336914 | MAE Test Loss: 43.14534378051758 \n",
      "Epoch: 72480 | MAE Train Loss: 44.48633575439453 | MAE Test Loss: 43.14524841308594 \n",
      "Epoch: 72490 | MAE Train Loss: 44.48588180541992 | MAE Test Loss: 43.145172119140625 \n",
      "Epoch: 72500 | MAE Train Loss: 44.48542404174805 | MAE Test Loss: 43.14509963989258 \n",
      "Epoch: 72510 | MAE Train Loss: 44.48496627807617 | MAE Test Loss: 43.145023345947266 \n",
      "Epoch: 72520 | MAE Train Loss: 44.48451232910156 | MAE Test Loss: 43.14494705200195 \n",
      "Epoch: 72530 | MAE Train Loss: 44.48405456542969 | MAE Test Loss: 43.14487075805664 \n",
      "Epoch: 72540 | MAE Train Loss: 44.48359298706055 | MAE Test Loss: 43.14479446411133 \n",
      "Epoch: 72550 | MAE Train Loss: 44.4831428527832 | MAE Test Loss: 43.144683837890625 \n",
      "Epoch: 72560 | MAE Train Loss: 44.48268127441406 | MAE Test Loss: 43.14460372924805 \n",
      "Epoch: 72570 | MAE Train Loss: 44.48222351074219 | MAE Test Loss: 43.144527435302734 \n",
      "Epoch: 72580 | MAE Train Loss: 44.48176574707031 | MAE Test Loss: 43.14445495605469 \n",
      "Epoch: 72590 | MAE Train Loss: 44.48130798339844 | MAE Test Loss: 43.14438247680664 \n",
      "Epoch: 72600 | MAE Train Loss: 44.48085403442383 | MAE Test Loss: 43.14430236816406 \n",
      "Epoch: 72610 | MAE Train Loss: 44.48039627075195 | MAE Test Loss: 43.14422607421875 \n",
      "Epoch: 72620 | MAE Train Loss: 44.479942321777344 | MAE Test Loss: 43.14414596557617 \n",
      "Epoch: 72630 | MAE Train Loss: 44.4794807434082 | MAE Test Loss: 43.14405822753906 \n",
      "Epoch: 72640 | MAE Train Loss: 44.47902297973633 | MAE Test Loss: 43.143978118896484 \n",
      "Epoch: 72650 | MAE Train Loss: 44.478572845458984 | MAE Test Loss: 43.14390182495117 \n",
      "Epoch: 72660 | MAE Train Loss: 44.47811508178711 | MAE Test Loss: 43.143829345703125 \n",
      "Epoch: 72670 | MAE Train Loss: 44.477657318115234 | MAE Test Loss: 43.14375305175781 \n",
      "Epoch: 72680 | MAE Train Loss: 44.477203369140625 | MAE Test Loss: 43.1436767578125 \n",
      "Epoch: 72690 | MAE Train Loss: 44.47674560546875 | MAE Test Loss: 43.14360046386719 \n",
      "Epoch: 72700 | MAE Train Loss: 44.476287841796875 | MAE Test Loss: 43.14352035522461 \n",
      "Epoch: 72710 | MAE Train Loss: 44.475833892822266 | MAE Test Loss: 43.1434440612793 \n",
      "Epoch: 72720 | MAE Train Loss: 44.475372314453125 | MAE Test Loss: 43.143367767333984 \n",
      "Epoch: 72730 | MAE Train Loss: 44.474918365478516 | MAE Test Loss: 43.14329147338867 \n",
      "Epoch: 72740 | MAE Train Loss: 44.47446060180664 | MAE Test Loss: 43.143218994140625 \n",
      "Epoch: 72750 | MAE Train Loss: 44.4740104675293 | MAE Test Loss: 43.14311218261719 \n",
      "Epoch: 72760 | MAE Train Loss: 44.47355651855469 | MAE Test Loss: 43.14300537109375 \n",
      "Epoch: 72770 | MAE Train Loss: 44.473114013671875 | MAE Test Loss: 43.1429443359375 \n",
      "Epoch: 72780 | MAE Train Loss: 44.4726676940918 | MAE Test Loss: 43.142845153808594 \n",
      "Epoch: 72790 | MAE Train Loss: 44.47222900390625 | MAE Test Loss: 43.14275360107422 \n",
      "Epoch: 72800 | MAE Train Loss: 44.47178649902344 | MAE Test Loss: 43.14265060424805 \n",
      "Epoch: 72810 | MAE Train Loss: 44.471343994140625 | MAE Test Loss: 43.14255905151367 \n",
      "Epoch: 72820 | MAE Train Loss: 44.47089767456055 | MAE Test Loss: 43.142494201660156 \n",
      "Epoch: 72830 | MAE Train Loss: 44.47046661376953 | MAE Test Loss: 43.142391204833984 \n",
      "Epoch: 72840 | MAE Train Loss: 44.47003173828125 | MAE Test Loss: 43.14231872558594 \n",
      "Epoch: 72850 | MAE Train Loss: 44.4695930480957 | MAE Test Loss: 43.14220428466797 \n",
      "Epoch: 72860 | MAE Train Loss: 44.46916580200195 | MAE Test Loss: 43.14212417602539 \n",
      "Epoch: 72870 | MAE Train Loss: 44.4687385559082 | MAE Test Loss: 43.14204406738281 \n",
      "Epoch: 72880 | MAE Train Loss: 44.468299865722656 | MAE Test Loss: 43.1419677734375 \n",
      "Epoch: 72890 | MAE Train Loss: 44.46786880493164 | MAE Test Loss: 43.14186096191406 \n",
      "Epoch: 72900 | MAE Train Loss: 44.467437744140625 | MAE Test Loss: 43.141780853271484 \n",
      "Epoch: 72910 | MAE Train Loss: 44.467002868652344 | MAE Test Loss: 43.14170455932617 \n",
      "Epoch: 72920 | MAE Train Loss: 44.46657180786133 | MAE Test Loss: 43.141624450683594 \n",
      "Epoch: 72930 | MAE Train Loss: 44.46613693237305 | MAE Test Loss: 43.14151382446289 \n",
      "Epoch: 72940 | MAE Train Loss: 44.4657096862793 | MAE Test Loss: 43.14143753051758 \n",
      "Epoch: 72950 | MAE Train Loss: 44.46527862548828 | MAE Test Loss: 43.14134216308594 \n",
      "Epoch: 72960 | MAE Train Loss: 44.46484375 | MAE Test Loss: 43.141265869140625 \n",
      "Epoch: 72970 | MAE Train Loss: 44.46441650390625 | MAE Test Loss: 43.14118576049805 \n",
      "Epoch: 72980 | MAE Train Loss: 44.46397399902344 | MAE Test Loss: 43.141109466552734 \n",
      "Epoch: 72990 | MAE Train Loss: 44.46354675292969 | MAE Test Loss: 43.140995025634766 \n",
      "Epoch: 73000 | MAE Train Loss: 44.46311569213867 | MAE Test Loss: 43.14091491699219 \n",
      "Epoch: 73010 | MAE Train Loss: 44.462684631347656 | MAE Test Loss: 43.14084243774414 \n",
      "Epoch: 73020 | MAE Train Loss: 44.462249755859375 | MAE Test Loss: 43.14073181152344 \n",
      "Epoch: 73030 | MAE Train Loss: 44.46181869506836 | MAE Test Loss: 43.140655517578125 \n",
      "Epoch: 73040 | MAE Train Loss: 44.461387634277344 | MAE Test Loss: 43.14057159423828 \n",
      "Epoch: 73050 | MAE Train Loss: 44.46095275878906 | MAE Test Loss: 43.14049530029297 \n",
      "Epoch: 73060 | MAE Train Loss: 44.46051788330078 | MAE Test Loss: 43.140384674072266 \n",
      "Epoch: 73070 | MAE Train Loss: 44.46009063720703 | MAE Test Loss: 43.14030838012695 \n",
      "Epoch: 73080 | MAE Train Loss: 44.459651947021484 | MAE Test Loss: 43.14020919799805 \n",
      "Epoch: 73090 | MAE Train Loss: 44.459232330322266 | MAE Test Loss: 43.140132904052734 \n",
      "Epoch: 73100 | MAE Train Loss: 44.45879364013672 | MAE Test Loss: 43.140052795410156 \n",
      "Epoch: 73110 | MAE Train Loss: 44.45835876464844 | MAE Test Loss: 43.13997268676758 \n",
      "Epoch: 73120 | MAE Train Loss: 44.45792770385742 | MAE Test Loss: 43.13986587524414 \n",
      "Epoch: 73130 | MAE Train Loss: 44.457496643066406 | MAE Test Loss: 43.13978958129883 \n",
      "Epoch: 73140 | MAE Train Loss: 44.45706558227539 | MAE Test Loss: 43.13970947265625 \n",
      "Epoch: 73150 | MAE Train Loss: 44.45663070678711 | MAE Test Loss: 43.13962936401367 \n",
      "Epoch: 73160 | MAE Train Loss: 44.45619583129883 | MAE Test Loss: 43.1395149230957 \n",
      "Epoch: 73170 | MAE Train Loss: 44.45576858520508 | MAE Test Loss: 43.139442443847656 \n",
      "Epoch: 73180 | MAE Train Loss: 44.45533752441406 | MAE Test Loss: 43.13936233520508 \n",
      "Epoch: 73190 | MAE Train Loss: 44.45490264892578 | MAE Test Loss: 43.139286041259766 \n",
      "Epoch: 73200 | MAE Train Loss: 44.4544677734375 | MAE Test Loss: 43.13917541503906 \n",
      "Epoch: 73210 | MAE Train Loss: 44.454036712646484 | MAE Test Loss: 43.139095306396484 \n",
      "Epoch: 73220 | MAE Train Loss: 44.4536018371582 | MAE Test Loss: 43.138999938964844 \n",
      "Epoch: 73230 | MAE Train Loss: 44.45317840576172 | MAE Test Loss: 43.13892364501953 \n",
      "Epoch: 73240 | MAE Train Loss: 44.4527473449707 | MAE Test Loss: 43.13884353637695 \n",
      "Epoch: 73250 | MAE Train Loss: 44.45231246948242 | MAE Test Loss: 43.138763427734375 \n",
      "Epoch: 73260 | MAE Train Loss: 44.45187759399414 | MAE Test Loss: 43.13865661621094 \n",
      "Epoch: 73270 | MAE Train Loss: 44.45144271850586 | MAE Test Loss: 43.138580322265625 \n",
      "Epoch: 73280 | MAE Train Loss: 44.45101547241211 | MAE Test Loss: 43.13849639892578 \n",
      "Epoch: 73290 | MAE Train Loss: 44.450584411621094 | MAE Test Loss: 43.13842010498047 \n",
      "Epoch: 73300 | MAE Train Loss: 44.45014953613281 | MAE Test Loss: 43.13831329345703 \n",
      "Epoch: 73310 | MAE Train Loss: 44.4497184753418 | MAE Test Loss: 43.13823318481445 \n",
      "Epoch: 73320 | MAE Train Loss: 44.449283599853516 | MAE Test Loss: 43.138153076171875 \n",
      "Epoch: 73330 | MAE Train Loss: 44.448848724365234 | MAE Test Loss: 43.13807678222656 \n",
      "Epoch: 73340 | MAE Train Loss: 44.44841766357422 | MAE Test Loss: 43.13796615600586 \n",
      "Epoch: 73350 | MAE Train Loss: 44.44799041748047 | MAE Test Loss: 43.13788604736328 \n",
      "Epoch: 73360 | MAE Train Loss: 44.44755172729492 | MAE Test Loss: 43.137794494628906 \n",
      "Epoch: 73370 | MAE Train Loss: 44.44712448120117 | MAE Test Loss: 43.13771438598633 \n",
      "Epoch: 73380 | MAE Train Loss: 44.44668960571289 | MAE Test Loss: 43.13763427734375 \n",
      "Epoch: 73390 | MAE Train Loss: 44.44625473022461 | MAE Test Loss: 43.13755798339844 \n",
      "Epoch: 73400 | MAE Train Loss: 44.44582748413086 | MAE Test Loss: 43.137447357177734 \n",
      "Epoch: 73410 | MAE Train Loss: 44.445396423339844 | MAE Test Loss: 43.137367248535156 \n",
      "Epoch: 73420 | MAE Train Loss: 44.44496536254883 | MAE Test Loss: 43.13728713989258 \n",
      "Epoch: 73430 | MAE Train Loss: 44.44453048706055 | MAE Test Loss: 43.13720703125 \n",
      "Epoch: 73440 | MAE Train Loss: 44.444095611572266 | MAE Test Loss: 43.13710021972656 \n",
      "Epoch: 73450 | MAE Train Loss: 44.443668365478516 | MAE Test Loss: 43.137020111083984 \n",
      "Epoch: 73460 | MAE Train Loss: 44.4432373046875 | MAE Test Loss: 43.13694381713867 \n",
      "Epoch: 73470 | MAE Train Loss: 44.44280242919922 | MAE Test Loss: 43.13686752319336 \n",
      "Epoch: 73480 | MAE Train Loss: 44.4423713684082 | MAE Test Loss: 43.136756896972656 \n",
      "Epoch: 73490 | MAE Train Loss: 44.44193649291992 | MAE Test Loss: 43.13667678833008 \n",
      "Epoch: 73500 | MAE Train Loss: 44.441505432128906 | MAE Test Loss: 43.1365966796875 \n",
      "Epoch: 73510 | MAE Train Loss: 44.441070556640625 | MAE Test Loss: 43.13652038574219 \n",
      "Epoch: 73520 | MAE Train Loss: 44.44063949584961 | MAE Test Loss: 43.136409759521484 \n",
      "Epoch: 73530 | MAE Train Loss: 44.44021224975586 | MAE Test Loss: 43.13633346557617 \n",
      "Epoch: 73540 | MAE Train Loss: 44.43977737426758 | MAE Test Loss: 43.13624954223633 \n",
      "Epoch: 73550 | MAE Train Loss: 44.43933868408203 | MAE Test Loss: 43.136173248291016 \n",
      "Epoch: 73560 | MAE Train Loss: 44.43891143798828 | MAE Test Loss: 43.13606262207031 \n",
      "Epoch: 73570 | MAE Train Loss: 44.438480377197266 | MAE Test Loss: 43.135990142822266 \n",
      "Epoch: 73580 | MAE Train Loss: 44.43804931640625 | MAE Test Loss: 43.13590621948242 \n",
      "Epoch: 73590 | MAE Train Loss: 44.43761444091797 | MAE Test Loss: 43.13582992553711 \n",
      "Epoch: 73600 | MAE Train Loss: 44.43718338012695 | MAE Test Loss: 43.135719299316406 \n",
      "Epoch: 73610 | MAE Train Loss: 44.43675231933594 | MAE Test Loss: 43.13563919067383 \n",
      "Epoch: 73620 | MAE Train Loss: 44.43632125854492 | MAE Test Loss: 43.135562896728516 \n",
      "Epoch: 73630 | MAE Train Loss: 44.43588638305664 | MAE Test Loss: 43.13548278808594 \n",
      "Epoch: 73640 | MAE Train Loss: 44.43545150756836 | MAE Test Loss: 43.135372161865234 \n",
      "Epoch: 73650 | MAE Train Loss: 44.435020446777344 | MAE Test Loss: 43.13529968261719 \n",
      "Epoch: 73660 | MAE Train Loss: 44.43458938598633 | MAE Test Loss: 43.135215759277344 \n",
      "Epoch: 73670 | MAE Train Loss: 44.43415832519531 | MAE Test Loss: 43.135135650634766 \n",
      "Epoch: 73680 | MAE Train Loss: 44.4337272644043 | MAE Test Loss: 43.13502883911133 \n",
      "Epoch: 73690 | MAE Train Loss: 44.43329620361328 | MAE Test Loss: 43.134952545166016 \n",
      "Epoch: 73700 | MAE Train Loss: 44.432865142822266 | MAE Test Loss: 43.13486862182617 \n",
      "Epoch: 73710 | MAE Train Loss: 44.432430267333984 | MAE Test Loss: 43.1347770690918 \n",
      "Epoch: 73720 | MAE Train Loss: 44.43199920654297 | MAE Test Loss: 43.13469314575195 \n",
      "Epoch: 73730 | MAE Train Loss: 44.43156433105469 | MAE Test Loss: 43.13459014892578 \n",
      "Epoch: 73740 | MAE Train Loss: 44.43113327026367 | MAE Test Loss: 43.13451385498047 \n",
      "Epoch: 73750 | MAE Train Loss: 44.43069839477539 | MAE Test Loss: 43.13443374633789 \n",
      "Epoch: 73760 | MAE Train Loss: 44.430267333984375 | MAE Test Loss: 43.13434982299805 \n",
      "Epoch: 73770 | MAE Train Loss: 44.429832458496094 | MAE Test Loss: 43.134246826171875 \n",
      "Epoch: 73780 | MAE Train Loss: 44.429405212402344 | MAE Test Loss: 43.1341667175293 \n",
      "Epoch: 73790 | MAE Train Loss: 44.42897415161133 | MAE Test Loss: 43.13408660888672 \n",
      "Epoch: 73800 | MAE Train Loss: 44.42853927612305 | MAE Test Loss: 43.134010314941406 \n",
      "Epoch: 73810 | MAE Train Loss: 44.428104400634766 | MAE Test Loss: 43.1338996887207 \n",
      "Epoch: 73820 | MAE Train Loss: 44.427677154541016 | MAE Test Loss: 43.133819580078125 \n",
      "Epoch: 73830 | MAE Train Loss: 44.42724609375 | MAE Test Loss: 43.13373947143555 \n",
      "Epoch: 73840 | MAE Train Loss: 44.42681121826172 | MAE Test Loss: 43.1336669921875 \n",
      "Epoch: 73850 | MAE Train Loss: 44.4263801574707 | MAE Test Loss: 43.133567810058594 \n",
      "Epoch: 73860 | MAE Train Loss: 44.42594909667969 | MAE Test Loss: 43.13349151611328 \n",
      "Epoch: 73870 | MAE Train Loss: 44.425514221191406 | MAE Test Loss: 43.13337707519531 \n",
      "Epoch: 73880 | MAE Train Loss: 44.42508316040039 | MAE Test Loss: 43.13330078125 \n",
      "Epoch: 73890 | MAE Train Loss: 44.424652099609375 | MAE Test Loss: 43.133216857910156 \n",
      "Epoch: 73900 | MAE Train Loss: 44.424217224121094 | MAE Test Loss: 43.13314437866211 \n",
      "Epoch: 73910 | MAE Train Loss: 44.42378234863281 | MAE Test Loss: 43.13303756713867 \n",
      "Epoch: 73920 | MAE Train Loss: 44.42335510253906 | MAE Test Loss: 43.13295364379883 \n",
      "Epoch: 73930 | MAE Train Loss: 44.42292404174805 | MAE Test Loss: 43.13287353515625 \n",
      "Epoch: 73940 | MAE Train Loss: 44.4224853515625 | MAE Test Loss: 43.13279724121094 \n",
      "Epoch: 73950 | MAE Train Loss: 44.42205810546875 | MAE Test Loss: 43.1326904296875 \n",
      "Epoch: 73960 | MAE Train Loss: 44.42162322998047 | MAE Test Loss: 43.13261032104492 \n",
      "Epoch: 73970 | MAE Train Loss: 44.42119216918945 | MAE Test Loss: 43.13253402709961 \n",
      "Epoch: 73980 | MAE Train Loss: 44.42076110839844 | MAE Test Loss: 43.1324577331543 \n",
      "Epoch: 73990 | MAE Train Loss: 44.420326232910156 | MAE Test Loss: 43.13234329223633 \n",
      "Epoch: 74000 | MAE Train Loss: 44.41989517211914 | MAE Test Loss: 43.132266998291016 \n",
      "Epoch: 74010 | MAE Train Loss: 44.419464111328125 | MAE Test Loss: 43.13218688964844 \n",
      "Epoch: 74020 | MAE Train Loss: 44.419029235839844 | MAE Test Loss: 43.13210678100586 \n",
      "Epoch: 74030 | MAE Train Loss: 44.41859817504883 | MAE Test Loss: 43.131996154785156 \n",
      "Epoch: 74040 | MAE Train Loss: 44.41816711425781 | MAE Test Loss: 43.131919860839844 \n",
      "Epoch: 74050 | MAE Train Loss: 44.41773223876953 | MAE Test Loss: 43.131839752197266 \n",
      "Epoch: 74060 | MAE Train Loss: 44.417301177978516 | MAE Test Loss: 43.13176345825195 \n",
      "Epoch: 74070 | MAE Train Loss: 44.416873931884766 | MAE Test Loss: 43.13165283203125 \n",
      "Epoch: 74080 | MAE Train Loss: 44.41644287109375 | MAE Test Loss: 43.13157272338867 \n",
      "Epoch: 74090 | MAE Train Loss: 44.41600799560547 | MAE Test Loss: 43.13149642944336 \n",
      "Epoch: 74100 | MAE Train Loss: 44.41556930541992 | MAE Test Loss: 43.131412506103516 \n",
      "Epoch: 74110 | MAE Train Loss: 44.41514205932617 | MAE Test Loss: 43.13130569458008 \n",
      "Epoch: 74120 | MAE Train Loss: 44.414710998535156 | MAE Test Loss: 43.1312255859375 \n",
      "Epoch: 74130 | MAE Train Loss: 44.414276123046875 | MAE Test Loss: 43.13114929199219 \n",
      "Epoch: 74140 | MAE Train Loss: 44.41384506225586 | MAE Test Loss: 43.13106918334961 \n",
      "Epoch: 74150 | MAE Train Loss: 44.413414001464844 | MAE Test Loss: 43.13096237182617 \n",
      "Epoch: 74160 | MAE Train Loss: 44.41298294067383 | MAE Test Loss: 43.130882263183594 \n",
      "Epoch: 74170 | MAE Train Loss: 44.41254806518555 | MAE Test Loss: 43.130802154541016 \n",
      "Epoch: 74180 | MAE Train Loss: 44.41211700439453 | MAE Test Loss: 43.1307258605957 \n",
      "Epoch: 74190 | MAE Train Loss: 44.41168212890625 | MAE Test Loss: 43.130615234375 \n",
      "Epoch: 74200 | MAE Train Loss: 44.4112548828125 | MAE Test Loss: 43.13054275512695 \n",
      "Epoch: 74210 | MAE Train Loss: 44.41082000732422 | MAE Test Loss: 43.13044357299805 \n",
      "Epoch: 74220 | MAE Train Loss: 44.4103889465332 | MAE Test Loss: 43.130367279052734 \n",
      "Epoch: 74230 | MAE Train Loss: 44.40996170043945 | MAE Test Loss: 43.130287170410156 \n",
      "Epoch: 74240 | MAE Train Loss: 44.409523010253906 | MAE Test Loss: 43.13020706176758 \n",
      "Epoch: 74250 | MAE Train Loss: 44.409095764160156 | MAE Test Loss: 43.13010025024414 \n",
      "Epoch: 74260 | MAE Train Loss: 44.40867614746094 | MAE Test Loss: 43.13004684448242 \n",
      "Epoch: 74270 | MAE Train Loss: 44.408267974853516 | MAE Test Loss: 43.130001068115234 \n",
      "Epoch: 74280 | MAE Train Loss: 44.407867431640625 | MAE Test Loss: 43.129966735839844 \n",
      "Epoch: 74290 | MAE Train Loss: 44.4074592590332 | MAE Test Loss: 43.12994384765625 \n",
      "Epoch: 74300 | MAE Train Loss: 44.40706253051758 | MAE Test Loss: 43.1298942565918 \n",
      "Epoch: 74310 | MAE Train Loss: 44.40665817260742 | MAE Test Loss: 43.12984848022461 \n",
      "Epoch: 74320 | MAE Train Loss: 44.406253814697266 | MAE Test Loss: 43.12982940673828 \n",
      "Epoch: 74330 | MAE Train Loss: 44.405853271484375 | MAE Test Loss: 43.12977981567383 \n",
      "Epoch: 74340 | MAE Train Loss: 44.40544891357422 | MAE Test Loss: 43.12972640991211 \n",
      "Epoch: 74350 | MAE Train Loss: 44.40504837036133 | MAE Test Loss: 43.12971115112305 \n",
      "Epoch: 74360 | MAE Train Loss: 44.40464401245117 | MAE Test Loss: 43.12966537475586 \n",
      "Epoch: 74370 | MAE Train Loss: 44.40423583984375 | MAE Test Loss: 43.129642486572266 \n",
      "Epoch: 74380 | MAE Train Loss: 44.403839111328125 | MAE Test Loss: 43.12959289550781 \n",
      "Epoch: 74390 | MAE Train Loss: 44.40343475341797 | MAE Test Loss: 43.129539489746094 \n",
      "Epoch: 74400 | MAE Train Loss: 44.40303039550781 | MAE Test Loss: 43.1295280456543 \n",
      "Epoch: 74410 | MAE Train Loss: 44.40262985229492 | MAE Test Loss: 43.129478454589844 \n",
      "Epoch: 74420 | MAE Train Loss: 44.402225494384766 | MAE Test Loss: 43.12942886352539 \n",
      "Epoch: 74430 | MAE Train Loss: 44.401824951171875 | MAE Test Loss: 43.1294059753418 \n",
      "Epoch: 74440 | MAE Train Loss: 44.401424407958984 | MAE Test Loss: 43.12935256958008 \n",
      "Epoch: 74450 | MAE Train Loss: 44.40101623535156 | MAE Test Loss: 43.12930679321289 \n",
      "Epoch: 74460 | MAE Train Loss: 44.400611877441406 | MAE Test Loss: 43.12929153442383 \n",
      "Epoch: 74470 | MAE Train Loss: 44.40020751953125 | MAE Test Loss: 43.129241943359375 \n",
      "Epoch: 74480 | MAE Train Loss: 44.399803161621094 | MAE Test Loss: 43.12922286987305 \n",
      "Epoch: 74490 | MAE Train Loss: 44.399410247802734 | MAE Test Loss: 43.12916564941406 \n",
      "Epoch: 74500 | MAE Train Loss: 44.39900588989258 | MAE Test Loss: 43.12913513183594 \n",
      "Epoch: 74510 | MAE Train Loss: 44.39860534667969 | MAE Test Loss: 43.129085540771484 \n",
      "Epoch: 74520 | MAE Train Loss: 44.398197174072266 | MAE Test Loss: 43.129066467285156 \n",
      "Epoch: 74530 | MAE Train Loss: 44.397789001464844 | MAE Test Loss: 43.1290168762207 \n",
      "Epoch: 74540 | MAE Train Loss: 44.397396087646484 | MAE Test Loss: 43.12893295288086 \n",
      "Epoch: 74550 | MAE Train Loss: 44.397003173828125 | MAE Test Loss: 43.128910064697266 \n",
      "Epoch: 74560 | MAE Train Loss: 44.3966178894043 | MAE Test Loss: 43.12895202636719 \n",
      "Epoch: 74570 | MAE Train Loss: 44.3962287902832 | MAE Test Loss: 43.12889099121094 \n",
      "Epoch: 74580 | MAE Train Loss: 44.395843505859375 | MAE Test Loss: 43.12883377075195 \n",
      "Epoch: 74590 | MAE Train Loss: 44.39546203613281 | MAE Test Loss: 43.1287727355957 \n",
      "Epoch: 74600 | MAE Train Loss: 44.39507293701172 | MAE Test Loss: 43.12871551513672 \n",
      "Epoch: 74610 | MAE Train Loss: 44.394683837890625 | MAE Test Loss: 43.128658294677734 \n",
      "Epoch: 74620 | MAE Train Loss: 44.3942985534668 | MAE Test Loss: 43.128700256347656 \n",
      "Epoch: 74630 | MAE Train Loss: 44.39391326904297 | MAE Test Loss: 43.128639221191406 \n",
      "Epoch: 74640 | MAE Train Loss: 44.39352798461914 | MAE Test Loss: 43.12862777709961 \n",
      "Epoch: 74650 | MAE Train Loss: 44.39313507080078 | MAE Test Loss: 43.128570556640625 \n",
      "Epoch: 74660 | MAE Train Loss: 44.39275360107422 | MAE Test Loss: 43.128509521484375 \n",
      "Epoch: 74670 | MAE Train Loss: 44.39236831665039 | MAE Test Loss: 43.128501892089844 \n",
      "Epoch: 74680 | MAE Train Loss: 44.39198684692383 | MAE Test Loss: 43.128440856933594 \n",
      "Epoch: 74690 | MAE Train Loss: 44.391597747802734 | MAE Test Loss: 43.12839126586914 \n",
      "Epoch: 74700 | MAE Train Loss: 44.391204833984375 | MAE Test Loss: 43.128379821777344 \n",
      "Epoch: 74710 | MAE Train Loss: 44.39082336425781 | MAE Test Loss: 43.128318786621094 \n",
      "Epoch: 74720 | MAE Train Loss: 44.390438079833984 | MAE Test Loss: 43.128257751464844 \n",
      "Epoch: 74730 | MAE Train Loss: 44.39004898071289 | MAE Test Loss: 43.12825393676758 \n",
      "Epoch: 74740 | MAE Train Loss: 44.38966369628906 | MAE Test Loss: 43.128196716308594 \n",
      "Epoch: 74750 | MAE Train Loss: 44.3892822265625 | MAE Test Loss: 43.128135681152344 \n",
      "Epoch: 74760 | MAE Train Loss: 44.38889694213867 | MAE Test Loss: 43.12807846069336 \n",
      "Epoch: 74770 | MAE Train Loss: 44.38850784301758 | MAE Test Loss: 43.12801742553711 \n",
      "Epoch: 74780 | MAE Train Loss: 44.388118743896484 | MAE Test Loss: 43.1280632019043 \n",
      "Epoch: 74790 | MAE Train Loss: 44.38772964477539 | MAE Test Loss: 43.12800216674805 \n",
      "Epoch: 74800 | MAE Train Loss: 44.38734817504883 | MAE Test Loss: 43.1279411315918 \n",
      "Epoch: 74810 | MAE Train Loss: 44.386966705322266 | MAE Test Loss: 43.12788391113281 \n",
      "Epoch: 74820 | MAE Train Loss: 44.38657760620117 | MAE Test Loss: 43.12782287597656 \n",
      "Epoch: 74830 | MAE Train Loss: 44.38618850708008 | MAE Test Loss: 43.12776565551758 \n",
      "Epoch: 74840 | MAE Train Loss: 44.38580322265625 | MAE Test Loss: 43.12775802612305 \n",
      "Epoch: 74850 | MAE Train Loss: 44.38541793823242 | MAE Test Loss: 43.1276969909668 \n",
      "Epoch: 74860 | MAE Train Loss: 44.385032653808594 | MAE Test Loss: 43.12763977050781 \n",
      "Epoch: 74870 | MAE Train Loss: 44.3846435546875 | MAE Test Loss: 43.12763214111328 \n",
      "Epoch: 74880 | MAE Train Loss: 44.38425827026367 | MAE Test Loss: 43.1275749206543 \n",
      "Epoch: 74890 | MAE Train Loss: 44.38386917114258 | MAE Test Loss: 43.1275634765625 \n",
      "Epoch: 74900 | MAE Train Loss: 44.38349151611328 | MAE Test Loss: 43.12751388549805 \n",
      "Epoch: 74910 | MAE Train Loss: 44.38312911987305 | MAE Test Loss: 43.12726974487305 \n",
      "Epoch: 74920 | MAE Train Loss: 44.38277053833008 | MAE Test Loss: 43.12712478637695 \n",
      "Epoch: 74930 | MAE Train Loss: 44.382415771484375 | MAE Test Loss: 43.126983642578125 \n",
      "Epoch: 74940 | MAE Train Loss: 44.38205337524414 | MAE Test Loss: 43.12674331665039 \n",
      "Epoch: 74950 | MAE Train Loss: 44.38169860839844 | MAE Test Loss: 43.1265983581543 \n",
      "Epoch: 74960 | MAE Train Loss: 44.38134002685547 | MAE Test Loss: 43.1264533996582 \n",
      "Epoch: 74970 | MAE Train Loss: 44.3809814453125 | MAE Test Loss: 43.12621307373047 \n",
      "Epoch: 74980 | MAE Train Loss: 44.38062286376953 | MAE Test Loss: 43.126068115234375 \n",
      "Epoch: 74990 | MAE Train Loss: 44.3802604675293 | MAE Test Loss: 43.12592697143555 \n",
      "Epoch: 75000 | MAE Train Loss: 44.379905700683594 | MAE Test Loss: 43.12569046020508 \n",
      "Epoch: 75010 | MAE Train Loss: 44.379547119140625 | MAE Test Loss: 43.12554168701172 \n",
      "Epoch: 75020 | MAE Train Loss: 44.37918472290039 | MAE Test Loss: 43.125396728515625 \n",
      "Epoch: 75030 | MAE Train Loss: 44.37882614135742 | MAE Test Loss: 43.12515640258789 \n",
      "Epoch: 75040 | MAE Train Loss: 44.37846755981445 | MAE Test Loss: 43.12501525878906 \n",
      "Epoch: 75050 | MAE Train Loss: 44.37811279296875 | MAE Test Loss: 43.1248664855957 \n",
      "Epoch: 75060 | MAE Train Loss: 44.37775421142578 | MAE Test Loss: 43.12468338012695 \n",
      "Epoch: 75070 | MAE Train Loss: 44.37739181518555 | MAE Test Loss: 43.12444305419922 \n",
      "Epoch: 75080 | MAE Train Loss: 44.377037048339844 | MAE Test Loss: 43.1243896484375 \n",
      "Epoch: 75090 | MAE Train Loss: 44.37667465209961 | MAE Test Loss: 43.12434005737305 \n",
      "Epoch: 75100 | MAE Train Loss: 44.376312255859375 | MAE Test Loss: 43.12425994873047 \n",
      "Epoch: 75110 | MAE Train Loss: 44.37595748901367 | MAE Test Loss: 43.12420654296875 \n",
      "Epoch: 75120 | MAE Train Loss: 44.3755989074707 | MAE Test Loss: 43.1241569519043 \n",
      "Epoch: 75130 | MAE Train Loss: 44.37523651123047 | MAE Test Loss: 43.12406921386719 \n",
      "Epoch: 75140 | MAE Train Loss: 44.37488555908203 | MAE Test Loss: 43.124019622802734 \n",
      "Epoch: 75150 | MAE Train Loss: 44.3745231628418 | MAE Test Loss: 43.12394714355469 \n",
      "Epoch: 75160 | MAE Train Loss: 44.374168395996094 | MAE Test Loss: 43.12389373779297 \n",
      "Epoch: 75170 | MAE Train Loss: 44.373802185058594 | MAE Test Loss: 43.123809814453125 \n",
      "Epoch: 75180 | MAE Train Loss: 44.373451232910156 | MAE Test Loss: 43.12376022338867 \n",
      "Epoch: 75190 | MAE Train Loss: 44.373085021972656 | MAE Test Loss: 43.12371063232422 \n",
      "Epoch: 75200 | MAE Train Loss: 44.37273025512695 | MAE Test Loss: 43.12362289428711 \n",
      "Epoch: 75210 | MAE Train Loss: 44.372371673583984 | MAE Test Loss: 43.123573303222656 \n",
      "Epoch: 75220 | MAE Train Loss: 44.372013092041016 | MAE Test Loss: 43.12351989746094 \n",
      "Epoch: 75230 | MAE Train Loss: 44.37165069580078 | MAE Test Loss: 43.12343215942383 \n",
      "Epoch: 75240 | MAE Train Loss: 44.37129211425781 | MAE Test Loss: 43.12337112426758 \n",
      "Epoch: 75250 | MAE Train Loss: 44.37094497680664 | MAE Test Loss: 43.123348236083984 \n",
      "Epoch: 75260 | MAE Train Loss: 44.3705940246582 | MAE Test Loss: 43.12332534790039 \n",
      "Epoch: 75270 | MAE Train Loss: 44.370262145996094 | MAE Test Loss: 43.12329864501953 \n",
      "Epoch: 75280 | MAE Train Loss: 44.36992263793945 | MAE Test Loss: 43.123268127441406 \n",
      "Epoch: 75290 | MAE Train Loss: 44.36958694458008 | MAE Test Loss: 43.12324523925781 \n",
      "Epoch: 75300 | MAE Train Loss: 44.36924743652344 | MAE Test Loss: 43.12321853637695 \n",
      "Epoch: 75310 | MAE Train Loss: 44.3689079284668 | MAE Test Loss: 43.123226165771484 \n",
      "Epoch: 75320 | MAE Train Loss: 44.36857604980469 | MAE Test Loss: 43.12320327758789 \n",
      "Epoch: 75330 | MAE Train Loss: 44.36824035644531 | MAE Test Loss: 43.12317657470703 \n",
      "Epoch: 75340 | MAE Train Loss: 44.367897033691406 | MAE Test Loss: 43.1231689453125 \n",
      "Epoch: 75350 | MAE Train Loss: 44.3675651550293 | MAE Test Loss: 43.123138427734375 \n",
      "Epoch: 75360 | MAE Train Loss: 44.36722946166992 | MAE Test Loss: 43.12311553955078 \n",
      "Epoch: 75370 | MAE Train Loss: 44.36688995361328 | MAE Test Loss: 43.12309265136719 \n",
      "Epoch: 75380 | MAE Train Loss: 44.366546630859375 | MAE Test Loss: 43.12306594848633 \n",
      "Epoch: 75390 | MAE Train Loss: 44.366214752197266 | MAE Test Loss: 43.123069763183594 \n",
      "Epoch: 75400 | MAE Train Loss: 44.365875244140625 | MAE Test Loss: 43.123043060302734 \n",
      "Epoch: 75410 | MAE Train Loss: 44.36553955078125 | MAE Test Loss: 43.123016357421875 \n",
      "Epoch: 75420 | MAE Train Loss: 44.365203857421875 | MAE Test Loss: 43.12299346923828 \n",
      "Epoch: 75430 | MAE Train Loss: 44.3648681640625 | MAE Test Loss: 43.12297058105469 \n",
      "Epoch: 75440 | MAE Train Loss: 44.364524841308594 | MAE Test Loss: 43.12294387817383 \n",
      "Epoch: 75450 | MAE Train Loss: 44.36418914794922 | MAE Test Loss: 43.122947692871094 \n",
      "Epoch: 75460 | MAE Train Loss: 44.363853454589844 | MAE Test Loss: 43.1229248046875 \n",
      "Epoch: 75470 | MAE Train Loss: 44.3635139465332 | MAE Test Loss: 43.122894287109375 \n",
      "Epoch: 75480 | MAE Train Loss: 44.36317825317383 | MAE Test Loss: 43.12287521362305 \n",
      "Epoch: 75490 | MAE Train Loss: 44.36283874511719 | MAE Test Loss: 43.12284851074219 \n",
      "Epoch: 75500 | MAE Train Loss: 44.36249923706055 | MAE Test Loss: 43.12284851074219 \n",
      "Epoch: 75510 | MAE Train Loss: 44.36216735839844 | MAE Test Loss: 43.122825622558594 \n",
      "Epoch: 75520 | MAE Train Loss: 44.36183166503906 | MAE Test Loss: 43.122802734375 \n",
      "Epoch: 75530 | MAE Train Loss: 44.36149597167969 | MAE Test Loss: 43.12277603149414 \n",
      "Epoch: 75540 | MAE Train Loss: 44.36115264892578 | MAE Test Loss: 43.12274932861328 \n",
      "Epoch: 75550 | MAE Train Loss: 44.360816955566406 | MAE Test Loss: 43.12274932861328 \n",
      "Epoch: 75560 | MAE Train Loss: 44.36048126220703 | MAE Test Loss: 43.12273406982422 \n",
      "Epoch: 75570 | MAE Train Loss: 44.360145568847656 | MAE Test Loss: 43.12270736694336 \n",
      "Epoch: 75580 | MAE Train Loss: 44.359806060791016 | MAE Test Loss: 43.1226806640625 \n",
      "Epoch: 75590 | MAE Train Loss: 44.35947036743164 | MAE Test Loss: 43.12265396118164 \n",
      "Epoch: 75600 | MAE Train Loss: 44.359130859375 | MAE Test Loss: 43.122657775878906 \n",
      "Epoch: 75610 | MAE Train Loss: 44.358795166015625 | MAE Test Loss: 43.12263488769531 \n",
      "Epoch: 75620 | MAE Train Loss: 44.35845947265625 | MAE Test Loss: 43.12260818481445 \n",
      "Epoch: 75630 | MAE Train Loss: 44.35811996459961 | MAE Test Loss: 43.122581481933594 \n",
      "Epoch: 75640 | MAE Train Loss: 44.35778045654297 | MAE Test Loss: 43.122554779052734 \n",
      "Epoch: 75650 | MAE Train Loss: 44.357444763183594 | MAE Test Loss: 43.12253189086914 \n",
      "Epoch: 75660 | MAE Train Loss: 44.35710525512695 | MAE Test Loss: 43.122535705566406 \n",
      "Epoch: 75670 | MAE Train Loss: 44.35676574707031 | MAE Test Loss: 43.12251281738281 \n",
      "Epoch: 75680 | MAE Train Loss: 44.35643005371094 | MAE Test Loss: 43.12248611450195 \n",
      "Epoch: 75690 | MAE Train Loss: 44.35609817504883 | MAE Test Loss: 43.122459411621094 \n",
      "Epoch: 75700 | MAE Train Loss: 44.355751037597656 | MAE Test Loss: 43.1224365234375 \n",
      "Epoch: 75710 | MAE Train Loss: 44.35541915893555 | MAE Test Loss: 43.122440338134766 \n",
      "Epoch: 75720 | MAE Train Loss: 44.35508346557617 | MAE Test Loss: 43.12241744995117 \n",
      "Epoch: 75730 | MAE Train Loss: 44.3547477722168 | MAE Test Loss: 43.12238693237305 \n",
      "Epoch: 75740 | MAE Train Loss: 44.354408264160156 | MAE Test Loss: 43.12236785888672 \n",
      "Epoch: 75750 | MAE Train Loss: 44.35407257080078 | MAE Test Loss: 43.122337341308594 \n",
      "Epoch: 75760 | MAE Train Loss: 44.35373306274414 | MAE Test Loss: 43.12234878540039 \n",
      "Epoch: 75770 | MAE Train Loss: 44.3533935546875 | MAE Test Loss: 43.122318267822266 \n",
      "Epoch: 75780 | MAE Train Loss: 44.35306167602539 | MAE Test Loss: 43.12229919433594 \n",
      "Epoch: 75790 | MAE Train Loss: 44.352725982666016 | MAE Test Loss: 43.12227249145508 \n",
      "Epoch: 75800 | MAE Train Loss: 44.352386474609375 | MAE Test Loss: 43.12224197387695 \n",
      "Epoch: 75810 | MAE Train Loss: 44.352046966552734 | MAE Test Loss: 43.122249603271484 \n",
      "Epoch: 75820 | MAE Train Loss: 44.351707458496094 | MAE Test Loss: 43.122222900390625 \n",
      "Epoch: 75830 | MAE Train Loss: 44.351375579833984 | MAE Test Loss: 43.122196197509766 \n",
      "Epoch: 75840 | MAE Train Loss: 44.351036071777344 | MAE Test Loss: 43.12217330932617 \n",
      "Epoch: 75850 | MAE Train Loss: 44.35070037841797 | MAE Test Loss: 43.12214660644531 \n",
      "Epoch: 75860 | MAE Train Loss: 44.35035705566406 | MAE Test Loss: 43.12211990356445 \n",
      "Epoch: 75870 | MAE Train Loss: 44.35002136230469 | MAE Test Loss: 43.122127532958984 \n",
      "Epoch: 75880 | MAE Train Loss: 44.34968566894531 | MAE Test Loss: 43.122100830078125 \n",
      "Epoch: 75890 | MAE Train Loss: 44.34934997558594 | MAE Test Loss: 43.12207794189453 \n",
      "Epoch: 75900 | MAE Train Loss: 44.3490104675293 | MAE Test Loss: 43.122047424316406 \n",
      "Epoch: 75910 | MAE Train Loss: 44.348670959472656 | MAE Test Loss: 43.12202453613281 \n",
      "Epoch: 75920 | MAE Train Loss: 44.34833526611328 | MAE Test Loss: 43.122032165527344 \n",
      "Epoch: 75930 | MAE Train Loss: 44.347999572753906 | MAE Test Loss: 43.122005462646484 \n",
      "Epoch: 75940 | MAE Train Loss: 44.34766387939453 | MAE Test Loss: 43.12200927734375 \n",
      "Epoch: 75950 | MAE Train Loss: 44.347347259521484 | MAE Test Loss: 43.12199020385742 \n",
      "Epoch: 75960 | MAE Train Loss: 44.34703826904297 | MAE Test Loss: 43.12204360961914 \n",
      "Epoch: 75970 | MAE Train Loss: 44.34672546386719 | MAE Test Loss: 43.12205505371094 \n",
      "Epoch: 75980 | MAE Train Loss: 44.34641647338867 | MAE Test Loss: 43.122108459472656 \n",
      "Epoch: 75990 | MAE Train Loss: 44.346107482910156 | MAE Test Loss: 43.12211990356445 \n",
      "Epoch: 76000 | MAE Train Loss: 44.34579849243164 | MAE Test Loss: 43.12217330932617 \n",
      "Epoch: 76010 | MAE Train Loss: 44.34548568725586 | MAE Test Loss: 43.1221809387207 \n",
      "Epoch: 76020 | MAE Train Loss: 44.34517288208008 | MAE Test Loss: 43.122230529785156 \n",
      "Epoch: 76030 | MAE Train Loss: 44.34486389160156 | MAE Test Loss: 43.12226104736328 \n",
      "Epoch: 76040 | MAE Train Loss: 44.34455108642578 | MAE Test Loss: 43.12227249145508 \n",
      "Epoch: 76050 | MAE Train Loss: 44.34424591064453 | MAE Test Loss: 43.12232971191406 \n",
      "Epoch: 76060 | MAE Train Loss: 44.34393310546875 | MAE Test Loss: 43.12234115600586 \n",
      "Epoch: 76070 | MAE Train Loss: 44.343624114990234 | MAE Test Loss: 43.12238693237305 \n",
      "Epoch: 76080 | MAE Train Loss: 44.34331130981445 | MAE Test Loss: 43.12240219116211 \n",
      "Epoch: 76090 | MAE Train Loss: 44.34300231933594 | MAE Test Loss: 43.12245559692383 \n",
      "Epoch: 76100 | MAE Train Loss: 44.34269332885742 | MAE Test Loss: 43.122467041015625 \n",
      "Epoch: 76110 | MAE Train Loss: 44.342384338378906 | MAE Test Loss: 43.12251281738281 \n",
      "Epoch: 76120 | MAE Train Loss: 44.342071533203125 | MAE Test Loss: 43.122528076171875 \n",
      "Epoch: 76130 | MAE Train Loss: 44.341766357421875 | MAE Test Loss: 43.122581481933594 \n",
      "Epoch: 76140 | MAE Train Loss: 44.341453552246094 | MAE Test Loss: 43.12259292602539 \n",
      "Epoch: 76150 | MAE Train Loss: 44.34114456176758 | MAE Test Loss: 43.122642517089844 \n",
      "Epoch: 76160 | MAE Train Loss: 44.34083557128906 | MAE Test Loss: 43.122676849365234 \n",
      "Epoch: 76170 | MAE Train Loss: 44.34052276611328 | MAE Test Loss: 43.122718811035156 \n",
      "Epoch: 76180 | MAE Train Loss: 44.340213775634766 | MAE Test Loss: 43.12273406982422 \n",
      "Epoch: 76190 | MAE Train Loss: 44.33990478515625 | MAE Test Loss: 43.12278747558594 \n",
      "Epoch: 76200 | MAE Train Loss: 44.33959197998047 | MAE Test Loss: 43.1228141784668 \n",
      "Epoch: 76210 | MAE Train Loss: 44.33928298950195 | MAE Test Loss: 43.12284851074219 \n",
      "Epoch: 76220 | MAE Train Loss: 44.33897399902344 | MAE Test Loss: 43.12286376953125 \n",
      "Epoch: 76230 | MAE Train Loss: 44.338661193847656 | MAE Test Loss: 43.1229133605957 \n",
      "Epoch: 76240 | MAE Train Loss: 44.338356018066406 | MAE Test Loss: 43.122928619384766 \n",
      "Epoch: 76250 | MAE Train Loss: 44.33805847167969 | MAE Test Loss: 43.1229362487793 \n",
      "Epoch: 76260 | MAE Train Loss: 44.33776092529297 | MAE Test Loss: 43.12290573120117 \n",
      "Epoch: 76270 | MAE Train Loss: 44.33747100830078 | MAE Test Loss: 43.12287521362305 \n",
      "Epoch: 76280 | MAE Train Loss: 44.337181091308594 | MAE Test Loss: 43.122840881347656 \n",
      "Epoch: 76290 | MAE Train Loss: 44.336891174316406 | MAE Test Loss: 43.1228141784668 \n",
      "Epoch: 76300 | MAE Train Loss: 44.33660125732422 | MAE Test Loss: 43.122779846191406 \n",
      "Epoch: 76310 | MAE Train Loss: 44.336307525634766 | MAE Test Loss: 43.122745513916016 \n",
      "Epoch: 76320 | MAE Train Loss: 44.336021423339844 | MAE Test Loss: 43.12273025512695 \n",
      "Epoch: 76330 | MAE Train Loss: 44.335731506347656 | MAE Test Loss: 43.12269973754883 \n",
      "Epoch: 76340 | MAE Train Loss: 44.3354377746582 | MAE Test Loss: 43.1226692199707 \n",
      "Epoch: 76350 | MAE Train Loss: 44.335147857666016 | MAE Test Loss: 43.122642517089844 \n",
      "Epoch: 76360 | MAE Train Loss: 44.33485794067383 | MAE Test Loss: 43.122642517089844 \n",
      "Epoch: 76370 | MAE Train Loss: 44.33456802368164 | MAE Test Loss: 43.12261199951172 \n",
      "Epoch: 76380 | MAE Train Loss: 44.33428192138672 | MAE Test Loss: 43.12257766723633 \n",
      "Epoch: 76390 | MAE Train Loss: 44.333988189697266 | MAE Test Loss: 43.1225471496582 \n",
      "Epoch: 76400 | MAE Train Loss: 44.333702087402344 | MAE Test Loss: 43.12251281738281 \n",
      "Epoch: 76410 | MAE Train Loss: 44.333412170410156 | MAE Test Loss: 43.122501373291016 \n",
      "Epoch: 76420 | MAE Train Loss: 44.33312225341797 | MAE Test Loss: 43.12247085571289 \n",
      "Epoch: 76430 | MAE Train Loss: 44.332828521728516 | MAE Test Loss: 43.1224365234375 \n",
      "Epoch: 76440 | MAE Train Loss: 44.332542419433594 | MAE Test Loss: 43.122406005859375 \n",
      "Epoch: 76450 | MAE Train Loss: 44.332252502441406 | MAE Test Loss: 43.122371673583984 \n",
      "Epoch: 76460 | MAE Train Loss: 44.33195877075195 | MAE Test Loss: 43.12234115600586 \n",
      "Epoch: 76470 | MAE Train Loss: 44.331668853759766 | MAE Test Loss: 43.122310638427734 \n",
      "Epoch: 76480 | MAE Train Loss: 44.331382751464844 | MAE Test Loss: 43.12228012084961 \n",
      "Epoch: 76490 | MAE Train Loss: 44.331085205078125 | MAE Test Loss: 43.12224578857422 \n",
      "Epoch: 76500 | MAE Train Loss: 44.3307991027832 | MAE Test Loss: 43.12223434448242 \n",
      "Epoch: 76510 | MAE Train Loss: 44.330509185791016 | MAE Test Loss: 43.1222038269043 \n",
      "Epoch: 76520 | MAE Train Loss: 44.330223083496094 | MAE Test Loss: 43.12216567993164 \n",
      "Epoch: 76530 | MAE Train Loss: 44.32992935180664 | MAE Test Loss: 43.12213897705078 \n",
      "Epoch: 76540 | MAE Train Loss: 44.32963562011719 | MAE Test Loss: 43.12214279174805 \n",
      "Epoch: 76550 | MAE Train Loss: 44.329349517822266 | MAE Test Loss: 43.122108459472656 \n",
      "Epoch: 76560 | MAE Train Loss: 44.32905578613281 | MAE Test Loss: 43.12207794189453 \n",
      "Epoch: 76570 | MAE Train Loss: 44.328765869140625 | MAE Test Loss: 43.122047424316406 \n",
      "Epoch: 76580 | MAE Train Loss: 44.3284797668457 | MAE Test Loss: 43.12201690673828 \n",
      "Epoch: 76590 | MAE Train Loss: 44.328182220458984 | MAE Test Loss: 43.12200164794922 \n",
      "Epoch: 76600 | MAE Train Loss: 44.32789611816406 | MAE Test Loss: 43.121971130371094 \n",
      "Epoch: 76610 | MAE Train Loss: 44.32761001586914 | MAE Test Loss: 43.121944427490234 \n",
      "Epoch: 76620 | MAE Train Loss: 44.32731628417969 | MAE Test Loss: 43.12190246582031 \n",
      "Epoch: 76630 | MAE Train Loss: 44.32703399658203 | MAE Test Loss: 43.12187576293945 \n",
      "Epoch: 76640 | MAE Train Loss: 44.32674026489258 | MAE Test Loss: 43.121849060058594 \n",
      "Epoch: 76650 | MAE Train Loss: 44.326446533203125 | MAE Test Loss: 43.12181091308594 \n",
      "Epoch: 76660 | MAE Train Loss: 44.32615661621094 | MAE Test Loss: 43.12178039550781 \n",
      "Epoch: 76670 | MAE Train Loss: 44.325862884521484 | MAE Test Loss: 43.12174987792969 \n",
      "Epoch: 76680 | MAE Train Loss: 44.32558059692383 | MAE Test Loss: 43.121734619140625 \n",
      "Epoch: 76690 | MAE Train Loss: 44.325286865234375 | MAE Test Loss: 43.121707916259766 \n",
      "Epoch: 76700 | MAE Train Loss: 44.32499313354492 | MAE Test Loss: 43.12166976928711 \n",
      "Epoch: 76710 | MAE Train Loss: 44.32470703125 | MAE Test Loss: 43.12164306640625 \n",
      "Epoch: 76720 | MAE Train Loss: 44.32441329956055 | MAE Test Loss: 43.12160873413086 \n",
      "Epoch: 76730 | MAE Train Loss: 44.32412338256836 | MAE Test Loss: 43.121612548828125 \n",
      "Epoch: 76740 | MAE Train Loss: 44.32383728027344 | MAE Test Loss: 43.121585845947266 \n",
      "Epoch: 76750 | MAE Train Loss: 44.32354736328125 | MAE Test Loss: 43.12154769897461 \n",
      "Epoch: 76760 | MAE Train Loss: 44.32325744628906 | MAE Test Loss: 43.121517181396484 \n",
      "Epoch: 76770 | MAE Train Loss: 44.32296371459961 | MAE Test Loss: 43.12150573730469 \n",
      "Epoch: 76780 | MAE Train Loss: 44.32267379760742 | MAE Test Loss: 43.12147521972656 \n",
      "Epoch: 76790 | MAE Train Loss: 44.3223876953125 | MAE Test Loss: 43.12144088745117 \n",
      "Epoch: 76800 | MAE Train Loss: 44.32209396362305 | MAE Test Loss: 43.12140655517578 \n",
      "Epoch: 76810 | MAE Train Loss: 44.321807861328125 | MAE Test Loss: 43.12137985229492 \n",
      "Epoch: 76820 | MAE Train Loss: 44.32151412963867 | MAE Test Loss: 43.121341705322266 \n",
      "Epoch: 76830 | MAE Train Loss: 44.321224212646484 | MAE Test Loss: 43.121315002441406 \n",
      "Epoch: 76840 | MAE Train Loss: 44.32093811035156 | MAE Test Loss: 43.121280670166016 \n",
      "Epoch: 76850 | MAE Train Loss: 44.320640563964844 | MAE Test Loss: 43.121253967285156 \n",
      "Epoch: 76860 | MAE Train Loss: 44.32035827636719 | MAE Test Loss: 43.12123489379883 \n",
      "Epoch: 76870 | MAE Train Loss: 44.320064544677734 | MAE Test Loss: 43.1212043762207 \n",
      "Epoch: 76880 | MAE Train Loss: 44.31977462768555 | MAE Test Loss: 43.121177673339844 \n",
      "Epoch: 76890 | MAE Train Loss: 44.319480895996094 | MAE Test Loss: 43.12114334106445 \n",
      "Epoch: 76900 | MAE Train Loss: 44.319190979003906 | MAE Test Loss: 43.12110900878906 \n",
      "Epoch: 76910 | MAE Train Loss: 44.318904876708984 | MAE Test Loss: 43.12111282348633 \n",
      "Epoch: 76920 | MAE Train Loss: 44.3186149597168 | MAE Test Loss: 43.12108612060547 \n",
      "Epoch: 76930 | MAE Train Loss: 44.31832504272461 | MAE Test Loss: 43.12104797363281 \n",
      "Epoch: 76940 | MAE Train Loss: 44.318031311035156 | MAE Test Loss: 43.12102127075195 \n",
      "Epoch: 76950 | MAE Train Loss: 44.3177375793457 | MAE Test Loss: 43.12100601196289 \n",
      "Epoch: 76960 | MAE Train Loss: 44.31745147705078 | MAE Test Loss: 43.1209716796875 \n",
      "Epoch: 76970 | MAE Train Loss: 44.31716537475586 | MAE Test Loss: 43.120941162109375 \n",
      "Epoch: 76980 | MAE Train Loss: 44.31687545776367 | MAE Test Loss: 43.120914459228516 \n",
      "Epoch: 76990 | MAE Train Loss: 44.31658172607422 | MAE Test Loss: 43.120880126953125 \n",
      "Epoch: 77000 | MAE Train Loss: 44.3162956237793 | MAE Test Loss: 43.120845794677734 \n",
      "Epoch: 77010 | MAE Train Loss: 44.316001892089844 | MAE Test Loss: 43.12081527709961 \n",
      "Epoch: 77020 | MAE Train Loss: 44.315711975097656 | MAE Test Loss: 43.120784759521484 \n",
      "Epoch: 77030 | MAE Train Loss: 44.31542205810547 | MAE Test Loss: 43.12074661254883 \n",
      "Epoch: 77040 | MAE Train Loss: 44.315128326416016 | MAE Test Loss: 43.1207389831543 \n",
      "Epoch: 77050 | MAE Train Loss: 44.314842224121094 | MAE Test Loss: 43.120704650878906 \n",
      "Epoch: 77060 | MAE Train Loss: 44.31455612182617 | MAE Test Loss: 43.12067413330078 \n",
      "Epoch: 77070 | MAE Train Loss: 44.31425857543945 | MAE Test Loss: 43.12063980102539 \n",
      "Epoch: 77080 | MAE Train Loss: 44.313968658447266 | MAE Test Loss: 43.120609283447266 \n",
      "Epoch: 77090 | MAE Train Loss: 44.313682556152344 | MAE Test Loss: 43.1206169128418 \n",
      "Epoch: 77100 | MAE Train Loss: 44.313392639160156 | MAE Test Loss: 43.120582580566406 \n",
      "Epoch: 77110 | MAE Train Loss: 44.31310272216797 | MAE Test Loss: 43.12055206298828 \n",
      "Epoch: 77120 | MAE Train Loss: 44.31281280517578 | MAE Test Loss: 43.120521545410156 \n",
      "Epoch: 77130 | MAE Train Loss: 44.31251907348633 | MAE Test Loss: 43.12049102783203 \n",
      "Epoch: 77140 | MAE Train Loss: 44.31222915649414 | MAE Test Loss: 43.1204719543457 \n",
      "Epoch: 77150 | MAE Train Loss: 44.31194305419922 | MAE Test Loss: 43.12044143676758 \n",
      "Epoch: 77160 | MAE Train Loss: 44.31165313720703 | MAE Test Loss: 43.12041473388672 \n",
      "Epoch: 77170 | MAE Train Loss: 44.311363220214844 | MAE Test Loss: 43.12037658691406 \n",
      "Epoch: 77180 | MAE Train Loss: 44.311073303222656 | MAE Test Loss: 43.1203498840332 \n",
      "Epoch: 77190 | MAE Train Loss: 44.3107795715332 | MAE Test Loss: 43.12031555175781 \n",
      "Epoch: 77200 | MAE Train Loss: 44.310489654541016 | MAE Test Loss: 43.12028884887695 \n",
      "Epoch: 77210 | MAE Train Loss: 44.3101921081543 | MAE Test Loss: 43.1202507019043 \n",
      "Epoch: 77220 | MAE Train Loss: 44.30990982055664 | MAE Test Loss: 43.12022018432617 \n",
      "Epoch: 77230 | MAE Train Loss: 44.30961990356445 | MAE Test Loss: 43.120208740234375 \n",
      "Epoch: 77240 | MAE Train Loss: 44.309329986572266 | MAE Test Loss: 43.12017822265625 \n",
      "Epoch: 77250 | MAE Train Loss: 44.30903625488281 | MAE Test Loss: 43.12014389038086 \n",
      "Epoch: 77260 | MAE Train Loss: 44.30875015258789 | MAE Test Loss: 43.120113372802734 \n",
      "Epoch: 77270 | MAE Train Loss: 44.30845642089844 | MAE Test Loss: 43.120121002197266 \n",
      "Epoch: 77280 | MAE Train Loss: 44.30816650390625 | MAE Test Loss: 43.12008285522461 \n",
      "Epoch: 77290 | MAE Train Loss: 44.30788040161133 | MAE Test Loss: 43.120052337646484 \n",
      "Epoch: 77300 | MAE Train Loss: 44.307586669921875 | MAE Test Loss: 43.120025634765625 \n",
      "Epoch: 77310 | MAE Train Loss: 44.30730056762695 | MAE Test Loss: 43.11998748779297 \n",
      "Epoch: 77320 | MAE Train Loss: 44.3070068359375 | MAE Test Loss: 43.11997604370117 \n",
      "Epoch: 77330 | MAE Train Loss: 44.30671691894531 | MAE Test Loss: 43.11994552612305 \n",
      "Epoch: 77340 | MAE Train Loss: 44.30642318725586 | MAE Test Loss: 43.11990737915039 \n",
      "Epoch: 77350 | MAE Train Loss: 44.30613708496094 | MAE Test Loss: 43.119876861572266 \n",
      "Epoch: 77360 | MAE Train Loss: 44.305850982666016 | MAE Test Loss: 43.119850158691406 \n",
      "Epoch: 77370 | MAE Train Loss: 44.30555725097656 | MAE Test Loss: 43.11981964111328 \n",
      "Epoch: 77380 | MAE Train Loss: 44.305267333984375 | MAE Test Loss: 43.119781494140625 \n",
      "Epoch: 77390 | MAE Train Loss: 44.30497360229492 | MAE Test Loss: 43.119754791259766 \n",
      "Epoch: 77400 | MAE Train Loss: 44.3046875 | MAE Test Loss: 43.119728088378906 \n",
      "Epoch: 77410 | MAE Train Loss: 44.30440139770508 | MAE Test Loss: 43.11970901489258 \n",
      "Epoch: 77420 | MAE Train Loss: 44.304107666015625 | MAE Test Loss: 43.11968231201172 \n",
      "Epoch: 77430 | MAE Train Loss: 44.30381774902344 | MAE Test Loss: 43.11964416503906 \n",
      "Epoch: 77440 | MAE Train Loss: 44.303524017333984 | MAE Test Loss: 43.11961364746094 \n",
      "Epoch: 77450 | MAE Train Loss: 44.3032341003418 | MAE Test Loss: 43.1196174621582 \n",
      "Epoch: 77460 | MAE Train Loss: 44.302947998046875 | MAE Test Loss: 43.11958312988281 \n",
      "Epoch: 77470 | MAE Train Loss: 44.30265426635742 | MAE Test Loss: 43.11955642700195 \n",
      "Epoch: 77480 | MAE Train Loss: 44.3023681640625 | MAE Test Loss: 43.11952590942383 \n",
      "Epoch: 77490 | MAE Train Loss: 44.30207443237305 | MAE Test Loss: 43.1194953918457 \n",
      "Epoch: 77500 | MAE Train Loss: 44.30178451538086 | MAE Test Loss: 43.119476318359375 \n",
      "Epoch: 77510 | MAE Train Loss: 44.301490783691406 | MAE Test Loss: 43.11944580078125 \n",
      "Epoch: 77520 | MAE Train Loss: 44.30120849609375 | MAE Test Loss: 43.119441986083984 \n",
      "Epoch: 77530 | MAE Train Loss: 44.30092239379883 | MAE Test Loss: 43.11940383911133 \n",
      "Epoch: 77540 | MAE Train Loss: 44.300636291503906 | MAE Test Loss: 43.11930847167969 \n",
      "Epoch: 77550 | MAE Train Loss: 44.30035400390625 | MAE Test Loss: 43.1192741394043 \n",
      "Epoch: 77560 | MAE Train Loss: 44.300071716308594 | MAE Test Loss: 43.119232177734375 \n",
      "Epoch: 77570 | MAE Train Loss: 44.29978942871094 | MAE Test Loss: 43.119163513183594 \n",
      "Epoch: 77580 | MAE Train Loss: 44.299503326416016 | MAE Test Loss: 43.119117736816406 \n",
      "Epoch: 77590 | MAE Train Loss: 44.299224853515625 | MAE Test Loss: 43.119049072265625 \n",
      "Epoch: 77600 | MAE Train Loss: 44.29894256591797 | MAE Test Loss: 43.1190071105957 \n",
      "Epoch: 77610 | MAE Train Loss: 44.29865646362305 | MAE Test Loss: 43.11894226074219 \n",
      "Epoch: 77620 | MAE Train Loss: 44.298370361328125 | MAE Test Loss: 43.118900299072266 \n",
      "Epoch: 77630 | MAE Train Loss: 44.29808807373047 | MAE Test Loss: 43.11882781982422 \n",
      "Epoch: 77640 | MAE Train Loss: 44.29780578613281 | MAE Test Loss: 43.11878967285156 \n",
      "Epoch: 77650 | MAE Train Loss: 44.297523498535156 | MAE Test Loss: 43.118717193603516 \n",
      "Epoch: 77660 | MAE Train Loss: 44.2972412109375 | MAE Test Loss: 43.118675231933594 \n",
      "Epoch: 77670 | MAE Train Loss: 44.29695510864258 | MAE Test Loss: 43.11861038208008 \n",
      "Epoch: 77680 | MAE Train Loss: 44.29667663574219 | MAE Test Loss: 43.11856460571289 \n",
      "Epoch: 77690 | MAE Train Loss: 44.296390533447266 | MAE Test Loss: 43.118499755859375 \n",
      "Epoch: 77700 | MAE Train Loss: 44.296112060546875 | MAE Test Loss: 43.11845397949219 \n",
      "Epoch: 77710 | MAE Train Loss: 44.29582214355469 | MAE Test Loss: 43.118412017822266 \n",
      "Epoch: 77720 | MAE Train Loss: 44.2955436706543 | MAE Test Loss: 43.118343353271484 \n",
      "Epoch: 77730 | MAE Train Loss: 44.295257568359375 | MAE Test Loss: 43.11830520629883 \n",
      "Epoch: 77740 | MAE Train Loss: 44.294979095458984 | MAE Test Loss: 43.11823654174805 \n",
      "Epoch: 77750 | MAE Train Loss: 44.29469299316406 | MAE Test Loss: 43.11819076538086 \n",
      "Epoch: 77760 | MAE Train Loss: 44.294410705566406 | MAE Test Loss: 43.118141174316406 \n",
      "Epoch: 77770 | MAE Train Loss: 44.29412841796875 | MAE Test Loss: 43.118064880371094 \n",
      "Epoch: 77780 | MAE Train Loss: 44.29384231567383 | MAE Test Loss: 43.11802291870117 \n",
      "Epoch: 77790 | MAE Train Loss: 44.293556213378906 | MAE Test Loss: 43.117958068847656 \n",
      "Epoch: 77800 | MAE Train Loss: 44.29328155517578 | MAE Test Loss: 43.11791229248047 \n",
      "Epoch: 77810 | MAE Train Loss: 44.29299545288086 | MAE Test Loss: 43.11784744262695 \n",
      "Epoch: 77820 | MAE Train Loss: 44.2927131652832 | MAE Test Loss: 43.117801666259766 \n",
      "Epoch: 77830 | MAE Train Loss: 44.29242706298828 | MAE Test Loss: 43.117740631103516 \n",
      "Epoch: 77840 | MAE Train Loss: 44.29214859008789 | MAE Test Loss: 43.11769104003906 \n",
      "Epoch: 77850 | MAE Train Loss: 44.29186248779297 | MAE Test Loss: 43.11762237548828 \n",
      "Epoch: 77860 | MAE Train Loss: 44.29158401489258 | MAE Test Loss: 43.117576599121094 \n",
      "Epoch: 77870 | MAE Train Loss: 44.29129409790039 | MAE Test Loss: 43.1175422668457 \n",
      "Epoch: 77880 | MAE Train Loss: 44.291015625 | MAE Test Loss: 43.117469787597656 \n",
      "Epoch: 77890 | MAE Train Loss: 44.29072952270508 | MAE Test Loss: 43.117431640625 \n",
      "Epoch: 77900 | MAE Train Loss: 44.29045104980469 | MAE Test Loss: 43.11735916137695 \n",
      "Epoch: 77910 | MAE Train Loss: 44.290164947509766 | MAE Test Loss: 43.1173210144043 \n",
      "Epoch: 77920 | MAE Train Loss: 44.28988265991211 | MAE Test Loss: 43.11724853515625 \n",
      "Epoch: 77930 | MAE Train Loss: 44.28960037231445 | MAE Test Loss: 43.117210388183594 \n",
      "Epoch: 77940 | MAE Train Loss: 44.28931427001953 | MAE Test Loss: 43.11713409423828 \n",
      "Epoch: 77950 | MAE Train Loss: 44.28902816772461 | MAE Test Loss: 43.117095947265625 \n",
      "Epoch: 77960 | MAE Train Loss: 44.28874969482422 | MAE Test Loss: 43.117027282714844 \n",
      "Epoch: 77970 | MAE Train Loss: 44.28847122192383 | MAE Test Loss: 43.11698532104492 \n",
      "Epoch: 77980 | MAE Train Loss: 44.28818130493164 | MAE Test Loss: 43.11690902709961 \n",
      "Epoch: 77990 | MAE Train Loss: 44.287899017333984 | MAE Test Loss: 43.11687469482422 \n",
      "Epoch: 78000 | MAE Train Loss: 44.287620544433594 | MAE Test Loss: 43.11680221557617 \n",
      "Epoch: 78010 | MAE Train Loss: 44.28733444213867 | MAE Test Loss: 43.116764068603516 \n",
      "Epoch: 78020 | MAE Train Loss: 44.287052154541016 | MAE Test Loss: 43.116703033447266 \n",
      "Epoch: 78030 | MAE Train Loss: 44.286766052246094 | MAE Test Loss: 43.11666488647461 \n",
      "Epoch: 78040 | MAE Train Loss: 44.2864875793457 | MAE Test Loss: 43.11659240722656 \n",
      "Epoch: 78050 | MAE Train Loss: 44.28620147705078 | MAE Test Loss: 43.11655807495117 \n",
      "Epoch: 78060 | MAE Train Loss: 44.28592300415039 | MAE Test Loss: 43.11648941040039 \n",
      "Epoch: 78070 | MAE Train Loss: 44.28563690185547 | MAE Test Loss: 43.11643981933594 \n",
      "Epoch: 78080 | MAE Train Loss: 44.28535079956055 | MAE Test Loss: 43.11637496948242 \n",
      "Epoch: 78090 | MAE Train Loss: 44.28506851196289 | MAE Test Loss: 43.116329193115234 \n",
      "Epoch: 78100 | MAE Train Loss: 44.2847900390625 | MAE Test Loss: 43.11626434326172 \n",
      "Epoch: 78110 | MAE Train Loss: 44.28450393676758 | MAE Test Loss: 43.11622619628906 \n",
      "Epoch: 78120 | MAE Train Loss: 44.28422164916992 | MAE Test Loss: 43.11614990234375 \n",
      "Epoch: 78130 | MAE Train Loss: 44.283931732177734 | MAE Test Loss: 43.116111755371094 \n",
      "Epoch: 78140 | MAE Train Loss: 44.28364944458008 | MAE Test Loss: 43.11603927612305 \n",
      "Epoch: 78150 | MAE Train Loss: 44.28337478637695 | MAE Test Loss: 43.11600112915039 \n",
      "Epoch: 78160 | MAE Train Loss: 44.28308868408203 | MAE Test Loss: 43.115928649902344 \n",
      "Epoch: 78170 | MAE Train Loss: 44.282806396484375 | MAE Test Loss: 43.11589050292969 \n",
      "Epoch: 78180 | MAE Train Loss: 44.28252029418945 | MAE Test Loss: 43.11581802368164 \n",
      "Epoch: 78190 | MAE Train Loss: 44.28224182128906 | MAE Test Loss: 43.11577606201172 \n",
      "Epoch: 78200 | MAE Train Loss: 44.28195571899414 | MAE Test Loss: 43.11573791503906 \n",
      "Epoch: 78210 | MAE Train Loss: 44.28167724609375 | MAE Test Loss: 43.115665435791016 \n",
      "Epoch: 78220 | MAE Train Loss: 44.28139114379883 | MAE Test Loss: 43.1156120300293 \n",
      "Epoch: 78230 | MAE Train Loss: 44.281105041503906 | MAE Test Loss: 43.115570068359375 \n",
      "Epoch: 78240 | MAE Train Loss: 44.280826568603516 | MAE Test Loss: 43.115501403808594 \n",
      "Epoch: 78250 | MAE Train Loss: 44.280540466308594 | MAE Test Loss: 43.11545944213867 \n",
      "Epoch: 78260 | MAE Train Loss: 44.28025817871094 | MAE Test Loss: 43.115386962890625 \n",
      "Epoch: 78270 | MAE Train Loss: 44.27997589111328 | MAE Test Loss: 43.11534881591797 \n",
      "Epoch: 78280 | MAE Train Loss: 44.27968978881836 | MAE Test Loss: 43.11528015136719 \n",
      "Epoch: 78290 | MAE Train Loss: 44.27941131591797 | MAE Test Loss: 43.115234375 \n",
      "Epoch: 78300 | MAE Train Loss: 44.27912521362305 | MAE Test Loss: 43.11516189575195 \n",
      "Epoch: 78310 | MAE Train Loss: 44.27884292602539 | MAE Test Loss: 43.1151237487793 \n",
      "Epoch: 78320 | MAE Train Loss: 44.27855682373047 | MAE Test Loss: 43.115055084228516 \n",
      "Epoch: 78330 | MAE Train Loss: 44.27827453613281 | MAE Test Loss: 43.115013122558594 \n",
      "Epoch: 78340 | MAE Train Loss: 44.277992248535156 | MAE Test Loss: 43.11494064331055 \n",
      "Epoch: 78350 | MAE Train Loss: 44.277713775634766 | MAE Test Loss: 43.114906311035156 \n",
      "Epoch: 78360 | MAE Train Loss: 44.27742385864258 | MAE Test Loss: 43.11486053466797 \n",
      "Epoch: 78370 | MAE Train Loss: 44.27714538574219 | MAE Test Loss: 43.11479187011719 \n",
      "Epoch: 78380 | MAE Train Loss: 44.2768669128418 | MAE Test Loss: 43.1147346496582 \n",
      "Epoch: 78390 | MAE Train Loss: 44.27657699584961 | MAE Test Loss: 43.11469650268555 \n",
      "Epoch: 78400 | MAE Train Loss: 44.27629852294922 | MAE Test Loss: 43.114627838134766 \n",
      "Epoch: 78410 | MAE Train Loss: 44.27600860595703 | MAE Test Loss: 43.114585876464844 \n",
      "Epoch: 78420 | MAE Train Loss: 44.275726318359375 | MAE Test Loss: 43.11451721191406 \n",
      "Epoch: 78430 | MAE Train Loss: 44.27544403076172 | MAE Test Loss: 43.11447525024414 \n",
      "Epoch: 78440 | MAE Train Loss: 44.27516555786133 | MAE Test Loss: 43.114402770996094 \n",
      "Epoch: 78450 | MAE Train Loss: 44.274879455566406 | MAE Test Loss: 43.11436462402344 \n",
      "Epoch: 78460 | MAE Train Loss: 44.27459716796875 | MAE Test Loss: 43.114295959472656 \n",
      "Epoch: 78470 | MAE Train Loss: 44.274314880371094 | MAE Test Loss: 43.114253997802734 \n",
      "Epoch: 78480 | MAE Train Loss: 44.27402877807617 | MAE Test Loss: 43.11418151855469 \n",
      "Epoch: 78490 | MAE Train Loss: 44.27375030517578 | MAE Test Loss: 43.114139556884766 \n",
      "Epoch: 78500 | MAE Train Loss: 44.27346420288086 | MAE Test Loss: 43.11406707763672 \n",
      "Epoch: 78510 | MAE Train Loss: 44.27318572998047 | MAE Test Loss: 43.11402893066406 \n",
      "Epoch: 78520 | MAE Train Loss: 44.27289962768555 | MAE Test Loss: 43.11398696899414 \n",
      "Epoch: 78530 | MAE Train Loss: 44.27261734008789 | MAE Test Loss: 43.11391830444336 \n",
      "Epoch: 78540 | MAE Train Loss: 44.27233123779297 | MAE Test Loss: 43.1138801574707 \n",
      "Epoch: 78550 | MAE Train Loss: 44.27205276489258 | MAE Test Loss: 43.11380386352539 \n",
      "Epoch: 78560 | MAE Train Loss: 44.271766662597656 | MAE Test Loss: 43.113765716552734 \n",
      "Epoch: 78570 | MAE Train Loss: 44.271484375 | MAE Test Loss: 43.11369705200195 \n",
      "Epoch: 78580 | MAE Train Loss: 44.27119827270508 | MAE Test Loss: 43.11365509033203 \n",
      "Epoch: 78590 | MAE Train Loss: 44.27091598510742 | MAE Test Loss: 43.113582611083984 \n",
      "Epoch: 78600 | MAE Train Loss: 44.27063751220703 | MAE Test Loss: 43.11354446411133 \n",
      "Epoch: 78610 | MAE Train Loss: 44.27035140991211 | MAE Test Loss: 43.11347579956055 \n",
      "Epoch: 78620 | MAE Train Loss: 44.27006912231445 | MAE Test Loss: 43.113433837890625 \n",
      "Epoch: 78630 | MAE Train Loss: 44.269779205322266 | MAE Test Loss: 43.113365173339844 \n",
      "Epoch: 78640 | MAE Train Loss: 44.269500732421875 | MAE Test Loss: 43.11330795288086 \n",
      "Epoch: 78650 | MAE Train Loss: 44.269222259521484 | MAE Test Loss: 43.1132698059082 \n",
      "Epoch: 78660 | MAE Train Loss: 44.26893615722656 | MAE Test Loss: 43.11319351196289 \n",
      "Epoch: 78670 | MAE Train Loss: 44.26865768432617 | MAE Test Loss: 43.11315155029297 \n",
      "Epoch: 78680 | MAE Train Loss: 44.268367767333984 | MAE Test Loss: 43.11311721801758 \n",
      "Epoch: 78690 | MAE Train Loss: 44.26808547973633 | MAE Test Loss: 43.11304473876953 \n",
      "Epoch: 78700 | MAE Train Loss: 44.26780319213867 | MAE Test Loss: 43.11300277709961 \n",
      "Epoch: 78710 | MAE Train Loss: 44.267520904541016 | MAE Test Loss: 43.11293411254883 \n",
      "Epoch: 78720 | MAE Train Loss: 44.267242431640625 | MAE Test Loss: 43.11289596557617 \n",
      "Epoch: 78730 | MAE Train Loss: 44.26695251464844 | MAE Test Loss: 43.112815856933594 \n",
      "Epoch: 78740 | MAE Train Loss: 44.26667022705078 | MAE Test Loss: 43.1127815246582 \n",
      "Epoch: 78750 | MAE Train Loss: 44.26639175415039 | MAE Test Loss: 43.11271667480469 \n",
      "Epoch: 78760 | MAE Train Loss: 44.2661018371582 | MAE Test Loss: 43.1126708984375 \n",
      "Epoch: 78770 | MAE Train Loss: 44.26581954956055 | MAE Test Loss: 43.11260223388672 \n",
      "Epoch: 78780 | MAE Train Loss: 44.265541076660156 | MAE Test Loss: 43.1125602722168 \n",
      "Epoch: 78790 | MAE Train Loss: 44.265254974365234 | MAE Test Loss: 43.11248779296875 \n",
      "Epoch: 78800 | MAE Train Loss: 44.264976501464844 | MAE Test Loss: 43.112449645996094 \n",
      "Epoch: 78810 | MAE Train Loss: 44.264686584472656 | MAE Test Loss: 43.11237716674805 \n",
      "Epoch: 78820 | MAE Train Loss: 44.264408111572266 | MAE Test Loss: 43.11233139038086 \n",
      "Epoch: 78830 | MAE Train Loss: 44.26411819458008 | MAE Test Loss: 43.11229705810547 \n",
      "Epoch: 78840 | MAE Train Loss: 44.26383972167969 | MAE Test Loss: 43.112239837646484 \n",
      "Epoch: 78850 | MAE Train Loss: 44.26355743408203 | MAE Test Loss: 43.11216735839844 \n",
      "Epoch: 78860 | MAE Train Loss: 44.263275146484375 | MAE Test Loss: 43.11212921142578 \n",
      "Epoch: 78870 | MAE Train Loss: 44.262996673583984 | MAE Test Loss: 43.112060546875 \n",
      "Epoch: 78880 | MAE Train Loss: 44.26271057128906 | MAE Test Loss: 43.11201858520508 \n",
      "Epoch: 78890 | MAE Train Loss: 44.262428283691406 | MAE Test Loss: 43.11194610595703 \n",
      "Epoch: 78900 | MAE Train Loss: 44.262142181396484 | MAE Test Loss: 43.111907958984375 \n",
      "Epoch: 78910 | MAE Train Loss: 44.26185607910156 | MAE Test Loss: 43.11183547973633 \n",
      "Epoch: 78920 | MAE Train Loss: 44.26157760620117 | MAE Test Loss: 43.11179733276367 \n",
      "Epoch: 78930 | MAE Train Loss: 44.26129150390625 | MAE Test Loss: 43.111724853515625 \n",
      "Epoch: 78940 | MAE Train Loss: 44.26101303100586 | MAE Test Loss: 43.1116828918457 \n",
      "Epoch: 78950 | MAE Train Loss: 44.26072692871094 | MAE Test Loss: 43.11161804199219 \n",
      "Epoch: 78960 | MAE Train Loss: 44.26044464111328 | MAE Test Loss: 43.111576080322266 \n",
      "Epoch: 78970 | MAE Train Loss: 44.260162353515625 | MAE Test Loss: 43.111507415771484 \n",
      "Epoch: 78980 | MAE Train Loss: 44.259883880615234 | MAE Test Loss: 43.11146545410156 \n",
      "Epoch: 78990 | MAE Train Loss: 44.25959014892578 | MAE Test Loss: 43.111419677734375 \n",
      "Epoch: 79000 | MAE Train Loss: 44.259315490722656 | MAE Test Loss: 43.111351013183594 \n",
      "Epoch: 79010 | MAE Train Loss: 44.25902557373047 | MAE Test Loss: 43.11130905151367 \n",
      "Epoch: 79020 | MAE Train Loss: 44.25874710083008 | MAE Test Loss: 43.11124038696289 \n",
      "Epoch: 79030 | MAE Train Loss: 44.258460998535156 | MAE Test Loss: 43.11119842529297 \n",
      "Epoch: 79040 | MAE Train Loss: 44.2581787109375 | MAE Test Loss: 43.11117935180664 \n",
      "Epoch: 79050 | MAE Train Loss: 44.257896423339844 | MAE Test Loss: 43.111209869384766 \n",
      "Epoch: 79060 | MAE Train Loss: 44.25761032104492 | MAE Test Loss: 43.11128616333008 \n",
      "Epoch: 79070 | MAE Train Loss: 44.25732421875 | MAE Test Loss: 43.11127471923828 \n",
      "Epoch: 79080 | MAE Train Loss: 44.257049560546875 | MAE Test Loss: 43.111351013183594 \n",
      "Epoch: 79090 | MAE Train Loss: 44.25676345825195 | MAE Test Loss: 43.111331939697266 \n",
      "Epoch: 79100 | MAE Train Loss: 44.2564811706543 | MAE Test Loss: 43.11141586303711 \n",
      "Epoch: 79110 | MAE Train Loss: 44.256195068359375 | MAE Test Loss: 43.11140060424805 \n",
      "Epoch: 79120 | MAE Train Loss: 44.25592041015625 | MAE Test Loss: 43.11150360107422 \n",
      "Epoch: 79130 | MAE Train Loss: 44.25563430786133 | MAE Test Loss: 43.11147689819336 \n",
      "Epoch: 79140 | MAE Train Loss: 44.25535202026367 | MAE Test Loss: 43.11159896850586 \n",
      "Epoch: 79150 | MAE Train Loss: 44.255062103271484 | MAE Test Loss: 43.111724853515625 \n",
      "Epoch: 79160 | MAE Train Loss: 44.25478744506836 | MAE Test Loss: 43.1116943359375 \n",
      "Epoch: 79170 | MAE Train Loss: 44.25450134277344 | MAE Test Loss: 43.11181640625 \n",
      "Epoch: 79180 | MAE Train Loss: 44.25421905517578 | MAE Test Loss: 43.111785888671875 \n",
      "Epoch: 79190 | MAE Train Loss: 44.25393295288086 | MAE Test Loss: 43.11191177368164 \n",
      "Epoch: 79200 | MAE Train Loss: 44.25365447998047 | MAE Test Loss: 43.11188507080078 \n",
      "Epoch: 79210 | MAE Train Loss: 44.25336456298828 | MAE Test Loss: 43.112003326416016 \n",
      "Epoch: 79220 | MAE Train Loss: 44.25308609008789 | MAE Test Loss: 43.11197280883789 \n",
      "Epoch: 79230 | MAE Train Loss: 44.252803802490234 | MAE Test Loss: 43.11209487915039 \n",
      "Epoch: 79240 | MAE Train Loss: 44.25252151489258 | MAE Test Loss: 43.112064361572266 \n",
      "Epoch: 79250 | MAE Train Loss: 44.252235412597656 | MAE Test Loss: 43.1121940612793 \n",
      "Epoch: 79260 | MAE Train Loss: 44.251953125 | MAE Test Loss: 43.11216354370117 \n",
      "Epoch: 79270 | MAE Train Loss: 44.251670837402344 | MAE Test Loss: 43.112281799316406 \n",
      "Epoch: 79280 | MAE Train Loss: 44.25138473510742 | MAE Test Loss: 43.11225128173828 \n",
      "Epoch: 79290 | MAE Train Loss: 44.251102447509766 | MAE Test Loss: 43.11237716674805 \n",
      "Epoch: 79300 | MAE Train Loss: 44.25082015991211 | MAE Test Loss: 43.11235046386719 \n",
      "Epoch: 79310 | MAE Train Loss: 44.25053787231445 | MAE Test Loss: 43.11247253417969 \n",
      "Epoch: 79320 | MAE Train Loss: 44.25025177001953 | MAE Test Loss: 43.11259460449219 \n",
      "Epoch: 79330 | MAE Train Loss: 44.24997329711914 | MAE Test Loss: 43.11256408691406 \n",
      "Epoch: 79340 | MAE Train Loss: 44.249691009521484 | MAE Test Loss: 43.11268997192383 \n",
      "Epoch: 79350 | MAE Train Loss: 44.2494010925293 | MAE Test Loss: 43.1126594543457 \n",
      "Epoch: 79360 | MAE Train Loss: 44.249122619628906 | MAE Test Loss: 43.11278533935547 \n",
      "Epoch: 79370 | MAE Train Loss: 44.24884033203125 | MAE Test Loss: 43.11274719238281 \n",
      "Epoch: 79380 | MAE Train Loss: 44.24855422973633 | MAE Test Loss: 43.112876892089844 \n",
      "Epoch: 79390 | MAE Train Loss: 44.24827194213867 | MAE Test Loss: 43.11284637451172 \n",
      "Epoch: 79400 | MAE Train Loss: 44.24799346923828 | MAE Test Loss: 43.112972259521484 \n",
      "Epoch: 79410 | MAE Train Loss: 44.247703552246094 | MAE Test Loss: 43.11294174194336 \n",
      "Epoch: 79420 | MAE Train Loss: 44.24742889404297 | MAE Test Loss: 43.11306381225586 \n",
      "Epoch: 79430 | MAE Train Loss: 44.24713897705078 | MAE Test Loss: 43.113033294677734 \n",
      "Epoch: 79440 | MAE Train Loss: 44.246856689453125 | MAE Test Loss: 43.1131591796875 \n",
      "Epoch: 79450 | MAE Train Loss: 44.24657440185547 | MAE Test Loss: 43.113128662109375 \n",
      "Epoch: 79460 | MAE Train Loss: 44.24628829956055 | MAE Test Loss: 43.113250732421875 \n",
      "Epoch: 79470 | MAE Train Loss: 44.246009826660156 | MAE Test Loss: 43.11337661743164 \n",
      "Epoch: 79480 | MAE Train Loss: 44.2457275390625 | MAE Test Loss: 43.113346099853516 \n",
      "Epoch: 79490 | MAE Train Loss: 44.24544143676758 | MAE Test Loss: 43.113468170166016 \n",
      "Epoch: 79500 | MAE Train Loss: 44.24516296386719 | MAE Test Loss: 43.113441467285156 \n",
      "Epoch: 79510 | MAE Train Loss: 44.244873046875 | MAE Test Loss: 43.113563537597656 \n",
      "Epoch: 79520 | MAE Train Loss: 44.24458694458008 | MAE Test Loss: 43.113529205322266 \n",
      "Epoch: 79530 | MAE Train Loss: 44.24430847167969 | MAE Test Loss: 43.1136589050293 \n",
      "Epoch: 79540 | MAE Train Loss: 44.24402618408203 | MAE Test Loss: 43.11362838745117 \n",
      "Epoch: 79550 | MAE Train Loss: 44.243743896484375 | MAE Test Loss: 43.113746643066406 \n",
      "Epoch: 79560 | MAE Train Loss: 44.24346160888672 | MAE Test Loss: 43.11371994018555 \n",
      "Epoch: 79570 | MAE Train Loss: 44.24317932128906 | MAE Test Loss: 43.11384201049805 \n",
      "Epoch: 79580 | MAE Train Loss: 44.242897033691406 | MAE Test Loss: 43.11381149291992 \n",
      "Epoch: 79590 | MAE Train Loss: 44.24261474609375 | MAE Test Loss: 43.11394119262695 \n",
      "Epoch: 79600 | MAE Train Loss: 44.24232482910156 | MAE Test Loss: 43.11390686035156 \n",
      "Epoch: 79610 | MAE Train Loss: 44.24205017089844 | MAE Test Loss: 43.11402893066406 \n",
      "Epoch: 79620 | MAE Train Loss: 44.24176025390625 | MAE Test Loss: 43.114158630371094 \n",
      "Epoch: 79630 | MAE Train Loss: 44.241485595703125 | MAE Test Loss: 43.1141242980957 \n",
      "Epoch: 79640 | MAE Train Loss: 44.2412109375 | MAE Test Loss: 43.11408615112305 \n",
      "Epoch: 79650 | MAE Train Loss: 44.240936279296875 | MAE Test Loss: 43.113887786865234 \n",
      "Epoch: 79660 | MAE Train Loss: 44.24067687988281 | MAE Test Loss: 43.11384582519531 \n",
      "Epoch: 79670 | MAE Train Loss: 44.24040985107422 | MAE Test Loss: 43.11363983154297 \n",
      "Epoch: 79680 | MAE Train Loss: 44.240142822265625 | MAE Test Loss: 43.11359786987305 \n",
      "Epoch: 79690 | MAE Train Loss: 44.23988342285156 | MAE Test Loss: 43.11339569091797 \n",
      "Epoch: 79700 | MAE Train Loss: 44.23960876464844 | MAE Test Loss: 43.113197326660156 \n",
      "Epoch: 79710 | MAE Train Loss: 44.239349365234375 | MAE Test Loss: 43.113155364990234 \n",
      "Epoch: 79720 | MAE Train Loss: 44.23908233642578 | MAE Test Loss: 43.112953186035156 \n",
      "Epoch: 79730 | MAE Train Loss: 44.23881530761719 | MAE Test Loss: 43.11290740966797 \n",
      "Epoch: 79740 | MAE Train Loss: 44.238548278808594 | MAE Test Loss: 43.112709045410156 \n",
      "Epoch: 79750 | MAE Train Loss: 44.23829650878906 | MAE Test Loss: 43.11269760131836 \n",
      "Epoch: 79760 | MAE Train Loss: 44.23804473876953 | MAE Test Loss: 43.112850189208984 \n",
      "Epoch: 79770 | MAE Train Loss: 44.237796783447266 | MAE Test Loss: 43.11284255981445 \n",
      "Epoch: 79780 | MAE Train Loss: 44.237552642822266 | MAE Test Loss: 43.112831115722656 \n",
      "Epoch: 79790 | MAE Train Loss: 44.2372932434082 | MAE Test Loss: 43.112823486328125 \n",
      "Epoch: 79800 | MAE Train Loss: 44.2370491027832 | MAE Test Loss: 43.112979888916016 \n",
      "Epoch: 79810 | MAE Train Loss: 44.23679733276367 | MAE Test Loss: 43.11296844482422 \n",
      "Epoch: 79820 | MAE Train Loss: 44.23654556274414 | MAE Test Loss: 43.11295700073242 \n",
      "Epoch: 79830 | MAE Train Loss: 44.23629379272461 | MAE Test Loss: 43.11310958862305 \n",
      "Epoch: 79840 | MAE Train Loss: 44.23604202270508 | MAE Test Loss: 43.11310577392578 \n",
      "Epoch: 79850 | MAE Train Loss: 44.23579025268555 | MAE Test Loss: 43.113094329833984 \n",
      "Epoch: 79860 | MAE Train Loss: 44.235538482666016 | MAE Test Loss: 43.11308288574219 \n",
      "Epoch: 79870 | MAE Train Loss: 44.23529052734375 | MAE Test Loss: 43.11323547363281 \n",
      "Epoch: 79880 | MAE Train Loss: 44.235042572021484 | MAE Test Loss: 43.11322784423828 \n",
      "Epoch: 79890 | MAE Train Loss: 44.23479080200195 | MAE Test Loss: 43.113216400146484 \n",
      "Epoch: 79900 | MAE Train Loss: 44.23453903198242 | MAE Test Loss: 43.11337661743164 \n",
      "Epoch: 79910 | MAE Train Loss: 44.234291076660156 | MAE Test Loss: 43.113365173339844 \n",
      "Epoch: 79920 | MAE Train Loss: 44.234039306640625 | MAE Test Loss: 43.11335372924805 \n",
      "Epoch: 79930 | MAE Train Loss: 44.23377990722656 | MAE Test Loss: 43.113346099853516 \n",
      "Epoch: 79940 | MAE Train Loss: 44.23353576660156 | MAE Test Loss: 43.113494873046875 \n",
      "Epoch: 79950 | MAE Train Loss: 44.23329162597656 | MAE Test Loss: 43.11349105834961 \n",
      "Epoch: 79960 | MAE Train Loss: 44.2330322265625 | MAE Test Loss: 43.11347961425781 \n",
      "Epoch: 79970 | MAE Train Loss: 44.2327880859375 | MAE Test Loss: 43.113548278808594 \n",
      "Epoch: 79980 | MAE Train Loss: 44.23252868652344 | MAE Test Loss: 43.11354064941406 \n",
      "Epoch: 79990 | MAE Train Loss: 44.232276916503906 | MAE Test Loss: 43.11369323730469 \n",
      "Epoch: 80000 | MAE Train Loss: 44.232032775878906 | MAE Test Loss: 43.11368179321289 \n",
      "Epoch: 80010 | MAE Train Loss: 44.231781005859375 | MAE Test Loss: 43.113677978515625 \n",
      "Epoch: 80020 | MAE Train Loss: 44.23152542114258 | MAE Test Loss: 43.11366653442383 \n",
      "Epoch: 80030 | MAE Train Loss: 44.23127746582031 | MAE Test Loss: 43.11382293701172 \n",
      "Epoch: 80040 | MAE Train Loss: 44.23102569580078 | MAE Test Loss: 43.11381149291992 \n",
      "Epoch: 80050 | MAE Train Loss: 44.230777740478516 | MAE Test Loss: 43.11380386352539 \n",
      "Epoch: 80060 | MAE Train Loss: 44.230525970458984 | MAE Test Loss: 43.11395263671875 \n",
      "Epoch: 80070 | MAE Train Loss: 44.230281829833984 | MAE Test Loss: 43.113948822021484 \n",
      "Epoch: 80080 | MAE Train Loss: 44.23002624511719 | MAE Test Loss: 43.11393356323242 \n",
      "Epoch: 80090 | MAE Train Loss: 44.22977066040039 | MAE Test Loss: 43.113922119140625 \n",
      "Epoch: 80100 | MAE Train Loss: 44.229522705078125 | MAE Test Loss: 43.11408233642578 \n",
      "Epoch: 80110 | MAE Train Loss: 44.229270935058594 | MAE Test Loss: 43.11415481567383 \n",
      "Epoch: 80120 | MAE Train Loss: 44.22902297973633 | MAE Test Loss: 43.1141471862793 \n",
      "Epoch: 80130 | MAE Train Loss: 44.22877502441406 | MAE Test Loss: 43.1141357421875 \n",
      "Epoch: 80140 | MAE Train Loss: 44.228519439697266 | MAE Test Loss: 43.1141242980957 \n",
      "Epoch: 80150 | MAE Train Loss: 44.228267669677734 | MAE Test Loss: 43.114280700683594 \n",
      "Epoch: 80160 | MAE Train Loss: 44.228023529052734 | MAE Test Loss: 43.11426544189453 \n",
      "Epoch: 80170 | MAE Train Loss: 44.22776794433594 | MAE Test Loss: 43.1142578125 \n",
      "Epoch: 80180 | MAE Train Loss: 44.227516174316406 | MAE Test Loss: 43.114410400390625 \n",
      "Epoch: 80190 | MAE Train Loss: 44.227264404296875 | MAE Test Loss: 43.114402770996094 \n",
      "Epoch: 80200 | MAE Train Loss: 44.227020263671875 | MAE Test Loss: 43.114479064941406 \n",
      "Epoch: 80210 | MAE Train Loss: 44.22676086425781 | MAE Test Loss: 43.11446762084961 \n",
      "Epoch: 80220 | MAE Train Loss: 44.22651672363281 | MAE Test Loss: 43.11445617675781 \n",
      "Epoch: 80230 | MAE Train Loss: 44.226261138916016 | MAE Test Loss: 43.11444854736328 \n",
      "Epoch: 80240 | MAE Train Loss: 44.22601318359375 | MAE Test Loss: 43.11459732055664 \n",
      "Epoch: 80250 | MAE Train Loss: 44.225765228271484 | MAE Test Loss: 43.114593505859375 \n",
      "Epoch: 80260 | MAE Train Loss: 44.22550964355469 | MAE Test Loss: 43.11458206176758 \n",
      "Epoch: 80270 | MAE Train Loss: 44.225257873535156 | MAE Test Loss: 43.1147346496582 \n",
      "Epoch: 80280 | MAE Train Loss: 44.22500991821289 | MAE Test Loss: 43.11472702026367 \n",
      "Epoch: 80290 | MAE Train Loss: 44.22475814819336 | MAE Test Loss: 43.11471939086914 \n",
      "Epoch: 80300 | MAE Train Loss: 44.224510192871094 | MAE Test Loss: 43.11470413208008 \n",
      "Epoch: 80310 | MAE Train Loss: 44.22426223754883 | MAE Test Loss: 43.11486053466797 \n",
      "Epoch: 80320 | MAE Train Loss: 44.2240104675293 | MAE Test Loss: 43.11484909057617 \n",
      "Epoch: 80330 | MAE Train Loss: 44.2237548828125 | MAE Test Loss: 43.114837646484375 \n",
      "Epoch: 80340 | MAE Train Loss: 44.2234992980957 | MAE Test Loss: 43.114994049072266 \n",
      "Epoch: 80350 | MAE Train Loss: 44.22325897216797 | MAE Test Loss: 43.114986419677734 \n",
      "Epoch: 80360 | MAE Train Loss: 44.22300338745117 | MAE Test Loss: 43.11497497558594 \n",
      "Epoch: 80370 | MAE Train Loss: 44.22275161743164 | MAE Test Loss: 43.114967346191406 \n",
      "Epoch: 80380 | MAE Train Loss: 44.22249984741211 | MAE Test Loss: 43.1151237487793 \n",
      "Epoch: 80390 | MAE Train Loss: 44.22225570678711 | MAE Test Loss: 43.115108489990234 \n",
      "Epoch: 80400 | MAE Train Loss: 44.22200393676758 | MAE Test Loss: 43.11518096923828 \n",
      "Epoch: 80410 | MAE Train Loss: 44.22175598144531 | MAE Test Loss: 43.11517333984375 \n",
      "Epoch: 80420 | MAE Train Loss: 44.22150421142578 | MAE Test Loss: 43.11516189575195 \n",
      "Epoch: 80430 | MAE Train Loss: 44.221248626708984 | MAE Test Loss: 43.115318298339844 \n",
      "Epoch: 80440 | MAE Train Loss: 44.22100067138672 | MAE Test Loss: 43.11530685424805 \n",
      "Epoch: 80450 | MAE Train Loss: 44.22075271606445 | MAE Test Loss: 43.115299224853516 \n",
      "Epoch: 80460 | MAE Train Loss: 44.220497131347656 | MAE Test Loss: 43.11528778076172 \n",
      "Epoch: 80470 | MAE Train Loss: 44.22024917602539 | MAE Test Loss: 43.11544418334961 \n",
      "Epoch: 80480 | MAE Train Loss: 44.21999740600586 | MAE Test Loss: 43.11543273925781 \n",
      "Epoch: 80490 | MAE Train Loss: 44.21974182128906 | MAE Test Loss: 43.11542510986328 \n",
      "Epoch: 80500 | MAE Train Loss: 44.21949768066406 | MAE Test Loss: 43.115577697753906 \n",
      "Epoch: 80510 | MAE Train Loss: 44.2192497253418 | MAE Test Loss: 43.11556625366211 \n",
      "Epoch: 80520 | MAE Train Loss: 44.218994140625 | MAE Test Loss: 43.11555862426758 \n",
      "Epoch: 80530 | MAE Train Loss: 44.2187385559082 | MAE Test Loss: 43.11555099487305 \n",
      "Epoch: 80540 | MAE Train Loss: 44.21849060058594 | MAE Test Loss: 43.11561965942383 \n",
      "Epoch: 80550 | MAE Train Loss: 44.21824264526367 | MAE Test Loss: 43.11577224731445 \n",
      "Epoch: 80560 | MAE Train Loss: 44.21799087524414 | MAE Test Loss: 43.11576843261719 \n",
      "Epoch: 80570 | MAE Train Loss: 44.217742919921875 | MAE Test Loss: 43.115753173828125 \n",
      "Epoch: 80580 | MAE Train Loss: 44.21748733520508 | MAE Test Loss: 43.11574935913086 \n",
      "Epoch: 80590 | MAE Train Loss: 44.21723937988281 | MAE Test Loss: 43.115901947021484 \n",
      "Epoch: 80600 | MAE Train Loss: 44.21699142456055 | MAE Test Loss: 43.11589050292969 \n",
      "Epoch: 80610 | MAE Train Loss: 44.21673583984375 | MAE Test Loss: 43.115875244140625 \n",
      "Epoch: 80620 | MAE Train Loss: 44.216487884521484 | MAE Test Loss: 43.11595153808594 \n",
      "Epoch: 80630 | MAE Train Loss: 44.21623229980469 | MAE Test Loss: 43.115943908691406 \n",
      "Epoch: 80640 | MAE Train Loss: 44.21598434448242 | MAE Test Loss: 43.11609649658203 \n",
      "Epoch: 80650 | MAE Train Loss: 44.215736389160156 | MAE Test Loss: 43.1160888671875 \n",
      "Epoch: 80660 | MAE Train Loss: 44.215484619140625 | MAE Test Loss: 43.1160774230957 \n",
      "Epoch: 80670 | MAE Train Loss: 44.215232849121094 | MAE Test Loss: 43.116065979003906 \n",
      "Epoch: 80680 | MAE Train Loss: 44.21498107910156 | MAE Test Loss: 43.11622619628906 \n",
      "Epoch: 80690 | MAE Train Loss: 44.21472930908203 | MAE Test Loss: 43.1162109375 \n",
      "Epoch: 80700 | MAE Train Loss: 44.2144775390625 | MAE Test Loss: 43.11620330810547 \n",
      "Epoch: 80710 | MAE Train Loss: 44.214229583740234 | MAE Test Loss: 43.11635971069336 \n",
      "Epoch: 80720 | MAE Train Loss: 44.2139778137207 | MAE Test Loss: 43.1163444519043 \n",
      "Epoch: 80730 | MAE Train Loss: 44.21372604370117 | MAE Test Loss: 43.116336822509766 \n",
      "Epoch: 80740 | MAE Train Loss: 44.21347427368164 | MAE Test Loss: 43.11632537841797 \n",
      "Epoch: 80750 | MAE Train Loss: 44.213226318359375 | MAE Test Loss: 43.116485595703125 \n",
      "Epoch: 80760 | MAE Train Loss: 44.212974548339844 | MAE Test Loss: 43.11647415161133 \n",
      "Epoch: 80770 | MAE Train Loss: 44.21272277832031 | MAE Test Loss: 43.11646270751953 \n",
      "Epoch: 80780 | MAE Train Loss: 44.21247100830078 | MAE Test Loss: 43.11661911010742 \n",
      "Epoch: 80790 | MAE Train Loss: 44.212223052978516 | MAE Test Loss: 43.116607666015625 \n",
      "Epoch: 80800 | MAE Train Loss: 44.211978912353516 | MAE Test Loss: 43.116600036621094 \n",
      "Epoch: 80810 | MAE Train Loss: 44.21172332763672 | MAE Test Loss: 43.11658477783203 \n",
      "Epoch: 80820 | MAE Train Loss: 44.21147155761719 | MAE Test Loss: 43.11665725708008 \n",
      "Epoch: 80830 | MAE Train Loss: 44.211219787597656 | MAE Test Loss: 43.11664962768555 \n",
      "Epoch: 80840 | MAE Train Loss: 44.210968017578125 | MAE Test Loss: 43.11680221557617 \n",
      "Epoch: 80850 | MAE Train Loss: 44.21072006225586 | MAE Test Loss: 43.116790771484375 \n",
      "Epoch: 80860 | MAE Train Loss: 44.21046829223633 | MAE Test Loss: 43.116783142089844 \n",
      "Epoch: 80870 | MAE Train Loss: 44.2102165222168 | MAE Test Loss: 43.116939544677734 \n",
      "Epoch: 80880 | MAE Train Loss: 44.209964752197266 | MAE Test Loss: 43.11692810058594 \n",
      "Epoch: 80890 | MAE Train Loss: 44.209720611572266 | MAE Test Loss: 43.116920471191406 \n",
      "Epoch: 80900 | MAE Train Loss: 44.20946502685547 | MAE Test Loss: 43.11690902709961 \n",
      "Epoch: 80910 | MAE Train Loss: 44.20922088623047 | MAE Test Loss: 43.116981506347656 \n",
      "Epoch: 80920 | MAE Train Loss: 44.208961486816406 | MAE Test Loss: 43.11713409423828 \n",
      "Epoch: 80930 | MAE Train Loss: 44.20871353149414 | MAE Test Loss: 43.11712646484375 \n",
      "Epoch: 80940 | MAE Train Loss: 44.208465576171875 | MAE Test Loss: 43.11711502075195 \n",
      "Epoch: 80950 | MAE Train Loss: 44.208213806152344 | MAE Test Loss: 43.11710739135742 \n",
      "Epoch: 80960 | MAE Train Loss: 44.20796203613281 | MAE Test Loss: 43.11725997924805 \n",
      "Epoch: 80970 | MAE Train Loss: 44.20771026611328 | MAE Test Loss: 43.117252349853516 \n",
      "Epoch: 80980 | MAE Train Loss: 44.20745849609375 | MAE Test Loss: 43.11724090576172 \n",
      "Epoch: 80990 | MAE Train Loss: 44.20720672607422 | MAE Test Loss: 43.11723327636719 \n",
      "Epoch: 81000 | MAE Train Loss: 44.20695877075195 | MAE Test Loss: 43.11738586425781 \n",
      "Epoch: 81010 | MAE Train Loss: 44.20671081542969 | MAE Test Loss: 43.11737823486328 \n",
      "Epoch: 81020 | MAE Train Loss: 44.20645523071289 | MAE Test Loss: 43.117366790771484 \n",
      "Epoch: 81030 | MAE Train Loss: 44.20620346069336 | MAE Test Loss: 43.117523193359375 \n",
      "Epoch: 81040 | MAE Train Loss: 44.20595932006836 | MAE Test Loss: 43.11750411987305 \n",
      "Epoch: 81050 | MAE Train Loss: 44.20570755004883 | MAE Test Loss: 43.1175651550293 \n",
      "Epoch: 81060 | MAE Train Loss: 44.205467224121094 | MAE Test Loss: 43.117698669433594 \n",
      "Epoch: 81070 | MAE Train Loss: 44.2052116394043 | MAE Test Loss: 43.1176643371582 \n",
      "Epoch: 81080 | MAE Train Loss: 44.204959869384766 | MAE Test Loss: 43.11762619018555 \n",
      "Epoch: 81090 | MAE Train Loss: 44.2047119140625 | MAE Test Loss: 43.11774826049805 \n",
      "Epoch: 81100 | MAE Train Loss: 44.2044677734375 | MAE Test Loss: 43.11787414550781 \n",
      "Epoch: 81110 | MAE Train Loss: 44.20421600341797 | MAE Test Loss: 43.11783218383789 \n",
      "Epoch: 81120 | MAE Train Loss: 44.203975677490234 | MAE Test Loss: 43.11795425415039 \n",
      "Epoch: 81130 | MAE Train Loss: 44.2037239074707 | MAE Test Loss: 43.11791229248047 \n",
      "Epoch: 81140 | MAE Train Loss: 44.2034797668457 | MAE Test Loss: 43.11802673339844 \n",
      "Epoch: 81150 | MAE Train Loss: 44.20322799682617 | MAE Test Loss: 43.11798858642578 \n",
      "Epoch: 81160 | MAE Train Loss: 44.20296859741211 | MAE Test Loss: 43.118099212646484 \n",
      "Epoch: 81170 | MAE Train Loss: 44.20272445678711 | MAE Test Loss: 43.11806106567383 \n",
      "Epoch: 81180 | MAE Train Loss: 44.20247268676758 | MAE Test Loss: 43.1181755065918 \n",
      "Epoch: 81190 | MAE Train Loss: 44.202232360839844 | MAE Test Loss: 43.1182975769043 \n",
      "Epoch: 81200 | MAE Train Loss: 44.20197677612305 | MAE Test Loss: 43.118255615234375 \n",
      "Epoch: 81210 | MAE Train Loss: 44.20173263549805 | MAE Test Loss: 43.11821365356445 \n",
      "Epoch: 81220 | MAE Train Loss: 44.20147705078125 | MAE Test Loss: 43.11832809448242 \n",
      "Epoch: 81230 | MAE Train Loss: 44.201236724853516 | MAE Test Loss: 43.1182861328125 \n",
      "Epoch: 81240 | MAE Train Loss: 44.200984954833984 | MAE Test Loss: 43.11832809448242 \n",
      "Epoch: 81250 | MAE Train Loss: 44.20073699951172 | MAE Test Loss: 43.118438720703125 \n",
      "Epoch: 81260 | MAE Train Loss: 44.20048904418945 | MAE Test Loss: 43.118404388427734 \n",
      "Epoch: 81270 | MAE Train Loss: 44.20023727416992 | MAE Test Loss: 43.1185188293457 \n",
      "Epoch: 81280 | MAE Train Loss: 44.19999313354492 | MAE Test Loss: 43.11847686767578 \n",
      "Epoch: 81290 | MAE Train Loss: 44.19974136352539 | MAE Test Loss: 43.118595123291016 \n",
      "Epoch: 81300 | MAE Train Loss: 44.19949722290039 | MAE Test Loss: 43.118553161621094 \n",
      "Epoch: 81310 | MAE Train Loss: 44.19924545288086 | MAE Test Loss: 43.11866760253906 \n",
      "Epoch: 81320 | MAE Train Loss: 44.198997497558594 | MAE Test Loss: 43.118629455566406 \n",
      "Epoch: 81330 | MAE Train Loss: 44.19874954223633 | MAE Test Loss: 43.1186637878418 \n",
      "Epoch: 81340 | MAE Train Loss: 44.1984977722168 | MAE Test Loss: 43.11878204345703 \n",
      "Epoch: 81350 | MAE Train Loss: 44.1982536315918 | MAE Test Loss: 43.118743896484375 \n",
      "Epoch: 81360 | MAE Train Loss: 44.197998046875 | MAE Test Loss: 43.11886215209961 \n",
      "Epoch: 81370 | MAE Train Loss: 44.19775390625 | MAE Test Loss: 43.11881637573242 \n",
      "Epoch: 81380 | MAE Train Loss: 44.19750213623047 | MAE Test Loss: 43.11893081665039 \n",
      "Epoch: 81390 | MAE Train Loss: 44.197261810302734 | MAE Test Loss: 43.118892669677734 \n",
      "Epoch: 81400 | MAE Train Loss: 44.1970100402832 | MAE Test Loss: 43.119014739990234 \n",
      "Epoch: 81410 | MAE Train Loss: 44.19675827026367 | MAE Test Loss: 43.11896896362305 \n",
      "Epoch: 81420 | MAE Train Loss: 44.19651412963867 | MAE Test Loss: 43.11901092529297 \n",
      "Epoch: 81430 | MAE Train Loss: 44.19626235961914 | MAE Test Loss: 43.11912536621094 \n",
      "Epoch: 81440 | MAE Train Loss: 44.196014404296875 | MAE Test Loss: 43.11908721923828 \n",
      "Epoch: 81450 | MAE Train Loss: 44.195770263671875 | MAE Test Loss: 43.119205474853516 \n",
      "Epoch: 81460 | MAE Train Loss: 44.195518493652344 | MAE Test Loss: 43.11915969848633 \n",
      "Epoch: 81470 | MAE Train Loss: 44.19526672363281 | MAE Test Loss: 43.11943817138672 \n",
      "Epoch: 81480 | MAE Train Loss: 44.19502639770508 | MAE Test Loss: 43.11923599243164 \n",
      "Epoch: 81490 | MAE Train Loss: 44.19477462768555 | MAE Test Loss: 43.11951446533203 \n",
      "Epoch: 81500 | MAE Train Loss: 44.19453048706055 | MAE Test Loss: 43.11947250366211 \n",
      "Epoch: 81510 | MAE Train Loss: 44.19427490234375 | MAE Test Loss: 43.119590759277344 \n",
      "Epoch: 81520 | MAE Train Loss: 44.194034576416016 | MAE Test Loss: 43.11954879760742 \n",
      "Epoch: 81530 | MAE Train Loss: 44.19378662109375 | MAE Test Loss: 43.1195068359375 \n",
      "Epoch: 81540 | MAE Train Loss: 44.193538665771484 | MAE Test Loss: 43.119625091552734 \n",
      "Epoch: 81550 | MAE Train Loss: 44.19328308105469 | MAE Test Loss: 43.11958312988281 \n",
      "Epoch: 81560 | MAE Train Loss: 44.19303894042969 | MAE Test Loss: 43.11970138549805 \n",
      "Epoch: 81570 | MAE Train Loss: 44.19278335571289 | MAE Test Loss: 43.11966323852539 \n",
      "Epoch: 81580 | MAE Train Loss: 44.19253921508789 | MAE Test Loss: 43.119693756103516 \n",
      "Epoch: 81590 | MAE Train Loss: 44.19228744506836 | MAE Test Loss: 43.11981201171875 \n",
      "Epoch: 81600 | MAE Train Loss: 44.192047119140625 | MAE Test Loss: 43.11985397338867 \n",
      "Epoch: 81610 | MAE Train Loss: 44.191795349121094 | MAE Test Loss: 43.119815826416016 \n",
      "Epoch: 81620 | MAE Train Loss: 44.19154357910156 | MAE Test Loss: 43.11992645263672 \n",
      "Epoch: 81630 | MAE Train Loss: 44.1912956237793 | MAE Test Loss: 43.119964599609375 \n",
      "Epoch: 81640 | MAE Train Loss: 44.19104766845703 | MAE Test Loss: 43.11992645263672 \n",
      "Epoch: 81650 | MAE Train Loss: 44.19080352783203 | MAE Test Loss: 43.12004470825195 \n",
      "Epoch: 81660 | MAE Train Loss: 44.1905517578125 | MAE Test Loss: 43.12000274658203 \n",
      "Epoch: 81670 | MAE Train Loss: 44.19029998779297 | MAE Test Loss: 43.1201171875 \n",
      "Epoch: 81680 | MAE Train Loss: 44.1900520324707 | MAE Test Loss: 43.120079040527344 \n",
      "Epoch: 81690 | MAE Train Loss: 44.18980026245117 | MAE Test Loss: 43.12019729614258 \n",
      "Epoch: 81700 | MAE Train Loss: 44.18955993652344 | MAE Test Loss: 43.12016296386719 \n",
      "Epoch: 81710 | MAE Train Loss: 44.189308166503906 | MAE Test Loss: 43.120277404785156 \n",
      "Epoch: 81720 | MAE Train Loss: 44.189056396484375 | MAE Test Loss: 43.1202278137207 \n",
      "Epoch: 81730 | MAE Train Loss: 44.188812255859375 | MAE Test Loss: 43.12034606933594 \n",
      "Epoch: 81740 | MAE Train Loss: 44.188560485839844 | MAE Test Loss: 43.120304107666016 \n",
      "Epoch: 81750 | MAE Train Loss: 44.18831253051758 | MAE Test Loss: 43.120418548583984 \n",
      "Epoch: 81760 | MAE Train Loss: 44.18806457519531 | MAE Test Loss: 43.120384216308594 \n",
      "Epoch: 81770 | MAE Train Loss: 44.18781661987305 | MAE Test Loss: 43.1204948425293 \n",
      "Epoch: 81780 | MAE Train Loss: 44.18757247924805 | MAE Test Loss: 43.12044906616211 \n",
      "Epoch: 81790 | MAE Train Loss: 44.187320709228516 | MAE Test Loss: 43.12057113647461 \n",
      "Epoch: 81800 | MAE Train Loss: 44.187068939208984 | MAE Test Loss: 43.12053298950195 \n",
      "Epoch: 81810 | MAE Train Loss: 44.18682098388672 | MAE Test Loss: 43.12064743041992 \n",
      "Epoch: 81820 | MAE Train Loss: 44.18656921386719 | MAE Test Loss: 43.12060546875 \n",
      "Epoch: 81830 | MAE Train Loss: 44.18632888793945 | MAE Test Loss: 43.12071990966797 \n",
      "Epoch: 81840 | MAE Train Loss: 44.18607711791992 | MAE Test Loss: 43.12068176269531 \n",
      "Epoch: 81850 | MAE Train Loss: 44.18583297729492 | MAE Test Loss: 43.12079620361328 \n",
      "Epoch: 81860 | MAE Train Loss: 44.185577392578125 | MAE Test Loss: 43.12075424194336 \n",
      "Epoch: 81870 | MAE Train Loss: 44.185333251953125 | MAE Test Loss: 43.12103271484375 \n",
      "Epoch: 81880 | MAE Train Loss: 44.18507766723633 | MAE Test Loss: 43.12083435058594 \n",
      "Epoch: 81890 | MAE Train Loss: 44.184837341308594 | MAE Test Loss: 43.12111282348633 \n",
      "Epoch: 81900 | MAE Train Loss: 44.18458557128906 | MAE Test Loss: 43.120906829833984 \n",
      "Epoch: 81910 | MAE Train Loss: 44.1843376159668 | MAE Test Loss: 43.121185302734375 \n",
      "Epoch: 81920 | MAE Train Loss: 44.18409729003906 | MAE Test Loss: 43.12114334106445 \n",
      "Epoch: 81930 | MAE Train Loss: 44.183841705322266 | MAE Test Loss: 43.12126541137695 \n",
      "Epoch: 81940 | MAE Train Loss: 44.183597564697266 | MAE Test Loss: 43.121219635009766 \n",
      "Epoch: 81950 | MAE Train Loss: 44.183345794677734 | MAE Test Loss: 43.121177673339844 \n",
      "Epoch: 81960 | MAE Train Loss: 44.183101654052734 | MAE Test Loss: 43.12130355834961 \n",
      "Epoch: 81970 | MAE Train Loss: 44.1828498840332 | MAE Test Loss: 43.12126541137695 \n",
      "Epoch: 81980 | MAE Train Loss: 44.18260192871094 | MAE Test Loss: 43.12137222290039 \n",
      "Epoch: 81990 | MAE Train Loss: 44.182350158691406 | MAE Test Loss: 43.121334075927734 \n",
      "Epoch: 82000 | MAE Train Loss: 44.182098388671875 | MAE Test Loss: 43.12137222290039 \n",
      "Epoch: 82010 | MAE Train Loss: 44.18185043334961 | MAE Test Loss: 43.12148666381836 \n",
      "Epoch: 82020 | MAE Train Loss: 44.18160629272461 | MAE Test Loss: 43.12144088745117 \n",
      "Epoch: 82030 | MAE Train Loss: 44.18135452270508 | MAE Test Loss: 43.121559143066406 \n",
      "Epoch: 82040 | MAE Train Loss: 44.181114196777344 | MAE Test Loss: 43.12168502807617 \n",
      "Epoch: 82050 | MAE Train Loss: 44.18085861206055 | MAE Test Loss: 43.12164306640625 \n",
      "Epoch: 82060 | MAE Train Loss: 44.18061065673828 | MAE Test Loss: 43.12160110473633 \n",
      "Epoch: 82070 | MAE Train Loss: 44.180362701416016 | MAE Test Loss: 43.1217155456543 \n",
      "Epoch: 82080 | MAE Train Loss: 44.180118560791016 | MAE Test Loss: 43.121673583984375 \n",
      "Epoch: 82090 | MAE Train Loss: 44.17987060546875 | MAE Test Loss: 43.1217155456543 \n",
      "Epoch: 82100 | MAE Train Loss: 44.17961883544922 | MAE Test Loss: 43.121822357177734 \n",
      "Epoch: 82110 | MAE Train Loss: 44.17937088012695 | MAE Test Loss: 43.12186813354492 \n",
      "Epoch: 82120 | MAE Train Loss: 44.17912673950195 | MAE Test Loss: 43.121826171875 \n",
      "Epoch: 82130 | MAE Train Loss: 44.17886734008789 | MAE Test Loss: 43.12194061279297 \n",
      "Epoch: 82140 | MAE Train Loss: 44.178619384765625 | MAE Test Loss: 43.12197494506836 \n",
      "Epoch: 82150 | MAE Train Loss: 44.178375244140625 | MAE Test Loss: 43.1219367980957 \n",
      "Epoch: 82160 | MAE Train Loss: 44.17812728881836 | MAE Test Loss: 43.1220588684082 \n",
      "Epoch: 82170 | MAE Train Loss: 44.177879333496094 | MAE Test Loss: 43.12201690673828 \n",
      "Epoch: 82180 | MAE Train Loss: 44.17763137817383 | MAE Test Loss: 43.12205505371094 \n",
      "Epoch: 82190 | MAE Train Loss: 44.1773796081543 | MAE Test Loss: 43.12217330932617 \n",
      "Epoch: 82200 | MAE Train Loss: 44.17713165283203 | MAE Test Loss: 43.122135162353516 \n",
      "Epoch: 82210 | MAE Train Loss: 44.176883697509766 | MAE Test Loss: 43.122249603271484 \n",
      "Epoch: 82220 | MAE Train Loss: 44.1766357421875 | MAE Test Loss: 43.12220764160156 \n",
      "Epoch: 82230 | MAE Train Loss: 44.176387786865234 | MAE Test Loss: 43.122318267822266 \n",
      "Epoch: 82240 | MAE Train Loss: 44.17613983154297 | MAE Test Loss: 43.12228012084961 \n",
      "Epoch: 82250 | MAE Train Loss: 44.17588806152344 | MAE Test Loss: 43.12239456176758 \n",
      "Epoch: 82260 | MAE Train Loss: 44.17564392089844 | MAE Test Loss: 43.12234878540039 \n",
      "Epoch: 82270 | MAE Train Loss: 44.175392150878906 | MAE Test Loss: 43.122474670410156 \n",
      "Epoch: 82280 | MAE Train Loss: 44.17514419555664 | MAE Test Loss: 43.122432708740234 \n",
      "Epoch: 82290 | MAE Train Loss: 44.174896240234375 | MAE Test Loss: 43.1225471496582 \n",
      "Epoch: 82300 | MAE Train Loss: 44.17464828491211 | MAE Test Loss: 43.12250518798828 \n",
      "Epoch: 82310 | MAE Train Loss: 44.174400329589844 | MAE Test Loss: 43.12278747558594 \n",
      "Epoch: 82320 | MAE Train Loss: 44.17414855957031 | MAE Test Loss: 43.122581481933594 \n",
      "Epoch: 82330 | MAE Train Loss: 44.17390441894531 | MAE Test Loss: 43.12285614013672 \n",
      "Epoch: 82340 | MAE Train Loss: 44.17366027832031 | MAE Test Loss: 43.12281799316406 \n",
      "Epoch: 82350 | MAE Train Loss: 44.17340850830078 | MAE Test Loss: 43.12294387817383 \n",
      "Epoch: 82360 | MAE Train Loss: 44.17316436767578 | MAE Test Loss: 43.12289810180664 \n",
      "Epoch: 82370 | MAE Train Loss: 44.17291259765625 | MAE Test Loss: 43.12301254272461 \n",
      "Epoch: 82380 | MAE Train Loss: 44.17266845703125 | MAE Test Loss: 43.12297058105469 \n",
      "Epoch: 82390 | MAE Train Loss: 44.17241287231445 | MAE Test Loss: 43.12293243408203 \n",
      "Epoch: 82400 | MAE Train Loss: 44.17216873168945 | MAE Test Loss: 43.123046875 \n",
      "Epoch: 82410 | MAE Train Loss: 44.17192077636719 | MAE Test Loss: 43.12300491333008 \n",
      "Epoch: 82420 | MAE Train Loss: 44.171669006347656 | MAE Test Loss: 43.122962951660156 \n",
      "Epoch: 82430 | MAE Train Loss: 44.17142105102539 | MAE Test Loss: 43.123085021972656 \n",
      "Epoch: 82440 | MAE Train Loss: 44.171165466308594 | MAE Test Loss: 43.123199462890625 \n",
      "Epoch: 82450 | MAE Train Loss: 44.17092514038086 | MAE Test Loss: 43.1231575012207 \n",
      "Epoch: 82460 | MAE Train Loss: 44.17066955566406 | MAE Test Loss: 43.12327575683594 \n",
      "Epoch: 82470 | MAE Train Loss: 44.17042922973633 | MAE Test Loss: 43.12339782714844 \n",
      "Epoch: 82480 | MAE Train Loss: 44.17017364501953 | MAE Test Loss: 43.123355865478516 \n",
      "Epoch: 82490 | MAE Train Loss: 44.1699333190918 | MAE Test Loss: 43.12339401245117 \n",
      "Epoch: 82500 | MAE Train Loss: 44.169681549072266 | MAE Test Loss: 43.12335968017578 \n",
      "Epoch: 82510 | MAE Train Loss: 44.169429779052734 | MAE Test Loss: 43.123470306396484 \n",
      "Epoch: 82520 | MAE Train Loss: 44.169185638427734 | MAE Test Loss: 43.1234245300293 \n",
      "Epoch: 82530 | MAE Train Loss: 44.1689338684082 | MAE Test Loss: 43.12354278564453 \n",
      "Epoch: 82540 | MAE Train Loss: 44.16868591308594 | MAE Test Loss: 43.123504638671875 \n",
      "Epoch: 82550 | MAE Train Loss: 44.16843795776367 | MAE Test Loss: 43.123619079589844 \n",
      "Epoch: 82560 | MAE Train Loss: 44.168190002441406 | MAE Test Loss: 43.12357711791992 \n",
      "Epoch: 82570 | MAE Train Loss: 44.16793441772461 | MAE Test Loss: 43.12369155883789 \n",
      "Epoch: 82580 | MAE Train Loss: 44.16769027709961 | MAE Test Loss: 43.12364959716797 \n",
      "Epoch: 82590 | MAE Train Loss: 44.16743850708008 | MAE Test Loss: 43.1237678527832 \n",
      "Epoch: 82600 | MAE Train Loss: 44.16719055175781 | MAE Test Loss: 43.12372589111328 \n",
      "Epoch: 82610 | MAE Train Loss: 44.16694259643555 | MAE Test Loss: 43.12376403808594 \n",
      "Epoch: 82620 | MAE Train Loss: 44.16669845581055 | MAE Test Loss: 43.12388229370117 \n",
      "Epoch: 82630 | MAE Train Loss: 44.16645050048828 | MAE Test Loss: 43.123844146728516 \n",
      "Epoch: 82640 | MAE Train Loss: 44.16619873046875 | MAE Test Loss: 43.123958587646484 \n",
      "Epoch: 82650 | MAE Train Loss: 44.16595458984375 | MAE Test Loss: 43.124000549316406 \n",
      "Epoch: 82660 | MAE Train Loss: 44.165706634521484 | MAE Test Loss: 43.123958587646484 \n",
      "Epoch: 82670 | MAE Train Loss: 44.16545486450195 | MAE Test Loss: 43.12406921386719 \n",
      "Epoch: 82680 | MAE Train Loss: 44.16520690917969 | MAE Test Loss: 43.124027252197266 \n",
      "Epoch: 82690 | MAE Train Loss: 44.16495895385742 | MAE Test Loss: 43.1241455078125 \n",
      "Epoch: 82700 | MAE Train Loss: 44.164710998535156 | MAE Test Loss: 43.124107360839844 \n",
      "Epoch: 82710 | MAE Train Loss: 44.164459228515625 | MAE Test Loss: 43.12422180175781 \n",
      "Epoch: 82720 | MAE Train Loss: 44.164215087890625 | MAE Test Loss: 43.124176025390625 \n",
      "Epoch: 82730 | MAE Train Loss: 44.16396713256836 | MAE Test Loss: 43.12445831298828 \n",
      "Epoch: 82740 | MAE Train Loss: 44.16371536254883 | MAE Test Loss: 43.12425994873047 \n",
      "Epoch: 82750 | MAE Train Loss: 44.16347122192383 | MAE Test Loss: 43.12453842163086 \n",
      "Epoch: 82760 | MAE Train Loss: 44.16322326660156 | MAE Test Loss: 43.12433624267578 \n",
      "Epoch: 82770 | MAE Train Loss: 44.16297149658203 | MAE Test Loss: 43.124610900878906 \n",
      "Epoch: 82780 | MAE Train Loss: 44.16272735595703 | MAE Test Loss: 43.124568939208984 \n",
      "Epoch: 82790 | MAE Train Loss: 44.1624755859375 | MAE Test Loss: 43.12468338012695 \n",
      "Epoch: 82800 | MAE Train Loss: 44.1622314453125 | MAE Test Loss: 43.1246452331543 \n",
      "Epoch: 82810 | MAE Train Loss: 44.16197967529297 | MAE Test Loss: 43.12459945678711 \n",
      "Epoch: 82820 | MAE Train Loss: 44.16173553466797 | MAE Test Loss: 43.124725341796875 \n",
      "Epoch: 82830 | MAE Train Loss: 44.16147994995117 | MAE Test Loss: 43.12468719482422 \n",
      "Epoch: 82840 | MAE Train Loss: 44.16123962402344 | MAE Test Loss: 43.12479782104492 \n",
      "Epoch: 82850 | MAE Train Loss: 44.160987854003906 | MAE Test Loss: 43.124755859375 \n",
      "Epoch: 82860 | MAE Train Loss: 44.160736083984375 | MAE Test Loss: 43.12479782104492 \n",
      "Epoch: 82870 | MAE Train Loss: 44.160484313964844 | MAE Test Loss: 43.124908447265625 \n",
      "Epoch: 82880 | MAE Train Loss: 44.160247802734375 | MAE Test Loss: 43.12495040893555 \n",
      "Epoch: 82890 | MAE Train Loss: 44.15998840332031 | MAE Test Loss: 43.124908447265625 \n",
      "Epoch: 82900 | MAE Train Loss: 44.15973663330078 | MAE Test Loss: 43.125022888183594 \n",
      "Epoch: 82910 | MAE Train Loss: 44.15949249267578 | MAE Test Loss: 43.12506103515625 \n",
      "Epoch: 82920 | MAE Train Loss: 44.159244537353516 | MAE Test Loss: 43.12501525878906 \n",
      "Epoch: 82930 | MAE Train Loss: 44.15900421142578 | MAE Test Loss: 43.12514114379883 \n",
      "Epoch: 82940 | MAE Train Loss: 44.15875244140625 | MAE Test Loss: 43.125099182128906 \n",
      "Epoch: 82950 | MAE Train Loss: 44.15850067138672 | MAE Test Loss: 43.12514114379883 \n",
      "Epoch: 82960 | MAE Train Loss: 44.15824890136719 | MAE Test Loss: 43.1252555847168 \n",
      "Epoch: 82970 | MAE Train Loss: 44.15800476074219 | MAE Test Loss: 43.125213623046875 \n",
      "Epoch: 82980 | MAE Train Loss: 44.157752990722656 | MAE Test Loss: 43.125328063964844 \n",
      "Epoch: 82990 | MAE Train Loss: 44.15750503540039 | MAE Test Loss: 43.125370025634766 \n",
      "Epoch: 83000 | MAE Train Loss: 44.157257080078125 | MAE Test Loss: 43.12533187866211 \n",
      "Epoch: 83010 | MAE Train Loss: 44.15700912475586 | MAE Test Loss: 43.12544250488281 \n",
      "Epoch: 83020 | MAE Train Loss: 44.15675735473633 | MAE Test Loss: 43.125404357910156 \n",
      "Epoch: 83030 | MAE Train Loss: 44.15650939941406 | MAE Test Loss: 43.12552261352539 \n",
      "Epoch: 83040 | MAE Train Loss: 44.1562614440918 | MAE Test Loss: 43.12548065185547 \n",
      "Epoch: 83050 | MAE Train Loss: 44.15601348876953 | MAE Test Loss: 43.12559127807617 \n",
      "Epoch: 83060 | MAE Train Loss: 44.15576934814453 | MAE Test Loss: 43.125553131103516 \n",
      "Epoch: 83070 | MAE Train Loss: 44.155517578125 | MAE Test Loss: 43.125667572021484 \n",
      "Epoch: 83080 | MAE Train Loss: 44.15526580810547 | MAE Test Loss: 43.12562942504883 \n",
      "Epoch: 83090 | MAE Train Loss: 44.15502166748047 | MAE Test Loss: 43.12574768066406 \n",
      "Epoch: 83100 | MAE Train Loss: 44.15476989746094 | MAE Test Loss: 43.12570571899414 \n",
      "Epoch: 83110 | MAE Train Loss: 44.154518127441406 | MAE Test Loss: 43.12582015991211 \n",
      "Epoch: 83120 | MAE Train Loss: 44.154273986816406 | MAE Test Loss: 43.12577819824219 \n",
      "Epoch: 83130 | MAE Train Loss: 44.15402603149414 | MAE Test Loss: 43.125892639160156 \n",
      "Epoch: 83140 | MAE Train Loss: 44.153778076171875 | MAE Test Loss: 43.1258544921875 \n",
      "Epoch: 83150 | MAE Train Loss: 44.15353012084961 | MAE Test Loss: 43.126129150390625 \n",
      "Epoch: 83160 | MAE Train Loss: 44.15327835083008 | MAE Test Loss: 43.12593078613281 \n",
      "Epoch: 83170 | MAE Train Loss: 44.15303421020508 | MAE Test Loss: 43.126216888427734 \n",
      "Epoch: 83180 | MAE Train Loss: 44.15278625488281 | MAE Test Loss: 43.126007080078125 \n",
      "Epoch: 83190 | MAE Train Loss: 44.15253829956055 | MAE Test Loss: 43.12628173828125 \n",
      "Epoch: 83200 | MAE Train Loss: 44.15229797363281 | MAE Test Loss: 43.126243591308594 \n",
      "Epoch: 83210 | MAE Train Loss: 44.15204620361328 | MAE Test Loss: 43.12628173828125 \n",
      "Epoch: 83220 | MAE Train Loss: 44.151790618896484 | MAE Test Loss: 43.12639617919922 \n",
      "Epoch: 83230 | MAE Train Loss: 44.15155029296875 | MAE Test Loss: 43.1263542175293 \n",
      "Epoch: 83240 | MAE Train Loss: 44.15129852294922 | MAE Test Loss: 43.12631607055664 \n",
      "Epoch: 83250 | MAE Train Loss: 44.15105056762695 | MAE Test Loss: 43.126434326171875 \n",
      "Epoch: 83260 | MAE Train Loss: 44.15079879760742 | MAE Test Loss: 43.12639617919922 \n",
      "Epoch: 83270 | MAE Train Loss: 44.15055847167969 | MAE Test Loss: 43.12651062011719 \n",
      "Epoch: 83280 | MAE Train Loss: 44.15030288696289 | MAE Test Loss: 43.12646484375 \n",
      "Epoch: 83290 | MAE Train Loss: 44.150047302246094 | MAE Test Loss: 43.12650680541992 \n",
      "Epoch: 83300 | MAE Train Loss: 44.14979934692383 | MAE Test Loss: 43.126625061035156 \n",
      "Epoch: 83310 | MAE Train Loss: 44.149559020996094 | MAE Test Loss: 43.12666320800781 \n",
      "Epoch: 83320 | MAE Train Loss: 44.14930725097656 | MAE Test Loss: 43.126625061035156 \n",
      "Epoch: 83330 | MAE Train Loss: 44.149051666259766 | MAE Test Loss: 43.126731872558594 \n",
      "Epoch: 83340 | MAE Train Loss: 44.148807525634766 | MAE Test Loss: 43.126773834228516 \n",
      "Epoch: 83350 | MAE Train Loss: 44.148563385009766 | MAE Test Loss: 43.12672805786133 \n",
      "Epoch: 83360 | MAE Train Loss: 44.148319244384766 | MAE Test Loss: 43.126853942871094 \n",
      "Epoch: 83370 | MAE Train Loss: 44.148067474365234 | MAE Test Loss: 43.12681198120117 \n",
      "Epoch: 83380 | MAE Train Loss: 44.14781951904297 | MAE Test Loss: 43.12685012817383 \n",
      "Epoch: 83390 | MAE Train Loss: 44.14756774902344 | MAE Test Loss: 43.12696838378906 \n",
      "Epoch: 83400 | MAE Train Loss: 44.147315979003906 | MAE Test Loss: 43.126930236816406 \n",
      "Epoch: 83410 | MAE Train Loss: 44.14706802368164 | MAE Test Loss: 43.127044677734375 \n",
      "Epoch: 83420 | MAE Train Loss: 44.146820068359375 | MAE Test Loss: 43.12700271606445 \n",
      "Epoch: 83430 | MAE Train Loss: 44.14657211303711 | MAE Test Loss: 43.12711715698242 \n",
      "Epoch: 83440 | MAE Train Loss: 44.146324157714844 | MAE Test Loss: 43.1270751953125 \n",
      "Epoch: 83450 | MAE Train Loss: 44.14607620239258 | MAE Test Loss: 43.127193450927734 \n",
      "Epoch: 83460 | MAE Train Loss: 44.14582824707031 | MAE Test Loss: 43.12714385986328 \n",
      "Epoch: 83470 | MAE Train Loss: 44.14557647705078 | MAE Test Loss: 43.12726974487305 \n",
      "Epoch: 83480 | MAE Train Loss: 44.145328521728516 | MAE Test Loss: 43.12723159790039 \n",
      "Epoch: 83490 | MAE Train Loss: 44.14508056640625 | MAE Test Loss: 43.127342224121094 \n",
      "Epoch: 83500 | MAE Train Loss: 44.14483642578125 | MAE Test Loss: 43.12730407714844 \n",
      "Epoch: 83510 | MAE Train Loss: 44.14458465576172 | MAE Test Loss: 43.127418518066406 \n",
      "Epoch: 83520 | MAE Train Loss: 44.14433670043945 | MAE Test Loss: 43.12737274169922 \n",
      "Epoch: 83530 | MAE Train Loss: 44.14409255981445 | MAE Test Loss: 43.12749099731445 \n",
      "Epoch: 83540 | MAE Train Loss: 44.14384078979492 | MAE Test Loss: 43.1274528503418 \n",
      "Epoch: 83550 | MAE Train Loss: 44.14358901977539 | MAE Test Loss: 43.12757110595703 \n",
      "Epoch: 83560 | MAE Train Loss: 44.143341064453125 | MAE Test Loss: 43.12752914428711 \n",
      "Epoch: 83570 | MAE Train Loss: 44.14309310913086 | MAE Test Loss: 43.12765121459961 \n",
      "Epoch: 83580 | MAE Train Loss: 44.142845153808594 | MAE Test Loss: 43.127601623535156 \n",
      "Epoch: 83590 | MAE Train Loss: 44.14259719848633 | MAE Test Loss: 43.12788391113281 \n",
      "Epoch: 83600 | MAE Train Loss: 44.14235305786133 | MAE Test Loss: 43.127681732177734 \n",
      "Epoch: 83610 | MAE Train Loss: 44.1421012878418 | MAE Test Loss: 43.127952575683594 \n",
      "Epoch: 83620 | MAE Train Loss: 44.1418571472168 | MAE Test Loss: 43.12791442871094 \n",
      "Epoch: 83630 | MAE Train Loss: 44.141605377197266 | MAE Test Loss: 43.1280403137207 \n",
      "Epoch: 83640 | MAE Train Loss: 44.141361236572266 | MAE Test Loss: 43.127994537353516 \n",
      "Epoch: 83650 | MAE Train Loss: 44.141109466552734 | MAE Test Loss: 43.128108978271484 \n",
      "Epoch: 83660 | MAE Train Loss: 44.1408805847168 | MAE Test Loss: 43.12810516357422 \n",
      "Epoch: 83670 | MAE Train Loss: 44.14064407348633 | MAE Test Loss: 43.12809371948242 \n",
      "Epoch: 83680 | MAE Train Loss: 44.14041519165039 | MAE Test Loss: 43.128082275390625 \n",
      "Epoch: 83690 | MAE Train Loss: 44.140193939208984 | MAE Test Loss: 43.12807083129883 \n",
      "Epoch: 83700 | MAE Train Loss: 44.13996887207031 | MAE Test Loss: 43.1280632019043 \n",
      "Epoch: 83710 | MAE Train Loss: 44.139747619628906 | MAE Test Loss: 43.12821960449219 \n",
      "Epoch: 83720 | MAE Train Loss: 44.139522552490234 | MAE Test Loss: 43.12820816040039 \n",
      "Epoch: 83730 | MAE Train Loss: 44.13930130004883 | MAE Test Loss: 43.128196716308594 \n",
      "Epoch: 83740 | MAE Train Loss: 44.13908004760742 | MAE Test Loss: 43.12835693359375 \n",
      "Epoch: 83750 | MAE Train Loss: 44.138858795166016 | MAE Test Loss: 43.12834548950195 \n",
      "Epoch: 83760 | MAE Train Loss: 44.13863754272461 | MAE Test Loss: 43.128334045410156 \n",
      "Epoch: 83770 | MAE Train Loss: 44.13841247558594 | MAE Test Loss: 43.12849044799805 \n",
      "Epoch: 83780 | MAE Train Loss: 44.13819122314453 | MAE Test Loss: 43.12847900390625 \n",
      "Epoch: 83790 | MAE Train Loss: 44.137962341308594 | MAE Test Loss: 43.12847137451172 \n",
      "Epoch: 83800 | MAE Train Loss: 44.13774108886719 | MAE Test Loss: 43.12862777709961 \n",
      "Epoch: 83810 | MAE Train Loss: 44.13751983642578 | MAE Test Loss: 43.12869644165039 \n",
      "Epoch: 83820 | MAE Train Loss: 44.13730239868164 | MAE Test Loss: 43.128684997558594 \n",
      "Epoch: 83830 | MAE Train Loss: 44.13707733154297 | MAE Test Loss: 43.12867736816406 \n",
      "Epoch: 83840 | MAE Train Loss: 44.1368522644043 | MAE Test Loss: 43.12883377075195 \n",
      "Epoch: 83850 | MAE Train Loss: 44.136634826660156 | MAE Test Loss: 43.128822326660156 \n",
      "Epoch: 83860 | MAE Train Loss: 44.136409759521484 | MAE Test Loss: 43.1288948059082 \n",
      "Epoch: 83870 | MAE Train Loss: 44.13618850708008 | MAE Test Loss: 43.128883361816406 \n",
      "Epoch: 83880 | MAE Train Loss: 44.135963439941406 | MAE Test Loss: 43.12887191772461 \n",
      "Epoch: 83890 | MAE Train Loss: 44.135746002197266 | MAE Test Loss: 43.1290283203125 \n",
      "Epoch: 83900 | MAE Train Loss: 44.13551712036133 | MAE Test Loss: 43.12910461425781 \n",
      "Epoch: 83910 | MAE Train Loss: 44.13529968261719 | MAE Test Loss: 43.129093170166016 \n",
      "Epoch: 83920 | MAE Train Loss: 44.13507843017578 | MAE Test Loss: 43.129093170166016 \n",
      "Epoch: 83930 | MAE Train Loss: 44.13486099243164 | MAE Test Loss: 43.12909698486328 \n",
      "Epoch: 83940 | MAE Train Loss: 44.1346435546875 | MAE Test Loss: 43.12909698486328 \n",
      "Epoch: 83950 | MAE Train Loss: 44.13442611694336 | MAE Test Loss: 43.12910461425781 \n",
      "Epoch: 83960 | MAE Train Loss: 44.134212493896484 | MAE Test Loss: 43.12910842895508 \n",
      "Epoch: 83970 | MAE Train Loss: 44.13399124145508 | MAE Test Loss: 43.12911605834961 \n",
      "Epoch: 83980 | MAE Train Loss: 44.13377380371094 | MAE Test Loss: 43.12895965576172 \n",
      "Epoch: 83990 | MAE Train Loss: 44.13356018066406 | MAE Test Loss: 43.12896728515625 \n",
      "Epoch: 84000 | MAE Train Loss: 44.13334274291992 | MAE Test Loss: 43.12897491455078 \n",
      "Epoch: 84010 | MAE Train Loss: 44.13312911987305 | MAE Test Loss: 43.12897491455078 \n",
      "Epoch: 84020 | MAE Train Loss: 44.13290786743164 | MAE Test Loss: 43.12898254394531 \n",
      "Epoch: 84030 | MAE Train Loss: 44.13269805908203 | MAE Test Loss: 43.12898635864258 \n",
      "Epoch: 84040 | MAE Train Loss: 44.132476806640625 | MAE Test Loss: 43.12899398803711 \n",
      "Epoch: 84050 | MAE Train Loss: 44.132259368896484 | MAE Test Loss: 43.128997802734375 \n",
      "Epoch: 84060 | MAE Train Loss: 44.132041931152344 | MAE Test Loss: 43.129005432128906 \n",
      "Epoch: 84070 | MAE Train Loss: 44.1318244934082 | MAE Test Loss: 43.12900924682617 \n",
      "Epoch: 84080 | MAE Train Loss: 44.13161087036133 | MAE Test Loss: 43.1290168762207 \n",
      "Epoch: 84090 | MAE Train Loss: 44.13139343261719 | MAE Test Loss: 43.12885665893555 \n",
      "Epoch: 84100 | MAE Train Loss: 44.13117218017578 | MAE Test Loss: 43.12886428833008 \n",
      "Epoch: 84110 | MAE Train Loss: 44.130958557128906 | MAE Test Loss: 43.12887191772461 \n",
      "Epoch: 84120 | MAE Train Loss: 44.13074493408203 | MAE Test Loss: 43.128875732421875 \n",
      "Epoch: 84130 | MAE Train Loss: 44.130523681640625 | MAE Test Loss: 43.128875732421875 \n",
      "Epoch: 84140 | MAE Train Loss: 44.13031005859375 | MAE Test Loss: 43.128883361816406 \n",
      "Epoch: 84150 | MAE Train Loss: 44.130088806152344 | MAE Test Loss: 43.128807067871094 \n",
      "Epoch: 84160 | MAE Train Loss: 44.12986755371094 | MAE Test Loss: 43.128814697265625 \n",
      "Epoch: 84170 | MAE Train Loss: 44.12965774536133 | MAE Test Loss: 43.12881851196289 \n",
      "Epoch: 84180 | MAE Train Loss: 44.12944412231445 | MAE Test Loss: 43.12882614135742 \n",
      "Epoch: 84190 | MAE Train Loss: 44.12922668457031 | MAE Test Loss: 43.12883377075195 \n",
      "Epoch: 84200 | MAE Train Loss: 44.12901306152344 | MAE Test Loss: 43.12883377075195 \n",
      "Epoch: 84210 | MAE Train Loss: 44.12879180908203 | MAE Test Loss: 43.128841400146484 \n",
      "Epoch: 84220 | MAE Train Loss: 44.128578186035156 | MAE Test Loss: 43.12884521484375 \n",
      "Epoch: 84230 | MAE Train Loss: 44.12835693359375 | MAE Test Loss: 43.128849029541016 \n",
      "Epoch: 84240 | MAE Train Loss: 44.128135681152344 | MAE Test Loss: 43.12885665893555 \n",
      "Epoch: 84250 | MAE Train Loss: 44.12792205810547 | MAE Test Loss: 43.12886428833008 \n",
      "Epoch: 84260 | MAE Train Loss: 44.127708435058594 | MAE Test Loss: 43.12870788574219 \n",
      "Epoch: 84270 | MAE Train Loss: 44.12749099731445 | MAE Test Loss: 43.12871170043945 \n",
      "Epoch: 84280 | MAE Train Loss: 44.12727355957031 | MAE Test Loss: 43.12871551513672 \n",
      "Epoch: 84290 | MAE Train Loss: 44.127052307128906 | MAE Test Loss: 43.128726959228516 \n",
      "Epoch: 84300 | MAE Train Loss: 44.1268424987793 | MAE Test Loss: 43.128726959228516 \n",
      "Epoch: 84310 | MAE Train Loss: 44.126625061035156 | MAE Test Loss: 43.12873458862305 \n",
      "Epoch: 84320 | MAE Train Loss: 44.12640380859375 | MAE Test Loss: 43.128658294677734 \n",
      "Epoch: 84330 | MAE Train Loss: 44.126190185546875 | MAE Test Loss: 43.128662109375 \n",
      "Epoch: 84340 | MAE Train Loss: 44.125972747802734 | MAE Test Loss: 43.12866973876953 \n",
      "Epoch: 84350 | MAE Train Loss: 44.12575912475586 | MAE Test Loss: 43.12867736816406 \n",
      "Epoch: 84360 | MAE Train Loss: 44.12554168701172 | MAE Test Loss: 43.12867736816406 \n",
      "Epoch: 84370 | MAE Train Loss: 44.12532424926758 | MAE Test Loss: 43.128604888916016 \n",
      "Epoch: 84380 | MAE Train Loss: 44.12510681152344 | MAE Test Loss: 43.12860870361328 \n",
      "Epoch: 84390 | MAE Train Loss: 44.12489318847656 | MAE Test Loss: 43.12861633300781 \n",
      "Epoch: 84400 | MAE Train Loss: 44.124671936035156 | MAE Test Loss: 43.12862014770508 \n",
      "Epoch: 84410 | MAE Train Loss: 44.12445831298828 | MAE Test Loss: 43.128623962402344 \n",
      "Epoch: 84420 | MAE Train Loss: 44.124244689941406 | MAE Test Loss: 43.12862777709961 \n",
      "Epoch: 84430 | MAE Train Loss: 44.124019622802734 | MAE Test Loss: 43.12855911254883 \n",
      "Epoch: 84440 | MAE Train Loss: 44.12380599975586 | MAE Test Loss: 43.12855911254883 \n",
      "Epoch: 84450 | MAE Train Loss: 44.12358856201172 | MAE Test Loss: 43.128570556640625 \n",
      "Epoch: 84460 | MAE Train Loss: 44.12337112426758 | MAE Test Loss: 43.12857437133789 \n",
      "Epoch: 84470 | MAE Train Loss: 44.1231575012207 | MAE Test Loss: 43.12857437133789 \n",
      "Epoch: 84480 | MAE Train Loss: 44.12294006347656 | MAE Test Loss: 43.12858200073242 \n",
      "Epoch: 84490 | MAE Train Loss: 44.12272644042969 | MAE Test Loss: 43.12850570678711 \n",
      "Epoch: 84500 | MAE Train Loss: 44.12250518798828 | MAE Test Loss: 43.128517150878906 \n",
      "Epoch: 84510 | MAE Train Loss: 44.12228775024414 | MAE Test Loss: 43.12852096557617 \n",
      "Epoch: 84520 | MAE Train Loss: 44.122074127197266 | MAE Test Loss: 43.12852096557617 \n",
      "Epoch: 84530 | MAE Train Loss: 44.121856689453125 | MAE Test Loss: 43.1285285949707 \n",
      "Epoch: 84540 | MAE Train Loss: 44.121639251708984 | MAE Test Loss: 43.12845230102539 \n",
      "Epoch: 84550 | MAE Train Loss: 44.12141799926758 | MAE Test Loss: 43.128456115722656 \n",
      "Epoch: 84560 | MAE Train Loss: 44.1212043762207 | MAE Test Loss: 43.12846374511719 \n",
      "Epoch: 84570 | MAE Train Loss: 44.12099075317383 | MAE Test Loss: 43.12847137451172 \n",
      "Epoch: 84580 | MAE Train Loss: 44.12077331542969 | MAE Test Loss: 43.128475189208984 \n",
      "Epoch: 84590 | MAE Train Loss: 44.12055587768555 | MAE Test Loss: 43.12847900390625 \n",
      "Epoch: 84600 | MAE Train Loss: 44.120338439941406 | MAE Test Loss: 43.12840270996094 \n",
      "Epoch: 84610 | MAE Train Loss: 44.120121002197266 | MAE Test Loss: 43.1284065246582 \n",
      "Epoch: 84620 | MAE Train Loss: 44.119903564453125 | MAE Test Loss: 43.128414154052734 \n",
      "Epoch: 84630 | MAE Train Loss: 44.11968994140625 | MAE Test Loss: 43.12841796875 \n",
      "Epoch: 84640 | MAE Train Loss: 44.119476318359375 | MAE Test Loss: 43.128421783447266 \n",
      "Epoch: 84650 | MAE Train Loss: 44.11925506591797 | MAE Test Loss: 43.12834930419922 \n",
      "Epoch: 84660 | MAE Train Loss: 44.11903381347656 | MAE Test Loss: 43.12835693359375 \n",
      "Epoch: 84670 | MAE Train Loss: 44.11882019042969 | MAE Test Loss: 43.12835693359375 \n",
      "Epoch: 84680 | MAE Train Loss: 44.11860275268555 | MAE Test Loss: 43.12836456298828 \n",
      "Epoch: 84690 | MAE Train Loss: 44.11839294433594 | MAE Test Loss: 43.12837219238281 \n",
      "Epoch: 84700 | MAE Train Loss: 44.11817169189453 | MAE Test Loss: 43.12837219238281 \n",
      "Epoch: 84710 | MAE Train Loss: 44.117950439453125 | MAE Test Loss: 43.128299713134766 \n",
      "Epoch: 84720 | MAE Train Loss: 44.11773681640625 | MAE Test Loss: 43.1283073425293 \n",
      "Epoch: 84730 | MAE Train Loss: 44.117523193359375 | MAE Test Loss: 43.12831115722656 \n",
      "Epoch: 84740 | MAE Train Loss: 44.11730194091797 | MAE Test Loss: 43.128318786621094 \n",
      "Epoch: 84750 | MAE Train Loss: 44.11708450317383 | MAE Test Loss: 43.128326416015625 \n",
      "Epoch: 84760 | MAE Train Loss: 44.11687088012695 | MAE Test Loss: 43.128326416015625 \n",
      "Epoch: 84770 | MAE Train Loss: 44.11664962768555 | MAE Test Loss: 43.12825393676758 \n",
      "Epoch: 84780 | MAE Train Loss: 44.11643981933594 | MAE Test Loss: 43.128257751464844 \n",
      "Epoch: 84790 | MAE Train Loss: 44.1162223815918 | MAE Test Loss: 43.128265380859375 \n",
      "Epoch: 84800 | MAE Train Loss: 44.116004943847656 | MAE Test Loss: 43.128265380859375 \n",
      "Epoch: 84810 | MAE Train Loss: 44.11579132080078 | MAE Test Loss: 43.12827682495117 \n",
      "Epoch: 84820 | MAE Train Loss: 44.115570068359375 | MAE Test Loss: 43.12827682495117 \n",
      "Epoch: 84830 | MAE Train Loss: 44.1153564453125 | MAE Test Loss: 43.1282844543457 \n",
      "Epoch: 84840 | MAE Train Loss: 44.115135192871094 | MAE Test Loss: 43.12828826904297 \n",
      "Epoch: 84850 | MAE Train Loss: 44.11491775512695 | MAE Test Loss: 43.1282958984375 \n",
      "Epoch: 84860 | MAE Train Loss: 44.11470031738281 | MAE Test Loss: 43.1282958984375 \n",
      "Epoch: 84870 | MAE Train Loss: 44.11448287963867 | MAE Test Loss: 43.12830352783203 \n",
      "Epoch: 84880 | MAE Train Loss: 44.1142692565918 | MAE Test Loss: 43.12814712524414 \n",
      "Epoch: 84890 | MAE Train Loss: 44.114051818847656 | MAE Test Loss: 43.12815475463867 \n",
      "Epoch: 84900 | MAE Train Loss: 44.113834381103516 | MAE Test Loss: 43.1281623840332 \n",
      "Epoch: 84910 | MAE Train Loss: 44.11362075805664 | MAE Test Loss: 43.12816619873047 \n",
      "Epoch: 84920 | MAE Train Loss: 44.113407135009766 | MAE Test Loss: 43.128170013427734 \n",
      "Epoch: 84930 | MAE Train Loss: 44.113189697265625 | MAE Test Loss: 43.128177642822266 \n",
      "Epoch: 84940 | MAE Train Loss: 44.11297607421875 | MAE Test Loss: 43.1281852722168 \n",
      "Epoch: 84950 | MAE Train Loss: 44.112754821777344 | MAE Test Loss: 43.12818908691406 \n",
      "Epoch: 84960 | MAE Train Loss: 44.1125373840332 | MAE Test Loss: 43.12818908691406 \n",
      "Epoch: 84970 | MAE Train Loss: 44.11231994628906 | MAE Test Loss: 43.128196716308594 \n",
      "Epoch: 84980 | MAE Train Loss: 44.112098693847656 | MAE Test Loss: 43.12820816040039 \n",
      "Epoch: 84990 | MAE Train Loss: 44.11188507080078 | MAE Test Loss: 43.128047943115234 \n",
      "Epoch: 85000 | MAE Train Loss: 44.111671447753906 | MAE Test Loss: 43.1280517578125 \n",
      "Epoch: 85010 | MAE Train Loss: 44.111454010009766 | MAE Test Loss: 43.128055572509766 \n",
      "Epoch: 85020 | MAE Train Loss: 44.111236572265625 | MAE Test Loss: 43.1280632019043 \n",
      "Epoch: 85030 | MAE Train Loss: 44.11102294921875 | MAE Test Loss: 43.12807083129883 \n",
      "Epoch: 85040 | MAE Train Loss: 44.11080551147461 | MAE Test Loss: 43.128074645996094 \n",
      "Epoch: 85050 | MAE Train Loss: 44.11058807373047 | MAE Test Loss: 43.12807846069336 \n",
      "Epoch: 85060 | MAE Train Loss: 44.11037063598633 | MAE Test Loss: 43.128082275390625 \n",
      "Epoch: 85070 | MAE Train Loss: 44.11015319824219 | MAE Test Loss: 43.128089904785156 \n",
      "Epoch: 85080 | MAE Train Loss: 44.10993576049805 | MAE Test Loss: 43.12809753417969 \n",
      "Epoch: 85090 | MAE Train Loss: 44.109718322753906 | MAE Test Loss: 43.12810516357422 \n",
      "Epoch: 85100 | MAE Train Loss: 44.109500885009766 | MAE Test Loss: 43.12802505493164 \n",
      "Epoch: 85110 | MAE Train Loss: 44.109291076660156 | MAE Test Loss: 43.128028869628906 \n",
      "Epoch: 85120 | MAE Train Loss: 44.10906982421875 | MAE Test Loss: 43.12803268432617 \n",
      "Epoch: 85130 | MAE Train Loss: 44.108848571777344 | MAE Test Loss: 43.1280403137207 \n",
      "Epoch: 85140 | MAE Train Loss: 44.108638763427734 | MAE Test Loss: 43.12804412841797 \n",
      "Epoch: 85150 | MAE Train Loss: 44.108421325683594 | MAE Test Loss: 43.1280517578125 \n",
      "Epoch: 85160 | MAE Train Loss: 44.10820388793945 | MAE Test Loss: 43.12797546386719 \n",
      "Epoch: 85170 | MAE Train Loss: 44.10798645019531 | MAE Test Loss: 43.12797927856445 \n",
      "Epoch: 85180 | MAE Train Loss: 44.10776901245117 | MAE Test Loss: 43.12798309326172 \n",
      "Epoch: 85190 | MAE Train Loss: 44.10755157470703 | MAE Test Loss: 43.127994537353516 \n",
      "Epoch: 85200 | MAE Train Loss: 44.10733413696289 | MAE Test Loss: 43.12799835205078 \n",
      "Epoch: 85210 | MAE Train Loss: 44.107120513916016 | MAE Test Loss: 43.12792205810547 \n",
      "Epoch: 85220 | MAE Train Loss: 44.106903076171875 | MAE Test Loss: 43.127925872802734 \n",
      "Epoch: 85230 | MAE Train Loss: 44.106685638427734 | MAE Test Loss: 43.127933502197266 \n",
      "Epoch: 85240 | MAE Train Loss: 44.10646438598633 | MAE Test Loss: 43.12793731689453 \n",
      "Epoch: 85250 | MAE Train Loss: 44.10625076293945 | MAE Test Loss: 43.12794494628906 \n",
      "Epoch: 85260 | MAE Train Loss: 44.10602951049805 | MAE Test Loss: 43.12794494628906 \n",
      "Epoch: 85270 | MAE Train Loss: 44.10581970214844 | MAE Test Loss: 43.12787628173828 \n",
      "Epoch: 85280 | MAE Train Loss: 44.1056022644043 | MAE Test Loss: 43.12788009643555 \n",
      "Epoch: 85290 | MAE Train Loss: 44.105384826660156 | MAE Test Loss: 43.12788391113281 \n",
      "Epoch: 85300 | MAE Train Loss: 44.105167388916016 | MAE Test Loss: 43.12788772583008 \n",
      "Epoch: 85310 | MAE Train Loss: 44.104949951171875 | MAE Test Loss: 43.12789535522461 \n",
      "Epoch: 85320 | MAE Train Loss: 44.10472869873047 | MAE Test Loss: 43.1278190612793 \n",
      "Epoch: 85330 | MAE Train Loss: 44.10451889038086 | MAE Test Loss: 43.12782669067383 \n",
      "Epoch: 85340 | MAE Train Loss: 44.10430145263672 | MAE Test Loss: 43.127830505371094 \n",
      "Epoch: 85350 | MAE Train Loss: 44.10408020019531 | MAE Test Loss: 43.127838134765625 \n",
      "Epoch: 85360 | MAE Train Loss: 44.1038703918457 | MAE Test Loss: 43.127838134765625 \n",
      "Epoch: 85370 | MAE Train Loss: 44.10365295410156 | MAE Test Loss: 43.127845764160156 \n",
      "Epoch: 85380 | MAE Train Loss: 44.103431701660156 | MAE Test Loss: 43.127769470214844 \n",
      "Epoch: 85390 | MAE Train Loss: 44.10322189331055 | MAE Test Loss: 43.127777099609375 \n",
      "Epoch: 85400 | MAE Train Loss: 44.10300064086914 | MAE Test Loss: 43.127777099609375 \n",
      "Epoch: 85410 | MAE Train Loss: 44.102779388427734 | MAE Test Loss: 43.127784729003906 \n",
      "Epoch: 85420 | MAE Train Loss: 44.10256576538086 | MAE Test Loss: 43.12779235839844 \n",
      "Epoch: 85430 | MAE Train Loss: 44.10234832763672 | MAE Test Loss: 43.1277961730957 \n",
      "Epoch: 85440 | MAE Train Loss: 44.10213851928711 | MAE Test Loss: 43.12771987915039 \n",
      "Epoch: 85450 | MAE Train Loss: 44.1019172668457 | MAE Test Loss: 43.12773132324219 \n",
      "Epoch: 85460 | MAE Train Loss: 44.10169982910156 | MAE Test Loss: 43.12773132324219 \n",
      "Epoch: 85470 | MAE Train Loss: 44.10148239135742 | MAE Test Loss: 43.12773895263672 \n",
      "Epoch: 85480 | MAE Train Loss: 44.10126495361328 | MAE Test Loss: 43.12774658203125 \n",
      "Epoch: 85490 | MAE Train Loss: 44.10105514526367 | MAE Test Loss: 43.12767028808594 \n",
      "Epoch: 85500 | MAE Train Loss: 44.10083770751953 | MAE Test Loss: 43.12767028808594 \n",
      "Epoch: 85510 | MAE Train Loss: 44.100616455078125 | MAE Test Loss: 43.1276741027832 \n",
      "Epoch: 85520 | MAE Train Loss: 44.100399017333984 | MAE Test Loss: 43.127689361572266 \n",
      "Epoch: 85530 | MAE Train Loss: 44.100181579589844 | MAE Test Loss: 43.127689361572266 \n",
      "Epoch: 85540 | MAE Train Loss: 44.09996795654297 | MAE Test Loss: 43.1276969909668 \n",
      "Epoch: 85550 | MAE Train Loss: 44.099754333496094 | MAE Test Loss: 43.12761688232422 \n",
      "Epoch: 85560 | MAE Train Loss: 44.09953308105469 | MAE Test Loss: 43.12762451171875 \n",
      "Epoch: 85570 | MAE Train Loss: 44.09931945800781 | MAE Test Loss: 43.127628326416016 \n",
      "Epoch: 85580 | MAE Train Loss: 44.09909439086914 | MAE Test Loss: 43.12763977050781 \n",
      "Epoch: 85590 | MAE Train Loss: 44.098880767822266 | MAE Test Loss: 43.12763977050781 \n",
      "Epoch: 85600 | MAE Train Loss: 44.09866714477539 | MAE Test Loss: 43.12748718261719 \n",
      "Epoch: 85610 | MAE Train Loss: 44.098445892333984 | MAE Test Loss: 43.12748718261719 \n",
      "Epoch: 85620 | MAE Train Loss: 44.098228454589844 | MAE Test Loss: 43.12749481201172 \n",
      "Epoch: 85630 | MAE Train Loss: 44.09801483154297 | MAE Test Loss: 43.12750244140625 \n",
      "Epoch: 85640 | MAE Train Loss: 44.097801208496094 | MAE Test Loss: 43.127506256103516 \n",
      "Epoch: 85650 | MAE Train Loss: 44.09758758544922 | MAE Test Loss: 43.12751388549805 \n",
      "Epoch: 85660 | MAE Train Loss: 44.09737014770508 | MAE Test Loss: 43.12751770019531 \n",
      "Epoch: 85670 | MAE Train Loss: 44.09714889526367 | MAE Test Loss: 43.127525329589844 \n",
      "Epoch: 85680 | MAE Train Loss: 44.0969352722168 | MAE Test Loss: 43.127532958984375 \n",
      "Epoch: 85690 | MAE Train Loss: 44.09671401977539 | MAE Test Loss: 43.1275634765625 \n",
      "Epoch: 85700 | MAE Train Loss: 44.09649658203125 | MAE Test Loss: 43.12759017944336 \n",
      "Epoch: 85710 | MAE Train Loss: 44.096275329589844 | MAE Test Loss: 43.12761688232422 \n",
      "Epoch: 85720 | MAE Train Loss: 44.09606170654297 | MAE Test Loss: 43.1275520324707 \n",
      "Epoch: 85730 | MAE Train Loss: 44.095848083496094 | MAE Test Loss: 43.12757873535156 \n",
      "Epoch: 85740 | MAE Train Loss: 44.09563446044922 | MAE Test Loss: 43.12760543823242 \n",
      "Epoch: 85750 | MAE Train Loss: 44.09541702270508 | MAE Test Loss: 43.12763214111328 \n",
      "Epoch: 85760 | MAE Train Loss: 44.09519958496094 | MAE Test Loss: 43.127655029296875 \n",
      "Epoch: 85770 | MAE Train Loss: 44.0949821472168 | MAE Test Loss: 43.127681732177734 \n",
      "Epoch: 85780 | MAE Train Loss: 44.09476852416992 | MAE Test Loss: 43.12771224975586 \n",
      "Epoch: 85790 | MAE Train Loss: 44.09455108642578 | MAE Test Loss: 43.127742767333984 \n",
      "Epoch: 85800 | MAE Train Loss: 44.094329833984375 | MAE Test Loss: 43.127769470214844 \n",
      "Epoch: 85810 | MAE Train Loss: 44.0941162109375 | MAE Test Loss: 43.1277961730957 \n",
      "Epoch: 85820 | MAE Train Loss: 44.09389877319336 | MAE Test Loss: 43.12782669067383 \n",
      "Epoch: 85830 | MAE Train Loss: 44.093685150146484 | MAE Test Loss: 43.12775802612305 \n",
      "Epoch: 85840 | MAE Train Loss: 44.09346389770508 | MAE Test Loss: 43.12778854370117 \n",
      "Epoch: 85850 | MAE Train Loss: 44.09324645996094 | MAE Test Loss: 43.12781524658203 \n",
      "Epoch: 85860 | MAE Train Loss: 44.0930290222168 | MAE Test Loss: 43.12784194946289 \n",
      "Epoch: 85870 | MAE Train Loss: 44.09281921386719 | MAE Test Loss: 43.12786865234375 \n",
      "Epoch: 85880 | MAE Train Loss: 44.09259796142578 | MAE Test Loss: 43.127845764160156 \n",
      "Epoch: 85890 | MAE Train Loss: 44.09238052368164 | MAE Test Loss: 43.12787628173828 \n",
      "Epoch: 85900 | MAE Train Loss: 44.0921630859375 | MAE Test Loss: 43.127906799316406 \n",
      "Epoch: 85910 | MAE Train Loss: 44.09194564819336 | MAE Test Loss: 43.1279296875 \n",
      "Epoch: 85920 | MAE Train Loss: 44.091732025146484 | MAE Test Loss: 43.12796401977539 \n",
      "Epoch: 85930 | MAE Train Loss: 44.09151840209961 | MAE Test Loss: 43.12799072265625 \n",
      "Epoch: 85940 | MAE Train Loss: 44.0912971496582 | MAE Test Loss: 43.12797164916992 \n",
      "Epoch: 85950 | MAE Train Loss: 44.09108352661133 | MAE Test Loss: 43.127994537353516 \n",
      "Epoch: 85960 | MAE Train Loss: 44.09086608886719 | MAE Test Loss: 43.128021240234375 \n",
      "Epoch: 85970 | MAE Train Loss: 44.09064483642578 | MAE Test Loss: 43.1280517578125 \n",
      "Epoch: 85980 | MAE Train Loss: 44.090431213378906 | MAE Test Loss: 43.128082275390625 \n",
      "Epoch: 85990 | MAE Train Loss: 44.090213775634766 | MAE Test Loss: 43.128108978271484 \n",
      "Epoch: 86000 | MAE Train Loss: 44.08999252319336 | MAE Test Loss: 43.12808609008789 \n",
      "Epoch: 86010 | MAE Train Loss: 44.089778900146484 | MAE Test Loss: 43.128116607666016 \n",
      "Epoch: 86020 | MAE Train Loss: 44.08956527709961 | MAE Test Loss: 43.12813949584961 \n",
      "Epoch: 86030 | MAE Train Loss: 44.08934783935547 | MAE Test Loss: 43.128170013427734 \n",
      "Epoch: 86040 | MAE Train Loss: 44.089134216308594 | MAE Test Loss: 43.128196716308594 \n",
      "Epoch: 86050 | MAE Train Loss: 44.08891296386719 | MAE Test Loss: 43.128177642822266 \n",
      "Epoch: 86060 | MAE Train Loss: 44.08869552612305 | MAE Test Loss: 43.12820816040039 \n",
      "Epoch: 86070 | MAE Train Loss: 44.088478088378906 | MAE Test Loss: 43.128238677978516 \n",
      "Epoch: 86080 | MAE Train Loss: 44.08826446533203 | MAE Test Loss: 43.128257751464844 \n",
      "Epoch: 86090 | MAE Train Loss: 44.08804702758789 | MAE Test Loss: 43.12828826904297 \n",
      "Epoch: 86100 | MAE Train Loss: 44.08782958984375 | MAE Test Loss: 43.12831497192383 \n",
      "Epoch: 86110 | MAE Train Loss: 44.08761215209961 | MAE Test Loss: 43.1282958984375 \n",
      "Epoch: 86120 | MAE Train Loss: 44.08739471435547 | MAE Test Loss: 43.128326416015625 \n",
      "Epoch: 86130 | MAE Train Loss: 44.08717727661133 | MAE Test Loss: 43.128353118896484 \n",
      "Epoch: 86140 | MAE Train Loss: 44.08695983886719 | MAE Test Loss: 43.128379821777344 \n",
      "Epoch: 86150 | MAE Train Loss: 44.08674621582031 | MAE Test Loss: 43.1284065246582 \n",
      "Epoch: 86160 | MAE Train Loss: 44.08652877807617 | MAE Test Loss: 43.12838363647461 \n",
      "Epoch: 86170 | MAE Train Loss: 44.08631134033203 | MAE Test Loss: 43.12841796875 \n",
      "Epoch: 86180 | MAE Train Loss: 44.08609390258789 | MAE Test Loss: 43.12844467163086 \n",
      "Epoch: 86190 | MAE Train Loss: 44.085880279541016 | MAE Test Loss: 43.12847137451172 \n",
      "Epoch: 86200 | MAE Train Loss: 44.085662841796875 | MAE Test Loss: 43.12849426269531 \n",
      "Epoch: 86210 | MAE Train Loss: 44.08544921875 | MAE Test Loss: 43.1285285949707 \n",
      "Epoch: 86220 | MAE Train Loss: 44.085227966308594 | MAE Test Loss: 43.128501892089844 \n",
      "Epoch: 86230 | MAE Train Loss: 44.085018157958984 | MAE Test Loss: 43.12853240966797 \n",
      "Epoch: 86240 | MAE Train Loss: 44.08479690551758 | MAE Test Loss: 43.12855911254883 \n",
      "Epoch: 86250 | MAE Train Loss: 44.08457946777344 | MAE Test Loss: 43.12858963012695 \n",
      "Epoch: 86260 | MAE Train Loss: 44.0843620300293 | MAE Test Loss: 43.12861633300781 \n",
      "Epoch: 86270 | MAE Train Loss: 44.084144592285156 | MAE Test Loss: 43.12864685058594 \n",
      "Epoch: 86280 | MAE Train Loss: 44.083927154541016 | MAE Test Loss: 43.12862777709961 \n",
      "Epoch: 86290 | MAE Train Loss: 44.08371353149414 | MAE Test Loss: 43.1286506652832 \n",
      "Epoch: 86300 | MAE Train Loss: 44.083492279052734 | MAE Test Loss: 43.12868118286133 \n",
      "Epoch: 86310 | MAE Train Loss: 44.08327865600586 | MAE Test Loss: 43.12870788574219 \n",
      "Epoch: 86320 | MAE Train Loss: 44.083065032958984 | MAE Test Loss: 43.12873458862305 \n",
      "Epoch: 86330 | MAE Train Loss: 44.08284378051758 | MAE Test Loss: 43.12871551513672 \n",
      "Epoch: 86340 | MAE Train Loss: 44.08262634277344 | MAE Test Loss: 43.12874221801758 \n",
      "Epoch: 86350 | MAE Train Loss: 44.0824089050293 | MAE Test Loss: 43.1287727355957 \n",
      "Epoch: 86360 | MAE Train Loss: 44.08219909667969 | MAE Test Loss: 43.12880325317383 \n",
      "Epoch: 86370 | MAE Train Loss: 44.08198165893555 | MAE Test Loss: 43.12882995605469 \n",
      "Epoch: 86380 | MAE Train Loss: 44.081764221191406 | MAE Test Loss: 43.12885284423828 \n",
      "Epoch: 86390 | MAE Train Loss: 44.08154296875 | MAE Test Loss: 43.12883758544922 \n",
      "Epoch: 86400 | MAE Train Loss: 44.08132553100586 | MAE Test Loss: 43.12886047363281 \n",
      "Epoch: 86410 | MAE Train Loss: 44.08110809326172 | MAE Test Loss: 43.12889099121094 \n",
      "Epoch: 86420 | MAE Train Loss: 44.08089828491211 | MAE Test Loss: 43.12892150878906 \n",
      "Epoch: 86430 | MAE Train Loss: 44.0806770324707 | MAE Test Loss: 43.12894821166992 \n",
      "Epoch: 86440 | MAE Train Loss: 44.08045959472656 | MAE Test Loss: 43.128929138183594 \n",
      "Epoch: 86450 | MAE Train Loss: 44.08024597167969 | MAE Test Loss: 43.12895202636719 \n",
      "Epoch: 86460 | MAE Train Loss: 44.08002853393555 | MAE Test Loss: 43.12898254394531 \n",
      "Epoch: 86470 | MAE Train Loss: 44.079811096191406 | MAE Test Loss: 43.12900924682617 \n",
      "Epoch: 86480 | MAE Train Loss: 44.079593658447266 | MAE Test Loss: 43.1290397644043 \n",
      "Epoch: 86490 | MAE Train Loss: 44.07938003540039 | MAE Test Loss: 43.129066467285156 \n",
      "Epoch: 86500 | MAE Train Loss: 44.07916259765625 | MAE Test Loss: 43.129093170166016 \n",
      "Epoch: 86510 | MAE Train Loss: 44.07894515991211 | MAE Test Loss: 43.129119873046875 \n",
      "Epoch: 86520 | MAE Train Loss: 44.07872772216797 | MAE Test Loss: 43.129150390625 \n",
      "Epoch: 86530 | MAE Train Loss: 44.078514099121094 | MAE Test Loss: 43.12917709350586 \n",
      "Epoch: 86540 | MAE Train Loss: 44.07829284667969 | MAE Test Loss: 43.129207611083984 \n",
      "Epoch: 86550 | MAE Train Loss: 44.07807540893555 | MAE Test Loss: 43.129234313964844 \n",
      "Epoch: 86560 | MAE Train Loss: 44.077857971191406 | MAE Test Loss: 43.12916564941406 \n",
      "Epoch: 86570 | MAE Train Loss: 44.07763671875 | MAE Test Loss: 43.12919616699219 \n",
      "Epoch: 86580 | MAE Train Loss: 44.077423095703125 | MAE Test Loss: 43.12921905517578 \n",
      "Epoch: 86590 | MAE Train Loss: 44.077213287353516 | MAE Test Loss: 43.129249572753906 \n",
      "Epoch: 86600 | MAE Train Loss: 44.076995849609375 | MAE Test Loss: 43.1292724609375 \n",
      "Epoch: 86610 | MAE Train Loss: 44.076778411865234 | MAE Test Loss: 43.12930679321289 \n",
      "Epoch: 86620 | MAE Train Loss: 44.076560974121094 | MAE Test Loss: 43.12933349609375 \n",
      "Epoch: 86630 | MAE Train Loss: 44.07634353637695 | MAE Test Loss: 43.12936019897461 \n",
      "Epoch: 86640 | MAE Train Loss: 44.07612609863281 | MAE Test Loss: 43.129390716552734 \n",
      "Epoch: 86650 | MAE Train Loss: 44.07591247558594 | MAE Test Loss: 43.129417419433594 \n",
      "Epoch: 86660 | MAE Train Loss: 44.07569122314453 | MAE Test Loss: 43.12944793701172 \n",
      "Epoch: 86670 | MAE Train Loss: 44.07547378540039 | MAE Test Loss: 43.12937545776367 \n",
      "Epoch: 86680 | MAE Train Loss: 44.075260162353516 | MAE Test Loss: 43.12940216064453 \n",
      "Epoch: 86690 | MAE Train Loss: 44.075042724609375 | MAE Test Loss: 43.12942886352539 \n",
      "Epoch: 86700 | MAE Train Loss: 44.0748291015625 | MAE Test Loss: 43.129459381103516 \n",
      "Epoch: 86710 | MAE Train Loss: 44.07461166381836 | MAE Test Loss: 43.129486083984375 \n",
      "Epoch: 86720 | MAE Train Loss: 44.07439422607422 | MAE Test Loss: 43.1295166015625 \n",
      "Epoch: 86730 | MAE Train Loss: 44.07417297363281 | MAE Test Loss: 43.12954330444336 \n",
      "Epoch: 86740 | MAE Train Loss: 44.0739631652832 | MAE Test Loss: 43.12957000732422 \n",
      "Epoch: 86750 | MAE Train Loss: 44.07374572753906 | MAE Test Loss: 43.12959671020508 \n",
      "Epoch: 86760 | MAE Train Loss: 44.073524475097656 | MAE Test Loss: 43.1296272277832 \n",
      "Epoch: 86770 | MAE Train Loss: 44.073307037353516 | MAE Test Loss: 43.12965393066406 \n",
      "Epoch: 86780 | MAE Train Loss: 44.07309341430664 | MAE Test Loss: 43.129634857177734 \n",
      "Epoch: 86790 | MAE Train Loss: 44.0728759765625 | MAE Test Loss: 43.129661560058594 \n",
      "Epoch: 86800 | MAE Train Loss: 44.072662353515625 | MAE Test Loss: 43.12969207763672 \n",
      "Epoch: 86810 | MAE Train Loss: 44.07244110107422 | MAE Test Loss: 43.129722595214844 \n",
      "Epoch: 86820 | MAE Train Loss: 44.072227478027344 | MAE Test Loss: 43.1297492980957 \n",
      "Epoch: 86830 | MAE Train Loss: 44.0720100402832 | MAE Test Loss: 43.129722595214844 \n",
      "Epoch: 86840 | MAE Train Loss: 44.07179641723633 | MAE Test Loss: 43.1297492980957 \n",
      "Epoch: 86850 | MAE Train Loss: 44.07157516479492 | MAE Test Loss: 43.129783630371094 \n",
      "Epoch: 86860 | MAE Train Loss: 44.07135772705078 | MAE Test Loss: 43.12981033325195 \n",
      "Epoch: 86870 | MAE Train Loss: 44.071144104003906 | MAE Test Loss: 43.12983703613281 \n",
      "Epoch: 86880 | MAE Train Loss: 44.070926666259766 | MAE Test Loss: 43.12986755371094 \n",
      "Epoch: 86890 | MAE Train Loss: 44.070709228515625 | MAE Test Loss: 43.129844665527344 \n",
      "Epoch: 86900 | MAE Train Loss: 44.070491790771484 | MAE Test Loss: 43.1298713684082 \n",
      "Epoch: 86910 | MAE Train Loss: 44.07027816772461 | MAE Test Loss: 43.12989807128906 \n",
      "Epoch: 86920 | MAE Train Loss: 44.0700569152832 | MAE Test Loss: 43.12993240356445 \n",
      "Epoch: 86930 | MAE Train Loss: 44.06984329223633 | MAE Test Loss: 43.12995529174805 \n",
      "Epoch: 86940 | MAE Train Loss: 44.06962203979492 | MAE Test Loss: 43.12998580932617 \n",
      "Epoch: 86950 | MAE Train Loss: 44.06941223144531 | MAE Test Loss: 43.12995910644531 \n",
      "Epoch: 86960 | MAE Train Loss: 44.069190979003906 | MAE Test Loss: 43.12998962402344 \n",
      "Epoch: 86970 | MAE Train Loss: 44.068973541259766 | MAE Test Loss: 43.1300163269043 \n",
      "Epoch: 86980 | MAE Train Loss: 44.068756103515625 | MAE Test Loss: 43.13005065917969 \n",
      "Epoch: 86990 | MAE Train Loss: 44.068538665771484 | MAE Test Loss: 43.13008117675781 \n",
      "Epoch: 87000 | MAE Train Loss: 44.06832504272461 | MAE Test Loss: 43.13005828857422 \n",
      "Epoch: 87010 | MAE Train Loss: 44.068111419677734 | MAE Test Loss: 43.13008117675781 \n",
      "Epoch: 87020 | MAE Train Loss: 44.06789016723633 | MAE Test Loss: 43.13011169433594 \n",
      "Epoch: 87030 | MAE Train Loss: 44.06767272949219 | MAE Test Loss: 43.13014221191406 \n",
      "Epoch: 87040 | MAE Train Loss: 44.06745529174805 | MAE Test Loss: 43.13016891479492 \n",
      "Epoch: 87050 | MAE Train Loss: 44.067237854003906 | MAE Test Loss: 43.13019943237305 \n",
      "Epoch: 87060 | MAE Train Loss: 44.06702423095703 | MAE Test Loss: 43.13017654418945 \n",
      "Epoch: 87070 | MAE Train Loss: 44.06680679321289 | MAE Test Loss: 43.13019943237305 \n",
      "Epoch: 87080 | MAE Train Loss: 44.066593170166016 | MAE Test Loss: 43.13022994995117 \n",
      "Epoch: 87090 | MAE Train Loss: 44.066375732421875 | MAE Test Loss: 43.1302604675293 \n",
      "Epoch: 87100 | MAE Train Loss: 44.06615447998047 | MAE Test Loss: 43.13028335571289 \n",
      "Epoch: 87110 | MAE Train Loss: 44.06593704223633 | MAE Test Loss: 43.13026428222656 \n",
      "Epoch: 87120 | MAE Train Loss: 44.06572341918945 | MAE Test Loss: 43.13029098510742 \n",
      "Epoch: 87130 | MAE Train Loss: 44.06550598144531 | MAE Test Loss: 43.13032150268555 \n",
      "Epoch: 87140 | MAE Train Loss: 44.06529235839844 | MAE Test Loss: 43.130348205566406 \n",
      "Epoch: 87150 | MAE Train Loss: 44.0650749206543 | MAE Test Loss: 43.130374908447266 \n",
      "Epoch: 87160 | MAE Train Loss: 44.064857482910156 | MAE Test Loss: 43.130401611328125 \n",
      "Epoch: 87170 | MAE Train Loss: 44.064640045166016 | MAE Test Loss: 43.13038635253906 \n",
      "Epoch: 87180 | MAE Train Loss: 44.064422607421875 | MAE Test Loss: 43.13041305541992 \n",
      "Epoch: 87190 | MAE Train Loss: 44.064208984375 | MAE Test Loss: 43.13044357299805 \n",
      "Epoch: 87200 | MAE Train Loss: 44.06398391723633 | MAE Test Loss: 43.13046646118164 \n",
      "Epoch: 87210 | MAE Train Loss: 44.06377410888672 | MAE Test Loss: 43.130496978759766 \n",
      "Epoch: 87220 | MAE Train Loss: 44.06355667114258 | MAE Test Loss: 43.130523681640625 \n",
      "Epoch: 87230 | MAE Train Loss: 44.0633430480957 | MAE Test Loss: 43.13050079345703 \n",
      "Epoch: 87240 | MAE Train Loss: 44.0631217956543 | MAE Test Loss: 43.130531311035156 \n",
      "Epoch: 87250 | MAE Train Loss: 44.06290817260742 | MAE Test Loss: 43.13056182861328 \n",
      "Epoch: 87260 | MAE Train Loss: 44.062686920166016 | MAE Test Loss: 43.13058853149414 \n",
      "Epoch: 87270 | MAE Train Loss: 44.06247329711914 | MAE Test Loss: 43.130611419677734 \n",
      "Epoch: 87280 | MAE Train Loss: 44.062259674072266 | MAE Test Loss: 43.130592346191406 \n",
      "Epoch: 87290 | MAE Train Loss: 44.062042236328125 | MAE Test Loss: 43.130619049072266 \n",
      "Epoch: 87300 | MAE Train Loss: 44.06182098388672 | MAE Test Loss: 43.130645751953125 \n",
      "Epoch: 87310 | MAE Train Loss: 44.06160354614258 | MAE Test Loss: 43.130680084228516 \n",
      "Epoch: 87320 | MAE Train Loss: 44.0613899230957 | MAE Test Loss: 43.130706787109375 \n",
      "Epoch: 87330 | MAE Train Loss: 44.0611686706543 | MAE Test Loss: 43.130733489990234 \n",
      "Epoch: 87340 | MAE Train Loss: 44.06095504760742 | MAE Test Loss: 43.13066101074219 \n",
      "Epoch: 87350 | MAE Train Loss: 44.06073760986328 | MAE Test Loss: 43.13068771362305 \n",
      "Epoch: 87360 | MAE Train Loss: 44.06052017211914 | MAE Test Loss: 43.13072204589844 \n",
      "Epoch: 87370 | MAE Train Loss: 44.06031036376953 | MAE Test Loss: 43.1307487487793 \n",
      "Epoch: 87380 | MAE Train Loss: 44.06009292602539 | MAE Test Loss: 43.130775451660156 \n",
      "Epoch: 87390 | MAE Train Loss: 44.05987548828125 | MAE Test Loss: 43.13080596923828 \n",
      "Epoch: 87400 | MAE Train Loss: 44.059654235839844 | MAE Test Loss: 43.130836486816406 \n",
      "Epoch: 87410 | MAE Train Loss: 44.0594367980957 | MAE Test Loss: 43.130859375 \n",
      "Epoch: 87420 | MAE Train Loss: 44.05922317504883 | MAE Test Loss: 43.13088607788086 \n",
      "Epoch: 87430 | MAE Train Loss: 44.05900192260742 | MAE Test Loss: 43.13091278076172 \n",
      "Epoch: 87440 | MAE Train Loss: 44.05878829956055 | MAE Test Loss: 43.13094711303711 \n",
      "Epoch: 87450 | MAE Train Loss: 44.058570861816406 | MAE Test Loss: 43.13087463378906 \n",
      "Epoch: 87460 | MAE Train Loss: 44.058349609375 | MAE Test Loss: 43.13090515136719 \n",
      "Epoch: 87470 | MAE Train Loss: 44.05813980102539 | MAE Test Loss: 43.13092803955078 \n",
      "Epoch: 87480 | MAE Train Loss: 44.05792236328125 | MAE Test Loss: 43.13095474243164 \n",
      "Epoch: 87490 | MAE Train Loss: 44.057701110839844 | MAE Test Loss: 43.130985260009766 \n",
      "Epoch: 87500 | MAE Train Loss: 44.057491302490234 | MAE Test Loss: 43.131011962890625 \n",
      "Epoch: 87510 | MAE Train Loss: 44.05727767944336 | MAE Test Loss: 43.13104248046875 \n",
      "Epoch: 87520 | MAE Train Loss: 44.05705642700195 | MAE Test Loss: 43.13106918334961 \n",
      "Epoch: 87530 | MAE Train Loss: 44.05683898925781 | MAE Test Loss: 43.131099700927734 \n",
      "Epoch: 87540 | MAE Train Loss: 44.05662536621094 | MAE Test Loss: 43.13112258911133 \n",
      "Epoch: 87550 | MAE Train Loss: 44.05640411376953 | MAE Test Loss: 43.13115310668945 \n",
      "Epoch: 87560 | MAE Train Loss: 44.05618667602539 | MAE Test Loss: 43.131080627441406 \n",
      "Epoch: 87570 | MAE Train Loss: 44.05596923828125 | MAE Test Loss: 43.1311149597168 \n",
      "Epoch: 87580 | MAE Train Loss: 44.055755615234375 | MAE Test Loss: 43.131141662597656 \n",
      "Epoch: 87590 | MAE Train Loss: 44.055538177490234 | MAE Test Loss: 43.131168365478516 \n",
      "Epoch: 87600 | MAE Train Loss: 44.05532455444336 | MAE Test Loss: 43.131195068359375 \n",
      "Epoch: 87610 | MAE Train Loss: 44.05510711669922 | MAE Test Loss: 43.1312255859375 \n",
      "Epoch: 87620 | MAE Train Loss: 44.05488586425781 | MAE Test Loss: 43.131202697753906 \n",
      "Epoch: 87630 | MAE Train Loss: 44.05466842651367 | MAE Test Loss: 43.131229400634766 \n",
      "Epoch: 87640 | MAE Train Loss: 44.0544548034668 | MAE Test Loss: 43.13125991821289 \n",
      "Epoch: 87650 | MAE Train Loss: 44.05424118041992 | MAE Test Loss: 43.131282806396484 \n",
      "Epoch: 87660 | MAE Train Loss: 44.05402374267578 | MAE Test Loss: 43.13131332397461 \n",
      "Epoch: 87670 | MAE Train Loss: 44.05380630493164 | MAE Test Loss: 43.13129425048828 \n",
      "Epoch: 87680 | MAE Train Loss: 44.053585052490234 | MAE Test Loss: 43.13132095336914 \n",
      "Epoch: 87690 | MAE Train Loss: 44.05337142944336 | MAE Test Loss: 43.131351470947266 \n",
      "Epoch: 87700 | MAE Train Loss: 44.05315399169922 | MAE Test Loss: 43.13138198852539 \n",
      "Epoch: 87710 | MAE Train Loss: 44.05293273925781 | MAE Test Loss: 43.131404876708984 \n",
      "Epoch: 87720 | MAE Train Loss: 44.0527229309082 | MAE Test Loss: 43.13143539428711 \n",
      "Epoch: 87730 | MAE Train Loss: 44.0525016784668 | MAE Test Loss: 43.13141632080078 \n",
      "Epoch: 87740 | MAE Train Loss: 44.052284240722656 | MAE Test Loss: 43.131439208984375 \n",
      "Epoch: 87750 | MAE Train Loss: 44.05207061767578 | MAE Test Loss: 43.1314697265625 \n",
      "Epoch: 87760 | MAE Train Loss: 44.05185317993164 | MAE Test Loss: 43.131500244140625 \n",
      "Epoch: 87770 | MAE Train Loss: 44.051639556884766 | MAE Test Loss: 43.131526947021484 \n",
      "Epoch: 87780 | MAE Train Loss: 44.051422119140625 | MAE Test Loss: 43.13154983520508 \n",
      "Epoch: 87790 | MAE Train Loss: 44.05120086669922 | MAE Test Loss: 43.131534576416016 \n",
      "Epoch: 87800 | MAE Train Loss: 44.05098342895508 | MAE Test Loss: 43.13156509399414 \n",
      "Epoch: 87810 | MAE Train Loss: 44.0507698059082 | MAE Test Loss: 43.131587982177734 \n",
      "Epoch: 87820 | MAE Train Loss: 44.05055236816406 | MAE Test Loss: 43.131614685058594 \n",
      "Epoch: 87830 | MAE Train Loss: 44.05033874511719 | MAE Test Loss: 43.13164520263672 \n",
      "Epoch: 87840 | MAE Train Loss: 44.050113677978516 | MAE Test Loss: 43.131622314453125 \n",
      "Epoch: 87850 | MAE Train Loss: 44.04990005493164 | MAE Test Loss: 43.13165283203125 \n",
      "Epoch: 87860 | MAE Train Loss: 44.049686431884766 | MAE Test Loss: 43.13167953491211 \n",
      "Epoch: 87870 | MAE Train Loss: 44.04947280883789 | MAE Test Loss: 43.1317024230957 \n",
      "Epoch: 87880 | MAE Train Loss: 44.04925537109375 | MAE Test Loss: 43.13173294067383 \n",
      "Epoch: 87890 | MAE Train Loss: 44.049034118652344 | MAE Test Loss: 43.13176345825195 \n",
      "Epoch: 87900 | MAE Train Loss: 44.0488166809082 | MAE Test Loss: 43.131744384765625 \n",
      "Epoch: 87910 | MAE Train Loss: 44.04860305786133 | MAE Test Loss: 43.131771087646484 \n",
      "Epoch: 87920 | MAE Train Loss: 44.04838562011719 | MAE Test Loss: 43.13180160522461 \n",
      "Epoch: 87930 | MAE Train Loss: 44.04816818237305 | MAE Test Loss: 43.13182830810547 \n",
      "Epoch: 87940 | MAE Train Loss: 44.04795455932617 | MAE Test Loss: 43.13185119628906 \n",
      "Epoch: 87950 | MAE Train Loss: 44.04773712158203 | MAE Test Loss: 43.131832122802734 \n",
      "Epoch: 87960 | MAE Train Loss: 44.047523498535156 | MAE Test Loss: 43.13186264038086 \n",
      "Epoch: 87970 | MAE Train Loss: 44.04730224609375 | MAE Test Loss: 43.13188934326172 \n",
      "Epoch: 87980 | MAE Train Loss: 44.04708480834961 | MAE Test Loss: 43.131919860839844 \n",
      "Epoch: 87990 | MAE Train Loss: 44.046871185302734 | MAE Test Loss: 43.1319465637207 \n",
      "Epoch: 88000 | MAE Train Loss: 44.046653747558594 | MAE Test Loss: 43.13197326660156 \n",
      "Epoch: 88010 | MAE Train Loss: 44.04643630981445 | MAE Test Loss: 43.13195037841797 \n",
      "Epoch: 88020 | MAE Train Loss: 44.04621505737305 | MAE Test Loss: 43.13197708129883 \n",
      "Epoch: 88030 | MAE Train Loss: 44.04600143432617 | MAE Test Loss: 43.13200759887695 \n",
      "Epoch: 88040 | MAE Train Loss: 44.04578399658203 | MAE Test Loss: 43.13203811645508 \n",
      "Epoch: 88050 | MAE Train Loss: 44.045570373535156 | MAE Test Loss: 43.13206481933594 \n",
      "Epoch: 88060 | MAE Train Loss: 44.045352935791016 | MAE Test Loss: 43.1320915222168 \n",
      "Epoch: 88070 | MAE Train Loss: 44.04513168334961 | MAE Test Loss: 43.13207244873047 \n",
      "Epoch: 88080 | MAE Train Loss: 44.04491424560547 | MAE Test Loss: 43.13209915161133 \n",
      "Epoch: 88090 | MAE Train Loss: 44.04470443725586 | MAE Test Loss: 43.13213348388672 \n",
      "Epoch: 88100 | MAE Train Loss: 44.04448318481445 | MAE Test Loss: 43.13215637207031 \n",
      "Epoch: 88110 | MAE Train Loss: 44.044273376464844 | MAE Test Loss: 43.13218307495117 \n",
      "Epoch: 88120 | MAE Train Loss: 44.04404830932617 | MAE Test Loss: 43.132164001464844 \n",
      "Epoch: 88130 | MAE Train Loss: 44.04383087158203 | MAE Test Loss: 43.1321907043457 \n",
      "Epoch: 88140 | MAE Train Loss: 44.043617248535156 | MAE Test Loss: 43.13222122192383 \n",
      "Epoch: 88150 | MAE Train Loss: 44.04339599609375 | MAE Test Loss: 43.13224411010742 \n",
      "Epoch: 88160 | MAE Train Loss: 44.04318618774414 | MAE Test Loss: 43.13227462768555 \n",
      "Epoch: 88170 | MAE Train Loss: 44.042972564697266 | MAE Test Loss: 43.132301330566406 \n",
      "Epoch: 88180 | MAE Train Loss: 44.04275131225586 | MAE Test Loss: 43.132328033447266 \n",
      "Epoch: 88190 | MAE Train Loss: 44.042537689208984 | MAE Test Loss: 43.132362365722656 \n",
      "Epoch: 88200 | MAE Train Loss: 44.042320251464844 | MAE Test Loss: 43.132389068603516 \n",
      "Epoch: 88210 | MAE Train Loss: 44.04209899902344 | MAE Test Loss: 43.132415771484375 \n",
      "Epoch: 88220 | MAE Train Loss: 44.0418815612793 | MAE Test Loss: 43.1324462890625 \n",
      "Epoch: 88230 | MAE Train Loss: 44.04166793823242 | MAE Test Loss: 43.13237380981445 \n",
      "Epoch: 88240 | MAE Train Loss: 44.041446685791016 | MAE Test Loss: 43.13240432739258 \n",
      "Epoch: 88250 | MAE Train Loss: 44.04123306274414 | MAE Test Loss: 43.13243103027344 \n",
      "Epoch: 88260 | MAE Train Loss: 44.041019439697266 | MAE Test Loss: 43.1324577331543 \n",
      "Epoch: 88270 | MAE Train Loss: 44.04079818725586 | MAE Test Loss: 43.132484436035156 \n",
      "Epoch: 88280 | MAE Train Loss: 44.04058837890625 | MAE Test Loss: 43.13251495361328 \n",
      "Epoch: 88290 | MAE Train Loss: 44.040367126464844 | MAE Test Loss: 43.132545471191406 \n",
      "Epoch: 88300 | MAE Train Loss: 44.04015350341797 | MAE Test Loss: 43.132568359375 \n",
      "Epoch: 88310 | MAE Train Loss: 44.03993225097656 | MAE Test Loss: 43.13259506225586 \n",
      "Epoch: 88320 | MAE Train Loss: 44.03971481323242 | MAE Test Loss: 43.132625579833984 \n",
      "Epoch: 88330 | MAE Train Loss: 44.03949737548828 | MAE Test Loss: 43.132652282714844 \n",
      "Epoch: 88340 | MAE Train Loss: 44.03927993774414 | MAE Test Loss: 43.1326789855957 \n",
      "Epoch: 88350 | MAE Train Loss: 44.0390625 | MAE Test Loss: 43.13261413574219 \n",
      "Epoch: 88360 | MAE Train Loss: 44.03885269165039 | MAE Test Loss: 43.13264083862305 \n",
      "Epoch: 88370 | MAE Train Loss: 44.03863525390625 | MAE Test Loss: 43.132667541503906 \n",
      "Epoch: 88380 | MAE Train Loss: 44.038414001464844 | MAE Test Loss: 43.132694244384766 \n",
      "Epoch: 88390 | MAE Train Loss: 44.038204193115234 | MAE Test Loss: 43.13272476196289 \n",
      "Epoch: 88400 | MAE Train Loss: 44.03798294067383 | MAE Test Loss: 43.132755279541016 \n",
      "Epoch: 88410 | MAE Train Loss: 44.03776931762695 | MAE Test Loss: 43.13277816772461 \n",
      "Epoch: 88420 | MAE Train Loss: 44.03755187988281 | MAE Test Loss: 43.132808685302734 \n",
      "Epoch: 88430 | MAE Train Loss: 44.037330627441406 | MAE Test Loss: 43.132835388183594 \n",
      "Epoch: 88440 | MAE Train Loss: 44.037113189697266 | MAE Test Loss: 43.13286209106445 \n",
      "Epoch: 88450 | MAE Train Loss: 44.03689956665039 | MAE Test Loss: 43.13289260864258 \n",
      "Epoch: 88460 | MAE Train Loss: 44.036685943603516 | MAE Test Loss: 43.132869720458984 \n",
      "Epoch: 88470 | MAE Train Loss: 44.036468505859375 | MAE Test Loss: 43.13290023803711 \n",
      "Epoch: 88480 | MAE Train Loss: 44.03624725341797 | MAE Test Loss: 43.132930755615234 \n",
      "Epoch: 88490 | MAE Train Loss: 44.036033630371094 | MAE Test Loss: 43.13295364379883 \n",
      "Epoch: 88500 | MAE Train Loss: 44.03581237792969 | MAE Test Loss: 43.13298034667969 \n",
      "Epoch: 88510 | MAE Train Loss: 44.03560256958008 | MAE Test Loss: 43.13296127319336 \n",
      "Epoch: 88520 | MAE Train Loss: 44.03538513183594 | MAE Test Loss: 43.13298797607422 \n",
      "Epoch: 88530 | MAE Train Loss: 44.035160064697266 | MAE Test Loss: 43.13301467895508 \n",
      "Epoch: 88540 | MAE Train Loss: 44.03494644165039 | MAE Test Loss: 43.1330451965332 \n",
      "Epoch: 88550 | MAE Train Loss: 44.03472900390625 | MAE Test Loss: 43.13307189941406 \n",
      "Epoch: 88560 | MAE Train Loss: 44.03451156616211 | MAE Test Loss: 43.13310241699219 \n",
      "Epoch: 88570 | MAE Train Loss: 44.0343017578125 | MAE Test Loss: 43.133079528808594 \n",
      "Epoch: 88580 | MAE Train Loss: 44.03408432006836 | MAE Test Loss: 43.13310623168945 \n",
      "Epoch: 88590 | MAE Train Loss: 44.033870697021484 | MAE Test Loss: 43.13313674926758 \n",
      "Epoch: 88600 | MAE Train Loss: 44.03364562988281 | MAE Test Loss: 43.1331672668457 \n",
      "Epoch: 88610 | MAE Train Loss: 44.03342819213867 | MAE Test Loss: 43.1331901550293 \n",
      "Epoch: 88620 | MAE Train Loss: 44.03321838378906 | MAE Test Loss: 43.1331672668457 \n",
      "Epoch: 88630 | MAE Train Loss: 44.032997131347656 | MAE Test Loss: 43.13319778442383 \n",
      "Epoch: 88640 | MAE Train Loss: 44.03278350830078 | MAE Test Loss: 43.13322830200195 \n",
      "Epoch: 88650 | MAE Train Loss: 44.03256607055664 | MAE Test Loss: 43.13325500488281 \n",
      "Epoch: 88660 | MAE Train Loss: 44.032344818115234 | MAE Test Loss: 43.13328552246094 \n",
      "Epoch: 88670 | MAE Train Loss: 44.032127380371094 | MAE Test Loss: 43.1333122253418 \n",
      "Epoch: 88680 | MAE Train Loss: 44.03191375732422 | MAE Test Loss: 43.1332893371582 \n",
      "Epoch: 88690 | MAE Train Loss: 44.031700134277344 | MAE Test Loss: 43.13331985473633 \n",
      "Epoch: 88700 | MAE Train Loss: 44.0314826965332 | MAE Test Loss: 43.13334655761719 \n",
      "Epoch: 88710 | MAE Train Loss: 44.03126525878906 | MAE Test Loss: 43.13337707519531 \n",
      "Epoch: 88720 | MAE Train Loss: 44.03104782104492 | MAE Test Loss: 43.13340377807617 \n",
      "Epoch: 88730 | MAE Train Loss: 44.03083038330078 | MAE Test Loss: 43.13343048095703 \n",
      "Epoch: 88740 | MAE Train Loss: 44.03062057495117 | MAE Test Loss: 43.1334114074707 \n",
      "Epoch: 88750 | MAE Train Loss: 44.030399322509766 | MAE Test Loss: 43.13343811035156 \n",
      "Epoch: 88760 | MAE Train Loss: 44.03017807006836 | MAE Test Loss: 43.13346481323242 \n",
      "Epoch: 88770 | MAE Train Loss: 44.02996063232422 | MAE Test Loss: 43.13349151611328 \n",
      "Epoch: 88780 | MAE Train Loss: 44.02974319458008 | MAE Test Loss: 43.133522033691406 \n",
      "Epoch: 88790 | MAE Train Loss: 44.0295295715332 | MAE Test Loss: 43.13349914550781 \n",
      "Epoch: 88800 | MAE Train Loss: 44.02931594848633 | MAE Test Loss: 43.13352966308594 \n",
      "Epoch: 88810 | MAE Train Loss: 44.02910232543945 | MAE Test Loss: 43.1335563659668 \n",
      "Epoch: 88820 | MAE Train Loss: 44.02888107299805 | MAE Test Loss: 43.13357925415039 \n",
      "Epoch: 88830 | MAE Train Loss: 44.028663635253906 | MAE Test Loss: 43.133609771728516 \n",
      "Epoch: 88840 | MAE Train Loss: 44.028446197509766 | MAE Test Loss: 43.133636474609375 \n",
      "Epoch: 88850 | MAE Train Loss: 44.02823257446289 | MAE Test Loss: 43.13361740112305 \n",
      "Epoch: 88860 | MAE Train Loss: 44.02801513671875 | MAE Test Loss: 43.13364791870117 \n",
      "Epoch: 88870 | MAE Train Loss: 44.027801513671875 | MAE Test Loss: 43.13367462158203 \n",
      "Epoch: 88880 | MAE Train Loss: 44.02758026123047 | MAE Test Loss: 43.13370132446289 \n",
      "Epoch: 88890 | MAE Train Loss: 44.02735900878906 | MAE Test Loss: 43.133731842041016 \n",
      "Epoch: 88900 | MAE Train Loss: 44.02714157104492 | MAE Test Loss: 43.13370895385742 \n",
      "Epoch: 88910 | MAE Train Loss: 44.02693176269531 | MAE Test Loss: 43.13373947143555 \n",
      "Epoch: 88920 | MAE Train Loss: 44.02671432495117 | MAE Test Loss: 43.133766174316406 \n",
      "Epoch: 88930 | MAE Train Loss: 44.0265007019043 | MAE Test Loss: 43.13379669189453 \n",
      "Epoch: 88940 | MAE Train Loss: 44.026283264160156 | MAE Test Loss: 43.13382339477539 \n",
      "Epoch: 88950 | MAE Train Loss: 44.02606201171875 | MAE Test Loss: 43.133853912353516 \n",
      "Epoch: 88960 | MAE Train Loss: 44.025848388671875 | MAE Test Loss: 43.133827209472656 \n",
      "Epoch: 88970 | MAE Train Loss: 44.025630950927734 | MAE Test Loss: 43.13386154174805 \n",
      "Epoch: 88980 | MAE Train Loss: 44.025413513183594 | MAE Test Loss: 43.133888244628906 \n",
      "Epoch: 88990 | MAE Train Loss: 44.02519607543945 | MAE Test Loss: 43.133914947509766 \n",
      "Epoch: 89000 | MAE Train Loss: 44.02498245239258 | MAE Test Loss: 43.133941650390625 \n",
      "Epoch: 89010 | MAE Train Loss: 44.02476119995117 | MAE Test Loss: 43.133968353271484 \n",
      "Epoch: 89020 | MAE Train Loss: 44.02455520629883 | MAE Test Loss: 43.1338996887207 \n",
      "Epoch: 89030 | MAE Train Loss: 44.024356842041016 | MAE Test Loss: 43.133827209472656 \n",
      "Epoch: 89040 | MAE Train Loss: 44.024166107177734 | MAE Test Loss: 43.1336555480957 \n",
      "Epoch: 89050 | MAE Train Loss: 44.02397537231445 | MAE Test Loss: 43.13358688354492 \n",
      "Epoch: 89060 | MAE Train Loss: 44.02377700805664 | MAE Test Loss: 43.133514404296875 \n",
      "Epoch: 89070 | MAE Train Loss: 44.023582458496094 | MAE Test Loss: 43.13334655761719 \n",
      "Epoch: 89080 | MAE Train Loss: 44.02339172363281 | MAE Test Loss: 43.13327407836914 \n",
      "Epoch: 89090 | MAE Train Loss: 44.023193359375 | MAE Test Loss: 43.133201599121094 \n",
      "Epoch: 89100 | MAE Train Loss: 44.02299880981445 | MAE Test Loss: 43.133033752441406 \n",
      "Epoch: 89110 | MAE Train Loss: 44.02280807495117 | MAE Test Loss: 43.132965087890625 \n",
      "Epoch: 89120 | MAE Train Loss: 44.02261734008789 | MAE Test Loss: 43.13288879394531 \n",
      "Epoch: 89130 | MAE Train Loss: 44.02241516113281 | MAE Test Loss: 43.132816314697266 \n",
      "Epoch: 89140 | MAE Train Loss: 44.02222442626953 | MAE Test Loss: 43.13264846801758 \n",
      "Epoch: 89150 | MAE Train Loss: 44.02203369140625 | MAE Test Loss: 43.1325798034668 \n",
      "Epoch: 89160 | MAE Train Loss: 44.02183151245117 | MAE Test Loss: 43.132503509521484 \n",
      "Epoch: 89170 | MAE Train Loss: 44.021644592285156 | MAE Test Loss: 43.13233184814453 \n",
      "Epoch: 89180 | MAE Train Loss: 44.02145004272461 | MAE Test Loss: 43.13226318359375 \n",
      "Epoch: 89190 | MAE Train Loss: 44.02125549316406 | MAE Test Loss: 43.1321907043457 \n",
      "Epoch: 89200 | MAE Train Loss: 44.02105712890625 | MAE Test Loss: 43.13211441040039 \n",
      "Epoch: 89210 | MAE Train Loss: 44.02086639404297 | MAE Test Loss: 43.13195037841797 \n",
      "Epoch: 89220 | MAE Train Loss: 44.02067184448242 | MAE Test Loss: 43.13188171386719 \n",
      "Epoch: 89230 | MAE Train Loss: 44.020477294921875 | MAE Test Loss: 43.131805419921875 \n",
      "Epoch: 89240 | MAE Train Loss: 44.02028274536133 | MAE Test Loss: 43.13164138793945 \n",
      "Epoch: 89250 | MAE Train Loss: 44.02009201049805 | MAE Test Loss: 43.131568908691406 \n",
      "Epoch: 89260 | MAE Train Loss: 44.019893646240234 | MAE Test Loss: 43.13148880004883 \n",
      "Epoch: 89270 | MAE Train Loss: 44.01969909667969 | MAE Test Loss: 43.13142013549805 \n",
      "Epoch: 89280 | MAE Train Loss: 44.019508361816406 | MAE Test Loss: 43.13125228881836 \n",
      "Epoch: 89290 | MAE Train Loss: 44.01931381225586 | MAE Test Loss: 43.13117980957031 \n",
      "Epoch: 89300 | MAE Train Loss: 44.01911926269531 | MAE Test Loss: 43.131107330322266 \n",
      "Epoch: 89310 | MAE Train Loss: 44.018924713134766 | MAE Test Loss: 43.13093948364258 \n",
      "Epoch: 89320 | MAE Train Loss: 44.01873016357422 | MAE Test Loss: 43.130863189697266 \n",
      "Epoch: 89330 | MAE Train Loss: 44.01853942871094 | MAE Test Loss: 43.130794525146484 \n",
      "Epoch: 89340 | MAE Train Loss: 44.01834487915039 | MAE Test Loss: 43.13067626953125 \n",
      "Epoch: 89350 | MAE Train Loss: 44.01814651489258 | MAE Test Loss: 43.1306037902832 \n",
      "Epoch: 89360 | MAE Train Loss: 44.0179557800293 | MAE Test Loss: 43.13043212890625 \n",
      "Epoch: 89370 | MAE Train Loss: 44.01776123046875 | MAE Test Loss: 43.13036346435547 \n",
      "Epoch: 89380 | MAE Train Loss: 44.0175666809082 | MAE Test Loss: 43.130287170410156 \n",
      "Epoch: 89390 | MAE Train Loss: 44.017372131347656 | MAE Test Loss: 43.130218505859375 \n",
      "Epoch: 89400 | MAE Train Loss: 44.017181396484375 | MAE Test Loss: 43.13005065917969 \n",
      "Epoch: 89410 | MAE Train Loss: 44.01698684692383 | MAE Test Loss: 43.129974365234375 \n",
      "Epoch: 89420 | MAE Train Loss: 44.01679229736328 | MAE Test Loss: 43.129905700683594 \n",
      "Epoch: 89430 | MAE Train Loss: 44.016597747802734 | MAE Test Loss: 43.12973403930664 \n",
      "Epoch: 89440 | MAE Train Loss: 44.01640701293945 | MAE Test Loss: 43.12966537475586 \n",
      "Epoch: 89450 | MAE Train Loss: 44.016212463378906 | MAE Test Loss: 43.12959289550781 \n",
      "Epoch: 89460 | MAE Train Loss: 44.016014099121094 | MAE Test Loss: 43.12942123413086 \n",
      "Epoch: 89470 | MAE Train Loss: 44.01581954956055 | MAE Test Loss: 43.12934875488281 \n",
      "Epoch: 89480 | MAE Train Loss: 44.015628814697266 | MAE Test Loss: 43.129276275634766 \n",
      "Epoch: 89490 | MAE Train Loss: 44.01543045043945 | MAE Test Loss: 43.12920379638672 \n",
      "Epoch: 89500 | MAE Train Loss: 44.015235900878906 | MAE Test Loss: 43.1290397644043 \n",
      "Epoch: 89510 | MAE Train Loss: 44.015045166015625 | MAE Test Loss: 43.128963470458984 \n",
      "Epoch: 89520 | MAE Train Loss: 44.01485061645508 | MAE Test Loss: 43.12889862060547 \n",
      "Epoch: 89530 | MAE Train Loss: 44.01465606689453 | MAE Test Loss: 43.128719329833984 \n",
      "Epoch: 89540 | MAE Train Loss: 44.01445770263672 | MAE Test Loss: 43.12865447998047 \n",
      "Epoch: 89550 | MAE Train Loss: 44.0142707824707 | MAE Test Loss: 43.1285285949707 \n",
      "Epoch: 89560 | MAE Train Loss: 44.014076232910156 | MAE Test Loss: 43.128456115722656 \n",
      "Epoch: 89570 | MAE Train Loss: 44.01388168334961 | MAE Test Loss: 43.128387451171875 \n",
      "Epoch: 89580 | MAE Train Loss: 44.0136833190918 | MAE Test Loss: 43.12821960449219 \n",
      "Epoch: 89590 | MAE Train Loss: 44.013492584228516 | MAE Test Loss: 43.12814712524414 \n",
      "Epoch: 89600 | MAE Train Loss: 44.013301849365234 | MAE Test Loss: 43.128074645996094 \n",
      "Epoch: 89610 | MAE Train Loss: 44.01310348510742 | MAE Test Loss: 43.12800216674805 \n",
      "Epoch: 89620 | MAE Train Loss: 44.01291275024414 | MAE Test Loss: 43.127830505371094 \n",
      "Epoch: 89630 | MAE Train Loss: 44.012718200683594 | MAE Test Loss: 43.12775802612305 \n",
      "Epoch: 89640 | MAE Train Loss: 44.01251983642578 | MAE Test Loss: 43.1276969909668 \n",
      "Epoch: 89650 | MAE Train Loss: 44.0123291015625 | MAE Test Loss: 43.12751770019531 \n",
      "Epoch: 89660 | MAE Train Loss: 44.01213836669922 | MAE Test Loss: 43.12744903564453 \n",
      "Epoch: 89670 | MAE Train Loss: 44.011940002441406 | MAE Test Loss: 43.1273307800293 \n",
      "Epoch: 89680 | MAE Train Loss: 44.01174545288086 | MAE Test Loss: 43.12725830078125 \n",
      "Epoch: 89690 | MAE Train Loss: 44.01154708862305 | MAE Test Loss: 43.1271858215332 \n",
      "Epoch: 89700 | MAE Train Loss: 44.0113525390625 | MAE Test Loss: 43.127017974853516 \n",
      "Epoch: 89710 | MAE Train Loss: 44.011165618896484 | MAE Test Loss: 43.12694549560547 \n",
      "Epoch: 89720 | MAE Train Loss: 44.01096725463867 | MAE Test Loss: 43.126869201660156 \n",
      "Epoch: 89730 | MAE Train Loss: 44.010772705078125 | MAE Test Loss: 43.126800537109375 \n",
      "Epoch: 89740 | MAE Train Loss: 44.01057815551758 | MAE Test Loss: 43.12662887573242 \n",
      "Epoch: 89750 | MAE Train Loss: 44.01038360595703 | MAE Test Loss: 43.126556396484375 \n",
      "Epoch: 89760 | MAE Train Loss: 44.010189056396484 | MAE Test Loss: 43.126487731933594 \n",
      "Epoch: 89770 | MAE Train Loss: 44.00999069213867 | MAE Test Loss: 43.126319885253906 \n",
      "Epoch: 89780 | MAE Train Loss: 44.00980758666992 | MAE Test Loss: 43.126243591308594 \n",
      "Epoch: 89790 | MAE Train Loss: 44.00960922241211 | MAE Test Loss: 43.12617492675781 \n",
      "Epoch: 89800 | MAE Train Loss: 44.00941467285156 | MAE Test Loss: 43.126102447509766 \n",
      "Epoch: 89810 | MAE Train Loss: 44.00922393798828 | MAE Test Loss: 43.12593078613281 \n",
      "Epoch: 89820 | MAE Train Loss: 44.00902557373047 | MAE Test Loss: 43.1258659362793 \n",
      "Epoch: 89830 | MAE Train Loss: 44.00883483886719 | MAE Test Loss: 43.125789642333984 \n",
      "Epoch: 89840 | MAE Train Loss: 44.00864028930664 | MAE Test Loss: 43.1256217956543 \n",
      "Epoch: 89850 | MAE Train Loss: 44.00844192504883 | MAE Test Loss: 43.12554931640625 \n",
      "Epoch: 89860 | MAE Train Loss: 44.00825500488281 | MAE Test Loss: 43.12547302246094 \n",
      "Epoch: 89870 | MAE Train Loss: 44.008056640625 | MAE Test Loss: 43.1253547668457 \n",
      "Epoch: 89880 | MAE Train Loss: 44.00785827636719 | MAE Test Loss: 43.125282287597656 \n",
      "Epoch: 89890 | MAE Train Loss: 44.007667541503906 | MAE Test Loss: 43.12511444091797 \n",
      "Epoch: 89900 | MAE Train Loss: 44.007476806640625 | MAE Test Loss: 43.12504577636719 \n",
      "Epoch: 89910 | MAE Train Loss: 44.00728225708008 | MAE Test Loss: 43.124969482421875 \n",
      "Epoch: 89920 | MAE Train Loss: 44.00708770751953 | MAE Test Loss: 43.124900817871094 \n",
      "Epoch: 89930 | MAE Train Loss: 44.006893157958984 | MAE Test Loss: 43.12472915649414 \n",
      "Epoch: 89940 | MAE Train Loss: 44.00669860839844 | MAE Test Loss: 43.12466049194336 \n",
      "Epoch: 89950 | MAE Train Loss: 44.006507873535156 | MAE Test Loss: 43.12458419799805 \n",
      "Epoch: 89960 | MAE Train Loss: 44.006317138671875 | MAE Test Loss: 43.12450408935547 \n",
      "Epoch: 89970 | MAE Train Loss: 44.00613784790039 | MAE Test Loss: 43.1245002746582 \n",
      "Epoch: 89980 | MAE Train Loss: 44.00595474243164 | MAE Test Loss: 43.1244010925293 \n",
      "Epoch: 89990 | MAE Train Loss: 44.00577926635742 | MAE Test Loss: 43.1244010925293 \n",
      "Epoch: 90000 | MAE Train Loss: 44.005592346191406 | MAE Test Loss: 43.12439727783203 \n",
      "Epoch: 90010 | MAE Train Loss: 44.00541305541992 | MAE Test Loss: 43.12430191040039 \n",
      "Epoch: 90020 | MAE Train Loss: 44.00523376464844 | MAE Test Loss: 43.124298095703125 \n",
      "Epoch: 90030 | MAE Train Loss: 44.00505447387695 | MAE Test Loss: 43.12424850463867 \n",
      "Epoch: 90040 | MAE Train Loss: 44.00486755371094 | MAE Test Loss: 43.12425231933594 \n",
      "Epoch: 90050 | MAE Train Loss: 44.00469207763672 | MAE Test Loss: 43.124244689941406 \n",
      "Epoch: 90060 | MAE Train Loss: 44.00450897216797 | MAE Test Loss: 43.124149322509766 \n",
      "Epoch: 90070 | MAE Train Loss: 44.00433349609375 | MAE Test Loss: 43.1241455078125 \n",
      "Epoch: 90080 | MAE Train Loss: 44.004146575927734 | MAE Test Loss: 43.1241455078125 \n",
      "Epoch: 90090 | MAE Train Loss: 44.003963470458984 | MAE Test Loss: 43.124141693115234 \n",
      "Epoch: 90100 | MAE Train Loss: 44.0037841796875 | MAE Test Loss: 43.124046325683594 \n",
      "Epoch: 90110 | MAE Train Loss: 44.00360870361328 | MAE Test Loss: 43.12404251098633 \n",
      "Epoch: 90120 | MAE Train Loss: 44.0034294128418 | MAE Test Loss: 43.12403869628906 \n",
      "Epoch: 90130 | MAE Train Loss: 44.00324630737305 | MAE Test Loss: 43.123985290527344 \n",
      "Epoch: 90140 | MAE Train Loss: 44.0030632019043 | MAE Test Loss: 43.123985290527344 \n",
      "Epoch: 90150 | MAE Train Loss: 44.00288391113281 | MAE Test Loss: 43.1238899230957 \n",
      "Epoch: 90160 | MAE Train Loss: 44.00270462036133 | MAE Test Loss: 43.12388610839844 \n",
      "Epoch: 90170 | MAE Train Loss: 44.00252151489258 | MAE Test Loss: 43.12388610839844 \n",
      "Epoch: 90180 | MAE Train Loss: 44.002342224121094 | MAE Test Loss: 43.12378692626953 \n",
      "Epoch: 90190 | MAE Train Loss: 44.00216293334961 | MAE Test Loss: 43.12378692626953 \n",
      "Epoch: 90200 | MAE Train Loss: 44.00197982788086 | MAE Test Loss: 43.123783111572266 \n",
      "Epoch: 90210 | MAE Train Loss: 44.00179672241211 | MAE Test Loss: 43.123775482177734 \n",
      "Epoch: 90220 | MAE Train Loss: 44.001617431640625 | MAE Test Loss: 43.12368392944336 \n",
      "Epoch: 90230 | MAE Train Loss: 44.00143814086914 | MAE Test Loss: 43.12368392944336 \n",
      "Epoch: 90240 | MAE Train Loss: 44.00125503540039 | MAE Test Loss: 43.12363052368164 \n",
      "Epoch: 90250 | MAE Train Loss: 44.00107955932617 | MAE Test Loss: 43.12363052368164 \n",
      "Epoch: 90260 | MAE Train Loss: 44.00089645385742 | MAE Test Loss: 43.123626708984375 \n",
      "Epoch: 90270 | MAE Train Loss: 44.00071334838867 | MAE Test Loss: 43.123531341552734 \n",
      "Epoch: 90280 | MAE Train Loss: 44.00053405761719 | MAE Test Loss: 43.12352752685547 \n",
      "Epoch: 90290 | MAE Train Loss: 44.00035858154297 | MAE Test Loss: 43.12352752685547 \n",
      "Epoch: 90300 | MAE Train Loss: 44.00017166137695 | MAE Test Loss: 43.12342834472656 \n",
      "Epoch: 90310 | MAE Train Loss: 43.999996185302734 | MAE Test Loss: 43.1234245300293 \n",
      "Epoch: 90320 | MAE Train Loss: 43.999813079833984 | MAE Test Loss: 43.12337875366211 \n",
      "Epoch: 90330 | MAE Train Loss: 43.9996337890625 | MAE Test Loss: 43.123374938964844 \n",
      "Epoch: 90340 | MAE Train Loss: 43.99945068359375 | MAE Test Loss: 43.12337112426758 \n",
      "Epoch: 90350 | MAE Train Loss: 43.999263763427734 | MAE Test Loss: 43.12336730957031 \n",
      "Epoch: 90360 | MAE Train Loss: 43.999088287353516 | MAE Test Loss: 43.12327194213867 \n",
      "Epoch: 90370 | MAE Train Loss: 43.99890899658203 | MAE Test Loss: 43.123268127441406 \n",
      "Epoch: 90380 | MAE Train Loss: 43.99872589111328 | MAE Test Loss: 43.123268127441406 \n",
      "Epoch: 90390 | MAE Train Loss: 43.9985466003418 | MAE Test Loss: 43.123172760009766 \n",
      "Epoch: 90400 | MAE Train Loss: 43.99836349487305 | MAE Test Loss: 43.1231689453125 \n",
      "Epoch: 90410 | MAE Train Loss: 43.99818801879883 | MAE Test Loss: 43.123165130615234 \n",
      "Epoch: 90420 | MAE Train Loss: 43.998008728027344 | MAE Test Loss: 43.123069763183594 \n",
      "Epoch: 90430 | MAE Train Loss: 43.997825622558594 | MAE Test Loss: 43.12306213378906 \n",
      "Epoch: 90440 | MAE Train Loss: 43.99764633178711 | MAE Test Loss: 43.12302017211914 \n",
      "Epoch: 90450 | MAE Train Loss: 43.997467041015625 | MAE Test Loss: 43.123016357421875 \n",
      "Epoch: 90460 | MAE Train Loss: 43.997283935546875 | MAE Test Loss: 43.12301254272461 \n",
      "Epoch: 90470 | MAE Train Loss: 43.99709701538086 | MAE Test Loss: 43.123008728027344 \n",
      "Epoch: 90480 | MAE Train Loss: 43.99692153930664 | MAE Test Loss: 43.1229133605957 \n",
      "Epoch: 90490 | MAE Train Loss: 43.996742248535156 | MAE Test Loss: 43.12290954589844 \n",
      "Epoch: 90500 | MAE Train Loss: 43.996559143066406 | MAE Test Loss: 43.12290954589844 \n",
      "Epoch: 90510 | MAE Train Loss: 43.99637985229492 | MAE Test Loss: 43.1228141784668 \n",
      "Epoch: 90520 | MAE Train Loss: 43.99619674682617 | MAE Test Loss: 43.12281036376953 \n",
      "Epoch: 90530 | MAE Train Loss: 43.99601745605469 | MAE Test Loss: 43.122806549072266 \n",
      "Epoch: 90540 | MAE Train Loss: 43.9958381652832 | MAE Test Loss: 43.12275695800781 \n",
      "Epoch: 90550 | MAE Train Loss: 43.99565887451172 | MAE Test Loss: 43.12274932861328 \n",
      "Epoch: 90560 | MAE Train Loss: 43.9954719543457 | MAE Test Loss: 43.12265396118164 \n",
      "Epoch: 90570 | MAE Train Loss: 43.995296478271484 | MAE Test Loss: 43.122657775878906 \n",
      "Epoch: 90580 | MAE Train Loss: 43.995121002197266 | MAE Test Loss: 43.12274932861328 \n",
      "Epoch: 90590 | MAE Train Loss: 43.99494171142578 | MAE Test Loss: 43.12266540527344 \n",
      "Epoch: 90600 | MAE Train Loss: 43.9947624206543 | MAE Test Loss: 43.12267303466797 \n",
      "Epoch: 90610 | MAE Train Loss: 43.99458694458008 | MAE Test Loss: 43.1226921081543 \n",
      "Epoch: 90620 | MAE Train Loss: 43.99441146850586 | MAE Test Loss: 43.122711181640625 \n",
      "Epoch: 90630 | MAE Train Loss: 43.994239807128906 | MAE Test Loss: 43.12272644042969 \n",
      "Epoch: 90640 | MAE Train Loss: 43.99406433105469 | MAE Test Loss: 43.122737884521484 \n",
      "Epoch: 90650 | MAE Train Loss: 43.993892669677734 | MAE Test Loss: 43.12275314331055 \n",
      "Epoch: 90660 | MAE Train Loss: 43.99371337890625 | MAE Test Loss: 43.12276840209961 \n",
      "Epoch: 90670 | MAE Train Loss: 43.993534088134766 | MAE Test Loss: 43.1227912902832 \n",
      "Epoch: 90680 | MAE Train Loss: 43.99335861206055 | MAE Test Loss: 43.12289810180664 \n",
      "Epoch: 90690 | MAE Train Loss: 43.99319076538086 | MAE Test Loss: 43.1229133605957 \n",
      "Epoch: 90700 | MAE Train Loss: 43.993019104003906 | MAE Test Loss: 43.12293243408203 \n",
      "Epoch: 90710 | MAE Train Loss: 43.99283981323242 | MAE Test Loss: 43.122947692871094 \n",
      "Epoch: 90720 | MAE Train Loss: 43.9926643371582 | MAE Test Loss: 43.122962951660156 \n",
      "Epoch: 90730 | MAE Train Loss: 43.992488861083984 | MAE Test Loss: 43.122982025146484 \n",
      "Epoch: 90740 | MAE Train Loss: 43.99231719970703 | MAE Test Loss: 43.12299346923828 \n",
      "Epoch: 90750 | MAE Train Loss: 43.99213790893555 | MAE Test Loss: 43.1230583190918 \n",
      "Epoch: 90760 | MAE Train Loss: 43.99196243286133 | MAE Test Loss: 43.123077392578125 \n",
      "Epoch: 90770 | MAE Train Loss: 43.991790771484375 | MAE Test Loss: 43.12309265136719 \n",
      "Epoch: 90780 | MAE Train Loss: 43.99161148071289 | MAE Test Loss: 43.12310791015625 \n",
      "Epoch: 90790 | MAE Train Loss: 43.99143981933594 | MAE Test Loss: 43.12312316894531 \n",
      "Epoch: 90800 | MAE Train Loss: 43.99126434326172 | MAE Test Loss: 43.123138427734375 \n",
      "Epoch: 90810 | MAE Train Loss: 43.99109649658203 | MAE Test Loss: 43.1231575012207 \n",
      "Epoch: 90820 | MAE Train Loss: 43.99091720581055 | MAE Test Loss: 43.123172760009766 \n",
      "Epoch: 90830 | MAE Train Loss: 43.99074172973633 | MAE Test Loss: 43.12318801879883 \n",
      "Epoch: 90840 | MAE Train Loss: 43.99056625366211 | MAE Test Loss: 43.123199462890625 \n",
      "Epoch: 90850 | MAE Train Loss: 43.99039077758789 | MAE Test Loss: 43.12321472167969 \n",
      "Epoch: 90860 | MAE Train Loss: 43.990211486816406 | MAE Test Loss: 43.123233795166016 \n",
      "Epoch: 90870 | MAE Train Loss: 43.99004364013672 | MAE Test Loss: 43.12324905395508 \n",
      "Epoch: 90880 | MAE Train Loss: 43.9898681640625 | MAE Test Loss: 43.123268127441406 \n",
      "Epoch: 90890 | MAE Train Loss: 43.98969268798828 | MAE Test Loss: 43.1232795715332 \n",
      "Epoch: 90900 | MAE Train Loss: 43.98951721191406 | MAE Test Loss: 43.123348236083984 \n",
      "Epoch: 90910 | MAE Train Loss: 43.989341735839844 | MAE Test Loss: 43.12336349487305 \n",
      "Epoch: 90920 | MAE Train Loss: 43.98917007446289 | MAE Test Loss: 43.12337875366211 \n",
      "Epoch: 90930 | MAE Train Loss: 43.988990783691406 | MAE Test Loss: 43.12339401245117 \n",
      "Epoch: 90940 | MAE Train Loss: 43.98881912231445 | MAE Test Loss: 43.123409271240234 \n",
      "Epoch: 90950 | MAE Train Loss: 43.98863983154297 | MAE Test Loss: 43.1234245300293 \n",
      "Epoch: 90960 | MAE Train Loss: 43.98846435546875 | MAE Test Loss: 43.123443603515625 \n",
      "Epoch: 90970 | MAE Train Loss: 43.98829650878906 | MAE Test Loss: 43.12350845336914 \n",
      "Epoch: 90980 | MAE Train Loss: 43.98811721801758 | MAE Test Loss: 43.1235237121582 \n",
      "Epoch: 90990 | MAE Train Loss: 43.987945556640625 | MAE Test Loss: 43.123538970947266 \n",
      "Epoch: 91000 | MAE Train Loss: 43.987770080566406 | MAE Test Loss: 43.123558044433594 \n",
      "Epoch: 91010 | MAE Train Loss: 43.98759078979492 | MAE Test Loss: 43.12356948852539 \n",
      "Epoch: 91020 | MAE Train Loss: 43.98741912841797 | MAE Test Loss: 43.12358474731445 \n",
      "Epoch: 91030 | MAE Train Loss: 43.987247467041016 | MAE Test Loss: 43.12360382080078 \n",
      "Epoch: 91040 | MAE Train Loss: 43.98706817626953 | MAE Test Loss: 43.123714447021484 \n",
      "Epoch: 91050 | MAE Train Loss: 43.98689651489258 | MAE Test Loss: 43.12372970581055 \n",
      "Epoch: 91060 | MAE Train Loss: 43.986717224121094 | MAE Test Loss: 43.12374496459961 \n",
      "Epoch: 91070 | MAE Train Loss: 43.986549377441406 | MAE Test Loss: 43.12376022338867 \n",
      "Epoch: 91080 | MAE Train Loss: 43.98637390136719 | MAE Test Loss: 43.123775482177734 \n",
      "Epoch: 91090 | MAE Train Loss: 43.9861946105957 | MAE Test Loss: 43.12379455566406 \n",
      "Epoch: 91100 | MAE Train Loss: 43.98602294921875 | MAE Test Loss: 43.12381362915039 \n",
      "Epoch: 91110 | MAE Train Loss: 43.9858512878418 | MAE Test Loss: 43.12382507324219 \n",
      "Epoch: 91120 | MAE Train Loss: 43.98566818237305 | MAE Test Loss: 43.1238899230957 \n",
      "Epoch: 91130 | MAE Train Loss: 43.985496520996094 | MAE Test Loss: 43.123905181884766 \n",
      "Epoch: 91140 | MAE Train Loss: 43.98531723022461 | MAE Test Loss: 43.12392044067383 \n",
      "Epoch: 91150 | MAE Train Loss: 43.985145568847656 | MAE Test Loss: 43.12393569946289 \n",
      "Epoch: 91160 | MAE Train Loss: 43.9849739074707 | MAE Test Loss: 43.12395095825195 \n",
      "Epoch: 91170 | MAE Train Loss: 43.98479461669922 | MAE Test Loss: 43.12397003173828 \n",
      "Epoch: 91180 | MAE Train Loss: 43.984622955322266 | MAE Test Loss: 43.123985290527344 \n",
      "Epoch: 91190 | MAE Train Loss: 43.98444747924805 | MAE Test Loss: 43.12405014038086 \n",
      "Epoch: 91200 | MAE Train Loss: 43.98426818847656 | MAE Test Loss: 43.12406539916992 \n",
      "Epoch: 91210 | MAE Train Loss: 43.98409652709961 | MAE Test Loss: 43.12407684326172 \n",
      "Epoch: 91220 | MAE Train Loss: 43.983924865722656 | MAE Test Loss: 43.12409591674805 \n",
      "Epoch: 91230 | MAE Train Loss: 43.98374938964844 | MAE Test Loss: 43.124114990234375 \n",
      "Epoch: 91240 | MAE Train Loss: 43.98357391357422 | MAE Test Loss: 43.12412643432617 \n",
      "Epoch: 91250 | MAE Train Loss: 43.983402252197266 | MAE Test Loss: 43.1241455078125 \n",
      "Epoch: 91260 | MAE Train Loss: 43.98322296142578 | MAE Test Loss: 43.12416076660156 \n",
      "Epoch: 91270 | MAE Train Loss: 43.98304748535156 | MAE Test Loss: 43.124176025390625 \n",
      "Epoch: 91280 | MAE Train Loss: 43.98287582397461 | MAE Test Loss: 43.12419509887695 \n",
      "Epoch: 91290 | MAE Train Loss: 43.98270034790039 | MAE Test Loss: 43.124210357666016 \n",
      "Epoch: 91300 | MAE Train Loss: 43.98252487182617 | MAE Test Loss: 43.12422180175781 \n",
      "Epoch: 91310 | MAE Train Loss: 43.98234558105469 | MAE Test Loss: 43.124244689941406 \n",
      "Epoch: 91320 | MAE Train Loss: 43.982173919677734 | MAE Test Loss: 43.12425994873047 \n",
      "Epoch: 91330 | MAE Train Loss: 43.981998443603516 | MAE Test Loss: 43.12432098388672 \n",
      "Epoch: 91340 | MAE Train Loss: 43.98182678222656 | MAE Test Loss: 43.12433624267578 \n",
      "Epoch: 91350 | MAE Train Loss: 43.98164749145508 | MAE Test Loss: 43.124351501464844 \n",
      "Epoch: 91360 | MAE Train Loss: 43.98147201538086 | MAE Test Loss: 43.12436294555664 \n",
      "Epoch: 91370 | MAE Train Loss: 43.981300354003906 | MAE Test Loss: 43.124385833740234 \n",
      "Epoch: 91380 | MAE Train Loss: 43.98112487792969 | MAE Test Loss: 43.1244010925293 \n",
      "Epoch: 91390 | MAE Train Loss: 43.98094940185547 | MAE Test Loss: 43.12441635131836 \n",
      "Epoch: 91400 | MAE Train Loss: 43.98077392578125 | MAE Test Loss: 43.12447738647461 \n",
      "Epoch: 91410 | MAE Train Loss: 43.9806022644043 | MAE Test Loss: 43.12449645996094 \n",
      "Epoch: 91420 | MAE Train Loss: 43.98042678833008 | MAE Test Loss: 43.124507904052734 \n",
      "Epoch: 91430 | MAE Train Loss: 43.98025131225586 | MAE Test Loss: 43.12452697753906 \n",
      "Epoch: 91440 | MAE Train Loss: 43.98007583618164 | MAE Test Loss: 43.12454605102539 \n",
      "Epoch: 91450 | MAE Train Loss: 43.97990036010742 | MAE Test Loss: 43.12455749511719 \n",
      "Epoch: 91460 | MAE Train Loss: 43.97972106933594 | MAE Test Loss: 43.124576568603516 \n",
      "Epoch: 91470 | MAE Train Loss: 43.979549407958984 | MAE Test Loss: 43.12459182739258 \n",
      "Epoch: 91480 | MAE Train Loss: 43.97937774658203 | MAE Test Loss: 43.12470245361328 \n",
      "Epoch: 91490 | MAE Train Loss: 43.97920227050781 | MAE Test Loss: 43.12472152709961 \n",
      "Epoch: 91500 | MAE Train Loss: 43.97902297973633 | MAE Test Loss: 43.12473678588867 \n",
      "Epoch: 91510 | MAE Train Loss: 43.978851318359375 | MAE Test Loss: 43.124752044677734 \n",
      "Epoch: 91520 | MAE Train Loss: 43.978675842285156 | MAE Test Loss: 43.1247673034668 \n",
      "Epoch: 91530 | MAE Train Loss: 43.9785041809082 | MAE Test Loss: 43.124786376953125 \n",
      "Epoch: 91540 | MAE Train Loss: 43.97833251953125 | MAE Test Loss: 43.12480163574219 \n",
      "Epoch: 91550 | MAE Train Loss: 43.9781494140625 | MAE Test Loss: 43.12485885620117 \n",
      "Epoch: 91560 | MAE Train Loss: 43.97797775268555 | MAE Test Loss: 43.1248779296875 \n",
      "Epoch: 91570 | MAE Train Loss: 43.97780227661133 | MAE Test Loss: 43.12489700317383 \n",
      "Epoch: 91580 | MAE Train Loss: 43.977630615234375 | MAE Test Loss: 43.124908447265625 \n",
      "Epoch: 91590 | MAE Train Loss: 43.977455139160156 | MAE Test Loss: 43.12493133544922 \n",
      "Epoch: 91600 | MAE Train Loss: 43.9772834777832 | MAE Test Loss: 43.12494659423828 \n",
      "Epoch: 91610 | MAE Train Loss: 43.97710418701172 | MAE Test Loss: 43.124961853027344 \n",
      "Epoch: 91620 | MAE Train Loss: 43.9769287109375 | MAE Test Loss: 43.124977111816406 \n",
      "Epoch: 91630 | MAE Train Loss: 43.97675704956055 | MAE Test Loss: 43.1249885559082 \n",
      "Epoch: 91640 | MAE Train Loss: 43.97657775878906 | MAE Test Loss: 43.125003814697266 \n",
      "Epoch: 91650 | MAE Train Loss: 43.976402282714844 | MAE Test Loss: 43.125022888183594 \n",
      "Epoch: 91660 | MAE Train Loss: 43.97623062133789 | MAE Test Loss: 43.125038146972656 \n",
      "Epoch: 91670 | MAE Train Loss: 43.976051330566406 | MAE Test Loss: 43.125057220458984 \n",
      "Epoch: 91680 | MAE Train Loss: 43.97587585449219 | MAE Test Loss: 43.12507247924805 \n",
      "Epoch: 91690 | MAE Train Loss: 43.97570037841797 | MAE Test Loss: 43.12513732910156 \n",
      "Epoch: 91700 | MAE Train Loss: 43.97553253173828 | MAE Test Loss: 43.125152587890625 \n",
      "Epoch: 91710 | MAE Train Loss: 43.97535705566406 | MAE Test Loss: 43.12516784667969 \n",
      "Epoch: 91720 | MAE Train Loss: 43.97517776489258 | MAE Test Loss: 43.125179290771484 \n",
      "Epoch: 91730 | MAE Train Loss: 43.975006103515625 | MAE Test Loss: 43.12519836425781 \n",
      "Epoch: 91740 | MAE Train Loss: 43.97482681274414 | MAE Test Loss: 43.125213623046875 \n",
      "Epoch: 91750 | MAE Train Loss: 43.97465515136719 | MAE Test Loss: 43.12522888183594 \n",
      "Epoch: 91760 | MAE Train Loss: 43.97447967529297 | MAE Test Loss: 43.125247955322266 \n",
      "Epoch: 91770 | MAE Train Loss: 43.974308013916016 | MAE Test Loss: 43.12531280517578 \n",
      "Epoch: 91780 | MAE Train Loss: 43.9741325378418 | MAE Test Loss: 43.125328063964844 \n",
      "Epoch: 91790 | MAE Train Loss: 43.97395706176758 | MAE Test Loss: 43.125343322753906 \n",
      "Epoch: 91800 | MAE Train Loss: 43.973777770996094 | MAE Test Loss: 43.1253547668457 \n",
      "Epoch: 91810 | MAE Train Loss: 43.973602294921875 | MAE Test Loss: 43.1253776550293 \n",
      "Epoch: 91820 | MAE Train Loss: 43.973426818847656 | MAE Test Loss: 43.125389099121094 \n",
      "Epoch: 91830 | MAE Train Loss: 43.9732551574707 | MAE Test Loss: 43.125404357910156 \n",
      "Epoch: 91840 | MAE Train Loss: 43.973079681396484 | MAE Test Loss: 43.12552261352539 \n",
      "Epoch: 91850 | MAE Train Loss: 43.97290802001953 | MAE Test Loss: 43.12553787231445 \n",
      "Epoch: 91860 | MAE Train Loss: 43.97273254394531 | MAE Test Loss: 43.12554931640625 \n",
      "Epoch: 91870 | MAE Train Loss: 43.972557067871094 | MAE Test Loss: 43.12556838989258 \n",
      "Epoch: 91880 | MAE Train Loss: 43.972381591796875 | MAE Test Loss: 43.125579833984375 \n",
      "Epoch: 91890 | MAE Train Loss: 43.97220993041992 | MAE Test Loss: 43.1255989074707 \n",
      "Epoch: 91900 | MAE Train Loss: 43.9720344543457 | MAE Test Loss: 43.125614166259766 \n",
      "Epoch: 91910 | MAE Train Loss: 43.97185516357422 | MAE Test Loss: 43.12567901611328 \n",
      "Epoch: 91920 | MAE Train Loss: 43.9716796875 | MAE Test Loss: 43.125694274902344 \n",
      "Epoch: 91930 | MAE Train Loss: 43.97150421142578 | MAE Test Loss: 43.125709533691406 \n",
      "Epoch: 91940 | MAE Train Loss: 43.97133255004883 | MAE Test Loss: 43.125728607177734 \n",
      "Epoch: 91950 | MAE Train Loss: 43.97115707397461 | MAE Test Loss: 43.12574768066406 \n",
      "Epoch: 91960 | MAE Train Loss: 43.97098159790039 | MAE Test Loss: 43.125755310058594 \n",
      "Epoch: 91970 | MAE Train Loss: 43.97080993652344 | MAE Test Loss: 43.12577438354492 \n",
      "Epoch: 91980 | MAE Train Loss: 43.97063446044922 | MAE Test Loss: 43.12583923339844 \n",
      "Epoch: 91990 | MAE Train Loss: 43.970455169677734 | MAE Test Loss: 43.1258544921875 \n",
      "Epoch: 92000 | MAE Train Loss: 43.97028350830078 | MAE Test Loss: 43.12586975097656 \n",
      "Epoch: 92010 | MAE Train Loss: 43.97010803222656 | MAE Test Loss: 43.125885009765625 \n",
      "Epoch: 92020 | MAE Train Loss: 43.969932556152344 | MAE Test Loss: 43.12590408325195 \n",
      "Epoch: 92030 | MAE Train Loss: 43.969757080078125 | MAE Test Loss: 43.125919342041016 \n",
      "Epoch: 92040 | MAE Train Loss: 43.96958541870117 | MAE Test Loss: 43.12593460083008 \n",
      "Epoch: 92050 | MAE Train Loss: 43.96941375732422 | MAE Test Loss: 43.125953674316406 \n",
      "Epoch: 92060 | MAE Train Loss: 43.96923828125 | MAE Test Loss: 43.12596893310547 \n",
      "Epoch: 92070 | MAE Train Loss: 43.96906280517578 | MAE Test Loss: 43.125980377197266 \n",
      "Epoch: 92080 | MAE Train Loss: 43.96889114379883 | MAE Test Loss: 43.125999450683594 \n",
      "Epoch: 92090 | MAE Train Loss: 43.96870803833008 | MAE Test Loss: 43.12601089477539 \n",
      "Epoch: 92100 | MAE Train Loss: 43.96853256225586 | MAE Test Loss: 43.12602996826172 \n",
      "Epoch: 92110 | MAE Train Loss: 43.968360900878906 | MAE Test Loss: 43.12604522705078 \n",
      "Epoch: 92120 | MAE Train Loss: 43.96818161010742 | MAE Test Loss: 43.12606430053711 \n",
      "Epoch: 92130 | MAE Train Loss: 43.968013763427734 | MAE Test Loss: 43.126129150390625 \n",
      "Epoch: 92140 | MAE Train Loss: 43.967838287353516 | MAE Test Loss: 43.12614059448242 \n",
      "Epoch: 92150 | MAE Train Loss: 43.96765899658203 | MAE Test Loss: 43.126155853271484 \n",
      "Epoch: 92160 | MAE Train Loss: 43.96748733520508 | MAE Test Loss: 43.12617492675781 \n",
      "Epoch: 92170 | MAE Train Loss: 43.96731185913086 | MAE Test Loss: 43.126190185546875 \n",
      "Epoch: 92180 | MAE Train Loss: 43.96713638305664 | MAE Test Loss: 43.1262092590332 \n",
      "Epoch: 92190 | MAE Train Loss: 43.96696472167969 | MAE Test Loss: 43.126224517822266 \n",
      "Epoch: 92200 | MAE Train Loss: 43.966793060302734 | MAE Test Loss: 43.126285552978516 \n",
      "Epoch: 92210 | MAE Train Loss: 43.966617584228516 | MAE Test Loss: 43.12630081176758 \n",
      "Epoch: 92220 | MAE Train Loss: 43.9664421081543 | MAE Test Loss: 43.12631607055664 \n",
      "Epoch: 92230 | MAE Train Loss: 43.96626663208008 | MAE Test Loss: 43.1263313293457 \n",
      "Epoch: 92240 | MAE Train Loss: 43.966087341308594 | MAE Test Loss: 43.1263542175293 \n",
      "Epoch: 92250 | MAE Train Loss: 43.96591567993164 | MAE Test Loss: 43.12636947631836 \n",
      "Epoch: 92260 | MAE Train Loss: 43.96574020385742 | MAE Test Loss: 43.12638473510742 \n",
      "Epoch: 92270 | MAE Train Loss: 43.9655647277832 | MAE Test Loss: 43.126495361328125 \n",
      "Epoch: 92280 | MAE Train Loss: 43.96538543701172 | MAE Test Loss: 43.12651062011719 \n",
      "Epoch: 92290 | MAE Train Loss: 43.965213775634766 | MAE Test Loss: 43.126522064208984 \n",
      "Epoch: 92300 | MAE Train Loss: 43.96503829956055 | MAE Test Loss: 43.12654113769531 \n",
      "Epoch: 92310 | MAE Train Loss: 43.964866638183594 | MAE Test Loss: 43.126556396484375 \n",
      "Epoch: 92320 | MAE Train Loss: 43.96468734741211 | MAE Test Loss: 43.1265754699707 \n",
      "Epoch: 92330 | MAE Train Loss: 43.96451187133789 | MAE Test Loss: 43.126590728759766 \n",
      "Epoch: 92340 | MAE Train Loss: 43.9643440246582 | MAE Test Loss: 43.12660598754883 \n",
      "Epoch: 92350 | MAE Train Loss: 43.96416473388672 | MAE Test Loss: 43.12666702270508 \n",
      "Epoch: 92360 | MAE Train Loss: 43.963993072509766 | MAE Test Loss: 43.126686096191406 \n",
      "Epoch: 92370 | MAE Train Loss: 43.96381378173828 | MAE Test Loss: 43.12670135498047 \n",
      "Epoch: 92380 | MAE Train Loss: 43.96364212036133 | MAE Test Loss: 43.12671661376953 \n",
      "Epoch: 92390 | MAE Train Loss: 43.963470458984375 | MAE Test Loss: 43.126731872558594 \n",
      "Epoch: 92400 | MAE Train Loss: 43.96329116821289 | MAE Test Loss: 43.12675094604492 \n",
      "Epoch: 92410 | MAE Train Loss: 43.96311569213867 | MAE Test Loss: 43.126766204833984 \n",
      "Epoch: 92420 | MAE Train Loss: 43.96294021606445 | MAE Test Loss: 43.126827239990234 \n",
      "Epoch: 92430 | MAE Train Loss: 43.962764739990234 | MAE Test Loss: 43.1268424987793 \n",
      "Epoch: 92440 | MAE Train Loss: 43.96259307861328 | MAE Test Loss: 43.126861572265625 \n",
      "Epoch: 92450 | MAE Train Loss: 43.96241760253906 | MAE Test Loss: 43.12688064575195 \n",
      "Epoch: 92460 | MAE Train Loss: 43.962242126464844 | MAE Test Loss: 43.12689208984375 \n",
      "Epoch: 92470 | MAE Train Loss: 43.96207046508789 | MAE Test Loss: 43.12690734863281 \n",
      "Epoch: 92480 | MAE Train Loss: 43.96189498901367 | MAE Test Loss: 43.12692642211914 \n",
      "Epoch: 92490 | MAE Train Loss: 43.96171951293945 | MAE Test Loss: 43.1269416809082 \n",
      "Epoch: 92500 | MAE Train Loss: 43.961544036865234 | MAE Test Loss: 43.126956939697266 \n",
      "Epoch: 92510 | MAE Train Loss: 43.96136474609375 | MAE Test Loss: 43.126976013183594 \n",
      "Epoch: 92520 | MAE Train Loss: 43.96118927001953 | MAE Test Loss: 43.126991271972656 \n",
      "Epoch: 92530 | MAE Train Loss: 43.961021423339844 | MAE Test Loss: 43.12700653076172 \n",
      "Epoch: 92540 | MAE Train Loss: 43.96084213256836 | MAE Test Loss: 43.12702178955078 \n",
      "Epoch: 92550 | MAE Train Loss: 43.96066665649414 | MAE Test Loss: 43.127037048339844 \n",
      "Epoch: 92560 | MAE Train Loss: 43.96049499511719 | MAE Test Loss: 43.127098083496094 \n",
      "Epoch: 92570 | MAE Train Loss: 43.96031951904297 | MAE Test Loss: 43.127113342285156 \n",
      "Epoch: 92580 | MAE Train Loss: 43.960140228271484 | MAE Test Loss: 43.127132415771484 \n",
      "Epoch: 92590 | MAE Train Loss: 43.959964752197266 | MAE Test Loss: 43.12715148925781 \n",
      "Epoch: 92600 | MAE Train Loss: 43.95979309082031 | MAE Test Loss: 43.12716293334961 \n",
      "Epoch: 92610 | MAE Train Loss: 43.959617614746094 | MAE Test Loss: 43.12718200683594 \n",
      "Epoch: 92620 | MAE Train Loss: 43.959442138671875 | MAE Test Loss: 43.127197265625 \n",
      "Epoch: 92630 | MAE Train Loss: 43.959266662597656 | MAE Test Loss: 43.127262115478516 \n",
      "Epoch: 92640 | MAE Train Loss: 43.95909881591797 | MAE Test Loss: 43.12727355957031 \n",
      "Epoch: 92650 | MAE Train Loss: 43.958919525146484 | MAE Test Loss: 43.127288818359375 \n",
      "Epoch: 92660 | MAE Train Loss: 43.95874786376953 | MAE Test Loss: 43.1273078918457 \n",
      "Epoch: 92670 | MAE Train Loss: 43.95856475830078 | MAE Test Loss: 43.12732696533203 \n",
      "Epoch: 92680 | MAE Train Loss: 43.95839309692383 | MAE Test Loss: 43.12733840942383 \n",
      "Epoch: 92690 | MAE Train Loss: 43.95821762084961 | MAE Test Loss: 43.12735366821289 \n",
      "Epoch: 92700 | MAE Train Loss: 43.95804214477539 | MAE Test Loss: 43.12737274169922 \n",
      "Epoch: 92710 | MAE Train Loss: 43.95786666870117 | MAE Test Loss: 43.12748336791992 \n",
      "Epoch: 92720 | MAE Train Loss: 43.95769119262695 | MAE Test Loss: 43.12750244140625 \n",
      "Epoch: 92730 | MAE Train Loss: 43.957523345947266 | MAE Test Loss: 43.12751388549805 \n",
      "Epoch: 92740 | MAE Train Loss: 43.95734786987305 | MAE Test Loss: 43.127532958984375 \n",
      "Epoch: 92750 | MAE Train Loss: 43.95716857910156 | MAE Test Loss: 43.12754821777344 \n",
      "Epoch: 92760 | MAE Train Loss: 43.95699691772461 | MAE Test Loss: 43.127567291259766 \n",
      "Epoch: 92770 | MAE Train Loss: 43.95682144165039 | MAE Test Loss: 43.12757873535156 \n",
      "Epoch: 92780 | MAE Train Loss: 43.956642150878906 | MAE Test Loss: 43.12764358520508 \n",
      "Epoch: 92790 | MAE Train Loss: 43.95647048950195 | MAE Test Loss: 43.127662658691406 \n",
      "Epoch: 92800 | MAE Train Loss: 43.956295013427734 | MAE Test Loss: 43.1276741027832 \n",
      "Epoch: 92810 | MAE Train Loss: 43.95612335205078 | MAE Test Loss: 43.127689361572266 \n",
      "Epoch: 92820 | MAE Train Loss: 43.95594787597656 | MAE Test Loss: 43.127708435058594 \n",
      "Epoch: 92830 | MAE Train Loss: 43.955772399902344 | MAE Test Loss: 43.12772750854492 \n",
      "Epoch: 92840 | MAE Train Loss: 43.95560073852539 | MAE Test Loss: 43.12773895263672 \n",
      "Epoch: 92850 | MAE Train Loss: 43.95542526245117 | MAE Test Loss: 43.12775802612305 \n",
      "Epoch: 92860 | MAE Train Loss: 43.95524597167969 | MAE Test Loss: 43.127769470214844 \n",
      "Epoch: 92870 | MAE Train Loss: 43.955078125 | MAE Test Loss: 43.127784729003906 \n",
      "Epoch: 92880 | MAE Train Loss: 43.954898834228516 | MAE Test Loss: 43.1278076171875 \n",
      "Epoch: 92890 | MAE Train Loss: 43.9547233581543 | MAE Test Loss: 43.1278190612793 \n",
      "Epoch: 92900 | MAE Train Loss: 43.95454788208008 | MAE Test Loss: 43.127838134765625 \n",
      "Epoch: 92910 | MAE Train Loss: 43.954368591308594 | MAE Test Loss: 43.12784957885742 \n",
      "Epoch: 92920 | MAE Train Loss: 43.95419692993164 | MAE Test Loss: 43.12791442871094 \n",
      "Epoch: 92930 | MAE Train Loss: 43.95402526855469 | MAE Test Loss: 43.1279296875 \n",
      "Epoch: 92940 | MAE Train Loss: 43.95384979248047 | MAE Test Loss: 43.12794494628906 \n",
      "Epoch: 92950 | MAE Train Loss: 43.95367431640625 | MAE Test Loss: 43.12796401977539 \n",
      "Epoch: 92960 | MAE Train Loss: 43.953495025634766 | MAE Test Loss: 43.12798309326172 \n",
      "Epoch: 92970 | MAE Train Loss: 43.95331954956055 | MAE Test Loss: 43.12800216674805 \n",
      "Epoch: 92980 | MAE Train Loss: 43.953147888183594 | MAE Test Loss: 43.12800979614258 \n",
      "Epoch: 92990 | MAE Train Loss: 43.95296859741211 | MAE Test Loss: 43.12803268432617 \n",
      "Epoch: 93000 | MAE Train Loss: 43.95280456542969 | MAE Test Loss: 43.12809371948242 \n",
      "Epoch: 93010 | MAE Train Loss: 43.9526252746582 | MAE Test Loss: 43.128108978271484 \n",
      "Epoch: 93020 | MAE Train Loss: 43.952449798583984 | MAE Test Loss: 43.12812423706055 \n",
      "Epoch: 93030 | MAE Train Loss: 43.952274322509766 | MAE Test Loss: 43.128143310546875 \n",
      "Epoch: 93040 | MAE Train Loss: 43.95210266113281 | MAE Test Loss: 43.12815856933594 \n",
      "Epoch: 93050 | MAE Train Loss: 43.951927185058594 | MAE Test Loss: 43.128177642822266 \n",
      "Epoch: 93060 | MAE Train Loss: 43.951751708984375 | MAE Test Loss: 43.12819290161133 \n",
      "Epoch: 93070 | MAE Train Loss: 43.951576232910156 | MAE Test Loss: 43.128299713134766 \n",
      "Epoch: 93080 | MAE Train Loss: 43.95140075683594 | MAE Test Loss: 43.128318786621094 \n",
      "Epoch: 93090 | MAE Train Loss: 43.95122146606445 | MAE Test Loss: 43.12833786010742 \n",
      "Epoch: 93100 | MAE Train Loss: 43.9510498046875 | MAE Test Loss: 43.128353118896484 \n",
      "Epoch: 93110 | MAE Train Loss: 43.95087432861328 | MAE Test Loss: 43.12836456298828 \n",
      "Epoch: 93120 | MAE Train Loss: 43.95070266723633 | MAE Test Loss: 43.12838363647461 \n",
      "Epoch: 93130 | MAE Train Loss: 43.950531005859375 | MAE Test Loss: 43.12839889526367 \n",
      "Epoch: 93140 | MAE Train Loss: 43.950347900390625 | MAE Test Loss: 43.12846374511719 \n",
      "Epoch: 93150 | MAE Train Loss: 43.95017623901367 | MAE Test Loss: 43.12847900390625 \n",
      "Epoch: 93160 | MAE Train Loss: 43.95000076293945 | MAE Test Loss: 43.12849807739258 \n",
      "Epoch: 93170 | MAE Train Loss: 43.949832916259766 | MAE Test Loss: 43.12851333618164 \n",
      "Epoch: 93180 | MAE Train Loss: 43.94965362548828 | MAE Test Loss: 43.1285285949707 \n",
      "Epoch: 93190 | MAE Train Loss: 43.9494743347168 | MAE Test Loss: 43.12854766845703 \n",
      "Epoch: 93200 | MAE Train Loss: 43.94930648803711 | MAE Test Loss: 43.12855911254883 \n",
      "Epoch: 93210 | MAE Train Loss: 43.949127197265625 | MAE Test Loss: 43.128623962402344 \n",
      "Epoch: 93220 | MAE Train Loss: 43.94894790649414 | MAE Test Loss: 43.128639221191406 \n",
      "Epoch: 93230 | MAE Train Loss: 43.94878005981445 | MAE Test Loss: 43.12865447998047 \n",
      "Epoch: 93240 | MAE Train Loss: 43.94860076904297 | MAE Test Loss: 43.1286735534668 \n",
      "Epoch: 93250 | MAE Train Loss: 43.94842529296875 | MAE Test Loss: 43.128692626953125 \n",
      "Epoch: 93260 | MAE Train Loss: 43.94825744628906 | MAE Test Loss: 43.12870788574219 \n",
      "Epoch: 93270 | MAE Train Loss: 43.94807434082031 | MAE Test Loss: 43.128719329833984 \n",
      "Epoch: 93280 | MAE Train Loss: 43.947906494140625 | MAE Test Loss: 43.12873840332031 \n",
      "Epoch: 93290 | MAE Train Loss: 43.94772720336914 | MAE Test Loss: 43.128753662109375 \n",
      "Epoch: 93300 | MAE Train Loss: 43.94755172729492 | MAE Test Loss: 43.1287727355957 \n",
      "Epoch: 93310 | MAE Train Loss: 43.94738006591797 | MAE Test Loss: 43.128787994384766 \n",
      "Epoch: 93320 | MAE Train Loss: 43.947200775146484 | MAE Test Loss: 43.12879943847656 \n",
      "Epoch: 93330 | MAE Train Loss: 43.94702911376953 | MAE Test Loss: 43.12881851196289 \n",
      "Epoch: 93340 | MAE Train Loss: 43.94685745239258 | MAE Test Loss: 43.12883377075195 \n",
      "Epoch: 93350 | MAE Train Loss: 43.94667053222656 | MAE Test Loss: 43.12885284423828 \n",
      "Epoch: 93360 | MAE Train Loss: 43.94650650024414 | MAE Test Loss: 43.1289176940918 \n",
      "Epoch: 93370 | MAE Train Loss: 43.946327209472656 | MAE Test Loss: 43.12893295288086 \n",
      "Epoch: 93380 | MAE Train Loss: 43.9461555480957 | MAE Test Loss: 43.12894821166992 \n",
      "Epoch: 93390 | MAE Train Loss: 43.945980072021484 | MAE Test Loss: 43.128963470458984 \n",
      "Epoch: 93400 | MAE Train Loss: 43.94580078125 | MAE Test Loss: 43.12897872924805 \n",
      "Epoch: 93410 | MAE Train Loss: 43.94562911987305 | MAE Test Loss: 43.12899398803711 \n",
      "Epoch: 93420 | MAE Train Loss: 43.94545364379883 | MAE Test Loss: 43.12900924682617 \n",
      "Epoch: 93430 | MAE Train Loss: 43.94527816772461 | MAE Test Loss: 43.12907791137695 \n",
      "Epoch: 93440 | MAE Train Loss: 43.945106506347656 | MAE Test Loss: 43.12909698486328 \n",
      "Epoch: 93450 | MAE Train Loss: 43.94493103027344 | MAE Test Loss: 43.12910842895508 \n",
      "Epoch: 93460 | MAE Train Loss: 43.94475555419922 | MAE Test Loss: 43.129127502441406 \n",
      "Epoch: 93470 | MAE Train Loss: 43.944583892822266 | MAE Test Loss: 43.12914276123047 \n",
      "Epoch: 93480 | MAE Train Loss: 43.94440460205078 | MAE Test Loss: 43.1291618347168 \n",
      "Epoch: 93490 | MAE Train Loss: 43.94422912597656 | MAE Test Loss: 43.129173278808594 \n",
      "Epoch: 93500 | MAE Train Loss: 43.944053649902344 | MAE Test Loss: 43.12928771972656 \n",
      "Epoch: 93510 | MAE Train Loss: 43.943878173828125 | MAE Test Loss: 43.129302978515625 \n",
      "Epoch: 93520 | MAE Train Loss: 43.94370651245117 | MAE Test Loss: 43.12931823730469 \n",
      "Epoch: 93530 | MAE Train Loss: 43.94353485107422 | MAE Test Loss: 43.129337310791016 \n",
      "Epoch: 93540 | MAE Train Loss: 43.943355560302734 | MAE Test Loss: 43.12934875488281 \n",
      "Epoch: 93550 | MAE Train Loss: 43.94318389892578 | MAE Test Loss: 43.129371643066406 \n",
      "Epoch: 93560 | MAE Train Loss: 43.9430046081543 | MAE Test Loss: 43.12938690185547 \n",
      "Epoch: 93570 | MAE Train Loss: 43.94282913208008 | MAE Test Loss: 43.129398345947266 \n",
      "Epoch: 93580 | MAE Train Loss: 43.942657470703125 | MAE Test Loss: 43.12946319580078 \n",
      "Epoch: 93590 | MAE Train Loss: 43.94248580932617 | MAE Test Loss: 43.12948226928711 \n",
      "Epoch: 93600 | MAE Train Loss: 43.94230651855469 | MAE Test Loss: 43.12949752807617 \n",
      "Epoch: 93610 | MAE Train Loss: 43.94213104248047 | MAE Test Loss: 43.129512786865234 \n",
      "Epoch: 93620 | MAE Train Loss: 43.94195556640625 | MAE Test Loss: 43.1295280456543 \n",
      "Epoch: 93630 | MAE Train Loss: 43.9417839050293 | MAE Test Loss: 43.129547119140625 \n",
      "Epoch: 93640 | MAE Train Loss: 43.941612243652344 | MAE Test Loss: 43.12956237792969 \n",
      "Epoch: 93650 | MAE Train Loss: 43.94143295288086 | MAE Test Loss: 43.12962341308594 \n",
      "Epoch: 93660 | MAE Train Loss: 43.941261291503906 | MAE Test Loss: 43.129638671875 \n",
      "Epoch: 93670 | MAE Train Loss: 43.94108581542969 | MAE Test Loss: 43.12965393066406 \n",
      "Epoch: 93680 | MAE Train Loss: 43.94091033935547 | MAE Test Loss: 43.12967300415039 \n",
      "Epoch: 93690 | MAE Train Loss: 43.94073486328125 | MAE Test Loss: 43.12968826293945 \n",
      "Epoch: 93700 | MAE Train Loss: 43.940555572509766 | MAE Test Loss: 43.12970733642578 \n",
      "Epoch: 93710 | MAE Train Loss: 43.94038772583008 | MAE Test Loss: 43.129722595214844 \n",
      "Epoch: 93720 | MAE Train Loss: 43.94021224975586 | MAE Test Loss: 43.12974166870117 \n",
      "Epoch: 93730 | MAE Train Loss: 43.94003677368164 | MAE Test Loss: 43.12975311279297 \n",
      "Epoch: 93740 | MAE Train Loss: 43.93986129760742 | MAE Test Loss: 43.1297721862793 \n",
      "Epoch: 93750 | MAE Train Loss: 43.9396858215332 | MAE Test Loss: 43.12978744506836 \n",
      "Epoch: 93760 | MAE Train Loss: 43.939510345458984 | MAE Test Loss: 43.12980651855469 \n",
      "Epoch: 93770 | MAE Train Loss: 43.939334869384766 | MAE Test Loss: 43.12982177734375 \n",
      "Epoch: 93780 | MAE Train Loss: 43.93915557861328 | MAE Test Loss: 43.12983703613281 \n",
      "Epoch: 93790 | MAE Train Loss: 43.938987731933594 | MAE Test Loss: 43.12989807128906 \n",
      "Epoch: 93800 | MAE Train Loss: 43.938812255859375 | MAE Test Loss: 43.12991714477539 \n",
      "Epoch: 93810 | MAE Train Loss: 43.93864059448242 | MAE Test Loss: 43.12993240356445 \n",
      "Epoch: 93820 | MAE Train Loss: 43.93846130371094 | MAE Test Loss: 43.129947662353516 \n",
      "Epoch: 93830 | MAE Train Loss: 43.93828582763672 | MAE Test Loss: 43.129966735839844 \n",
      "Epoch: 93840 | MAE Train Loss: 43.9381103515625 | MAE Test Loss: 43.12997817993164 \n",
      "Epoch: 93850 | MAE Train Loss: 43.93793487548828 | MAE Test Loss: 43.12999725341797 \n",
      "Epoch: 93860 | MAE Train Loss: 43.9377555847168 | MAE Test Loss: 43.13006591796875 \n",
      "Epoch: 93870 | MAE Train Loss: 43.93758773803711 | MAE Test Loss: 43.13007354736328 \n",
      "Epoch: 93880 | MAE Train Loss: 43.93741226196289 | MAE Test Loss: 43.13009262084961 \n",
      "Epoch: 93890 | MAE Train Loss: 43.93724060058594 | MAE Test Loss: 43.13011169433594 \n",
      "Epoch: 93900 | MAE Train Loss: 43.93706130981445 | MAE Test Loss: 43.130126953125 \n",
      "Epoch: 93910 | MAE Train Loss: 43.9368896484375 | MAE Test Loss: 43.13014602661133 \n",
      "Epoch: 93920 | MAE Train Loss: 43.93671417236328 | MAE Test Loss: 43.13016128540039 \n",
      "Epoch: 93930 | MAE Train Loss: 43.93653106689453 | MAE Test Loss: 43.13017272949219 \n",
      "Epoch: 93940 | MAE Train Loss: 43.93636703491211 | MAE Test Loss: 43.1302375793457 \n",
      "Epoch: 93950 | MAE Train Loss: 43.936187744140625 | MAE Test Loss: 43.13025665283203 \n",
      "Epoch: 93960 | MAE Train Loss: 43.936012268066406 | MAE Test Loss: 43.130271911621094 \n",
      "Epoch: 93970 | MAE Train Loss: 43.93584060668945 | MAE Test Loss: 43.130287170410156 \n",
      "Epoch: 93980 | MAE Train Loss: 43.93566131591797 | MAE Test Loss: 43.13030242919922 \n",
      "Epoch: 93990 | MAE Train Loss: 43.935489654541016 | MAE Test Loss: 43.13032150268555 \n",
      "Epoch: 94000 | MAE Train Loss: 43.93531036376953 | MAE Test Loss: 43.13033676147461 \n",
      "Epoch: 94010 | MAE Train Loss: 43.93513488769531 | MAE Test Loss: 43.13044738769531 \n",
      "Epoch: 94020 | MAE Train Loss: 43.934959411621094 | MAE Test Loss: 43.130462646484375 \n",
      "Epoch: 94030 | MAE Train Loss: 43.93478775024414 | MAE Test Loss: 43.1304817199707 \n",
      "Epoch: 94040 | MAE Train Loss: 43.93461608886719 | MAE Test Loss: 43.1304931640625 \n",
      "Epoch: 94050 | MAE Train Loss: 43.9344367980957 | MAE Test Loss: 43.13051223754883 \n",
      "Epoch: 94060 | MAE Train Loss: 43.93426513671875 | MAE Test Loss: 43.130531311035156 \n",
      "Epoch: 94070 | MAE Train Loss: 43.934085845947266 | MAE Test Loss: 43.130550384521484 \n",
      "Epoch: 94080 | MAE Train Loss: 43.93391036987305 | MAE Test Loss: 43.13060760498047 \n",
      "Epoch: 94090 | MAE Train Loss: 43.93374252319336 | MAE Test Loss: 43.13062286376953 \n",
      "Epoch: 94100 | MAE Train Loss: 43.93356704711914 | MAE Test Loss: 43.130638122558594 \n",
      "Epoch: 94110 | MAE Train Loss: 43.933387756347656 | MAE Test Loss: 43.13065719604492 \n",
      "Epoch: 94120 | MAE Train Loss: 43.93321228027344 | MAE Test Loss: 43.130672454833984 \n",
      "Epoch: 94130 | MAE Train Loss: 43.933040618896484 | MAE Test Loss: 43.13069152832031 \n",
      "Epoch: 94140 | MAE Train Loss: 43.932865142822266 | MAE Test Loss: 43.130706787109375 \n",
      "Epoch: 94150 | MAE Train Loss: 43.93268585205078 | MAE Test Loss: 43.130767822265625 \n",
      "Epoch: 94160 | MAE Train Loss: 43.93251419067383 | MAE Test Loss: 43.13078689575195 \n",
      "Epoch: 94170 | MAE Train Loss: 43.932342529296875 | MAE Test Loss: 43.13080596923828 \n",
      "Epoch: 94180 | MAE Train Loss: 43.932167053222656 | MAE Test Loss: 43.130821228027344 \n",
      "Epoch: 94190 | MAE Train Loss: 43.93199157714844 | MAE Test Loss: 43.13084030151367 \n",
      "Epoch: 94200 | MAE Train Loss: 43.93181610107422 | MAE Test Loss: 43.130855560302734 \n",
      "Epoch: 94210 | MAE Train Loss: 43.931636810302734 | MAE Test Loss: 43.13086700439453 \n",
      "Epoch: 94220 | MAE Train Loss: 43.93146514892578 | MAE Test Loss: 43.130882263183594 \n",
      "Epoch: 94230 | MAE Train Loss: 43.93129348754883 | MAE Test Loss: 43.130897521972656 \n",
      "Epoch: 94240 | MAE Train Loss: 43.93111801147461 | MAE Test Loss: 43.130916595458984 \n",
      "Epoch: 94250 | MAE Train Loss: 43.93094253540039 | MAE Test Loss: 43.13093185424805 \n",
      "Epoch: 94260 | MAE Train Loss: 43.930763244628906 | MAE Test Loss: 43.13094711303711 \n",
      "Epoch: 94270 | MAE Train Loss: 43.93058776855469 | MAE Test Loss: 43.13096237182617 \n",
      "Epoch: 94280 | MAE Train Loss: 43.93041229248047 | MAE Test Loss: 43.1309814453125 \n",
      "Epoch: 94290 | MAE Train Loss: 43.93023681640625 | MAE Test Loss: 43.13099670410156 \n",
      "Epoch: 94300 | MAE Train Loss: 43.93006896972656 | MAE Test Loss: 43.13105773925781 \n",
      "Epoch: 94310 | MAE Train Loss: 43.929893493652344 | MAE Test Loss: 43.131072998046875 \n",
      "Epoch: 94320 | MAE Train Loss: 43.92971420288086 | MAE Test Loss: 43.13109588623047 \n",
      "Epoch: 94330 | MAE Train Loss: 43.929542541503906 | MAE Test Loss: 43.13111114501953 \n",
      "Epoch: 94340 | MAE Train Loss: 43.92936706542969 | MAE Test Loss: 43.131126403808594 \n",
      "Epoch: 94350 | MAE Train Loss: 43.9291877746582 | MAE Test Loss: 43.13114547729492 \n",
      "Epoch: 94360 | MAE Train Loss: 43.92901611328125 | MAE Test Loss: 43.13115692138672 \n",
      "Epoch: 94370 | MAE Train Loss: 43.9288444519043 | MAE Test Loss: 43.131221771240234 \n",
      "Epoch: 94380 | MAE Train Loss: 43.92866897583008 | MAE Test Loss: 43.13124465942383 \n",
      "Epoch: 94390 | MAE Train Loss: 43.92849349975586 | MAE Test Loss: 43.131256103515625 \n",
      "Epoch: 94400 | MAE Train Loss: 43.928321838378906 | MAE Test Loss: 43.13127136230469 \n",
      "Epoch: 94410 | MAE Train Loss: 43.92814254760742 | MAE Test Loss: 43.131290435791016 \n",
      "Epoch: 94420 | MAE Train Loss: 43.9279670715332 | MAE Test Loss: 43.13130187988281 \n",
      "Epoch: 94430 | MAE Train Loss: 43.927791595458984 | MAE Test Loss: 43.131317138671875 \n",
      "Epoch: 94440 | MAE Train Loss: 43.927616119384766 | MAE Test Loss: 43.13143539428711 \n",
      "Epoch: 94450 | MAE Train Loss: 43.92744064331055 | MAE Test Loss: 43.131446838378906 \n",
      "Epoch: 94460 | MAE Train Loss: 43.927268981933594 | MAE Test Loss: 43.131465911865234 \n",
      "Epoch: 94470 | MAE Train Loss: 43.927093505859375 | MAE Test Loss: 43.13148498535156 \n",
      "Epoch: 94480 | MAE Train Loss: 43.92692184448242 | MAE Test Loss: 43.131500244140625 \n",
      "Epoch: 94490 | MAE Train Loss: 43.92674255371094 | MAE Test Loss: 43.13151550292969 \n",
      "Epoch: 94500 | MAE Train Loss: 43.926570892333984 | MAE Test Loss: 43.131526947021484 \n",
      "Epoch: 94510 | MAE Train Loss: 43.92639923095703 | MAE Test Loss: 43.13154602050781 \n",
      "Epoch: 94520 | MAE Train Loss: 43.92621994018555 | MAE Test Loss: 43.13161087036133 \n",
      "Epoch: 94530 | MAE Train Loss: 43.92604064941406 | MAE Test Loss: 43.13162612915039 \n",
      "Epoch: 94540 | MAE Train Loss: 43.925872802734375 | MAE Test Loss: 43.13163757324219 \n",
      "Epoch: 94550 | MAE Train Loss: 43.925697326660156 | MAE Test Loss: 43.131656646728516 \n",
      "Epoch: 94560 | MAE Train Loss: 43.92552185058594 | MAE Test Loss: 43.131675720214844 \n",
      "Epoch: 94570 | MAE Train Loss: 43.92534637451172 | MAE Test Loss: 43.131690979003906 \n",
      "Epoch: 94580 | MAE Train Loss: 43.9251708984375 | MAE Test Loss: 43.1317024230957 \n",
      "Epoch: 94590 | MAE Train Loss: 43.92499542236328 | MAE Test Loss: 43.131771087646484 \n",
      "Epoch: 94600 | MAE Train Loss: 43.92481994628906 | MAE Test Loss: 43.13178634643555 \n",
      "Epoch: 94610 | MAE Train Loss: 43.92464828491211 | MAE Test Loss: 43.131805419921875 \n",
      "Epoch: 94620 | MAE Train Loss: 43.924468994140625 | MAE Test Loss: 43.13181686401367 \n",
      "Epoch: 94630 | MAE Train Loss: 43.924293518066406 | MAE Test Loss: 43.131832122802734 \n",
      "Epoch: 94640 | MAE Train Loss: 43.92412185668945 | MAE Test Loss: 43.13185119628906 \n",
      "Epoch: 94650 | MAE Train Loss: 43.923946380615234 | MAE Test Loss: 43.13186264038086 \n",
      "Epoch: 94660 | MAE Train Loss: 43.923770904541016 | MAE Test Loss: 43.13188171386719 \n",
      "Epoch: 94670 | MAE Train Loss: 43.92359924316406 | MAE Test Loss: 43.131900787353516 \n",
      "Epoch: 94680 | MAE Train Loss: 43.92341995239258 | MAE Test Loss: 43.13191223144531 \n",
      "Epoch: 94690 | MAE Train Loss: 43.923248291015625 | MAE Test Loss: 43.13193130493164 \n",
      "Epoch: 94700 | MAE Train Loss: 43.923072814941406 | MAE Test Loss: 43.1319465637207 \n",
      "Epoch: 94710 | MAE Train Loss: 43.92289352416992 | MAE Test Loss: 43.13196563720703 \n",
      "Epoch: 94720 | MAE Train Loss: 43.92272186279297 | MAE Test Loss: 43.13197708129883 \n",
      "Epoch: 94730 | MAE Train Loss: 43.92254638671875 | MAE Test Loss: 43.13204574584961 \n",
      "Epoch: 94740 | MAE Train Loss: 43.9223747253418 | MAE Test Loss: 43.13206481933594 \n",
      "Epoch: 94750 | MAE Train Loss: 43.922203063964844 | MAE Test Loss: 43.132083892822266 \n",
      "Epoch: 94760 | MAE Train Loss: 43.92202377319336 | MAE Test Loss: 43.13209533691406 \n",
      "Epoch: 94770 | MAE Train Loss: 43.92184829711914 | MAE Test Loss: 43.132110595703125 \n",
      "Epoch: 94780 | MAE Train Loss: 43.92167282104492 | MAE Test Loss: 43.13212585449219 \n",
      "Epoch: 94790 | MAE Train Loss: 43.92149353027344 | MAE Test Loss: 43.132137298583984 \n",
      "Epoch: 94800 | MAE Train Loss: 43.921321868896484 | MAE Test Loss: 43.13220977783203 \n",
      "Epoch: 94810 | MAE Train Loss: 43.92115020751953 | MAE Test Loss: 43.132225036621094 \n",
      "Epoch: 94820 | MAE Train Loss: 43.92097473144531 | MAE Test Loss: 43.132240295410156 \n",
      "Epoch: 94830 | MAE Train Loss: 43.920799255371094 | MAE Test Loss: 43.13225555419922 \n",
      "Epoch: 94840 | MAE Train Loss: 43.920623779296875 | MAE Test Loss: 43.132266998291016 \n",
      "Epoch: 94850 | MAE Train Loss: 43.920448303222656 | MAE Test Loss: 43.13228225708008 \n",
      "Epoch: 94860 | MAE Train Loss: 43.92026901245117 | MAE Test Loss: 43.132301330566406 \n",
      "Epoch: 94870 | MAE Train Loss: 43.92009735107422 | MAE Test Loss: 43.132320404052734 \n",
      "Epoch: 94880 | MAE Train Loss: 43.919925689697266 | MAE Test Loss: 43.13242721557617 \n",
      "Epoch: 94890 | MAE Train Loss: 43.91975021362305 | MAE Test Loss: 43.132450103759766 \n",
      "Epoch: 94900 | MAE Train Loss: 43.91957473754883 | MAE Test Loss: 43.13246536254883 \n",
      "Epoch: 94910 | MAE Train Loss: 43.91939926147461 | MAE Test Loss: 43.132476806640625 \n",
      "Epoch: 94920 | MAE Train Loss: 43.919227600097656 | MAE Test Loss: 43.13249588012695 \n",
      "Epoch: 94930 | MAE Train Loss: 43.91905212402344 | MAE Test Loss: 43.132511138916016 \n",
      "Epoch: 94940 | MAE Train Loss: 43.91887664794922 | MAE Test Loss: 43.13252639770508 \n",
      "Epoch: 94950 | MAE Train Loss: 43.918697357177734 | MAE Test Loss: 43.13259506225586 \n",
      "Epoch: 94960 | MAE Train Loss: 43.91852569580078 | MAE Test Loss: 43.13261032104492 \n",
      "Epoch: 94970 | MAE Train Loss: 43.91835021972656 | MAE Test Loss: 43.13262176513672 \n",
      "Epoch: 94980 | MAE Train Loss: 43.918174743652344 | MAE Test Loss: 43.13264083862305 \n",
      "Epoch: 94990 | MAE Train Loss: 43.917999267578125 | MAE Test Loss: 43.13265609741211 \n",
      "Epoch: 95000 | MAE Train Loss: 43.91783142089844 | MAE Test Loss: 43.13267135620117 \n",
      "Epoch: 95010 | MAE Train Loss: 43.91765213012695 | MAE Test Loss: 43.1326904296875 \n",
      "Epoch: 95020 | MAE Train Loss: 43.917476654052734 | MAE Test Loss: 43.132755279541016 \n",
      "Epoch: 95030 | MAE Train Loss: 43.91729736328125 | MAE Test Loss: 43.13277053833008 \n",
      "Epoch: 95040 | MAE Train Loss: 43.91712951660156 | MAE Test Loss: 43.13278579711914 \n",
      "Epoch: 95050 | MAE Train Loss: 43.916954040527344 | MAE Test Loss: 43.1328010559082 \n",
      "Epoch: 95060 | MAE Train Loss: 43.91677474975586 | MAE Test Loss: 43.132816314697266 \n",
      "Epoch: 95070 | MAE Train Loss: 43.916603088378906 | MAE Test Loss: 43.132835388183594 \n",
      "Epoch: 95080 | MAE Train Loss: 43.91642761230469 | MAE Test Loss: 43.132850646972656 \n",
      "Epoch: 95090 | MAE Train Loss: 43.91625213623047 | MAE Test Loss: 43.13286590576172 \n",
      "Epoch: 95100 | MAE Train Loss: 43.91607666015625 | MAE Test Loss: 43.13288116455078 \n",
      "Epoch: 95110 | MAE Train Loss: 43.91590118408203 | MAE Test Loss: 43.132896423339844 \n",
      "Epoch: 95120 | MAE Train Loss: 43.91572952270508 | MAE Test Loss: 43.13291549682617 \n",
      "Epoch: 95130 | MAE Train Loss: 43.91555404663086 | MAE Test Loss: 43.1329345703125 \n",
      "Epoch: 95140 | MAE Train Loss: 43.915374755859375 | MAE Test Loss: 43.13294982910156 \n",
      "Epoch: 95150 | MAE Train Loss: 43.91521453857422 | MAE Test Loss: 43.132877349853516 \n",
      "Epoch: 95160 | MAE Train Loss: 43.915042877197266 | MAE Test Loss: 43.13290786743164 \n",
      "Epoch: 95170 | MAE Train Loss: 43.91488265991211 | MAE Test Loss: 43.132938385009766 \n",
      "Epoch: 95180 | MAE Train Loss: 43.914710998535156 | MAE Test Loss: 43.132972717285156 \n",
      "Epoch: 95190 | MAE Train Loss: 43.91455078125 | MAE Test Loss: 43.13290786743164 \n",
      "Epoch: 95200 | MAE Train Loss: 43.914390563964844 | MAE Test Loss: 43.1329460144043 \n",
      "Epoch: 95210 | MAE Train Loss: 43.91421890258789 | MAE Test Loss: 43.13288116455078 \n",
      "Epoch: 95220 | MAE Train Loss: 43.914058685302734 | MAE Test Loss: 43.13290786743164 \n",
      "Epoch: 95230 | MAE Train Loss: 43.91388702392578 | MAE Test Loss: 43.132850646972656 \n",
      "Epoch: 95240 | MAE Train Loss: 43.913726806640625 | MAE Test Loss: 43.13288116455078 \n",
      "Epoch: 95250 | MAE Train Loss: 43.9135627746582 | MAE Test Loss: 43.132816314697266 \n",
      "Epoch: 95260 | MAE Train Loss: 43.91339874267578 | MAE Test Loss: 43.132850646972656 \n",
      "Epoch: 95270 | MAE Train Loss: 43.913230895996094 | MAE Test Loss: 43.13278579711914 \n",
      "Epoch: 95280 | MAE Train Loss: 43.91307067871094 | MAE Test Loss: 43.132816314697266 \n",
      "Epoch: 95290 | MAE Train Loss: 43.91290283203125 | MAE Test Loss: 43.1328010559082 \n",
      "Epoch: 95300 | MAE Train Loss: 43.91273880004883 | MAE Test Loss: 43.13283157348633 \n",
      "Epoch: 95310 | MAE Train Loss: 43.912574768066406 | MAE Test Loss: 43.13277053833008 \n",
      "Epoch: 95320 | MAE Train Loss: 43.912410736083984 | MAE Test Loss: 43.13280487060547 \n",
      "Epoch: 95330 | MAE Train Loss: 43.91224670410156 | MAE Test Loss: 43.13274002075195 \n",
      "Epoch: 95340 | MAE Train Loss: 43.912078857421875 | MAE Test Loss: 43.13277053833008 \n",
      "Epoch: 95350 | MAE Train Loss: 43.91191482543945 | MAE Test Loss: 43.13270950317383 \n",
      "Epoch: 95360 | MAE Train Loss: 43.91175079345703 | MAE Test Loss: 43.13274383544922 \n",
      "Epoch: 95370 | MAE Train Loss: 43.911582946777344 | MAE Test Loss: 43.1326789855957 \n",
      "Epoch: 95380 | MAE Train Loss: 43.91142272949219 | MAE Test Loss: 43.13270950317383 \n",
      "Epoch: 95390 | MAE Train Loss: 43.911258697509766 | MAE Test Loss: 43.132652282714844 \n",
      "Epoch: 95400 | MAE Train Loss: 43.911094665527344 | MAE Test Loss: 43.1326789855957 \n",
      "Epoch: 95410 | MAE Train Loss: 43.910926818847656 | MAE Test Loss: 43.13262176513672 \n",
      "Epoch: 95420 | MAE Train Loss: 43.910762786865234 | MAE Test Loss: 43.132652282714844 \n",
      "Epoch: 95430 | MAE Train Loss: 43.91059494018555 | MAE Test Loss: 43.13268280029297 \n",
      "Epoch: 95440 | MAE Train Loss: 43.91043472290039 | MAE Test Loss: 43.13262176513672 \n",
      "Epoch: 95450 | MAE Train Loss: 43.9102668762207 | MAE Test Loss: 43.13264846801758 \n",
      "Epoch: 95460 | MAE Train Loss: 43.910099029541016 | MAE Test Loss: 43.132591247558594 \n",
      "Epoch: 95470 | MAE Train Loss: 43.90993881225586 | MAE Test Loss: 43.13261795043945 \n",
      "Epoch: 95480 | MAE Train Loss: 43.90977096557617 | MAE Test Loss: 43.1325569152832 \n",
      "Epoch: 95490 | MAE Train Loss: 43.90961837768555 | MAE Test Loss: 43.132633209228516 \n",
      "Epoch: 95500 | MAE Train Loss: 43.90946578979492 | MAE Test Loss: 43.132659912109375 \n",
      "Epoch: 95510 | MAE Train Loss: 43.90932083129883 | MAE Test Loss: 43.132781982421875 \n",
      "Epoch: 95520 | MAE Train Loss: 43.90917205810547 | MAE Test Loss: 43.132808685302734 \n",
      "Epoch: 95530 | MAE Train Loss: 43.90902328491211 | MAE Test Loss: 43.13292694091797 \n",
      "Epoch: 95540 | MAE Train Loss: 43.90887451171875 | MAE Test Loss: 43.13295364379883 \n",
      "Epoch: 95550 | MAE Train Loss: 43.908721923828125 | MAE Test Loss: 43.13307571411133 \n",
      "Epoch: 95560 | MAE Train Loss: 43.9085807800293 | MAE Test Loss: 43.13310241699219 \n",
      "Epoch: 95570 | MAE Train Loss: 43.90842819213867 | MAE Test Loss: 43.13322067260742 \n",
      "Epoch: 95580 | MAE Train Loss: 43.90827941894531 | MAE Test Loss: 43.13324737548828 \n",
      "Epoch: 95590 | MAE Train Loss: 43.90813064575195 | MAE Test Loss: 43.13337326049805 \n",
      "Epoch: 95600 | MAE Train Loss: 43.907981872558594 | MAE Test Loss: 43.13339614868164 \n",
      "Epoch: 95610 | MAE Train Loss: 43.907833099365234 | MAE Test Loss: 43.1334228515625 \n",
      "Epoch: 95620 | MAE Train Loss: 43.90768814086914 | MAE Test Loss: 43.133541107177734 \n",
      "Epoch: 95630 | MAE Train Loss: 43.90753173828125 | MAE Test Loss: 43.133567810058594 \n",
      "Epoch: 95640 | MAE Train Loss: 43.907386779785156 | MAE Test Loss: 43.13368606567383 \n",
      "Epoch: 95650 | MAE Train Loss: 43.90724182128906 | MAE Test Loss: 43.13371658325195 \n",
      "Epoch: 95660 | MAE Train Loss: 43.90708923339844 | MAE Test Loss: 43.133785247802734 \n",
      "Epoch: 95670 | MAE Train Loss: 43.90694046020508 | MAE Test Loss: 43.1339111328125 \n",
      "Epoch: 95680 | MAE Train Loss: 43.90679168701172 | MAE Test Loss: 43.13398361206055 \n",
      "Epoch: 95690 | MAE Train Loss: 43.90664291381836 | MAE Test Loss: 43.134010314941406 \n",
      "Epoch: 95700 | MAE Train Loss: 43.906497955322266 | MAE Test Loss: 43.13412857055664 \n",
      "Epoch: 95710 | MAE Train Loss: 43.90634536743164 | MAE Test Loss: 43.1341552734375 \n",
      "Epoch: 95720 | MAE Train Loss: 43.90620040893555 | MAE Test Loss: 43.134273529052734 \n",
      "Epoch: 95730 | MAE Train Loss: 43.90605163574219 | MAE Test Loss: 43.134300231933594 \n",
      "Epoch: 95740 | MAE Train Loss: 43.90590286254883 | MAE Test Loss: 43.134422302246094 \n",
      "Epoch: 95750 | MAE Train Loss: 43.90575408935547 | MAE Test Loss: 43.13444900512695 \n",
      "Epoch: 95760 | MAE Train Loss: 43.905601501464844 | MAE Test Loss: 43.13456726074219 \n",
      "Epoch: 95770 | MAE Train Loss: 43.905460357666016 | MAE Test Loss: 43.13459396362305 \n",
      "Epoch: 95780 | MAE Train Loss: 43.905303955078125 | MAE Test Loss: 43.13471603393555 \n",
      "Epoch: 95790 | MAE Train Loss: 43.9051628112793 | MAE Test Loss: 43.13473892211914 \n",
      "Epoch: 95800 | MAE Train Loss: 43.90501022338867 | MAE Test Loss: 43.134864807128906 \n",
      "Epoch: 95810 | MAE Train Loss: 43.90486526489258 | MAE Test Loss: 43.1348876953125 \n",
      "Epoch: 95820 | MAE Train Loss: 43.90471267700195 | MAE Test Loss: 43.135005950927734 \n",
      "Epoch: 95830 | MAE Train Loss: 43.90456771850586 | MAE Test Loss: 43.135032653808594 \n",
      "Epoch: 95840 | MAE Train Loss: 43.9044189453125 | MAE Test Loss: 43.135066986083984 \n",
      "Epoch: 95850 | MAE Train Loss: 43.904266357421875 | MAE Test Loss: 43.13518142700195 \n",
      "Epoch: 95860 | MAE Train Loss: 43.904117584228516 | MAE Test Loss: 43.13520812988281 \n",
      "Epoch: 95870 | MAE Train Loss: 43.903968811035156 | MAE Test Loss: 43.13532638549805 \n",
      "Epoch: 95880 | MAE Train Loss: 43.9038200378418 | MAE Test Loss: 43.135353088378906 \n",
      "Epoch: 95890 | MAE Train Loss: 43.9036750793457 | MAE Test Loss: 43.13547897338867 \n",
      "Epoch: 95900 | MAE Train Loss: 43.903526306152344 | MAE Test Loss: 43.135501861572266 \n",
      "Epoch: 95910 | MAE Train Loss: 43.903377532958984 | MAE Test Loss: 43.1356201171875 \n",
      "Epoch: 95920 | MAE Train Loss: 43.90322494506836 | MAE Test Loss: 43.135650634765625 \n",
      "Epoch: 95930 | MAE Train Loss: 43.903079986572266 | MAE Test Loss: 43.135765075683594 \n",
      "Epoch: 95940 | MAE Train Loss: 43.902931213378906 | MAE Test Loss: 43.13579177856445 \n",
      "Epoch: 95950 | MAE Train Loss: 43.90278244018555 | MAE Test Loss: 43.135807037353516 \n",
      "Epoch: 95960 | MAE Train Loss: 43.90264129638672 | MAE Test Loss: 43.13591384887695 \n",
      "Epoch: 95970 | MAE Train Loss: 43.902496337890625 | MAE Test Loss: 43.135921478271484 \n",
      "Epoch: 95980 | MAE Train Loss: 43.90235137939453 | MAE Test Loss: 43.13593292236328 \n",
      "Epoch: 95990 | MAE Train Loss: 43.90220642089844 | MAE Test Loss: 43.13593292236328 \n",
      "Epoch: 96000 | MAE Train Loss: 43.902061462402344 | MAE Test Loss: 43.13594055175781 \n",
      "Epoch: 96010 | MAE Train Loss: 43.90192413330078 | MAE Test Loss: 43.135948181152344 \n",
      "Epoch: 96020 | MAE Train Loss: 43.90177536010742 | MAE Test Loss: 43.135955810546875 \n",
      "Epoch: 96030 | MAE Train Loss: 43.90163040161133 | MAE Test Loss: 43.13595962524414 \n",
      "Epoch: 96040 | MAE Train Loss: 43.90148162841797 | MAE Test Loss: 43.13597106933594 \n",
      "Epoch: 96050 | MAE Train Loss: 43.90134048461914 | MAE Test Loss: 43.13597106933594 \n",
      "Epoch: 96060 | MAE Train Loss: 43.90119934082031 | MAE Test Loss: 43.13607406616211 \n",
      "Epoch: 96070 | MAE Train Loss: 43.90105056762695 | MAE Test Loss: 43.136085510253906 \n",
      "Epoch: 96080 | MAE Train Loss: 43.900909423828125 | MAE Test Loss: 43.13609313964844 \n",
      "Epoch: 96090 | MAE Train Loss: 43.90076446533203 | MAE Test Loss: 43.1360969543457 \n",
      "Epoch: 96100 | MAE Train Loss: 43.90061950683594 | MAE Test Loss: 43.13610076904297 \n",
      "Epoch: 96110 | MAE Train Loss: 43.900474548339844 | MAE Test Loss: 43.1361083984375 \n",
      "Epoch: 96120 | MAE Train Loss: 43.90032958984375 | MAE Test Loss: 43.13611602783203 \n",
      "Epoch: 96130 | MAE Train Loss: 43.900184631347656 | MAE Test Loss: 43.1361198425293 \n",
      "Epoch: 96140 | MAE Train Loss: 43.90004348754883 | MAE Test Loss: 43.13612747192383 \n",
      "Epoch: 96150 | MAE Train Loss: 43.89989471435547 | MAE Test Loss: 43.136131286621094 \n",
      "Epoch: 96160 | MAE Train Loss: 43.899749755859375 | MAE Test Loss: 43.136234283447266 \n",
      "Epoch: 96170 | MAE Train Loss: 43.89960861206055 | MAE Test Loss: 43.13624572753906 \n",
      "Epoch: 96180 | MAE Train Loss: 43.89946365356445 | MAE Test Loss: 43.13624954223633 \n",
      "Epoch: 96190 | MAE Train Loss: 43.89931869506836 | MAE Test Loss: 43.13625717163086 \n",
      "Epoch: 96200 | MAE Train Loss: 43.89917755126953 | MAE Test Loss: 43.13625717163086 \n",
      "Epoch: 96210 | MAE Train Loss: 43.89903259277344 | MAE Test Loss: 43.13627243041992 \n",
      "Epoch: 96220 | MAE Train Loss: 43.898887634277344 | MAE Test Loss: 43.13627624511719 \n",
      "Epoch: 96230 | MAE Train Loss: 43.89874267578125 | MAE Test Loss: 43.13628005981445 \n",
      "Epoch: 96240 | MAE Train Loss: 43.898597717285156 | MAE Test Loss: 43.136287689208984 \n",
      "Epoch: 96250 | MAE Train Loss: 43.89845275878906 | MAE Test Loss: 43.136295318603516 \n",
      "Epoch: 96260 | MAE Train Loss: 43.898311614990234 | MAE Test Loss: 43.13639831542969 \n",
      "Epoch: 96270 | MAE Train Loss: 43.898162841796875 | MAE Test Loss: 43.13640213012695 \n",
      "Epoch: 96280 | MAE Train Loss: 43.89801788330078 | MAE Test Loss: 43.136409759521484 \n",
      "Epoch: 96290 | MAE Train Loss: 43.89788055419922 | MAE Test Loss: 43.13641357421875 \n",
      "Epoch: 96300 | MAE Train Loss: 43.89773178100586 | MAE Test Loss: 43.13642120361328 \n",
      "Epoch: 96310 | MAE Train Loss: 43.89759063720703 | MAE Test Loss: 43.13642883300781 \n",
      "Epoch: 96320 | MAE Train Loss: 43.89744186401367 | MAE Test Loss: 43.13643264770508 \n",
      "Epoch: 96330 | MAE Train Loss: 43.897300720214844 | MAE Test Loss: 43.13644027709961 \n",
      "Epoch: 96340 | MAE Train Loss: 43.89715576171875 | MAE Test Loss: 43.13644790649414 \n",
      "Epoch: 96350 | MAE Train Loss: 43.89700698852539 | MAE Test Loss: 43.13645553588867 \n",
      "Epoch: 96360 | MAE Train Loss: 43.89686584472656 | MAE Test Loss: 43.136558532714844 \n",
      "Epoch: 96370 | MAE Train Loss: 43.89672088623047 | MAE Test Loss: 43.13656234741211 \n",
      "Epoch: 96380 | MAE Train Loss: 43.89657974243164 | MAE Test Loss: 43.13656997680664 \n",
      "Epoch: 96390 | MAE Train Loss: 43.89643859863281 | MAE Test Loss: 43.13657760620117 \n",
      "Epoch: 96400 | MAE Train Loss: 43.89628982543945 | MAE Test Loss: 43.1365852355957 \n",
      "Epoch: 96410 | MAE Train Loss: 43.896148681640625 | MAE Test Loss: 43.136592864990234 \n",
      "Epoch: 96420 | MAE Train Loss: 43.89600372314453 | MAE Test Loss: 43.1365966796875 \n",
      "Epoch: 96430 | MAE Train Loss: 43.89585876464844 | MAE Test Loss: 43.13660430908203 \n",
      "Epoch: 96440 | MAE Train Loss: 43.89570999145508 | MAE Test Loss: 43.1366081237793 \n",
      "Epoch: 96450 | MAE Train Loss: 43.895565032958984 | MAE Test Loss: 43.13661575317383 \n",
      "Epoch: 96460 | MAE Train Loss: 43.895423889160156 | MAE Test Loss: 43.136722564697266 \n",
      "Epoch: 96470 | MAE Train Loss: 43.89527893066406 | MAE Test Loss: 43.136722564697266 \n",
      "Epoch: 96480 | MAE Train Loss: 43.89513397216797 | MAE Test Loss: 43.13673400878906 \n",
      "Epoch: 96490 | MAE Train Loss: 43.894989013671875 | MAE Test Loss: 43.13673782348633 \n",
      "Epoch: 96500 | MAE Train Loss: 43.89484786987305 | MAE Test Loss: 43.13674545288086 \n",
      "Epoch: 96510 | MAE Train Loss: 43.89470291137695 | MAE Test Loss: 43.13675308227539 \n",
      "Epoch: 96520 | MAE Train Loss: 43.89455795288086 | MAE Test Loss: 43.136756896972656 \n",
      "Epoch: 96530 | MAE Train Loss: 43.89441680908203 | MAE Test Loss: 43.13676452636719 \n",
      "Epoch: 96540 | MAE Train Loss: 43.89426803588867 | MAE Test Loss: 43.13676834106445 \n",
      "Epoch: 96550 | MAE Train Loss: 43.89412307739258 | MAE Test Loss: 43.136871337890625 \n",
      "Epoch: 96560 | MAE Train Loss: 43.89397430419922 | MAE Test Loss: 43.136878967285156 \n",
      "Epoch: 96570 | MAE Train Loss: 43.89383316040039 | MAE Test Loss: 43.13688278198242 \n",
      "Epoch: 96580 | MAE Train Loss: 43.89369201660156 | MAE Test Loss: 43.13689422607422 \n",
      "Epoch: 96590 | MAE Train Loss: 43.89354705810547 | MAE Test Loss: 43.136898040771484 \n",
      "Epoch: 96600 | MAE Train Loss: 43.89340591430664 | MAE Test Loss: 43.136905670166016 \n",
      "Epoch: 96610 | MAE Train Loss: 43.89326095581055 | MAE Test Loss: 43.13691329956055 \n",
      "Epoch: 96620 | MAE Train Loss: 43.89311218261719 | MAE Test Loss: 43.13692092895508 \n",
      "Epoch: 96630 | MAE Train Loss: 43.89297103881836 | MAE Test Loss: 43.136924743652344 \n",
      "Epoch: 96640 | MAE Train Loss: 43.892826080322266 | MAE Test Loss: 43.13692855834961 \n",
      "Epoch: 96650 | MAE Train Loss: 43.89268112182617 | MAE Test Loss: 43.13703155517578 \n",
      "Epoch: 96660 | MAE Train Loss: 43.89253616333008 | MAE Test Loss: 43.13703918457031 \n",
      "Epoch: 96670 | MAE Train Loss: 43.892391204833984 | MAE Test Loss: 43.137046813964844 \n",
      "Epoch: 96680 | MAE Train Loss: 43.892250061035156 | MAE Test Loss: 43.13705062866211 \n",
      "Epoch: 96690 | MAE Train Loss: 43.89210891723633 | MAE Test Loss: 43.137054443359375 \n",
      "Epoch: 96700 | MAE Train Loss: 43.89196014404297 | MAE Test Loss: 43.13706588745117 \n",
      "Epoch: 96710 | MAE Train Loss: 43.89181900024414 | MAE Test Loss: 43.1370735168457 \n",
      "Epoch: 96720 | MAE Train Loss: 43.89167022705078 | MAE Test Loss: 43.137081146240234 \n",
      "Epoch: 96730 | MAE Train Loss: 43.89152526855469 | MAE Test Loss: 43.1370849609375 \n",
      "Epoch: 96740 | MAE Train Loss: 43.89138412475586 | MAE Test Loss: 43.13709259033203 \n",
      "Epoch: 96750 | MAE Train Loss: 43.891239166259766 | MAE Test Loss: 43.13719177246094 \n",
      "Epoch: 96760 | MAE Train Loss: 43.89109420776367 | MAE Test Loss: 43.137203216552734 \n",
      "Epoch: 96770 | MAE Train Loss: 43.890953063964844 | MAE Test Loss: 43.137203216552734 \n",
      "Epoch: 96780 | MAE Train Loss: 43.89080810546875 | MAE Test Loss: 43.137210845947266 \n",
      "Epoch: 96790 | MAE Train Loss: 43.890663146972656 | MAE Test Loss: 43.13722229003906 \n",
      "Epoch: 96800 | MAE Train Loss: 43.89051818847656 | MAE Test Loss: 43.137229919433594 \n",
      "Epoch: 96810 | MAE Train Loss: 43.8903694152832 | MAE Test Loss: 43.137237548828125 \n",
      "Epoch: 96820 | MAE Train Loss: 43.890228271484375 | MAE Test Loss: 43.13724136352539 \n",
      "Epoch: 96830 | MAE Train Loss: 43.89008331298828 | MAE Test Loss: 43.137245178222656 \n",
      "Epoch: 96840 | MAE Train Loss: 43.88993453979492 | MAE Test Loss: 43.13725280761719 \n",
      "Epoch: 96850 | MAE Train Loss: 43.889793395996094 | MAE Test Loss: 43.13735580444336 \n",
      "Epoch: 96860 | MAE Train Loss: 43.889652252197266 | MAE Test Loss: 43.137359619140625 \n",
      "Epoch: 96870 | MAE Train Loss: 43.889503479003906 | MAE Test Loss: 43.137367248535156 \n",
      "Epoch: 96880 | MAE Train Loss: 43.88935852050781 | MAE Test Loss: 43.13737487792969 \n",
      "Epoch: 96890 | MAE Train Loss: 43.88922119140625 | MAE Test Loss: 43.13738250732422 \n",
      "Epoch: 96900 | MAE Train Loss: 43.88907241821289 | MAE Test Loss: 43.13743591308594 \n",
      "Epoch: 96910 | MAE Train Loss: 43.8889274597168 | MAE Test Loss: 43.1374397277832 \n",
      "Epoch: 96920 | MAE Train Loss: 43.8887825012207 | MAE Test Loss: 43.137447357177734 \n",
      "Epoch: 96930 | MAE Train Loss: 43.888641357421875 | MAE Test Loss: 43.137451171875 \n",
      "Epoch: 96940 | MAE Train Loss: 43.88849639892578 | MAE Test Loss: 43.1374626159668 \n",
      "Epoch: 96950 | MAE Train Loss: 43.88835144042969 | MAE Test Loss: 43.13747024536133 \n",
      "Epoch: 96960 | MAE Train Loss: 43.888206481933594 | MAE Test Loss: 43.137474060058594 \n",
      "Epoch: 96970 | MAE Train Loss: 43.8880615234375 | MAE Test Loss: 43.137481689453125 \n",
      "Epoch: 96980 | MAE Train Loss: 43.887916564941406 | MAE Test Loss: 43.13748550415039 \n",
      "Epoch: 96990 | MAE Train Loss: 43.88777160644531 | MAE Test Loss: 43.13749313354492 \n",
      "Epoch: 97000 | MAE Train Loss: 43.887630462646484 | MAE Test Loss: 43.137596130371094 \n",
      "Epoch: 97010 | MAE Train Loss: 43.887481689453125 | MAE Test Loss: 43.137603759765625 \n",
      "Epoch: 97020 | MAE Train Loss: 43.88734436035156 | MAE Test Loss: 43.13760757446289 \n",
      "Epoch: 97030 | MAE Train Loss: 43.8871955871582 | MAE Test Loss: 43.137611389160156 \n",
      "Epoch: 97040 | MAE Train Loss: 43.887054443359375 | MAE Test Loss: 43.13762283325195 \n",
      "Epoch: 97050 | MAE Train Loss: 43.88690948486328 | MAE Test Loss: 43.13762664794922 \n",
      "Epoch: 97060 | MAE Train Loss: 43.88676452636719 | MAE Test Loss: 43.13763427734375 \n",
      "Epoch: 97070 | MAE Train Loss: 43.886619567871094 | MAE Test Loss: 43.13764190673828 \n",
      "Epoch: 97080 | MAE Train Loss: 43.886474609375 | MAE Test Loss: 43.13764572143555 \n",
      "Epoch: 97090 | MAE Train Loss: 43.886329650878906 | MAE Test Loss: 43.13774871826172 \n",
      "Epoch: 97100 | MAE Train Loss: 43.88618469238281 | MAE Test Loss: 43.13775634765625 \n",
      "Epoch: 97110 | MAE Train Loss: 43.88603973388672 | MAE Test Loss: 43.13776397705078 \n",
      "Epoch: 97120 | MAE Train Loss: 43.88589859008789 | MAE Test Loss: 43.13776779174805 \n",
      "Epoch: 97130 | MAE Train Loss: 43.8857536315918 | MAE Test Loss: 43.137779235839844 \n",
      "Epoch: 97140 | MAE Train Loss: 43.8856086730957 | MAE Test Loss: 43.137779235839844 \n",
      "Epoch: 97150 | MAE Train Loss: 43.88546371459961 | MAE Test Loss: 43.137794494628906 \n",
      "Epoch: 97160 | MAE Train Loss: 43.88532257080078 | MAE Test Loss: 43.137794494628906 \n",
      "Epoch: 97170 | MAE Train Loss: 43.88517379760742 | MAE Test Loss: 43.13779830932617 \n",
      "Epoch: 97180 | MAE Train Loss: 43.88502883911133 | MAE Test Loss: 43.1378059387207 \n",
      "Epoch: 97190 | MAE Train Loss: 43.88488006591797 | MAE Test Loss: 43.13794708251953 \n",
      "Epoch: 97200 | MAE Train Loss: 43.88473892211914 | MAE Test Loss: 43.13798522949219 \n",
      "Epoch: 97210 | MAE Train Loss: 43.88459777832031 | MAE Test Loss: 43.13801574707031 \n",
      "Epoch: 97220 | MAE Train Loss: 43.884456634521484 | MAE Test Loss: 43.138057708740234 \n",
      "Epoch: 97230 | MAE Train Loss: 43.884307861328125 | MAE Test Loss: 43.138092041015625 \n",
      "Epoch: 97240 | MAE Train Loss: 43.8841667175293 | MAE Test Loss: 43.13812255859375 \n",
      "Epoch: 97250 | MAE Train Loss: 43.88401794433594 | MAE Test Loss: 43.13816452026367 \n",
      "Epoch: 97260 | MAE Train Loss: 43.88387680053711 | MAE Test Loss: 43.13819885253906 \n",
      "Epoch: 97270 | MAE Train Loss: 43.883731842041016 | MAE Test Loss: 43.13823318481445 \n",
      "Epoch: 97280 | MAE Train Loss: 43.88358688354492 | MAE Test Loss: 43.138267517089844 \n",
      "Epoch: 97290 | MAE Train Loss: 43.88344192504883 | MAE Test Loss: 43.13846206665039 \n",
      "Epoch: 97300 | MAE Train Loss: 43.88329315185547 | MAE Test Loss: 43.13849639892578 \n",
      "Epoch: 97310 | MAE Train Loss: 43.883155822753906 | MAE Test Loss: 43.13853454589844 \n",
      "Epoch: 97320 | MAE Train Loss: 43.88301086425781 | MAE Test Loss: 43.13856887817383 \n",
      "Epoch: 97330 | MAE Train Loss: 43.882869720458984 | MAE Test Loss: 43.138607025146484 \n",
      "Epoch: 97340 | MAE Train Loss: 43.88272476196289 | MAE Test Loss: 43.13863754272461 \n",
      "Epoch: 97350 | MAE Train Loss: 43.88257598876953 | MAE Test Loss: 43.138675689697266 \n",
      "Epoch: 97360 | MAE Train Loss: 43.88243103027344 | MAE Test Loss: 43.13870620727539 \n",
      "Epoch: 97370 | MAE Train Loss: 43.88228225708008 | MAE Test Loss: 43.13874435424805 \n",
      "Epoch: 97380 | MAE Train Loss: 43.882137298583984 | MAE Test Loss: 43.1387825012207 \n",
      "Epoch: 97390 | MAE Train Loss: 43.88199996948242 | MAE Test Loss: 43.13897705078125 \n",
      "Epoch: 97400 | MAE Train Loss: 43.88185501098633 | MAE Test Loss: 43.139007568359375 \n",
      "Epoch: 97410 | MAE Train Loss: 43.8817138671875 | MAE Test Loss: 43.1390495300293 \n",
      "Epoch: 97420 | MAE Train Loss: 43.881568908691406 | MAE Test Loss: 43.13908386230469 \n",
      "Epoch: 97430 | MAE Train Loss: 43.88142776489258 | MAE Test Loss: 43.13911437988281 \n",
      "Epoch: 97440 | MAE Train Loss: 43.88127899169922 | MAE Test Loss: 43.1391487121582 \n",
      "Epoch: 97450 | MAE Train Loss: 43.88113784790039 | MAE Test Loss: 43.13918685913086 \n",
      "Epoch: 97460 | MAE Train Loss: 43.8809928894043 | MAE Test Loss: 43.139225006103516 \n",
      "Epoch: 97470 | MAE Train Loss: 43.88084030151367 | MAE Test Loss: 43.13926315307617 \n",
      "Epoch: 97480 | MAE Train Loss: 43.88070297241211 | MAE Test Loss: 43.13929748535156 \n",
      "Epoch: 97490 | MAE Train Loss: 43.88055419921875 | MAE Test Loss: 43.139488220214844 \n",
      "Epoch: 97500 | MAE Train Loss: 43.88041305541992 | MAE Test Loss: 43.1395263671875 \n",
      "Epoch: 97510 | MAE Train Loss: 43.88026809692383 | MAE Test Loss: 43.13956069946289 \n",
      "Epoch: 97520 | MAE Train Loss: 43.880123138427734 | MAE Test Loss: 43.13959503173828 \n",
      "Epoch: 97530 | MAE Train Loss: 43.87997817993164 | MAE Test Loss: 43.13963317871094 \n",
      "Epoch: 97540 | MAE Train Loss: 43.87983703613281 | MAE Test Loss: 43.13966751098633 \n",
      "Epoch: 97550 | MAE Train Loss: 43.87968826293945 | MAE Test Loss: 43.13970184326172 \n",
      "Epoch: 97560 | MAE Train Loss: 43.87954330444336 | MAE Test Loss: 43.139739990234375 \n",
      "Epoch: 97570 | MAE Train Loss: 43.8794059753418 | MAE Test Loss: 43.139774322509766 \n",
      "Epoch: 97580 | MAE Train Loss: 43.87925338745117 | MAE Test Loss: 43.139888763427734 \n",
      "Epoch: 97590 | MAE Train Loss: 43.87911605834961 | MAE Test Loss: 43.13992691040039 \n",
      "Epoch: 97600 | MAE Train Loss: 43.878971099853516 | MAE Test Loss: 43.13996505737305 \n",
      "Epoch: 97610 | MAE Train Loss: 43.87882614135742 | MAE Test Loss: 43.13999938964844 \n",
      "Epoch: 97620 | MAE Train Loss: 43.87868118286133 | MAE Test Loss: 43.14003372192383 \n",
      "Epoch: 97630 | MAE Train Loss: 43.878536224365234 | MAE Test Loss: 43.140228271484375 \n",
      "Epoch: 97640 | MAE Train Loss: 43.878387451171875 | MAE Test Loss: 43.14026641845703 \n",
      "Epoch: 97650 | MAE Train Loss: 43.87825012207031 | MAE Test Loss: 43.140296936035156 \n",
      "Epoch: 97660 | MAE Train Loss: 43.87810516357422 | MAE Test Loss: 43.14033508300781 \n",
      "Epoch: 97670 | MAE Train Loss: 43.877960205078125 | MAE Test Loss: 43.14037322998047 \n",
      "Epoch: 97680 | MAE Train Loss: 43.8778190612793 | MAE Test Loss: 43.140403747558594 \n",
      "Epoch: 97690 | MAE Train Loss: 43.87767028808594 | MAE Test Loss: 43.140445709228516 \n",
      "Epoch: 97700 | MAE Train Loss: 43.877525329589844 | MAE Test Loss: 43.140480041503906 \n",
      "Epoch: 97710 | MAE Train Loss: 43.87738037109375 | MAE Test Loss: 43.1405143737793 \n",
      "Epoch: 97720 | MAE Train Loss: 43.877235412597656 | MAE Test Loss: 43.14055252075195 \n",
      "Epoch: 97730 | MAE Train Loss: 43.87709045410156 | MAE Test Loss: 43.14073944091797 \n",
      "Epoch: 97740 | MAE Train Loss: 43.876949310302734 | MAE Test Loss: 43.140777587890625 \n",
      "Epoch: 97750 | MAE Train Loss: 43.87680435180664 | MAE Test Loss: 43.14081573486328 \n",
      "Epoch: 97760 | MAE Train Loss: 43.87665939331055 | MAE Test Loss: 43.14085006713867 \n",
      "Epoch: 97770 | MAE Train Loss: 43.87651443481445 | MAE Test Loss: 43.14088439941406 \n",
      "Epoch: 97780 | MAE Train Loss: 43.876373291015625 | MAE Test Loss: 43.14091873168945 \n",
      "Epoch: 97790 | MAE Train Loss: 43.87622833251953 | MAE Test Loss: 43.140953063964844 \n",
      "Epoch: 97800 | MAE Train Loss: 43.87608337402344 | MAE Test Loss: 43.140987396240234 \n",
      "Epoch: 97810 | MAE Train Loss: 43.875938415527344 | MAE Test Loss: 43.141029357910156 \n",
      "Epoch: 97820 | MAE Train Loss: 43.875789642333984 | MAE Test Loss: 43.14105987548828 \n",
      "Epoch: 97830 | MAE Train Loss: 43.875648498535156 | MAE Test Loss: 43.14125442504883 \n",
      "Epoch: 97840 | MAE Train Loss: 43.87550735473633 | MAE Test Loss: 43.141292572021484 \n",
      "Epoch: 97850 | MAE Train Loss: 43.87535858154297 | MAE Test Loss: 43.141326904296875 \n",
      "Epoch: 97860 | MAE Train Loss: 43.87521743774414 | MAE Test Loss: 43.141361236572266 \n",
      "Epoch: 97870 | MAE Train Loss: 43.87507629394531 | MAE Test Loss: 43.14139938354492 \n",
      "Epoch: 97880 | MAE Train Loss: 43.87492752075195 | MAE Test Loss: 43.14143753051758 \n",
      "Epoch: 97890 | MAE Train Loss: 43.87478256225586 | MAE Test Loss: 43.1414680480957 \n",
      "Epoch: 97900 | MAE Train Loss: 43.87464141845703 | MAE Test Loss: 43.141510009765625 \n",
      "Epoch: 97910 | MAE Train Loss: 43.87449264526367 | MAE Test Loss: 43.14154052734375 \n",
      "Epoch: 97920 | MAE Train Loss: 43.874351501464844 | MAE Test Loss: 43.141578674316406 \n",
      "Epoch: 97930 | MAE Train Loss: 43.874202728271484 | MAE Test Loss: 43.14177322387695 \n",
      "Epoch: 97940 | MAE Train Loss: 43.87405776977539 | MAE Test Loss: 43.141807556152344 \n",
      "Epoch: 97950 | MAE Train Loss: 43.87391662597656 | MAE Test Loss: 43.141841888427734 \n",
      "Epoch: 97960 | MAE Train Loss: 43.873775482177734 | MAE Test Loss: 43.14188003540039 \n",
      "Epoch: 97970 | MAE Train Loss: 43.87363052368164 | MAE Test Loss: 43.14191436767578 \n",
      "Epoch: 97980 | MAE Train Loss: 43.87348556518555 | MAE Test Loss: 43.14194869995117 \n",
      "Epoch: 97990 | MAE Train Loss: 43.87334060668945 | MAE Test Loss: 43.14198684692383 \n",
      "Epoch: 98000 | MAE Train Loss: 43.87319564819336 | MAE Test Loss: 43.14202117919922 \n",
      "Epoch: 98010 | MAE Train Loss: 43.873050689697266 | MAE Test Loss: 43.142051696777344 \n",
      "Epoch: 98020 | MAE Train Loss: 43.87290573120117 | MAE Test Loss: 43.142093658447266 \n",
      "Epoch: 98030 | MAE Train Loss: 43.87276077270508 | MAE Test Loss: 43.14228820800781 \n",
      "Epoch: 98040 | MAE Train Loss: 43.87261962890625 | MAE Test Loss: 43.14231872558594 \n",
      "Epoch: 98050 | MAE Train Loss: 43.872474670410156 | MAE Test Loss: 43.142356872558594 \n",
      "Epoch: 98060 | MAE Train Loss: 43.87232971191406 | MAE Test Loss: 43.142391204833984 \n",
      "Epoch: 98070 | MAE Train Loss: 43.87218475341797 | MAE Test Loss: 43.142425537109375 \n",
      "Epoch: 98080 | MAE Train Loss: 43.872039794921875 | MAE Test Loss: 43.1424674987793 \n",
      "Epoch: 98090 | MAE Train Loss: 43.87189483642578 | MAE Test Loss: 43.142494201660156 \n",
      "Epoch: 98100 | MAE Train Loss: 43.87175369262695 | MAE Test Loss: 43.14253234863281 \n",
      "Epoch: 98110 | MAE Train Loss: 43.871604919433594 | MAE Test Loss: 43.14257049560547 \n",
      "Epoch: 98120 | MAE Train Loss: 43.8714599609375 | MAE Test Loss: 43.142765045166016 \n",
      "Epoch: 98130 | MAE Train Loss: 43.871315002441406 | MAE Test Loss: 43.142799377441406 \n",
      "Epoch: 98140 | MAE Train Loss: 43.87117385864258 | MAE Test Loss: 43.14283752441406 \n",
      "Epoch: 98150 | MAE Train Loss: 43.87103271484375 | MAE Test Loss: 43.14286804199219 \n",
      "Epoch: 98160 | MAE Train Loss: 43.870887756347656 | MAE Test Loss: 43.142906188964844 \n",
      "Epoch: 98170 | MAE Train Loss: 43.87074661254883 | MAE Test Loss: 43.1429443359375 \n",
      "Epoch: 98180 | MAE Train Loss: 43.8705940246582 | MAE Test Loss: 43.14297866821289 \n",
      "Epoch: 98190 | MAE Train Loss: 43.870452880859375 | MAE Test Loss: 43.14301300048828 \n",
      "Epoch: 98200 | MAE Train Loss: 43.87031173706055 | MAE Test Loss: 43.14304733276367 \n",
      "Epoch: 98210 | MAE Train Loss: 43.87016296386719 | MAE Test Loss: 43.14308166503906 \n",
      "Epoch: 98220 | MAE Train Loss: 43.87002182006836 | MAE Test Loss: 43.1431999206543 \n",
      "Epoch: 98230 | MAE Train Loss: 43.869876861572266 | MAE Test Loss: 43.14323806762695 \n",
      "Epoch: 98240 | MAE Train Loss: 43.869728088378906 | MAE Test Loss: 43.143272399902344 \n",
      "Epoch: 98250 | MAE Train Loss: 43.86958694458008 | MAE Test Loss: 43.143306732177734 \n",
      "Epoch: 98260 | MAE Train Loss: 43.869441986083984 | MAE Test Loss: 43.143341064453125 \n",
      "Epoch: 98270 | MAE Train Loss: 43.86929702758789 | MAE Test Loss: 43.143531799316406 \n",
      "Epoch: 98280 | MAE Train Loss: 43.8691520690918 | MAE Test Loss: 43.14357376098633 \n",
      "Epoch: 98290 | MAE Train Loss: 43.86901092529297 | MAE Test Loss: 43.14360809326172 \n",
      "Epoch: 98300 | MAE Train Loss: 43.868865966796875 | MAE Test Loss: 43.14364242553711 \n",
      "Epoch: 98310 | MAE Train Loss: 43.86872482299805 | MAE Test Loss: 43.1436767578125 \n",
      "Epoch: 98320 | MAE Train Loss: 43.86857604980469 | MAE Test Loss: 43.143714904785156 \n",
      "Epoch: 98330 | MAE Train Loss: 43.86843490600586 | MAE Test Loss: 43.14374923706055 \n",
      "Epoch: 98340 | MAE Train Loss: 43.868289947509766 | MAE Test Loss: 43.14378356933594 \n",
      "Epoch: 98350 | MAE Train Loss: 43.868141174316406 | MAE Test Loss: 43.143821716308594 \n",
      "Epoch: 98360 | MAE Train Loss: 43.86800003051758 | MAE Test Loss: 43.143856048583984 \n",
      "Epoch: 98370 | MAE Train Loss: 43.867855072021484 | MAE Test Loss: 43.14405059814453 \n",
      "Epoch: 98380 | MAE Train Loss: 43.867706298828125 | MAE Test Loss: 43.14408874511719 \n",
      "Epoch: 98390 | MAE Train Loss: 43.8675651550293 | MAE Test Loss: 43.14411926269531 \n",
      "Epoch: 98400 | MAE Train Loss: 43.86742401123047 | MAE Test Loss: 43.14415740966797 \n",
      "Epoch: 98410 | MAE Train Loss: 43.867279052734375 | MAE Test Loss: 43.14419174194336 \n",
      "Epoch: 98420 | MAE Train Loss: 43.867130279541016 | MAE Test Loss: 43.144229888916016 \n",
      "Epoch: 98430 | MAE Train Loss: 43.86698913574219 | MAE Test Loss: 43.144264221191406 \n",
      "Epoch: 98440 | MAE Train Loss: 43.866844177246094 | MAE Test Loss: 43.14430236816406 \n",
      "Epoch: 98450 | MAE Train Loss: 43.86669921875 | MAE Test Loss: 43.14433670043945 \n",
      "Epoch: 98460 | MAE Train Loss: 43.866554260253906 | MAE Test Loss: 43.144371032714844 \n",
      "Epoch: 98470 | MAE Train Loss: 43.86641311645508 | MAE Test Loss: 43.14456558227539 \n",
      "Epoch: 98480 | MAE Train Loss: 43.866268157958984 | MAE Test Loss: 43.14460372924805 \n",
      "Epoch: 98490 | MAE Train Loss: 43.86612319946289 | MAE Test Loss: 43.14463424682617 \n",
      "Epoch: 98500 | MAE Train Loss: 43.86598205566406 | MAE Test Loss: 43.14467239379883 \n",
      "Epoch: 98510 | MAE Train Loss: 43.865840911865234 | MAE Test Loss: 43.144710540771484 \n",
      "Epoch: 98520 | MAE Train Loss: 43.865692138671875 | MAE Test Loss: 43.14474105834961 \n",
      "Epoch: 98530 | MAE Train Loss: 43.865543365478516 | MAE Test Loss: 43.144779205322266 \n",
      "Epoch: 98540 | MAE Train Loss: 43.86540603637695 | MAE Test Loss: 43.144813537597656 \n",
      "Epoch: 98550 | MAE Train Loss: 43.86525344848633 | MAE Test Loss: 43.14484786987305 \n",
      "Epoch: 98560 | MAE Train Loss: 43.865108489990234 | MAE Test Loss: 43.1448860168457 \n",
      "Epoch: 98570 | MAE Train Loss: 43.864967346191406 | MAE Test Loss: 43.145084381103516 \n",
      "Epoch: 98580 | MAE Train Loss: 43.86482238769531 | MAE Test Loss: 43.145118713378906 \n",
      "Epoch: 98590 | MAE Train Loss: 43.864681243896484 | MAE Test Loss: 43.1451530456543 \n",
      "Epoch: 98600 | MAE Train Loss: 43.86453628540039 | MAE Test Loss: 43.14518356323242 \n",
      "Epoch: 98610 | MAE Train Loss: 43.86439514160156 | MAE Test Loss: 43.14522171020508 \n",
      "Epoch: 98620 | MAE Train Loss: 43.86425018310547 | MAE Test Loss: 43.145259857177734 \n",
      "Epoch: 98630 | MAE Train Loss: 43.86410140991211 | MAE Test Loss: 43.145294189453125 \n",
      "Epoch: 98640 | MAE Train Loss: 43.86396026611328 | MAE Test Loss: 43.145328521728516 \n",
      "Epoch: 98650 | MAE Train Loss: 43.86381149291992 | MAE Test Loss: 43.145362854003906 \n",
      "Epoch: 98660 | MAE Train Loss: 43.863670349121094 | MAE Test Loss: 43.14556121826172 \n",
      "Epoch: 98670 | MAE Train Loss: 43.863529205322266 | MAE Test Loss: 43.14559555053711 \n",
      "Epoch: 98680 | MAE Train Loss: 43.863380432128906 | MAE Test Loss: 43.1456298828125 \n",
      "Epoch: 98690 | MAE Train Loss: 43.86323547363281 | MAE Test Loss: 43.145668029785156 \n",
      "Epoch: 98700 | MAE Train Loss: 43.863094329833984 | MAE Test Loss: 43.14569854736328 \n",
      "Epoch: 98710 | MAE Train Loss: 43.862945556640625 | MAE Test Loss: 43.14574432373047 \n",
      "Epoch: 98720 | MAE Train Loss: 43.8628044128418 | MAE Test Loss: 43.145774841308594 \n",
      "Epoch: 98730 | MAE Train Loss: 43.86266326904297 | MAE Test Loss: 43.14580535888672 \n",
      "Epoch: 98740 | MAE Train Loss: 43.86251449584961 | MAE Test Loss: 43.145843505859375 \n",
      "Epoch: 98750 | MAE Train Loss: 43.862369537353516 | MAE Test Loss: 43.1458740234375 \n",
      "Epoch: 98760 | MAE Train Loss: 43.86222457885742 | MAE Test Loss: 43.14607238769531 \n",
      "Epoch: 98770 | MAE Train Loss: 43.86207962036133 | MAE Test Loss: 43.14611053466797 \n",
      "Epoch: 98780 | MAE Train Loss: 43.8619384765625 | MAE Test Loss: 43.14614486694336 \n",
      "Epoch: 98790 | MAE Train Loss: 43.86179733276367 | MAE Test Loss: 43.14617919921875 \n",
      "Epoch: 98800 | MAE Train Loss: 43.86165237426758 | MAE Test Loss: 43.146217346191406 \n",
      "Epoch: 98810 | MAE Train Loss: 43.86150360107422 | MAE Test Loss: 43.14625549316406 \n",
      "Epoch: 98820 | MAE Train Loss: 43.86136245727539 | MAE Test Loss: 43.14628601074219 \n",
      "Epoch: 98830 | MAE Train Loss: 43.8612174987793 | MAE Test Loss: 43.146324157714844 \n",
      "Epoch: 98840 | MAE Train Loss: 43.8610725402832 | MAE Test Loss: 43.146358489990234 \n",
      "Epoch: 98850 | MAE Train Loss: 43.86092758178711 | MAE Test Loss: 43.14639663696289 \n",
      "Epoch: 98860 | MAE Train Loss: 43.860782623291016 | MAE Test Loss: 43.14651107788086 \n",
      "Epoch: 98870 | MAE Train Loss: 43.86064147949219 | MAE Test Loss: 43.146549224853516 \n",
      "Epoch: 98880 | MAE Train Loss: 43.86049270629883 | MAE Test Loss: 43.14657974243164 \n",
      "Epoch: 98890 | MAE Train Loss: 43.860347747802734 | MAE Test Loss: 43.14661407470703 \n",
      "Epoch: 98900 | MAE Train Loss: 43.86020278930664 | MAE Test Loss: 43.14665603637695 \n",
      "Epoch: 98910 | MAE Train Loss: 43.86005783081055 | MAE Test Loss: 43.146846771240234 \n",
      "Epoch: 98920 | MAE Train Loss: 43.85991668701172 | MAE Test Loss: 43.146881103515625 \n",
      "Epoch: 98930 | MAE Train Loss: 43.859771728515625 | MAE Test Loss: 43.14691925048828 \n",
      "Epoch: 98940 | MAE Train Loss: 43.8596305847168 | MAE Test Loss: 43.146949768066406 \n",
      "Epoch: 98950 | MAE Train Loss: 43.8594856262207 | MAE Test Loss: 43.14698791503906 \n",
      "Epoch: 98960 | MAE Train Loss: 43.859336853027344 | MAE Test Loss: 43.14702606201172 \n",
      "Epoch: 98970 | MAE Train Loss: 43.85919952392578 | MAE Test Loss: 43.147056579589844 \n",
      "Epoch: 98980 | MAE Train Loss: 43.85905075073242 | MAE Test Loss: 43.1470947265625 \n",
      "Epoch: 98990 | MAE Train Loss: 43.85890197753906 | MAE Test Loss: 43.147132873535156 \n",
      "Epoch: 99000 | MAE Train Loss: 43.85875701904297 | MAE Test Loss: 43.14716339111328 \n",
      "Epoch: 99010 | MAE Train Loss: 43.85861587524414 | MAE Test Loss: 43.147361755371094 \n",
      "Epoch: 99020 | MAE Train Loss: 43.85847473144531 | MAE Test Loss: 43.147396087646484 \n",
      "Epoch: 99030 | MAE Train Loss: 43.85832595825195 | MAE Test Loss: 43.147430419921875 \n",
      "Epoch: 99040 | MAE Train Loss: 43.858184814453125 | MAE Test Loss: 43.147464752197266 \n",
      "Epoch: 99050 | MAE Train Loss: 43.85803985595703 | MAE Test Loss: 43.14750671386719 \n",
      "Epoch: 99060 | MAE Train Loss: 43.8578987121582 | MAE Test Loss: 43.14753723144531 \n",
      "Epoch: 99070 | MAE Train Loss: 43.857749938964844 | MAE Test Loss: 43.1475715637207 \n",
      "Epoch: 99080 | MAE Train Loss: 43.857608795166016 | MAE Test Loss: 43.14760971069336 \n",
      "Epoch: 99090 | MAE Train Loss: 43.857460021972656 | MAE Test Loss: 43.147640228271484 \n",
      "Epoch: 99100 | MAE Train Loss: 43.85731887817383 | MAE Test Loss: 43.147682189941406 \n",
      "Epoch: 99110 | MAE Train Loss: 43.857173919677734 | MAE Test Loss: 43.14787673950195 \n",
      "Epoch: 99120 | MAE Train Loss: 43.85702896118164 | MAE Test Loss: 43.147911071777344 \n",
      "Epoch: 99130 | MAE Train Loss: 43.85688400268555 | MAE Test Loss: 43.147945404052734 \n",
      "Epoch: 99140 | MAE Train Loss: 43.85674285888672 | MAE Test Loss: 43.14798355102539 \n",
      "Epoch: 99150 | MAE Train Loss: 43.85659408569336 | MAE Test Loss: 43.14802169799805 \n",
      "Epoch: 99160 | MAE Train Loss: 43.85645294189453 | MAE Test Loss: 43.14805221557617 \n",
      "Epoch: 99170 | MAE Train Loss: 43.85630798339844 | MAE Test Loss: 43.14809036254883 \n",
      "Epoch: 99180 | MAE Train Loss: 43.856163024902344 | MAE Test Loss: 43.14812088012695 \n",
      "Epoch: 99190 | MAE Train Loss: 43.85601806640625 | MAE Test Loss: 43.14815902709961 \n",
      "Epoch: 99200 | MAE Train Loss: 43.855873107910156 | MAE Test Loss: 43.148353576660156 \n",
      "Epoch: 99210 | MAE Train Loss: 43.85572814941406 | MAE Test Loss: 43.14839172363281 \n",
      "Epoch: 99220 | MAE Train Loss: 43.85558319091797 | MAE Test Loss: 43.1484260559082 \n",
      "Epoch: 99230 | MAE Train Loss: 43.85544204711914 | MAE Test Loss: 43.148460388183594 \n",
      "Epoch: 99240 | MAE Train Loss: 43.85530090332031 | MAE Test Loss: 43.148494720458984 \n",
      "Epoch: 99250 | MAE Train Loss: 43.855159759521484 | MAE Test Loss: 43.148372650146484 \n",
      "Epoch: 99260 | MAE Train Loss: 43.85501480102539 | MAE Test Loss: 43.14856719970703 \n",
      "Epoch: 99270 | MAE Train Loss: 43.85487365722656 | MAE Test Loss: 43.148441314697266 \n",
      "Epoch: 99280 | MAE Train Loss: 43.8547248840332 | MAE Test Loss: 43.14862823486328 \n",
      "Epoch: 99290 | MAE Train Loss: 43.854583740234375 | MAE Test Loss: 43.14866638183594 \n",
      "Epoch: 99300 | MAE Train Loss: 43.85444259643555 | MAE Test Loss: 43.14870071411133 \n",
      "Epoch: 99310 | MAE Train Loss: 43.85429382324219 | MAE Test Loss: 43.14864730834961 \n",
      "Epoch: 99320 | MAE Train Loss: 43.854148864746094 | MAE Test Loss: 43.14876174926758 \n",
      "Epoch: 99330 | MAE Train Loss: 43.854007720947266 | MAE Test Loss: 43.14878845214844 \n",
      "Epoch: 99340 | MAE Train Loss: 43.85387420654297 | MAE Test Loss: 43.14881896972656 \n",
      "Epoch: 99350 | MAE Train Loss: 43.853729248046875 | MAE Test Loss: 43.14885330200195 \n",
      "Epoch: 99360 | MAE Train Loss: 43.85358428955078 | MAE Test Loss: 43.14888000488281 \n",
      "Epoch: 99370 | MAE Train Loss: 43.85344696044922 | MAE Test Loss: 43.14891052246094 \n",
      "Epoch: 99380 | MAE Train Loss: 43.85330581665039 | MAE Test Loss: 43.14894104003906 \n",
      "Epoch: 99390 | MAE Train Loss: 43.8531608581543 | MAE Test Loss: 43.14897155761719 \n",
      "Epoch: 99400 | MAE Train Loss: 43.8530158996582 | MAE Test Loss: 43.14900207519531 \n",
      "Epoch: 99410 | MAE Train Loss: 43.85287857055664 | MAE Test Loss: 43.14903259277344 \n",
      "Epoch: 99420 | MAE Train Loss: 43.85273361206055 | MAE Test Loss: 43.14906311035156 \n",
      "Epoch: 99430 | MAE Train Loss: 43.85259246826172 | MAE Test Loss: 43.14909362792969 \n",
      "Epoch: 99440 | MAE Train Loss: 43.85245132446289 | MAE Test Loss: 43.14912414550781 \n",
      "Epoch: 99450 | MAE Train Loss: 43.8523063659668 | MAE Test Loss: 43.14915466308594 \n",
      "Epoch: 99460 | MAE Train Loss: 43.85216522216797 | MAE Test Loss: 43.14918518066406 \n",
      "Epoch: 99470 | MAE Train Loss: 43.852020263671875 | MAE Test Loss: 43.14921569824219 \n",
      "Epoch: 99480 | MAE Train Loss: 43.85187911987305 | MAE Test Loss: 43.14925003051758 \n",
      "Epoch: 99490 | MAE Train Loss: 43.85173797607422 | MAE Test Loss: 43.14927291870117 \n",
      "Epoch: 99500 | MAE Train Loss: 43.85159683227539 | MAE Test Loss: 43.14930725097656 \n",
      "Epoch: 99510 | MAE Train Loss: 43.85145568847656 | MAE Test Loss: 43.14933776855469 \n",
      "Epoch: 99520 | MAE Train Loss: 43.8513069152832 | MAE Test Loss: 43.14936828613281 \n",
      "Epoch: 99530 | MAE Train Loss: 43.85116958618164 | MAE Test Loss: 43.14939880371094 \n",
      "Epoch: 99540 | MAE Train Loss: 43.85102462768555 | MAE Test Loss: 43.14942932128906 \n",
      "Epoch: 99550 | MAE Train Loss: 43.85088348388672 | MAE Test Loss: 43.14946365356445 \n",
      "Epoch: 99560 | MAE Train Loss: 43.85074234008789 | MAE Test Loss: 43.14948654174805 \n",
      "Epoch: 99570 | MAE Train Loss: 43.8505973815918 | MAE Test Loss: 43.1495246887207 \n",
      "Epoch: 99580 | MAE Train Loss: 43.850460052490234 | MAE Test Loss: 43.14955520629883 \n",
      "Epoch: 99590 | MAE Train Loss: 43.85031509399414 | MAE Test Loss: 43.14958190917969 \n",
      "Epoch: 99600 | MAE Train Loss: 43.85017013549805 | MAE Test Loss: 43.14961242675781 \n",
      "Epoch: 99610 | MAE Train Loss: 43.85002899169922 | MAE Test Loss: 43.14964294433594 \n",
      "Epoch: 99620 | MAE Train Loss: 43.84988784790039 | MAE Test Loss: 43.14967346191406 \n",
      "Epoch: 99630 | MAE Train Loss: 43.84974670410156 | MAE Test Loss: 43.14970397949219 \n",
      "Epoch: 99640 | MAE Train Loss: 43.84960174560547 | MAE Test Loss: 43.14973068237305 \n",
      "Epoch: 99650 | MAE Train Loss: 43.84946060180664 | MAE Test Loss: 43.1497688293457 \n",
      "Epoch: 99660 | MAE Train Loss: 43.84932327270508 | MAE Test Loss: 43.1497917175293 \n",
      "Epoch: 99670 | MAE Train Loss: 43.849178314208984 | MAE Test Loss: 43.14982604980469 \n",
      "Epoch: 99680 | MAE Train Loss: 43.84903335571289 | MAE Test Loss: 43.14985656738281 \n",
      "Epoch: 99690 | MAE Train Loss: 43.8488883972168 | MAE Test Loss: 43.14988708496094 \n",
      "Epoch: 99700 | MAE Train Loss: 43.84874725341797 | MAE Test Loss: 43.14991760253906 \n",
      "Epoch: 99710 | MAE Train Loss: 43.84860610961914 | MAE Test Loss: 43.14994812011719 \n",
      "Epoch: 99720 | MAE Train Loss: 43.84846496582031 | MAE Test Loss: 43.14997482299805 \n",
      "Epoch: 99730 | MAE Train Loss: 43.84832763671875 | MAE Test Loss: 43.15000534057617 \n",
      "Epoch: 99740 | MAE Train Loss: 43.848182678222656 | MAE Test Loss: 43.1500358581543 \n",
      "Epoch: 99750 | MAE Train Loss: 43.84803771972656 | MAE Test Loss: 43.15006637573242 \n",
      "Epoch: 99760 | MAE Train Loss: 43.84789276123047 | MAE Test Loss: 43.15009689331055 \n",
      "Epoch: 99770 | MAE Train Loss: 43.847755432128906 | MAE Test Loss: 43.15012741088867 \n",
      "Epoch: 99780 | MAE Train Loss: 43.84761047363281 | MAE Test Loss: 43.15016174316406 \n",
      "Epoch: 99790 | MAE Train Loss: 43.847469329833984 | MAE Test Loss: 43.15019226074219 \n",
      "Epoch: 99800 | MAE Train Loss: 43.847328186035156 | MAE Test Loss: 43.15022277832031 \n",
      "Epoch: 99810 | MAE Train Loss: 43.84718704223633 | MAE Test Loss: 43.15024948120117 \n",
      "Epoch: 99820 | MAE Train Loss: 43.847042083740234 | MAE Test Loss: 43.1502799987793 \n",
      "Epoch: 99830 | MAE Train Loss: 43.84690475463867 | MAE Test Loss: 43.150394439697266 \n",
      "Epoch: 99840 | MAE Train Loss: 43.84675979614258 | MAE Test Loss: 43.1505012512207 \n",
      "Epoch: 99850 | MAE Train Loss: 43.846614837646484 | MAE Test Loss: 43.150535583496094 \n",
      "Epoch: 99860 | MAE Train Loss: 43.846473693847656 | MAE Test Loss: 43.15056228637695 \n",
      "Epoch: 99870 | MAE Train Loss: 43.84633255004883 | MAE Test Loss: 43.15058898925781 \n",
      "Epoch: 99880 | MAE Train Loss: 43.846187591552734 | MAE Test Loss: 43.15062713623047 \n",
      "Epoch: 99890 | MAE Train Loss: 43.84605026245117 | MAE Test Loss: 43.15065383911133 \n",
      "Epoch: 99900 | MAE Train Loss: 43.84590530395508 | MAE Test Loss: 43.15068817138672 \n",
      "Epoch: 99910 | MAE Train Loss: 43.84576416015625 | MAE Test Loss: 43.150718688964844 \n",
      "Epoch: 99920 | MAE Train Loss: 43.84562301635742 | MAE Test Loss: 43.1507453918457 \n",
      "Epoch: 99930 | MAE Train Loss: 43.84547805786133 | MAE Test Loss: 43.15077590942383 \n",
      "Epoch: 99940 | MAE Train Loss: 43.8453369140625 | MAE Test Loss: 43.15080642700195 \n",
      "Epoch: 99950 | MAE Train Loss: 43.84519577026367 | MAE Test Loss: 43.150840759277344 \n",
      "Epoch: 99960 | MAE Train Loss: 43.84505081176758 | MAE Test Loss: 43.15086364746094 \n",
      "Epoch: 99970 | MAE Train Loss: 43.84490966796875 | MAE Test Loss: 43.15089797973633 \n",
      "Epoch: 99980 | MAE Train Loss: 43.84476089477539 | MAE Test Loss: 43.15093231201172 \n",
      "Epoch: 99990 | MAE Train Loss: 43.84462356567383 | MAE Test Loss: 43.15095520019531 \n"
     ]
    }
   ],
   "source": [
    "epochs = 100000\n",
    "# Create empty loss lists to track values\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "torch.device(\"cuda:0\")\n",
    "for  epoch in range(epochs):\n",
    "\n",
    "    # model in training mode\n",
    "    linear_model.train()\n",
    "\n",
    "    # forward pass\n",
    "    y_pred = linear_model(X_train_tensor)\n",
    "\n",
    "    # loss calculation\n",
    "    loss = loss_fn(y_pred,y_train_tensor)\n",
    "\n",
    "    # Zero grad of the optimizer \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # Progress the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # real_time testing\n",
    "    linear_model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_pred = linear_model(X_test_tensor)\n",
    "\n",
    "        test_loss = loss_fn(test_pred,y_test_tensor)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy())\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce93d0f5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43dffd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2913.0291)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn2 = nn.MSELoss()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    \n",
    "    y_pred = linear_model(X_test_tensor)\n",
    "\n",
    "    loss = loss_fn2(y_pred, y_test_tensor)\n",
    "\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
